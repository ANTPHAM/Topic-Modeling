{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from tqdm._tqdm_notebook import tqdm_notebook,tnrange,tqdm\n",
    "from collections import Counter,OrderedDict\n",
    "from gensim import models,corpora\n",
    "from gensim.summarization import summarize,keywords\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_notebook.pandas('Progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>additional_info</th>\n",
       "      <td>['TECHNICAL SKILLS\\xa0', &lt;br/&gt;, '\\xa0', &lt;br/&gt;,...</td>\n",
       "      <td>['TECHNICAL SKILLS:\\xa0', &lt;br/&gt;, 'Languages   ...</td>\n",
       "      <td>['TECHNICAL SKILLS\\xa0', &lt;br/&gt;, '•   Proficien...</td>\n",
       "      <td>['TECHNICAL SKILLS\\xa0', &lt;br/&gt;, 'Relevant Cour...</td>\n",
       "      <td>['SKILLS\\xa0', &lt;br/&gt;, '\\xa0', &lt;br/&gt;, 'SOFTWARE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rb</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>Tracy-Ruan</td>\n",
       "      <td>Sai-Nadimpalli</td>\n",
       "      <td>Nick-Shi</td>\n",
       "      <td>Harsh-Mehta</td>\n",
       "      <td>Daniel-Wu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>c47f7ac095973653?sp=0</td>\n",
       "      <td>19e0d35744cc56a6?sp=0</td>\n",
       "      <td>accfd33784428f69?sp=0</td>\n",
       "      <td>2a4af24d87cca9cd?sp=0</td>\n",
       "      <td>246fa163d0b35d5b?sp=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary_title</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>Malibu, CA</td>\n",
       "      <td>Bloomington, IN</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_job_company</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['Sprint Corporation']</td>\n",
       "      <td>['MarketPsych Data']</td>\n",
       "      <td>['Indiana University']</td>\n",
       "      <td>['MAPSCorps']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_job_title</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_job_desc</th>\n",
       "      <td>['• Prepared customer behavior datasets for cl...</td>\n",
       "      <td>['• Developed a Hybrid Recommendation System f...</td>\n",
       "      <td>['•   Manipulated and interpreted insights fro...</td>\n",
       "      <td>['• Implemented probabilistic character recogn...</td>\n",
       "      <td>['Acted as a Chinese translator when collectin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_job_duration</th>\n",
       "      <td>August 2017 to November 2017</td>\n",
       "      <td>May 2017 to August 2017</td>\n",
       "      <td>February 2018 to Present</td>\n",
       "      <td>November 2017 to November 2017</td>\n",
       "      <td>July 2016 to August 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_job_company</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['IBM']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['University of Mumbai']</td>\n",
       "      <td>['NEUROLOGY CLINIC FRONT DESK']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_job_title</th>\n",
       "      <td>Web Designer Assistant</td>\n",
       "      <td>Software Development Engineer Intern</td>\n",
       "      <td>Technical Consultant</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Front Desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_job_desc</th>\n",
       "      <td>['•       Maintained university website (HTML ...</td>\n",
       "      <td>['• Developed Web and Android Applications for...</td>\n",
       "      <td>['•   Manipulated 12 year historical option da...</td>\n",
       "      <td>['• Performed analysis of supermarket data by ...</td>\n",
       "      <td>['• Translations from English to Chinese (Cant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_job_duration</th>\n",
       "      <td>September 2015 to January 2016</td>\n",
       "      <td>September 2015 to January 2016</td>\n",
       "      <td>January 2018 to Present</td>\n",
       "      <td>June 2017 to June 2017</td>\n",
       "      <td>May 2016 to July 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_exp_durations</th>\n",
       "      <td>['August 2017 to November 2017', 'September 20...</td>\n",
       "      <td>['May 2017 to August 2017', 'September 2015 to...</td>\n",
       "      <td>['February 2018 to Present', 'January 2018 to ...</td>\n",
       "      <td>['November 2017 to November 2017', 'June 2017 ...</td>\n",
       "      <td>['July 2016 to August 2016', 'May 2016 to July...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education1_title</th>\n",
       "      <td>B.S. in Data Science</td>\n",
       "      <td>Master of Science in Computer Science in Compu...</td>\n",
       "      <td>Master of Science in Applied Finance</td>\n",
       "      <td>Master's in Data Science</td>\n",
       "      <td>Engineering Computing and Problem Solving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education1_college</th>\n",
       "      <td>University of San Francisco</td>\n",
       "      <td>University of Missouri</td>\n",
       "      <td>Pepperdine University, Graziadio School of Bus...</td>\n",
       "      <td>Indiana University, School of Informatics</td>\n",
       "      <td>Baruch College Campus High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education1_duration</th>\n",
       "      <td>January 2013 to May 2017</td>\n",
       "      <td>May 2018</td>\n",
       "      <td>December 2017</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education2_title</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Master of Science in Computing</td>\n",
       "      <td>Bachelor's in Information Technology</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education2_college</th>\n",
       "      <td>NaN</td>\n",
       "      <td>K L University</td>\n",
       "      <td>Imperial College London</td>\n",
       "      <td>University of Mumbai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education2_duration</th>\n",
       "      <td>NaN</td>\n",
       "      <td>May 2016</td>\n",
       "      <td>October 2016</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education3_title</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science in Software Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education3_college</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The University of Nottingham, School of Comput...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education3_duration</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skils</th>\n",
       "      <td>[['JAVASCRIPT (Less than 1 year)'], ['PYTHON (...</td>\n",
       "      <td>[['C (Less than 1 year)'], ['CSS (Less than 1 ...</td>\n",
       "      <td>[['PYTHON (Less than 1 year)'], ['SQL (Less th...</td>\n",
       "      <td>[['APACHE HBASE (Less than 1 year)'], ['ARTIFI...</td>\n",
       "      <td>[['C++ (Less than 1 year)'], ['CREO (Less than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>links</th>\n",
       "      <td>['https://github.com/tracyruan007']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['http://www.linkedin.com/in/nick-shi']</td>\n",
       "      <td>['http://github.com/humehta/Projects.git', 'ht...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certifications</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awards</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['TSEC Hall of Fame', 'TSEC Deparment Ambassad...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_auth</th>\n",
       "      <td>Authorized to work in the US for any employer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sponsorship required to work in the US</td>\n",
       "      <td>Authorized to work in the US for any employer</td>\n",
       "      <td>Authorized to work in the US for any employer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_job_duration_months</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_job_duration_months</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_exp_durations_months</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_authp</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_job_desc_clean</th>\n",
       "      <td>['maintained', 'university', 'website', 'html'...</td>\n",
       "      <td>['developed', 'web', 'android', 'application',...</td>\n",
       "      <td>['manipulated', '12', 'year', 'historical', 'o...</td>\n",
       "      <td>['performed', 'analysis', 'supermarket', 'data...</td>\n",
       "      <td>['translation', 'english', 'chinese', 'cantone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_job_title_cats</th>\n",
       "      <td>Software Engg</td>\n",
       "      <td>Student</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             0  \\\n",
       "additional_info              ['TECHNICAL SKILLS\\xa0', <br/>, '\\xa0', <br/>,...   \n",
       "rb                                                                         NaN   \n",
       "name                                                                Tracy-Ruan   \n",
       "id                                                       c47f7ac095973653?sp=0   \n",
       "summary_title                                            Data Scientist Intern   \n",
       "location                                                     San Francisco, CA   \n",
       "current_job_company                                                        NaN   \n",
       "current_job_title                                        Data Scientist Intern   \n",
       "current_job_desc             ['• Prepared customer behavior datasets for cl...   \n",
       "current_job_duration                              August 2017 to November 2017   \n",
       "prev_job_company                                                           NaN   \n",
       "prev_job_title                                          Web Designer Assistant   \n",
       "prev_job_desc                ['•       Maintained university website (HTML ...   \n",
       "prev_job_duration                               September 2015 to January 2016   \n",
       "total_exp_durations          ['August 2017 to November 2017', 'September 20...   \n",
       "education1_title                                          B.S. in Data Science   \n",
       "education1_college                                 University of San Francisco   \n",
       "education1_duration                                   January 2013 to May 2017   \n",
       "education2_title                                                           NaN   \n",
       "education2_college                                                         NaN   \n",
       "education2_duration                                                        NaN   \n",
       "education3_title                                                           NaN   \n",
       "education3_college                                                         NaN   \n",
       "education3_duration                                                        NaN   \n",
       "skils                        [['JAVASCRIPT (Less than 1 year)'], ['PYTHON (...   \n",
       "links                                      ['https://github.com/tracyruan007']   \n",
       "certifications                                                              []   \n",
       "awards                                                                      []   \n",
       "work_auth                        Authorized to work in the US for any employer   \n",
       "current_job_duration_months                                                  3   \n",
       "prev_job_duration_months                                                     4   \n",
       "total_exp_durations_months                                                   8   \n",
       "work_authp                                                                   1   \n",
       "prev_job_desc_clean          ['maintained', 'university', 'website', 'html'...   \n",
       "prev_job_title_cats                                              Software Engg   \n",
       "\n",
       "                                                                             1  \\\n",
       "additional_info              ['TECHNICAL SKILLS:\\xa0', <br/>, 'Languages   ...   \n",
       "rb                                                                         NaN   \n",
       "name                                                            Sai-Nadimpalli   \n",
       "id                                                       19e0d35744cc56a6?sp=0   \n",
       "summary_title                                            Junior Data Scientist   \n",
       "location                                                       Kansas City, MO   \n",
       "current_job_company                                     ['Sprint Corporation']   \n",
       "current_job_title                                        Junior Data Scientist   \n",
       "current_job_desc             ['• Developed a Hybrid Recommendation System f...   \n",
       "current_job_duration                                   May 2017 to August 2017   \n",
       "prev_job_company                                                       ['IBM']   \n",
       "prev_job_title                            Software Development Engineer Intern   \n",
       "prev_job_desc                ['• Developed Web and Android Applications for...   \n",
       "prev_job_duration                               September 2015 to January 2016   \n",
       "total_exp_durations          ['May 2017 to August 2017', 'September 2015 to...   \n",
       "education1_title             Master of Science in Computer Science in Compu...   \n",
       "education1_college                                      University of Missouri   \n",
       "education1_duration                                                   May 2018   \n",
       "education2_title                                                    Technology   \n",
       "education2_college                                              K L University   \n",
       "education2_duration                                                   May 2016   \n",
       "education3_title                                                           NaN   \n",
       "education3_college                                                         NaN   \n",
       "education3_duration                                                        NaN   \n",
       "skils                        [['C (Less than 1 year)'], ['CSS (Less than 1 ...   \n",
       "links                                                                       []   \n",
       "certifications                                                              []   \n",
       "awards                                                                      []   \n",
       "work_auth                                                                  NaN   \n",
       "current_job_duration_months                                                  3   \n",
       "prev_job_duration_months                                                     4   \n",
       "total_exp_durations_months                                                   7   \n",
       "work_authp                                                                 NaN   \n",
       "prev_job_desc_clean          ['developed', 'web', 'android', 'application',...   \n",
       "prev_job_title_cats                                                    Student   \n",
       "\n",
       "                                                                             2  \\\n",
       "additional_info              ['TECHNICAL SKILLS\\xa0', <br/>, '•   Proficien...   \n",
       "rb                                                                         NaN   \n",
       "name                                                                  Nick-Shi   \n",
       "id                                                       accfd33784428f69?sp=0   \n",
       "summary_title                                            Data Scientist Intern   \n",
       "location                                                            Malibu, CA   \n",
       "current_job_company                                       ['MarketPsych Data']   \n",
       "current_job_title                                        Data Scientist Intern   \n",
       "current_job_desc             ['•   Manipulated and interpreted insights fro...   \n",
       "current_job_duration                                  February 2018 to Present   \n",
       "prev_job_company                                                           NaN   \n",
       "prev_job_title                                            Technical Consultant   \n",
       "prev_job_desc                ['•   Manipulated 12 year historical option da...   \n",
       "prev_job_duration                                      January 2018 to Present   \n",
       "total_exp_durations          ['February 2018 to Present', 'January 2018 to ...   \n",
       "education1_title                          Master of Science in Applied Finance   \n",
       "education1_college           Pepperdine University, Graziadio School of Bus...   \n",
       "education1_duration                                              December 2017   \n",
       "education2_title                                Master of Science in Computing   \n",
       "education2_college                                     Imperial College London   \n",
       "education2_duration                                               October 2016   \n",
       "education3_title                   Bachelor of Science in Software Engineering   \n",
       "education3_college           The University of Nottingham, School of Comput...   \n",
       "education3_duration                                                  July 2015   \n",
       "skils                        [['PYTHON (Less than 1 year)'], ['SQL (Less th...   \n",
       "links                                  ['http://www.linkedin.com/in/nick-shi']   \n",
       "certifications                                                              []   \n",
       "awards                                                                      []   \n",
       "work_auth                               Sponsorship required to work in the US   \n",
       "current_job_duration_months                                                  1   \n",
       "prev_job_duration_months                                                     2   \n",
       "total_exp_durations_months                                                  12   \n",
       "work_authp                                                                   0   \n",
       "prev_job_desc_clean          ['manipulated', '12', 'year', 'historical', 'o...   \n",
       "prev_job_title_cats                                            Project Manager   \n",
       "\n",
       "                                                                             3  \\\n",
       "additional_info              ['TECHNICAL SKILLS\\xa0', <br/>, 'Relevant Cour...   \n",
       "rb                                                                         NaN   \n",
       "name                                                               Harsh-Mehta   \n",
       "id                                                       2a4af24d87cca9cd?sp=0   \n",
       "summary_title                                                   Data Scientist   \n",
       "location                                                       Bloomington, IN   \n",
       "current_job_company                                     ['Indiana University']   \n",
       "current_job_title                                               Data Scientist   \n",
       "current_job_desc             ['• Implemented probabilistic character recogn...   \n",
       "current_job_duration                            November 2017 to November 2017   \n",
       "prev_job_company                                      ['University of Mumbai']   \n",
       "prev_job_title                                                    Data Analyst   \n",
       "prev_job_desc                ['• Performed analysis of supermarket data by ...   \n",
       "prev_job_duration                                       June 2017 to June 2017   \n",
       "total_exp_durations          ['November 2017 to November 2017', 'June 2017 ...   \n",
       "education1_title                                      Master's in Data Science   \n",
       "education1_college                   Indiana University, School of Informatics   \n",
       "education1_duration                                                   May 2019   \n",
       "education2_title                          Bachelor's in Information Technology   \n",
       "education2_college                                        University of Mumbai   \n",
       "education2_duration                                                  June 2017   \n",
       "education3_title                                                           NaN   \n",
       "education3_college                                                         NaN   \n",
       "education3_duration                                                        NaN   \n",
       "skils                        [['APACHE HBASE (Less than 1 year)'], ['ARTIFI...   \n",
       "links                        ['http://github.com/humehta/Projects.git', 'ht...   \n",
       "certifications                                                              []   \n",
       "awards                       ['TSEC Hall of Fame', 'TSEC Deparment Ambassad...   \n",
       "work_auth                        Authorized to work in the US for any employer   \n",
       "current_job_duration_months                                                  0   \n",
       "prev_job_duration_months                                                     0   \n",
       "total_exp_durations_months                                                   1   \n",
       "work_authp                                                                   1   \n",
       "prev_job_desc_clean          ['performed', 'analysis', 'supermarket', 'data...   \n",
       "prev_job_title_cats                                               Data Analyst   \n",
       "\n",
       "                                                                             4  \n",
       "additional_info              ['SKILLS\\xa0', <br/>, '\\xa0', <br/>, 'SOFTWARE...  \n",
       "rb                                                                         NaN  \n",
       "name                                                                 Daniel-Wu  \n",
       "id                                                       246fa163d0b35d5b?sp=0  \n",
       "summary_title                                                   DATA SCIENTIST  \n",
       "location                                                          Brooklyn, NY  \n",
       "current_job_company                                              ['MAPSCorps']  \n",
       "current_job_title                                               DATA SCIENTIST  \n",
       "current_job_desc             ['Acted as a Chinese translator when collectin...  \n",
       "current_job_duration                                  July 2016 to August 2016  \n",
       "prev_job_company                               ['NEUROLOGY CLINIC FRONT DESK']  \n",
       "prev_job_title                                                      Front Desk  \n",
       "prev_job_desc                ['• Translations from English to Chinese (Cant...  \n",
       "prev_job_duration                                        May 2016 to July 2016  \n",
       "total_exp_durations          ['July 2016 to August 2016', 'May 2016 to July...  \n",
       "education1_title                     Engineering Computing and Problem Solving  \n",
       "education1_college                           Baruch College Campus High School  \n",
       "education1_duration                                                        NaN  \n",
       "education2_title                                                           NaN  \n",
       "education2_college                                                         NaN  \n",
       "education2_duration                                                        NaN  \n",
       "education3_title                                                           NaN  \n",
       "education3_college                                                         NaN  \n",
       "education3_duration                                                        NaN  \n",
       "skils                        [['C++ (Less than 1 year)'], ['CREO (Less than...  \n",
       "links                                                                       []  \n",
       "certifications                                                              []  \n",
       "awards                                                                      []  \n",
       "work_auth                        Authorized to work in the US for any employer  \n",
       "current_job_duration_months                                                  1  \n",
       "prev_job_duration_months                                                     2  \n",
       "total_exp_durations_months                                                   4  \n",
       "work_authp                                                                   1  \n",
       "prev_job_desc_clean          ['translation', 'english', 'chinese', 'cantone...  \n",
       "prev_job_title_cats                                                     Others  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data_clean_1.csv')\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "skills = data.text_data.fillna(\"\")\n",
    "nlp = spacy.load('en')\n",
    "def clean_up_spacy(text):\n",
    "    text_out = set()\n",
    "    clean = re.sub(\"\\s\\s+\",',',text)\n",
    "    clean =re.sub(\"'|•|<br/>\",\"\",clean)\n",
    "    clean =re.sub(r'\\w*(?=\\\\|:)','',clean)\n",
    "    text = re.sub(\"xa0|\\\\\\\\|:\",',',clean)\n",
    "    text = re.sub(\"(?<=\\w)\\s(?=\\w+\\,)\",'_',text)\n",
    "    text = re.sub(\"(?<=\\w)\\s(?=\\w+)\",'',text)\n",
    "    text = re.sub(r\"\\[|]\",' ',text)\n",
    "    text = ' '.join(text.split(','))\n",
    "\n",
    "    removal1= ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','VERB','ADJ','SYM','NOUN','X','NUM','SPACE']\n",
    "    doc= nlp(text)\n",
    "    for token in doc:\n",
    "        \n",
    "        if token.string == token.string.upper() and len(token)<15 and token.is_punct is False and token.is_alpha: \n",
    "            lemma = token.lemma_.strip() \n",
    "            text_out.add(lemma)            \n",
    "        if  token.pos_ not in removal1 and len(token)<15 and token.is_punct is False :\n",
    "            lemma = token.lemma_.strip()\n",
    "            if lemma != '':\n",
    "                text_out.add(lemma)\n",
    "    text_out = list(text_out)\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3278096706924100887c2ef33cf8fa36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12537), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skillList = skills.progress_apply(lambda x:clean_up_spacy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 3845),\n",
       " ('r', 3615),\n",
       " ('sql', 3545),\n",
       " ('java', 2041),\n",
       " ('technical', 2030),\n",
       " ('c++', 1850),\n",
       " ('tableau', 1751),\n",
       " ('c', 1747),\n",
       " ('sas', 1685),\n",
       " ('matlab', 1613),\n",
       " ('hadoop', 1468),\n",
       " ('mysql', 1303),\n",
       " ('html', 1229),\n",
       " ('excel', 1219),\n",
       " ('linux', 1172),\n",
       " ('hive', 1149),\n",
       " ('javascript', 1123),\n",
       " ('spark', 1039),\n",
       " ('programming', 929),\n",
       " ('oracle', 922),\n",
       " ('data', 848),\n",
       " ('unix', 826),\n",
       " ('windows', 767),\n",
       " ('pandas', 762),\n",
       " ('spss', 759),\n",
       " ('css', 724),\n",
       " ('pig', 700),\n",
       " ('git', 661),\n",
       " ('numpy', 617),\n",
       " ('aws', 612),\n",
       " ('mongodb', 585),\n",
       " ('powerpoint', 581),\n",
       " ('xml', 567),\n",
       " ('word', 533),\n",
       " ('mapreduce', 521),\n",
       " ('statistical', 503),\n",
       " ('computer', 498),\n",
       " ('scikit', 498),\n",
       " ('ms', 476),\n",
       " ('access', 471),\n",
       " ('skills', 468),\n",
       " ('scala', 442),\n",
       " ('php', 434),\n",
       " ('tensorflow', 427),\n",
       " ('hdfs', 422),\n",
       " ('eclipse', 421),\n",
       " ('pl', 410),\n",
       " ('svm', 406),\n",
       " ('vba', 397),\n",
       " ('scipy', 391),\n",
       " ('clustering', 389),\n",
       " ('hbase', 386),\n",
       " ('regression', 369),\n",
       " ('bigdata', 365),\n",
       " ('perl', 360),\n",
       " ('teradata', 357),\n",
       " ('k', 355),\n",
       " ('nosql', 352),\n",
       " ('sql_server', 349),\n",
       " ('learn', 329),\n",
       " ('project', 329),\n",
       " ('matplotlib', 326),\n",
       " ('postgresql', 323),\n",
       " ('etl', 321),\n",
       " ('database', 319),\n",
       " ('software', 317),\n",
       " ('machine', 316),\n",
       " ('sqoop', 308),\n",
       " ('weka', 306),\n",
       " ('stata', 305),\n",
       " ('visio', 292),\n",
       " ('ssis', 289),\n",
       " ('microsoft', 286),\n",
       " ('jira', 286),\n",
       " ('jquery', 282),\n",
       " ('classification', 281),\n",
       " ('github', 277),\n",
       " ('keras', 272),\n",
       " ('nlp', 269),\n",
       " ('core', 262),\n",
       " ('operating', 261),\n",
       " ('ssrs', 261),\n",
       " ('db2', 260),\n",
       " ('pca', 260),\n",
       " ('ms_access', 258),\n",
       " ('cassandra', 253),\n",
       " ('agile', 247),\n",
       " ('nltk', 245),\n",
       " ('statistics', 237),\n",
       " ('databases', 232),\n",
       " ('languages', 228),\n",
       " ('a', 228),\n",
       " ('rstudio', 226),\n",
       " ('minitab', 226),\n",
       " ('t', 215),\n",
       " ('bi', 215),\n",
       " ('html5', 215),\n",
       " ('business', 213),\n",
       " ('tools', 212),\n",
       " ('qlikview', 206),\n",
       " ('ms_excel', 205),\n",
       " ('latex', 203),\n",
       " ('json', 196),\n",
       " ('ubuntu', 193),\n",
       " ('jsp', 189),\n",
       " ('flume', 189),\n",
       " ('jmp', 187),\n",
       " ('kafka', 184),\n",
       " ('apache', 181),\n",
       " ('bash', 178),\n",
       " ('d3.js', 177),\n",
       " ('analysis', 177),\n",
       " ('skill', 176),\n",
       " ('toad', 176),\n",
       " ('sharepoint', 175),\n",
       " ('ajax', 170),\n",
       " ('msoffice', 169),\n",
       " ('visualization', 167),\n",
       " ('knn', 167),\n",
       " ('areasof', 166),\n",
       " ('datascience', 162),\n",
       " ('linear', 157),\n",
       " ('anova', 157),\n",
       " ('ms_office', 157),\n",
       " ('cloud', 156),\n",
       " ('s3', 152),\n",
       " ('mathematica', 151),\n",
       " ('pyspark', 150),\n",
       " ('visual_studio', 150),\n",
       " ('outlook', 149),\n",
       " ('analytics', 149),\n",
       " ('svn', 149),\n",
       " ('seaborn', 148),\n",
       " ('ec2', 148),\n",
       " ('fortran', 148),\n",
       " ('professional', 147),\n",
       " ('shiny', 146),\n",
       " ('informatica', 144),\n",
       " ('ssas', 144),\n",
       " ('oozie', 143),\n",
       " ('mac', 140),\n",
       " ('key', 136),\n",
       " ('octave', 136),\n",
       " ('scrum', 136),\n",
       " ('research', 135),\n",
       " ('development', 135),\n",
       " ('naïve_bayes', 133),\n",
       " ('impala', 133),\n",
       " ('sap', 130),\n",
       " ('jupyter', 129),\n",
       " ('ruby', 129),\n",
       " ('mssql_server', 129),\n",
       " ('r_studio', 127),\n",
       " ('uml', 127),\n",
       " ('relevant', 125),\n",
       " ('flask', 124),\n",
       " ('spring', 123),\n",
       " ('bootstrap', 122),\n",
       " ('j2ee', 122),\n",
       " ('docker', 121),\n",
       " ('skillsand', 121),\n",
       " ('big', 120),\n",
       " ('salesforce', 120),\n",
       " ('erwin', 119),\n",
       " ('ms_project', 119),\n",
       " ('django', 116),\n",
       " ('azure', 116),\n",
       " ('ms_visio', 116),\n",
       " ('visual_basic', 116),\n",
       " ('design', 114),\n",
       " ('d3', 113),\n",
       " ('cognos', 111),\n",
       " ('english', 110),\n",
       " ('predictive', 110),\n",
       " ('sqlite', 109),\n",
       " ('shell', 109),\n",
       " ('redshift', 107),\n",
       " ('studio', 107),\n",
       " ('google', 106),\n",
       " ('office', 106),\n",
       " ('soap', 105),\n",
       " ('datamining', 103),\n",
       " ('jdbc', 103),\n",
       " ('photoshop', 103),\n",
       " ('analytical', 102),\n",
       " ('java_script', 101),\n",
       " ('maven', 100),\n",
       " ('optimization', 100),\n",
       " ('sybase', 100),\n",
       " ('netbeans', 99),\n",
       " ('dataanalysis', 99),\n",
       " ('time', 99),\n",
       " ('asp', 98),\n",
       " ('sdlc', 98),\n",
       " ('scripting', 97),\n",
       " ('ms_word', 96),\n",
       " ('alteryx', 96),\n",
       " ('means', 95),\n",
       " ('postgres', 95),\n",
       " ('elasticsearch', 93),\n",
       " ('theano', 92),\n",
       " ('zookeeper', 92),\n",
       " ('management', 91),\n",
       " ('multi', 91),\n",
       " ('android', 90),\n",
       " ('mahout', 90),\n",
       " ('neo4j', 89),\n",
       " ('hibernate', 89),\n",
       " ('ibm', 88),\n",
       " ('obiee', 88),\n",
       " ('stat', 88),\n",
       " ('modeling', 87),\n",
       " ('|', 87),\n",
       " ('vb', 87),\n",
       " ('leadership', 87),\n",
       " ('jenkins', 87),\n",
       " ('node.js', 86),\n",
       " ('mllib', 86),\n",
       " ('lda', 86),\n",
       " ('autocad', 86),\n",
       " ('e', 86),\n",
       " ('emr', 85),\n",
       " ('rdbms', 85),\n",
       " ('rest', 85),\n",
       " ('css3', 85),\n",
       " ('cloudera', 84),\n",
       " ('netezza', 84),\n",
       " ('spotfire', 83),\n",
       " ('xp', 82),\n",
       " ('logistic', 82),\n",
       " ('microstrategy', 82),\n",
       " ('naive_bayes', 81),\n",
       " ('pycharm', 81),\n",
       " ('arcgis', 81),\n",
       " ('cobol', 81),\n",
       " ('map', 80),\n",
       " ('servlets', 80),\n",
       " ('tomcat', 80),\n",
       " ('h2o', 79),\n",
       " ('tcp', 79),\n",
       " ('ip', 79),\n",
       " ('random_forest', 77),\n",
       " ('boosting', 77),\n",
       " ('waterfall', 77),\n",
       " ('mssql', 77),\n",
       " ('server', 76),\n",
       " ('testing', 76),\n",
       " ('rup', 75),\n",
       " ('base', 74),\n",
       " ('solaris', 74),\n",
       " ('arima', 73),\n",
       " ('yarn', 73),\n",
       " ('macos', 72),\n",
       " ('g', 72),\n",
       " ('technology', 72),\n",
       " ('application', 72),\n",
       " ('visualstudio', 71),\n",
       " ('cnn', 69),\n",
       " ('decision_tree', 69),\n",
       " ('gephi', 69),\n",
       " ('rapidminer', 69),\n",
       " ('web', 68),\n",
       " ('bayesian', 68),\n",
       " ('linear_algebra', 68),\n",
       " ('basic', 68),\n",
       " ('xgboost', 67),\n",
       " ('sqlserver', 67),\n",
       " ('algorithms', 67),\n",
       " ('mssqlserver', 67),\n",
       " ('map_reduce', 67),\n",
       " ('cvs', 67),\n",
       " ('adobe', 66),\n",
       " ('hp', 66),\n",
       " ('splunk', 66),\n",
       " ('co', 66),\n",
       " ('team', 66),\n",
       " ('macro', 66),\n",
       " ('anaconda', 65),\n",
       " ('soa', 65),\n",
       " ('dhtml', 65),\n",
       " ('deep', 64),\n",
       " ('proficient', 64),\n",
       " ('junit', 64),\n",
       " ('datamodeling', 63),\n",
       " ('macros', 63),\n",
       " ('advanced', 62),\n",
       " ('os', 62),\n",
       " ('xslt', 62),\n",
       " ('probability', 61),\n",
       " ('centos', 61),\n",
       " ('academic', 61),\n",
       " ('coursera', 61),\n",
       " ('gensim', 61),\n",
       " ('confluence', 61),\n",
       " ('financial', 61),\n",
       " ('redis', 61),\n",
       " ('gis', 61),\n",
       " ('non', 61),\n",
       " ('tfs', 61),\n",
       " ('may', 60),\n",
       " ('vista', 60),\n",
       " ('pentaho', 60),\n",
       " ('solr', 60),\n",
       " ('graph', 60),\n",
       " ('powerbi', 59),\n",
       " ('maple', 59),\n",
       " ('mac_os', 59),\n",
       " ('cplex', 59),\n",
       " ('communication', 59),\n",
       " ('mvc', 59),\n",
       " ('vb.net', 59),\n",
       " ('rad', 59),\n",
       " ('decision_trees', 58),\n",
       " ('version', 58),\n",
       " ('cross', 58),\n",
       " ('language', 58),\n",
       " ('crm', 58),\n",
       " ('selenium', 57),\n",
       " ('msexcel', 57),\n",
       " ('wordpress', 57),\n",
       " ('pascal', 57),\n",
       " ('ant', 57),\n",
       " ('lasso', 56),\n",
       " ('r.', 56),\n",
       " ('learning', 56),\n",
       " ('glm', 56),\n",
       " ('it', 56),\n",
       " ('aix', 56),\n",
       " ('beautifulsoup', 55),\n",
       " ('reduce', 55),\n",
       " ('redhat', 55),\n",
       " ('bloomberg', 54),\n",
       " ('deeplearning', 54),\n",
       " ('power', 54),\n",
       " ('struts', 54),\n",
       " ('b', 53),\n",
       " ('nn', 53),\n",
       " ('cart', 53),\n",
       " ('self', 53),\n",
       " ('er', 53),\n",
       " ('iis', 53),\n",
       " ('ipython', 52),\n",
       " ('olap', 52),\n",
       " ('dreamweaver', 52),\n",
       " ('vmware', 52),\n",
       " ('mpi', 51),\n",
       " ('microsoftexcel', 51),\n",
       " ('apache_hadoop', 51),\n",
       " ('caret', 51),\n",
       " ('msoffice_suite', 51),\n",
       " ('rnn', 50),\n",
       " ('deep_learning', 50),\n",
       " ('finance', 50),\n",
       " ('datascientist', 50),\n",
       " ('illustrator', 50),\n",
       " ('talend', 50),\n",
       " ('dos', 50),\n",
       " ('strategic', 50),\n",
       " ('s', 50),\n",
       " ('mathematical', 49),\n",
       " ('ml', 49),\n",
       " ('text', 49),\n",
       " ('quantitative', 49),\n",
       " ('ux', 49),\n",
       " ('sklearn', 48),\n",
       " ('random', 48),\n",
       " ('msaccess', 48),\n",
       " ('selected', 48),\n",
       " ('sql_developer', 48),\n",
       " ('pl/', 48),\n",
       " ('powershell', 47),\n",
       " ('frameworks', 47),\n",
       " ('visualbasic', 47),\n",
       " ('proficientin_r', 47),\n",
       " ('spyder', 47),\n",
       " ('process', 47),\n",
       " ('lisp', 47),\n",
       " ('my_sql', 47),\n",
       " ('angularjs', 46),\n",
       " ('qgis', 46),\n",
       " ('spss_modeler', 46),\n",
       " ('intermediate', 46),\n",
       " ('base_sas', 46),\n",
       " ('peoplesoft', 46),\n",
       " ('m', 46),\n",
       " ('systems', 46),\n",
       " ('ms_powerpoint', 45),\n",
       " ('http', 45),\n",
       " ('neural', 45),\n",
       " ('knime', 45),\n",
       " ('jad', 45),\n",
       " ('ide', 45),\n",
       " ('jcl', 45),\n",
       " ('visual', 44),\n",
       " ('ridge', 44),\n",
       " ('putty', 44),\n",
       " ('bagging', 44),\n",
       " ('program', 44),\n",
       " ('engineering', 44),\n",
       " ('weblogic', 44),\n",
       " ('caffe', 43),\n",
       " ('technologies', 43),\n",
       " ('product', 43),\n",
       " ('microsoft_word', 43),\n",
       " ('hortonworks', 43),\n",
       " ('jboss', 43),\n",
       " ('mongo_db', 43),\n",
       " ('vbscript', 43),\n",
       " ('wsdl', 43),\n",
       " ('ms_sql', 43),\n",
       " ('macos_x', 42),\n",
       " ('eviews', 42),\n",
       " ('bokeh', 42),\n",
       " ('hue', 42),\n",
       " ('ggplot2', 42),\n",
       " ('dynamodb', 41),\n",
       " ('randomforest', 41),\n",
       " ('xhtml', 41),\n",
       " ('marketing', 41),\n",
       " ('vertica', 41),\n",
       " ('jms', 41),\n",
       " ('vim', 40),\n",
       " ('india', 40),\n",
       " ('timeseries', 40),\n",
       " ('plotly', 40),\n",
       " ('network', 40),\n",
       " ('dec', 40),\n",
       " ('node', 40),\n",
       " ('simulation', 40),\n",
       " ('unixshell', 40),\n",
       " ('ejb', 40),\n",
       " ('familiar', 39),\n",
       " ('objective', 39),\n",
       " ('crystal', 39),\n",
       " ('additional', 39),\n",
       " ('js', 39),\n",
       " ('toolsand', 39),\n",
       " ('healthcare', 39),\n",
       " ('lucene', 39),\n",
       " ('linkedin', 39),\n",
       " ('nodejs', 38),\n",
       " ('sparksql', 38),\n",
       " ('ca', 38),\n",
       " ('k-', 38),\n",
       " ('processing', 38),\n",
       " ('other', 38),\n",
       " ('model', 38),\n",
       " ('rds', 38),\n",
       " ('summaryof', 38),\n",
       " ('data_scientist', 38),\n",
       " ('react', 38),\n",
       " ('decision', 38),\n",
       " ('client', 38),\n",
       " ('etl_tools', 38),\n",
       " ('apachespark', 37),\n",
       " ('julia', 37),\n",
       " ('cuda', 37),\n",
       " ('statsmodels', 37),\n",
       " ('packages', 37),\n",
       " ('supervised', 37),\n",
       " ('control', 37),\n",
       " ('oracle_11', 37),\n",
       " ('qa', 37),\n",
       " ('labview', 37),\n",
       " ('twitter', 37),\n",
       " ('swift', 36),\n",
       " ('assembly', 36),\n",
       " ('r_shiny', 36),\n",
       " ('solidworks', 36),\n",
       " ('data_analysis', 36),\n",
       " ('functional', 36),\n",
       " ('presentation', 36),\n",
       " ('m.', 36),\n",
       " ('hands', 36),\n",
       " ('taleo', 36),\n",
       " ('websphere', 36),\n",
       " ('mandarin', 35),\n",
       " ('system', 35),\n",
       " ('libraries', 35),\n",
       " ('dts', 35),\n",
       " ('ibm_db2', 35),\n",
       " ('j.', 35),\n",
       " ('mathematics', 34),\n",
       " ('arena', 34),\n",
       " ('dataanalytics', 34),\n",
       " ('operations', 34),\n",
       " ('d.', 34),\n",
       " ('macosx', 34),\n",
       " ('markdown', 34),\n",
       " ('ampl', 34),\n",
       " ('ods', 34),\n",
       " ('adaboost', 33),\n",
       " ('xcode', 33),\n",
       " ('wireshark', 33),\n",
       " ('french', 33),\n",
       " ('erp', 33),\n",
       " ('simulink', 33),\n",
       " ('mdm', 33),\n",
       " ('ambari', 33),\n",
       " ('net', 33),\n",
       " ('spanish', 33),\n",
       " ('miner', 33),\n",
       " ('relational', 33),\n",
       " ('chaid', 33),\n",
       " ('retail', 33),\n",
       " ('econometrics', 32),\n",
       " ('amazon', 32),\n",
       " ('validation', 32),\n",
       " ('gams', 32),\n",
       " ('scikit-', 32),\n",
       " ('lambda', 32),\n",
       " ('mongo', 32),\n",
       " ('➢', 32),\n",
       " ('ai', 32),\n",
       " ('facebook', 32),\n",
       " ('training', 32),\n",
       " ('sem', 32),\n",
       " ('linq', 32),\n",
       " ('domain', 32),\n",
       " ('ssh', 32),\n",
       " ('wcf', 32),\n",
       " ('general', 32),\n",
       " ('s.', 32),\n",
       " ('itil', 32),\n",
       " ('jsf', 32),\n",
       " ('mvs', 32),\n",
       " ('c.', 31),\n",
       " ('pytorch', 31),\n",
       " ('neuralnetworks', 31),\n",
       " ('object', 31),\n",
       " ('clearcase', 31),\n",
       " ('scrapy', 31),\n",
       " ('osx', 31),\n",
       " ('hierarchical', 31),\n",
       " ('quickbooks', 31),\n",
       " ('greenplum', 31),\n",
       " ('methodologies', 31),\n",
       " ('ftp', 31),\n",
       " ('plus', 31),\n",
       " ('august', 30),\n",
       " ('z', 30),\n",
       " ('lstm', 30),\n",
       " ('vlookup', 30),\n",
       " ('eda', 30),\n",
       " ('trello', 30),\n",
       " ('june', 30),\n",
       " ('o', 30),\n",
       " ('chi', 30),\n",
       " ('customer', 30),\n",
       " ('oop', 30),\n",
       " ('x', 30),\n",
       " ('socialmedia', 30),\n",
       " ('autosys', 30),\n",
       " ('macintosh_hd', 30),\n",
       " ('devops', 30),\n",
       " ('strategy', 30),\n",
       " ('banking', 30),\n",
       " ('vss', 30),\n",
       " ('nt', 30),\n",
       " ('cad', 29),\n",
       " ('programming/', 29),\n",
       " ('textmining', 29),\n",
       " ('bitbucket', 29),\n",
       " ('neural_network', 29),\n",
       " ('windows_xp', 29),\n",
       " ('ssms', 29),\n",
       " ('flash', 29),\n",
       " ('mdx', 29),\n",
       " ('languages/', 29),\n",
       " ('hql', 29),\n",
       " ('software/', 29),\n",
       " ('seo', 29),\n",
       " ('vb_script', 29),\n",
       " ('platforms', 29),\n",
       " ('mobile', 29),\n",
       " ('datawarehouse', 29),\n",
       " ('android_studio', 28),\n",
       " ('msofficesuite', 28),\n",
       " ('teaching', 28),\n",
       " ('random_forests', 28),\n",
       " ('oracle_sql', 28),\n",
       " ('decisiontrees', 28),\n",
       " ('svd', 28),\n",
       " ('versioncontrol', 28),\n",
       " ('kibana', 28),\n",
       " ('asp.net', 28),\n",
       " ('online', 28),\n",
       " ('hiveql', 28),\n",
       " ('sasenterprise', 28),\n",
       " ('segmentation', 28),\n",
       " ('angular', 28),\n",
       " ('indesign', 28),\n",
       " ('datastage', 28),\n",
       " ('oraclepl', 28),\n",
       " ('idl', 28),\n",
       " ('sales', 28),\n",
       " ('cics', 28),\n",
       " ('multivariate', 27),\n",
       " ('volunteer', 27),\n",
       " ('ms-', 27),\n",
       " ('microsoftsql', 27),\n",
       " ('amazon_aws', 27),\n",
       " ('information', 27),\n",
       " ('reporting', 27),\n",
       " ('april', 27),\n",
       " ('subversion', 27),\n",
       " ('ii', 27),\n",
       " ('awk', 27),\n",
       " ('ansible', 27),\n",
       " ('omniture', 27),\n",
       " ('architecture', 27),\n",
       " ('kanban', 27),\n",
       " ('hyperion', 27),\n",
       " ('iml', 27),\n",
       " ('sql*plus', 27),\n",
       " ('july', 26),\n",
       " ('gbm', 26),\n",
       " ('b_testing', 26),\n",
       " ('spark_mllib', 26),\n",
       " ('verilog', 26),\n",
       " ('personal', 26),\n",
       " ('-PRON-', 26),\n",
       " ('u.s.', 26),\n",
       " ('sublime', 26),\n",
       " ('sparkr', 26),\n",
       " ('analytic', 26),\n",
       " ('t-', 26),\n",
       " ('intellij', 26),\n",
       " ('plsql', 26),\n",
       " ('big_data', 26),\n",
       " ('xsl', 26),\n",
       " ('r-', 26),\n",
       " ('db', 26),\n",
       " ('mainframe', 26),\n",
       " ('bids', 26),\n",
       " ('ets', 26),\n",
       " ('hadoop2.x', 26),\n",
       " ('star', 26),\n",
       " ('trees', 25),\n",
       " ('vhdl', 25),\n",
       " ('unix_shell', 25),\n",
       " ('march', 25),\n",
       " ('windows_7', 25),\n",
       " ('inc.', 25),\n",
       " ('nov', 25),\n",
       " ('doe', 25),\n",
       " ('problem', 25),\n",
       " ('query', 25),\n",
       " ('drupal', 25),\n",
       " ('test', 25),\n",
       " ('applications', 25),\n",
       " ('activities', 25),\n",
       " ('storm', 25),\n",
       " ('powerpoint/', 25),\n",
       " ('expertise', 25),\n",
       " ('qc', 25),\n",
       " ('bteq', 25),\n",
       " ('powerpivot', 25),\n",
       " ('dns', 25),\n",
       " ('odbc', 25),\n",
       " ('jobvite', 25),\n",
       " ('tools/', 24),\n",
       " ('rubyon_rails', 24),\n",
       " ('projects', 24),\n",
       " ('azure_ml', 24),\n",
       " ('amazon_ec2', 24),\n",
       " ('spark_sql', 24),\n",
       " ('rand', 24),\n",
       " ('apache_kafka', 24),\n",
       " ('apachehadoop', 24),\n",
       " ('msproject', 24),\n",
       " ('technicalskill', 24),\n",
       " ('automation', 24),\n",
       " ('beginner', 24),\n",
       " ('xpath', 24),\n",
       " ('googlecloud', 24),\n",
       " ('association', 24),\n",
       " ('✓', 24),\n",
       " ('rally', 24),\n",
       " ('◦', 24),\n",
       " ('sunsolaris', 24),\n",
       " ('networking', 24),\n",
       " ('ansys', 23),\n",
       " ('apache_tomcat', 23),\n",
       " ('native', 23),\n",
       " ('pc', 23),\n",
       " ('heroku', 23),\n",
       " ('experience', 23),\n",
       " ('api', 23),\n",
       " ('btesting', 23),\n",
       " ('work', 23),\n",
       " ('datamanagement', 23),\n",
       " ('pp', 23),\n",
       " ('web_services', 23),\n",
       " ('qlik', 23),\n",
       " ('lean', 23),\n",
       " ('math', 23),\n",
       " ('slack', 23),\n",
       " ('usa', 23),\n",
       " ('publisher', 23),\n",
       " ('prolog', 23),\n",
       " ('montecarlo', 23),\n",
       " ('swing', 23),\n",
       " ('rshiny', 23),\n",
       " ('networkx', 23),\n",
       " ('debian', 23),\n",
       " ('operation', 23),\n",
       " ('dashboards', 23),\n",
       " ('regularization', 23),\n",
       " ('erwinr9.6', 23),\n",
       " ('remedy', 23),\n",
       " ('wpf', 23),\n",
       " ('pvcs', 23),\n",
       " ('cms', 23),\n",
       " ('statistica', 23),\n",
       " ('vsam', 23),\n",
       " ('orazuredata', 23),\n",
       " ('informix', 23),\n",
       " ('servlet', 22),\n",
       " ('python(numpy', 22),\n",
       " ('scientific', 22),\n",
       " ('express', 22),\n",
       " ('sqland', 22),\n",
       " ('security', 22),\n",
       " ('arduino', 22),\n",
       " ('angular_js', 22),\n",
       " ('mapr', 22),\n",
       " ('monte', 22),\n",
       " ('sci', 22),\n",
       " ('november', 22),\n",
       " ('iot', 22),\n",
       " ('image', 22),\n",
       " ('udp', 22),\n",
       " ('apr', 22),\n",
       " ('report', 22),\n",
       " ('member', 22),\n",
       " ('planning', 22),\n",
       " ('ibm_cognos', 22),\n",
       " ('ms_sharepoint', 22),\n",
       " ('supportvector', 22),\n",
       " ('scheduling', 22),\n",
       " ('jpa', 22),\n",
       " ('high', 22),\n",
       " ('framework', 22),\n",
       " ('b.', 22),\n",
       " ('ado.net', 22),\n",
       " ('oltp', 22),\n",
       " ('sparql', 22),\n",
       " ('tsql', 22),\n",
       " ('joomla', 22),\n",
       " ('ats', 22),\n",
       " ('tso', 22),\n",
       " ('highlightsof', 22),\n",
       " ('forest', 21),\n",
       " ('aws_ec2', 21),\n",
       " ('rmarkdown', 21),\n",
       " ('go', 21),\n",
       " ('cluster', 21),\n",
       " ('jan', 21),\n",
       " ('public', 21),\n",
       " ('file', 21),\n",
       " ('performance', 21),\n",
       " ('os_x', 21),\n",
       " ('tx', 21),\n",
       " ('p', 21),\n",
       " ('fluent', 21),\n",
       " ('html_5', 21),\n",
       " ('em', 21),\n",
       " ('feature', 21),\n",
       " ('postgis', 21),\n",
       " ('xquery', 21),\n",
       " ('shell_script', 21),\n",
       " ('workflow', 21),\n",
       " ('networks', 21),\n",
       " ('unix/', 21),\n",
       " ('tdd', 21),\n",
       " ('hr', 21),\n",
       " ('dax', 21),\n",
       " ('rmi', 21),\n",
       " ('expert', 21),\n",
       " ('import', 21),\n",
       " ('paas', 21),\n",
       " ('ispf', 21),\n",
       " ('ims', 21),\n",
       " ('ann', 20),\n",
       " ('ols', 20),\n",
       " ('regex', 20),\n",
       " ('fedora', 20),\n",
       " ('consulting', 20),\n",
       " ('chicago', 20),\n",
       " ('calculus', 20),\n",
       " ('hypothesis', 20),\n",
       " ('december', 20),\n",
       " ('google_cloud', 20),\n",
       " ('kaggle', 20),\n",
       " ('digital', 20),\n",
       " ('qliksense', 20),\n",
       " ('oct', 20),\n",
       " ('oracle_9i', 20),\n",
       " ('knowledge', 20),\n",
       " ('dice', 20),\n",
       " ('gurobi', 20),\n",
       " ('®', 20),\n",
       " ('word2vec', 20),\n",
       " ('sqlserver_2008', 20),\n",
       " ('distributed', 20),\n",
       " ('president', 20),\n",
       " ('v', 20),\n",
       " ('eg', 20),\n",
       " ('ma', 20),\n",
       " ('content', 20),\n",
       " ('p.', 20),\n",
       " ('ppt', 20),\n",
       " ('tibco', 20),\n",
       " ('market', 20),\n",
       " ('owl', 20),\n",
       " ('insurance', 20),\n",
       " ('tree', 19),\n",
       " ('vi', 19),\n",
       " ('salesforce.com', 19),\n",
       " ('graphx', 19),\n",
       " ('qualifications', 19),\n",
       " ('spring_mvc', 19),\n",
       " ('independent', 19),\n",
       " ('chinese', 19),\n",
       " ('risk', 19),\n",
       " ('stanford', 19),\n",
       " ('zeppelin', 19),\n",
       " ('ensemble', 19),\n",
       " ('october', 19),\n",
       " ('administration', 19),\n",
       " ('orange', 19),\n",
       " ('service', 19),\n",
       " ('idf', 19),\n",
       " ('services', 19),\n",
       " ('correlation', 19),\n",
       " ('tcl', 19),\n",
       " ('root', 19),\n",
       " ('graphlab', 19),\n",
       " ('social', 19),\n",
       " ('mining', 19),\n",
       " ('ar', 19),\n",
       " ('bi_tools', 19),\n",
       " ('tech', 19),\n",
       " ('e.', 19),\n",
       " ('windowsserver', 19),\n",
       " ('mac_osx', 19),\n",
       " ('target', 19),\n",
       " ('manufacturing', 19),\n",
       " ('lan', 19),\n",
       " ('lamp', 19),\n",
       " ('sas_base', 19),\n",
       " ('quality', 19),\n",
       " ('iaas', 19),\n",
       " ('objective_c', 19),\n",
       " ('inform', 19),\n",
       " ('pmp', 19),\n",
       " ('haskell', 18),\n",
       " ('xaml', 18),\n",
       " ('industry', 18),\n",
       " ('eclipse_ide', 18),\n",
       " ('jun', 18),\n",
       " ('scikitlearn', 18),\n",
       " ('rapid_miner', 18),\n",
       " ('numerical', 18),\n",
       " ('science', 18),\n",
       " ('advancedexcel', 18),\n",
       " ('support', 18),\n",
       " ('jndi', 18),\n",
       " ('integration', 18),\n",
       " ('open', 18),\n",
       " ('areaof', 18),\n",
       " ('series', 18),\n",
       " ('3years', 18),\n",
       " ('dplyr', 18),\n",
       " ('l', 18),\n",
       " ('cloudcomputing', 18),\n",
       " ('search', 18),\n",
       " ('ny', 18),\n",
       " ('teamwork', 18),\n",
       " ('envi', 18),\n",
       " ('algorithm', 18),\n",
       " ('dbms', 18),\n",
       " ('md', 18),\n",
       " ('ios', 18),\n",
       " ('scm', 18),\n",
       " ('bioinformatics', 18),\n",
       " ('cytoscape', 18),\n",
       " ('bootstrapping', 18),\n",
       " ('winscp', 18),\n",
       " ('avro', 18),\n",
       " ('soapui', 18),\n",
       " ('utilities', 18),\n",
       " ('groovy', 18),\n",
       " ('energy', 18),\n",
       " ('puppet', 18),\n",
       " ('commerce', 18),\n",
       " ('n.', 18),\n",
       " ('rdf', 18),\n",
       " ('epic', 18),\n",
       " ('y.', 18),\n",
       " ('a.', 18),\n",
       " ('cognos7.0/6.0', 18),\n",
       " ('documentum', 18),\n",
       " ('crystalreports', 18),\n",
       " ('aws_s3', 17),\n",
       " ('sql/', 17),\n",
       " ('aug', 17),\n",
       " ('microsoftazure', 17),\n",
       " ('solver', 17),\n",
       " ('ltex', 17),\n",
       " ('tf', 17),\n",
       " ('collaborative', 17),\n",
       " ('4years', 17),\n",
       " ('no', 17),\n",
       " ('databricks', 17),\n",
       " ('smtp', 17),\n",
       " ('enterprise', 17),\n",
       " ('ieee', 17),\n",
       " ('♦', 17),\n",
       " ('sqlserver_2012', 17),\n",
       " ('apriori', 17),\n",
       " ('hdinsight', 17),\n",
       " ('hardware', 17),\n",
       " ('rabbitmq', 17),\n",
       " ('snowflake', 17),\n",
       " ('vagrant', 17),\n",
       " ('mcmc', 17),\n",
       " ('tableau_server', 17),\n",
       " ('january', 17),\n",
       " ('ibm_watson', 17),\n",
       " ('primavera', 17),\n",
       " ('hmm', 17),\n",
       " ('amazonweb', 17),\n",
       " ('stl', 17),\n",
       " ('quality_center', 17),\n",
       " ('winbugs', 17),\n",
       " ('qda', 17),\n",
       " ('sas_em', 17),\n",
       " ('ides', 17),\n",
       " ('hl7', 17),\n",
       " ('opengl', 17),\n",
       " ('bugzilla', 17),\n",
       " ('vpc', 17),\n",
       " ('qtp', 17),\n",
       " ('titan', 17),\n",
       " ('windowsxp', 17),\n",
       " ('siebel', 17),\n",
       " ('reports', 17),\n",
       " ('change', 17),\n",
       " ('vpn', 17),\n",
       " ('h.', 17),\n",
       " ('dhcp', 17),\n",
       " ('python2.x/3.x', 17),\n",
       " ('visualc++', 17),\n",
       " ('apex', 16),\n",
       " ('artificial', 16),\n",
       " ('auto', 16),\n",
       " ('programmingand', 16),\n",
       " ('computing', 16),\n",
       " ('soft', 16),\n",
       " ('qualtrics', 16),\n",
       " ('leaflet', 16),\n",
       " ('international', 16),\n",
       " ('dashboard', 16),\n",
       " ('hplc', 16),\n",
       " ('pcr', 16),\n",
       " ('sap_lumira', 16),\n",
       " ('dr.', 16),\n",
       " ('mean', 16),\n",
       " ('atom', 16),\n",
       " ('streaming', 16),\n",
       " ('looker', 16),\n",
       " ('webdevelopment', 16),\n",
       " ('simulations', 16),\n",
       " ('documentation', 16),\n",
       " ('balsamiq', 16),\n",
       " ('intel', 16),\n",
       " ('virtualbox', 16),\n",
       " ('hpc', 16),\n",
       " ('sqs', 16),\n",
       " ('square', 16),\n",
       " ('softwareand', 16),\n",
       " ('logit', 16),\n",
       " ('ci', 16),\n",
       " ('ui', 16),\n",
       " ('sd', 16),\n",
       " ('mm', 16),\n",
       " ('prediction', 16),\n",
       " ('webservices', 16),\n",
       " ('case', 16),\n",
       " ('ms_outlook', 16),\n",
       " ('wan', 16),\n",
       " ('canada', 16),\n",
       " ('msvisio', 16),\n",
       " ('bpm', 16),\n",
       " ('spoken', 16),\n",
       " ('ssl', 16),\n",
       " ('bullhorn', 16),\n",
       " ('adp', 16),\n",
       " ...]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalList =[]\n",
    "for sublist in skillList:\n",
    "    for item in sublist:\n",
    "        finalList.append(item)\n",
    "c =Counter(finalList)\n",
    "sorted(c.items(), key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skill classification using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(skillList)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in skillList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]INFO : using symmetric alpha at 0.3333333333333333\n",
      "INFO : using symmetric eta at 0.3333333333333333\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 3 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 326/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 2308/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 2310/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 2272/4000 documents converged within 50 iterations\n",
      "DEBUG : updating topics\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.022*\"sql\" + 0.019*\"r\" + 0.019*\"python\" + 0.010*\"hadoop\" + 0.009*\"sas\" + 0.009*\"technical\" + 0.009*\"java\" + 0.009*\"hive\" + 0.008*\"matlab\" + 0.008*\"excel\"\n",
      "INFO : topic #1 (0.333): 0.028*\"python\" + 0.023*\"r\" + 0.022*\"sql\" + 0.017*\"technical\" + 0.017*\"java\" + 0.013*\"c\" + 0.013*\"tableau\" + 0.013*\"c++\" + 0.011*\"matlab\" + 0.010*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.018*\"r\" + 0.015*\"python\" + 0.014*\"sql\" + 0.010*\"c++\" + 0.009*\"sas\" + 0.008*\"linux\" + 0.008*\"tableau\" + 0.007*\"c\" + 0.007*\"programming\" + 0.007*\"java\"\n",
      "INFO : topic diff=1.679153, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.946 per-word bound, 493.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 477/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3383/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3364/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3408/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.333): 0.020*\"sql\" + 0.017*\"r\" + 0.017*\"python\" + 0.010*\"hadoop\" + 0.009*\"hive\" + 0.009*\"sas\" + 0.009*\"technical\" + 0.008*\"java\" + 0.008*\"excel\" + 0.008*\"javascript\"\n",
      "INFO : topic #1 (0.333): 0.030*\"python\" + 0.025*\"r\" + 0.024*\"sql\" + 0.017*\"technical\" + 0.017*\"java\" + 0.014*\"c++\" + 0.014*\"c\" + 0.014*\"tableau\" + 0.012*\"matlab\" + 0.011*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.016*\"r\" + 0.013*\"sql\" + 0.013*\"python\" + 0.009*\"c++\" + 0.009*\"sas\" + 0.008*\"linux\" + 0.007*\"tableau\" + 0.007*\"c\" + 0.006*\"excel\" + 0.006*\"programming\"\n",
      "INFO : topic diff=0.235642, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.866 per-word bound, 466.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 493/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3554/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : 3558/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3537/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.018*\"sql\" + 0.016*\"python\" + 0.015*\"r\" + 0.010*\"hadoop\" + 0.009*\"hive\" + 0.008*\"technical\" + 0.008*\"java\" + 0.008*\"sas\" + 0.007*\"javascript\" + 0.007*\"oracle\"\n",
      "INFO : topic #1 (0.333): 0.031*\"python\" + 0.027*\"r\" + 0.025*\"sql\" + 0.017*\"technical\" + 0.017*\"java\" + 0.014*\"c++\" + 0.014*\"tableau\" + 0.014*\"c\" + 0.013*\"matlab\" + 0.011*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.014*\"r\" + 0.012*\"sql\" + 0.011*\"python\" + 0.008*\"sas\" + 0.008*\"c++\" + 0.008*\"linux\" + 0.007*\"excel\" + 0.006*\"c\" + 0.006*\"tableau\" + 0.006*\"unix\"\n",
      "INFO : topic diff=0.169543, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.817 per-word bound, 451.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 496/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3642/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3648/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3675/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.017*\"sql\" + 0.014*\"python\" + 0.014*\"r\" + 0.009*\"hadoop\" + 0.009*\"hive\" + 0.008*\"technical\" + 0.008*\"java\" + 0.007*\"oracle\" + 0.007*\"sas\" + 0.007*\"javascript\"\n",
      "INFO : topic #1 (0.333): 0.032*\"python\" + 0.029*\"r\" + 0.026*\"sql\" + 0.017*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"tableau\" + 0.014*\"c\" + 0.014*\"matlab\" + 0.012*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.013*\"r\" + 0.011*\"sql\" + 0.010*\"python\" + 0.008*\"sas\" + 0.008*\"excel\" + 0.008*\"c++\" + 0.007*\"linux\" + 0.006*\"powerpoint\" + 0.006*\"unix\" + 0.006*\"computer\"\n",
      "INFO : topic diff=0.121950, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.787 per-word bound, 441.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 493/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3725/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3769/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3726/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.016*\"sql\" + 0.013*\"python\" + 0.012*\"r\" + 0.009*\"hive\" + 0.009*\"hadoop\" + 0.008*\"technical\" + 0.008*\"java\" + 0.008*\"oracle\" + 0.007*\"javascript\" + 0.007*\"c\"\n",
      "INFO : topic #1 (0.333): 0.033*\"python\" + 0.030*\"r\" + 0.027*\"sql\" + 0.017*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"tableau\" + 0.014*\"matlab\" + 0.014*\"c\" + 0.012*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.012*\"r\" + 0.010*\"sql\" + 0.008*\"python\" + 0.008*\"excel\" + 0.008*\"sas\" + 0.007*\"c++\" + 0.007*\"linux\" + 0.007*\"powerpoint\" + 0.006*\"word\" + 0.006*\"computer\"\n",
      "INFO : topic diff=0.090461, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.767 per-word bound, 435.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 504/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3833/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3779/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3767/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.015*\"sql\" + 0.012*\"python\" + 0.011*\"r\" + 0.009*\"hive\" + 0.008*\"hadoop\" + 0.008*\"technical\" + 0.008*\"java\" + 0.008*\"oracle\" + 0.007*\"pig\" + 0.007*\"c\"\n",
      "INFO : topic #1 (0.333): 0.034*\"python\" + 0.030*\"r\" + 0.028*\"sql\" + 0.017*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"tableau\" + 0.014*\"matlab\" + 0.014*\"c\" + 0.013*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.011*\"r\" + 0.010*\"sql\" + 0.008*\"excel\" + 0.007*\"python\" + 0.007*\"sas\" + 0.007*\"powerpoint\" + 0.006*\"linux\" + 0.006*\"word\" + 0.006*\"c++\" + 0.006*\"computer\"\n",
      "INFO : topic diff=0.068933, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.752 per-word bound, 431.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 517/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3820/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3791/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3852/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.333): 0.014*\"sql\" + 0.011*\"python\" + 0.010*\"r\" + 0.008*\"hive\" + 0.008*\"technical\" + 0.008*\"oracle\" + 0.008*\"hadoop\" + 0.008*\"java\" + 0.007*\"pig\" + 0.007*\"c\"\n",
      "INFO : topic #1 (0.333): 0.034*\"python\" + 0.031*\"r\" + 0.028*\"sql\" + 0.017*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"tableau\" + 0.015*\"matlab\" + 0.014*\"c\" + 0.013*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.010*\"r\" + 0.009*\"sql\" + 0.008*\"excel\" + 0.007*\"powerpoint\" + 0.007*\"sas\" + 0.007*\"word\" + 0.006*\"python\" + 0.006*\"linux\" + 0.006*\"c++\" + 0.006*\"computer\"\n",
      "INFO : topic diff=0.054045, rho=0.314126\n",
      "DEBUG : bound: at document #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : -8.740 per-word bound, 427.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 517/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3877/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3815/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3835/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.333): 0.014*\"sql\" + 0.010*\"python\" + 0.009*\"r\" + 0.008*\"technical\" + 0.008*\"hive\" + 0.008*\"oracle\" + 0.008*\"java\" + 0.008*\"hadoop\" + 0.007*\"pig\" + 0.006*\"c\"\n",
      "INFO : topic #1 (0.333): 0.035*\"python\" + 0.032*\"r\" + 0.028*\"sql\" + 0.017*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"tableau\" + 0.015*\"matlab\" + 0.014*\"c\" + 0.013*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.009*\"r\" + 0.009*\"excel\" + 0.008*\"sql\" + 0.007*\"powerpoint\" + 0.007*\"word\" + 0.007*\"sas\" + 0.006*\"linux\" + 0.006*\"computer\" + 0.006*\"python\" + 0.005*\"c++\"\n",
      "INFO : topic diff=0.043712, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.731 per-word bound, 425.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 515/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3886/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3845/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3819/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : updating topics\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.013*\"sql\" + 0.010*\"python\" + 0.009*\"r\" + 0.008*\"oracle\" + 0.008*\"technical\" + 0.008*\"hive\" + 0.008*\"java\" + 0.008*\"hadoop\" + 0.007*\"pig\" + 0.006*\"c\"\n",
      "INFO : topic #1 (0.333): 0.035*\"python\" + 0.032*\"r\" + 0.029*\"sql\" + 0.017*\"java\" + 0.016*\"technical\" + 0.016*\"c++\" + 0.015*\"tableau\" + 0.015*\"matlab\" + 0.014*\"c\" + 0.014*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.009*\"excel\" + 0.008*\"r\" + 0.008*\"sql\" + 0.008*\"powerpoint\" + 0.007*\"word\" + 0.006*\"sas\" + 0.006*\"computer\" + 0.006*\"linux\" + 0.005*\"c++\" + 0.005*\"python\"\n",
      "INFO : topic diff=0.036576, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.724 per-word bound, 422.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 517/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3840/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3842/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.013*\"sql\" + 0.009*\"python\" + 0.008*\"oracle\" + 0.008*\"technical\" + 0.008*\"r\" + 0.008*\"hive\" + 0.008*\"java\" + 0.007*\"hadoop\" + 0.007*\"pig\" + 0.006*\"c\"\n",
      "INFO : topic #1 (0.333): 0.035*\"python\" + 0.032*\"r\" + 0.029*\"sql\" + 0.017*\"java\" + 0.016*\"technical\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.015*\"matlab\" + 0.014*\"c\" + 0.014*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.009*\"excel\" + 0.008*\"powerpoint\" + 0.008*\"r\" + 0.007*\"sql\" + 0.007*\"word\" + 0.006*\"sas\" + 0.006*\"computer\" + 0.005*\"linux\" + 0.005*\"c++\" + 0.005*\"spss\"\n",
      "INFO : topic diff=0.031421, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.717 per-word bound, 420.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 517/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3841/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3849/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.012*\"sql\" + 0.009*\"python\" + 0.009*\"oracle\" + 0.008*\"technical\" + 0.008*\"hive\" + 0.008*\"java\" + 0.008*\"r\" + 0.007*\"hadoop\" + 0.007*\"pig\" + 0.006*\"c\"\n",
      "INFO : topic #1 (0.333): 0.036*\"python\" + 0.033*\"r\" + 0.029*\"sql\" + 0.017*\"java\" + 0.016*\"technical\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.015*\"matlab\" + 0.014*\"c\" + 0.014*\"sas\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #2 (0.333): 0.009*\"excel\" + 0.008*\"powerpoint\" + 0.007*\"r\" + 0.007*\"word\" + 0.007*\"sql\" + 0.006*\"computer\" + 0.006*\"sas\" + 0.005*\"linux\" + 0.005*\"spss\" + 0.005*\"c++\"\n",
      "INFO : topic diff=0.027652, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.712 per-word bound, 419.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 519/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3923/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3875/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3843/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.333): 0.012*\"sql\" + 0.009*\"oracle\" + 0.008*\"python\" + 0.008*\"technical\" + 0.008*\"hive\" + 0.008*\"java\" + 0.007*\"r\" + 0.007*\"hadoop\" + 0.007*\"pig\" + 0.006*\"c\"\n",
      "INFO : topic #1 (0.333): 0.036*\"python\" + 0.033*\"r\" + 0.029*\"sql\" + 0.017*\"java\" + 0.016*\"technical\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.015*\"matlab\" + 0.014*\"c\" + 0.014*\"sas\"\n",
      "INFO : topic #2 (0.333): 0.009*\"excel\" + 0.008*\"powerpoint\" + 0.007*\"word\" + 0.007*\"r\" + 0.007*\"sql\" + 0.006*\"computer\" + 0.006*\"sas\" + 0.005*\"linux\" + 0.004*\"spss\" + 0.004*\"access\"\n",
      "INFO : topic diff=0.024616, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.707 per-word bound, 417.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 521/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3887/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3839/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.333): 0.012*\"sql\" + 0.009*\"oracle\" + 0.008*\"technical\" + 0.008*\"python\" + 0.008*\"hive\" + 0.008*\"java\" + 0.007*\"hadoop\" + 0.007*\"r\" + 0.007*\"pig\" + 0.006*\"c\"\n",
      "INFO : topic #1 (0.333): 0.036*\"python\" + 0.033*\"r\" + 0.029*\"sql\" + 0.017*\"java\" + 0.016*\"technical\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.015*\"matlab\" + 0.014*\"sas\" + 0.014*\"c\"\n",
      "INFO : topic #2 (0.333): 0.009*\"excel\" + 0.008*\"powerpoint\" + 0.007*\"word\" + 0.007*\"r\" + 0.006*\"sql\" + 0.006*\"computer\" + 0.005*\"sas\" + 0.005*\"access\" + 0.004*\"linux\" + 0.004*\"spss\"\n",
      "INFO : topic diff=0.022506, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.702 per-word bound, 416.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3856/4000 documents converged within 50 iterations\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.012*\"sql\" + 0.009*\"oracle\" + 0.008*\"technical\" + 0.008*\"python\" + 0.008*\"hive\" + 0.008*\"java\" + 0.007*\"hadoop\" + 0.007*\"pig\" + 0.006*\"c\" + 0.006*\"r\"\n",
      "INFO : topic #1 (0.333): 0.036*\"python\" + 0.033*\"r\" + 0.029*\"sql\" + 0.017*\"java\" + 0.016*\"technical\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.016*\"matlab\" + 0.014*\"sas\" + 0.014*\"c\"\n",
      "INFO : topic #2 (0.333): 0.009*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.006*\"r\" + 0.006*\"sql\" + 0.006*\"computer\" + 0.005*\"sas\" + 0.005*\"access\" + 0.004*\"spss\" + 0.004*\"linux\"\n",
      "INFO : topic diff=0.020767, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.698 per-word bound, 415.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3865/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3904/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.012*\"sql\" + 0.009*\"oracle\" + 0.008*\"technical\" + 0.008*\"java\" + 0.008*\"hive\" + 0.007*\"python\" + 0.007*\"hadoop\" + 0.006*\"pig\" + 0.006*\"c\" + 0.006*\"unix\"\n",
      "INFO : topic #1 (0.333): 0.036*\"python\" + 0.034*\"r\" + 0.030*\"sql\" + 0.017*\"java\" + 0.016*\"c++\" + 0.016*\"technical\" + 0.016*\"tableau\" + 0.016*\"matlab\" + 0.014*\"sas\" + 0.014*\"c\"\n",
      "INFO : topic #2 (0.333): 0.010*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.006*\"r\" + 0.006*\"sql\" + 0.006*\"computer\" + 0.005*\"sas\" + 0.005*\"access\" + 0.004*\"spss\" + 0.004*\"linux\"\n",
      "INFO : topic diff=0.019262, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.695 per-word bound, 414.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3925/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3868/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.333): 0.012*\"sql\" + 0.009*\"oracle\" + 0.008*\"technical\" + 0.008*\"java\" + 0.007*\"hive\" + 0.007*\"python\" + 0.007*\"hadoop\" + 0.006*\"c\" + 0.006*\"pig\" + 0.006*\"unix\"\n",
      "INFO : topic #1 (0.333): 0.036*\"python\" + 0.034*\"r\" + 0.030*\"sql\" + 0.017*\"java\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.016*\"technical\" + 0.016*\"matlab\" + 0.015*\"sas\" + 0.014*\"c\"\n",
      "INFO : topic #2 (0.333): 0.010*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.006*\"computer\" + 0.006*\"r\" + 0.005*\"sql\" + 0.005*\"access\" + 0.005*\"sas\" + 0.004*\"spss\" + 0.004*\"data\"\n",
      "INFO : topic diff=0.017966, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.691 per-word bound, 413.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3872/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3913/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.011*\"sql\" + 0.009*\"oracle\" + 0.008*\"technical\" + 0.008*\"java\" + 0.007*\"hive\" + 0.007*\"python\" + 0.007*\"hadoop\" + 0.006*\"c\" + 0.006*\"pig\" + 0.006*\"unix\"\n",
      "INFO : topic #1 (0.333): 0.036*\"python\" + 0.034*\"r\" + 0.030*\"sql\" + 0.017*\"java\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.016*\"technical\" + 0.016*\"matlab\" + 0.015*\"sas\" + 0.014*\"c\"\n",
      "INFO : topic #2 (0.333): 0.010*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.006*\"computer\" + 0.005*\"r\" + 0.005*\"sql\" + 0.005*\"access\" + 0.005*\"sas\" + 0.004*\"spss\" + 0.004*\"data\"\n",
      "INFO : topic diff=0.017033, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.689 per-word bound, 412.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 522/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3925/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3883/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.333): 0.011*\"sql\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.008*\"java\" + 0.007*\"hive\" + 0.007*\"python\" + 0.007*\"c\" + 0.006*\"hadoop\" + 0.006*\"unix\" + 0.006*\"pig\"\n",
      "INFO : topic #1 (0.333): 0.037*\"python\" + 0.034*\"r\" + 0.030*\"sql\" + 0.017*\"java\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.016*\"matlab\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.014*\"c\"\n",
      "INFO : topic #2 (0.333): 0.010*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.006*\"computer\" + 0.005*\"r\" + 0.005*\"sql\" + 0.005*\"access\" + 0.004*\"sas\" + 0.004*\"spss\" + 0.004*\"project\"\n",
      "INFO : topic diff=0.016188, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.686 per-word bound, 411.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3881/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.011*\"sql\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.007*\"java\" + 0.007*\"hive\" + 0.007*\"python\" + 0.007*\"c\" + 0.006*\"unix\" + 0.006*\"hadoop\" + 0.006*\"pig\"\n",
      "INFO : topic #1 (0.333): 0.037*\"python\" + 0.034*\"r\" + 0.030*\"sql\" + 0.017*\"java\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.016*\"matlab\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.014*\"c\"\n",
      "INFO : topic #2 (0.333): 0.010*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.006*\"computer\" + 0.005*\"access\" + 0.005*\"r\" + 0.005*\"sql\" + 0.004*\"sas\" + 0.004*\"spss\" + 0.004*\"project\"\n",
      "INFO : topic diff=0.015424, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.683 per-word bound, 411.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3880/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.333): 0.011*\"sql\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.007*\"java\" + 0.007*\"hive\" + 0.007*\"c\" + 0.007*\"unix\" + 0.006*\"python\" + 0.006*\"hadoop\" + 0.006*\"html\"\n",
      "INFO : topic #1 (0.333): 0.037*\"python\" + 0.034*\"r\" + 0.030*\"sql\" + 0.017*\"java\" + 0.016*\"c++\" + 0.016*\"tableau\" + 0.016*\"matlab\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.014*\"c\"\n",
      "INFO : topic #2 (0.333): 0.010*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.006*\"computer\" + 0.005*\"access\" + 0.005*\"r\" + 0.005*\"sql\" + 0.004*\"sas\" + 0.004*\"project\" + 0.004*\"spss\"\n",
      "INFO : topic diff=0.014716, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.680 per-word bound, 410.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=3, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=3, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (473 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (537 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (601 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 9; 640 documents processed (665 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (307 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (439 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (520 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (260 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (371 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (612 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 10; 704 documents processed (828 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (301 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (827 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (577 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (515 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (584 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (628 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (586 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (324 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 3; 256 documents processed (273 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (384 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (586 virtual)\n",
      "DEBUG : finished all batches; 256 documents processed (273 virtual)\n",
      "DEBUG : finished all batches; 320 documents processed (324 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 4; 320 documents processed (577 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (577 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 11; 768 documents processed (892 virtual)\n",
      "DEBUG : completed batch 7; 468 documents processed (605 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 768 documents processed (892 virtual)\n",
      "DEBUG : finished all batches; 468 documents processed (605 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 5; 384 documents processed (641 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 9; 640 documents processed (648 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 512 documents processed (687 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (641 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (648 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (687 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (636 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (891 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 5; 384 documents processed (485 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (891 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (636 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (485 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 4; 320 documents processed (574 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (628 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (574 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 8831 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12276/12537 documents converged within 50 iterations\n",
      "  4%|▍         | 1/23 [00:24<08:52, 24.21s/it]INFO : using symmetric alpha at 0.25\n",
      "INFO : using symmetric eta at 0.25\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 4 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 362/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 2687/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 2678/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 2735/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.250): 0.022*\"sql\" + 0.021*\"r\" + 0.020*\"python\" + 0.011*\"hadoop\" + 0.010*\"sas\" + 0.009*\"hive\" + 0.009*\"matlab\" + 0.009*\"java\" + 0.009*\"excel\" + 0.009*\"c++\"\n",
      "INFO : topic #1 (0.250): 0.030*\"python\" + 0.024*\"r\" + 0.023*\"sql\" + 0.018*\"java\" + 0.016*\"technical\" + 0.014*\"c\" + 0.014*\"c++\" + 0.013*\"tableau\" + 0.012*\"matlab\" + 0.010*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.019*\"r\" + 0.016*\"python\" + 0.015*\"sql\" + 0.011*\"c++\" + 0.011*\"sas\" + 0.008*\"linux\" + 0.008*\"c\" + 0.008*\"programming\" + 0.007*\"tableau\" + 0.007*\"matlab\"\n",
      "INFO : topic #3 (0.250): 0.016*\"sql\" + 0.016*\"python\" + 0.014*\"technical\" + 0.014*\"r\" + 0.009*\"tableau\" + 0.009*\"unix\" + 0.008*\"java\" + 0.007*\"skills\" + 0.007*\"linux\" + 0.007*\"hadoop\"\n",
      "INFO : topic diff=2.277218, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.991 per-word bound, 508.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 492/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3536/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3560/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3528/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.021*\"sql\" + 0.019*\"r\" + 0.019*\"python\" + 0.011*\"hadoop\" + 0.010*\"hive\" + 0.010*\"sas\" + 0.009*\"java\" + 0.008*\"technical\" + 0.008*\"excel\" + 0.008*\"c++\"\n",
      "INFO : topic #1 (0.250): 0.032*\"python\" + 0.027*\"r\" + 0.025*\"sql\" + 0.018*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.014*\"matlab\" + 0.011*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.017*\"r\" + 0.014*\"python\" + 0.014*\"sql\" + 0.010*\"c++\" + 0.010*\"sas\" + 0.008*\"linux\" + 0.008*\"c\" + 0.007*\"matlab\" + 0.007*\"programming\" + 0.007*\"excel\"\n",
      "INFO : topic #3 (0.250): 0.014*\"sql\" + 0.013*\"python\" + 0.013*\"technical\" + 0.012*\"r\" + 0.009*\"unix\" + 0.008*\"tableau\" + 0.007*\"java\" + 0.007*\"skills\" + 0.006*\"linux\" + 0.005*\"hadoop\"\n",
      "INFO : topic diff=0.269627, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.884 per-word bound, 472.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 509/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3688/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3687/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3700/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.250): 0.019*\"sql\" + 0.017*\"python\" + 0.017*\"r\" + 0.010*\"hadoop\" + 0.010*\"hive\" + 0.009*\"java\" + 0.009*\"sas\" + 0.009*\"technical\" + 0.008*\"oracle\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.250): 0.033*\"python\" + 0.029*\"r\" + 0.027*\"sql\" + 0.018*\"java\" + 0.017*\"technical\" + 0.016*\"c++\" + 0.015*\"c\" + 0.015*\"tableau\" + 0.014*\"matlab\" + 0.012*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.016*\"r\" + 0.013*\"sql\" + 0.012*\"python\" + 0.010*\"sas\" + 0.010*\"c++\" + 0.008*\"linux\" + 0.007*\"excel\" + 0.007*\"c\" + 0.007*\"matlab\" + 0.006*\"computer\"\n",
      "INFO : topic #3 (0.250): 0.012*\"sql\" + 0.011*\"technical\" + 0.011*\"python\" + 0.010*\"r\" + 0.008*\"unix\" + 0.007*\"tableau\" + 0.007*\"skills\" + 0.006*\"java\" + 0.006*\"linux\" + 0.005*\"c\"\n",
      "INFO : topic diff=0.198545, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.827 per-word bound, 454.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 515/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3764/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3758/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3767/4000 documents converged within 50 iterations\n",
      "DEBUG : updating topics\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.250): 0.018*\"sql\" + 0.016*\"python\" + 0.015*\"r\" + 0.010*\"hive\" + 0.010*\"hadoop\" + 0.009*\"java\" + 0.009*\"technical\" + 0.008*\"oracle\" + 0.008*\"sas\" + 0.008*\"pig\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #1 (0.250): 0.035*\"python\" + 0.031*\"r\" + 0.028*\"sql\" + 0.018*\"java\" + 0.017*\"technical\" + 0.016*\"c++\" + 0.015*\"tableau\" + 0.015*\"matlab\" + 0.015*\"c\" + 0.013*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.015*\"r\" + 0.012*\"sql\" + 0.011*\"python\" + 0.010*\"sas\" + 0.009*\"c++\" + 0.008*\"excel\" + 0.007*\"linux\" + 0.007*\"c\" + 0.006*\"computer\" + 0.006*\"matlab\"\n",
      "INFO : topic #3 (0.250): 0.011*\"sql\" + 0.010*\"technical\" + 0.009*\"python\" + 0.008*\"r\" + 0.008*\"unix\" + 0.006*\"skills\" + 0.006*\"tableau\" + 0.005*\"linux\" + 0.005*\"java\" + 0.004*\"c\"\n",
      "INFO : topic diff=0.145775, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.790 per-word bound, 442.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 517/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3840/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3822/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3830/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.017*\"sql\" + 0.015*\"python\" + 0.014*\"r\" + 0.010*\"hive\" + 0.010*\"hadoop\" + 0.009*\"java\" + 0.009*\"technical\" + 0.008*\"oracle\" + 0.008*\"pig\" + 0.008*\"sas\"\n",
      "INFO : topic #1 (0.250): 0.036*\"python\" + 0.032*\"r\" + 0.029*\"sql\" + 0.018*\"java\" + 0.017*\"technical\" + 0.016*\"c++\" + 0.015*\"tableau\" + 0.015*\"matlab\" + 0.015*\"c\" + 0.013*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.014*\"r\" + 0.011*\"sql\" + 0.010*\"python\" + 0.009*\"sas\" + 0.008*\"c++\" + 0.008*\"excel\" + 0.007*\"linux\" + 0.007*\"computer\" + 0.006*\"powerpoint\" + 0.006*\"c\"\n",
      "INFO : topic #3 (0.250): 0.010*\"sql\" + 0.009*\"technical\" + 0.007*\"python\" + 0.007*\"unix\" + 0.007*\"r\" + 0.006*\"skills\" + 0.005*\"tableau\" + 0.005*\"linux\" + 0.004*\"java\" + 0.004*\"c\"\n",
      "INFO : topic diff=0.109170, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.765 per-word bound, 435.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 519/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3856/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3860/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3881/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.016*\"sql\" + 0.014*\"python\" + 0.013*\"r\" + 0.010*\"hive\" + 0.010*\"hadoop\" + 0.009*\"java\" + 0.009*\"technical\" + 0.009*\"oracle\" + 0.008*\"pig\" + 0.007*\"c\"\n",
      "INFO : topic #1 (0.250): 0.036*\"python\" + 0.033*\"r\" + 0.029*\"sql\" + 0.018*\"java\" + 0.017*\"technical\" + 0.016*\"c++\" + 0.016*\"matlab\" + 0.016*\"tableau\" + 0.015*\"c\" + 0.014*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.013*\"r\" + 0.010*\"sql\" + 0.009*\"python\" + 0.009*\"sas\" + 0.009*\"excel\" + 0.008*\"c++\" + 0.007*\"computer\" + 0.007*\"powerpoint\" + 0.006*\"linux\" + 0.006*\"word\"\n",
      "INFO : topic #3 (0.250): 0.009*\"technical\" + 0.009*\"sql\" + 0.007*\"unix\" + 0.006*\"skills\" + 0.006*\"python\" + 0.006*\"r\" + 0.005*\"tableau\" + 0.005*\"linux\" + 0.004*\"java\" + 0.003*\"excel\"\n",
      "INFO : topic diff=0.083206, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.748 per-word bound, 429.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 519/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3900/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3873/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3856/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.016*\"sql\" + 0.013*\"python\" + 0.012*\"r\" + 0.010*\"hive\" + 0.009*\"hadoop\" + 0.009*\"java\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.008*\"pig\" + 0.007*\"c\"\n",
      "INFO : topic #1 (0.250): 0.037*\"python\" + 0.033*\"r\" + 0.030*\"sql\" + 0.018*\"java\" + 0.017*\"technical\" + 0.016*\"c++\" + 0.016*\"matlab\" + 0.016*\"tableau\" + 0.015*\"c\" + 0.014*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.012*\"r\" + 0.009*\"sql\" + 0.009*\"excel\" + 0.008*\"sas\" + 0.008*\"python\" + 0.007*\"c++\" + 0.007*\"powerpoint\" + 0.007*\"computer\" + 0.006*\"word\" + 0.006*\"linux\"\n",
      "INFO : topic #3 (0.250): 0.008*\"technical\" + 0.008*\"sql\" + 0.007*\"unix\" + 0.006*\"skills\" + 0.005*\"python\" + 0.005*\"r\" + 0.004*\"linux\" + 0.004*\"tableau\" + 0.003*\"java\" + 0.003*\"excel\"\n",
      "INFO : topic diff=0.064846, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.735 per-word bound, 426.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3868/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.015*\"sql\" + 0.012*\"python\" + 0.011*\"r\" + 0.010*\"hive\" + 0.009*\"oracle\" + 0.009*\"hadoop\" + 0.009*\"java\" + 0.009*\"technical\" + 0.008*\"pig\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.250): 0.037*\"python\" + 0.034*\"r\" + 0.030*\"sql\" + 0.018*\"java\" + 0.017*\"technical\" + 0.017*\"c++\" + 0.016*\"matlab\" + 0.016*\"tableau\" + 0.015*\"c\" + 0.014*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.011*\"r\" + 0.009*\"excel\" + 0.009*\"sql\" + 0.008*\"sas\" + 0.007*\"python\" + 0.007*\"powerpoint\" + 0.007*\"c++\" + 0.007*\"computer\" + 0.007*\"word\" + 0.006*\"linux\"\n",
      "INFO : topic #3 (0.250): 0.007*\"technical\" + 0.007*\"sql\" + 0.006*\"unix\" + 0.006*\"skills\" + 0.004*\"python\" + 0.004*\"r\" + 0.004*\"linux\" + 0.004*\"tableau\" + 0.003*\"powerpoint\" + 0.003*\"excel\"\n",
      "INFO : topic diff=0.051706, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.725 per-word bound, 423.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3916/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3893/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.250): 0.015*\"sql\" + 0.012*\"python\" + 0.011*\"r\" + 0.010*\"hive\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.009*\"java\" + 0.009*\"hadoop\" + 0.008*\"pig\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.250): 0.038*\"python\" + 0.034*\"r\" + 0.030*\"sql\" + 0.018*\"java\" + 0.017*\"technical\" + 0.017*\"c++\" + 0.016*\"matlab\" + 0.016*\"tableau\" + 0.015*\"c\" + 0.015*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.010*\"r\" + 0.009*\"excel\" + 0.008*\"sql\" + 0.008*\"sas\" + 0.007*\"powerpoint\" + 0.007*\"word\" + 0.007*\"computer\" + 0.007*\"c++\" + 0.007*\"python\" + 0.005*\"spss\"\n",
      "INFO : topic #3 (0.250): 0.007*\"technical\" + 0.006*\"sql\" + 0.006*\"unix\" + 0.006*\"skills\" + 0.004*\"linux\" + 0.004*\"python\" + 0.004*\"r\" + 0.003*\"tableau\" + 0.003*\"powerpoint\" + 0.003*\"excel\"\n",
      "INFO : topic diff=0.042496, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.717 per-word bound, 420.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 521/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.250): 0.015*\"sql\" + 0.011*\"python\" + 0.010*\"r\" + 0.010*\"hive\" + 0.010*\"oracle\" + 0.009*\"technical\" + 0.009*\"java\" + 0.009*\"hadoop\" + 0.008*\"pig\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.250): 0.038*\"python\" + 0.035*\"r\" + 0.031*\"sql\" + 0.018*\"java\" + 0.017*\"c++\" + 0.017*\"technical\" + 0.017*\"matlab\" + 0.016*\"tableau\" + 0.015*\"c\" + 0.015*\"sas\"\n",
      "INFO : topic #2 (0.250): 0.010*\"excel\" + 0.010*\"r\" + 0.008*\"sql\" + 0.008*\"powerpoint\" + 0.007*\"sas\" + 0.007*\"word\" + 0.007*\"computer\" + 0.006*\"c++\" + 0.006*\"python\" + 0.005*\"spss\"\n",
      "INFO : topic #3 (0.250): 0.007*\"technical\" + 0.006*\"skills\" + 0.006*\"sql\" + 0.006*\"unix\" + 0.004*\"linux\" + 0.003*\"r\" + 0.003*\"python\" + 0.003*\"tableau\" + 0.003*\"powerpoint\" + 0.003*\"data\"\n",
      "INFO : topic diff=0.035811, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.710 per-word bound, 418.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.250): 0.014*\"sql\" + 0.011*\"python\" + 0.010*\"oracle\" + 0.010*\"hive\" + 0.010*\"r\" + 0.009*\"technical\" + 0.009*\"java\" + 0.009*\"hadoop\" + 0.008*\"pig\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.250): 0.038*\"python\" + 0.035*\"r\" + 0.031*\"sql\" + 0.018*\"java\" + 0.017*\"c++\" + 0.017*\"matlab\" + 0.017*\"technical\" + 0.017*\"tableau\" + 0.015*\"sas\" + 0.015*\"c\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #2 (0.250): 0.010*\"excel\" + 0.009*\"r\" + 0.008*\"powerpoint\" + 0.007*\"sql\" + 0.007*\"word\" + 0.007*\"sas\" + 0.007*\"computer\" + 0.006*\"c++\" + 0.006*\"python\" + 0.005*\"spss\"\n",
      "INFO : topic #3 (0.250): 0.006*\"technical\" + 0.006*\"skills\" + 0.005*\"unix\" + 0.005*\"sql\" + 0.003*\"linux\" + 0.003*\"tableau\" + 0.003*\"r\" + 0.003*\"python\" + 0.003*\"powerpoint\" + 0.002*\"data\"\n",
      "INFO : topic diff=0.030845, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.704 per-word bound, 417.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.250): 0.014*\"sql\" + 0.010*\"python\" + 0.010*\"oracle\" + 0.010*\"hive\" + 0.009*\"technical\" + 0.009*\"r\" + 0.009*\"java\" + 0.009*\"hadoop\" + 0.008*\"pig\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.250): 0.038*\"python\" + 0.035*\"r\" + 0.031*\"sql\" + 0.018*\"java\" + 0.017*\"c++\" + 0.017*\"matlab\" + 0.017*\"tableau\" + 0.017*\"technical\" + 0.015*\"sas\" + 0.015*\"c\"\n",
      "INFO : topic #2 (0.250): 0.010*\"excel\" + 0.009*\"r\" + 0.008*\"powerpoint\" + 0.008*\"word\" + 0.007*\"sql\" + 0.007*\"computer\" + 0.007*\"sas\" + 0.006*\"c++\" + 0.005*\"spss\" + 0.005*\"python\"\n",
      "INFO : topic #3 (0.250): 0.006*\"technical\" + 0.006*\"skills\" + 0.005*\"unix\" + 0.005*\"sql\" + 0.003*\"linux\" + 0.003*\"tableau\" + 0.002*\"r\" + 0.002*\"powerpoint\" + 0.002*\"python\" + 0.002*\"data\"\n",
      "INFO : topic diff=0.027090, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.699 per-word bound, 415.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3913/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.014*\"sql\" + 0.010*\"oracle\" + 0.010*\"python\" + 0.009*\"hive\" + 0.009*\"technical\" + 0.009*\"java\" + 0.009*\"r\" + 0.008*\"hadoop\" + 0.008*\"c\" + 0.008*\"pig\"\n",
      "INFO : topic #1 (0.250): 0.039*\"python\" + 0.036*\"r\" + 0.031*\"sql\" + 0.018*\"java\" + 0.017*\"matlab\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.017*\"technical\" + 0.015*\"sas\" + 0.015*\"c\"\n",
      "INFO : topic #2 (0.250): 0.010*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"r\" + 0.008*\"word\" + 0.007*\"computer\" + 0.007*\"sql\" + 0.007*\"sas\" + 0.006*\"c++\" + 0.005*\"spss\" + 0.005*\"python\"\n",
      "INFO : topic #3 (0.250): 0.006*\"technical\" + 0.006*\"skills\" + 0.005*\"unix\" + 0.004*\"sql\" + 0.003*\"linux\" + 0.002*\"tableau\" + 0.002*\"powerpoint\" + 0.002*\"data\" + 0.002*\"r\" + 0.002*\"excel\"\n",
      "INFO : topic diff=0.024211, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.694 per-word bound, 414.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3916/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.014*\"sql\" + 0.010*\"oracle\" + 0.010*\"python\" + 0.009*\"technical\" + 0.009*\"hive\" + 0.009*\"java\" + 0.009*\"r\" + 0.008*\"hadoop\" + 0.008*\"c\" + 0.008*\"pig\"\n",
      "INFO : topic #1 (0.250): 0.039*\"python\" + 0.036*\"r\" + 0.031*\"sql\" + 0.018*\"java\" + 0.017*\"matlab\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.017*\"technical\" + 0.015*\"sas\" + 0.015*\"c\"\n",
      "INFO : topic #2 (0.250): 0.010*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.008*\"r\" + 0.007*\"computer\" + 0.006*\"sas\" + 0.006*\"sql\" + 0.005*\"c++\" + 0.005*\"spss\" + 0.005*\"access\"\n",
      "INFO : topic #3 (0.250): 0.006*\"skills\" + 0.005*\"technical\" + 0.005*\"unix\" + 0.004*\"sql\" + 0.003*\"linux\" + 0.002*\"powerpoint\" + 0.002*\"data\" + 0.002*\"tableau\" + 0.002*\"excel\" + 0.002*\"windows\"\n",
      "INFO : topic diff=0.021932, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.690 per-word bound, 413.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.014*\"sql\" + 0.010*\"oracle\" + 0.009*\"technical\" + 0.009*\"python\" + 0.009*\"hive\" + 0.009*\"java\" + 0.008*\"r\" + 0.008*\"hadoop\" + 0.008*\"c\" + 0.008*\"pig\"\n",
      "INFO : topic #1 (0.250): 0.039*\"python\" + 0.036*\"r\" + 0.031*\"sql\" + 0.018*\"java\" + 0.017*\"matlab\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.017*\"technical\" + 0.015*\"sas\" + 0.015*\"c\"\n",
      "INFO : topic #2 (0.250): 0.011*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.007*\"r\" + 0.007*\"computer\" + 0.006*\"sas\" + 0.006*\"sql\" + 0.005*\"c++\" + 0.005*\"spss\" + 0.005*\"access\"\n",
      "INFO : topic #3 (0.250): 0.006*\"skills\" + 0.005*\"technical\" + 0.004*\"unix\" + 0.004*\"sql\" + 0.003*\"linux\" + 0.002*\"powerpoint\" + 0.002*\"data\" + 0.002*\"tableau\" + 0.002*\"excel\" + 0.002*\"windows\"\n",
      "INFO : topic diff=0.020150, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.686 per-word bound, 411.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4DEBUG : processing chunk #0 of 4000 documents\n",
      "\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3928/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.014*\"sql\" + 0.010*\"oracle\" + 0.010*\"technical\" + 0.009*\"hive\" + 0.009*\"java\" + 0.009*\"python\" + 0.008*\"hadoop\" + 0.008*\"r\" + 0.008*\"c\" + 0.008*\"pig\"\n",
      "INFO : topic #1 (0.250): 0.039*\"python\" + 0.036*\"r\" + 0.031*\"sql\" + 0.018*\"java\" + 0.017*\"matlab\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.015*\"c\"\n",
      "INFO : topic #2 (0.250): 0.011*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.007*\"r\" + 0.007*\"computer\" + 0.006*\"sas\" + 0.006*\"sql\" + 0.005*\"spss\" + 0.005*\"c++\" + 0.005*\"access\"\n",
      "INFO : topic #3 (0.250): 0.005*\"skills\" + 0.005*\"technical\" + 0.004*\"unix\" + 0.004*\"sql\" + 0.002*\"linux\" + 0.002*\"data\" + 0.002*\"powerpoint\" + 0.002*\"tableau\" + 0.002*\"j.\" + 0.002*\"excel\"\n",
      "INFO : topic diff=0.018581, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.681 per-word bound, 410.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.014*\"sql\" + 0.010*\"oracle\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"hive\" + 0.009*\"python\" + 0.008*\"hadoop\" + 0.008*\"c\" + 0.008*\"r\" + 0.008*\"pig\"\n",
      "INFO : topic #1 (0.250): 0.039*\"python\" + 0.036*\"r\" + 0.032*\"sql\" + 0.018*\"java\" + 0.017*\"matlab\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.016*\"technical\" + 0.016*\"sas\" + 0.015*\"c\"\n",
      "INFO : topic #2 (0.250): 0.011*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.007*\"computer\" + 0.007*\"r\" + 0.006*\"sas\" + 0.005*\"sql\" + 0.005*\"access\" + 0.005*\"spss\" + 0.005*\"c++\"\n",
      "INFO : topic #3 (0.250): 0.005*\"skills\" + 0.005*\"technical\" + 0.004*\"unix\" + 0.003*\"sql\" + 0.002*\"linux\" + 0.002*\"data\" + 0.002*\"powerpoint\" + 0.002*\"j.\" + 0.002*\"m.\" + 0.002*\"tableau\"\n",
      "INFO : topic diff=0.017025, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.678 per-word bound, 409.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.014*\"sql\" + 0.010*\"oracle\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"hive\" + 0.009*\"python\" + 0.008*\"c\" + 0.008*\"hadoop\" + 0.008*\"r\" + 0.008*\"pig\"\n",
      "INFO : topic #1 (0.250): 0.039*\"python\" + 0.036*\"r\" + 0.032*\"sql\" + 0.018*\"java\" + 0.017*\"matlab\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.016*\"technical\" + 0.016*\"sas\" + 0.015*\"c\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #2 (0.250): 0.011*\"excel\" + 0.010*\"powerpoint\" + 0.009*\"word\" + 0.007*\"computer\" + 0.006*\"r\" + 0.006*\"sas\" + 0.005*\"sql\" + 0.005*\"access\" + 0.005*\"spss\" + 0.004*\"c++\"\n",
      "INFO : topic #3 (0.250): 0.005*\"skills\" + 0.005*\"technical\" + 0.004*\"unix\" + 0.003*\"sql\" + 0.002*\"linux\" + 0.002*\"data\" + 0.002*\"j.\" + 0.002*\"powerpoint\" + 0.002*\"m.\" + 0.002*\"s.\"\n",
      "INFO : topic diff=0.015872, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.674 per-word bound, 408.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.250): 0.013*\"sql\" + 0.011*\"oracle\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"hive\" + 0.009*\"python\" + 0.008*\"c\" + 0.008*\"hadoop\" + 0.008*\"pig\" + 0.007*\"r\"\n",
      "INFO : topic #1 (0.250): 0.039*\"python\" + 0.036*\"r\" + 0.032*\"sql\" + 0.018*\"java\" + 0.017*\"matlab\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.016*\"technical\" + 0.016*\"sas\" + 0.015*\"c\"\n",
      "INFO : topic #2 (0.250): 0.011*\"excel\" + 0.010*\"powerpoint\" + 0.009*\"word\" + 0.007*\"computer\" + 0.006*\"r\" + 0.005*\"sas\" + 0.005*\"sql\" + 0.005*\"access\" + 0.005*\"spss\" + 0.004*\"c++\"\n",
      "INFO : topic #3 (0.250): 0.005*\"skills\" + 0.005*\"technical\" + 0.004*\"unix\" + 0.003*\"sql\" + 0.002*\"linux\" + 0.002*\"j.\" + 0.002*\"data\" + 0.002*\"m.\" + 0.002*\"powerpoint\" + 0.002*\"s.\"\n",
      "INFO : topic diff=0.014743, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.671 per-word bound, 407.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.250): 0.013*\"sql\" + 0.011*\"oracle\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"hive\" + 0.008*\"python\" + 0.008*\"c\" + 0.008*\"hadoop\" + 0.008*\"pig\" + 0.007*\"r\"\n",
      "INFO : topic #1 (0.250): 0.039*\"python\" + 0.037*\"r\" + 0.032*\"sql\" + 0.018*\"java\" + 0.017*\"matlab\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.016*\"technical\" + 0.016*\"sas\" + 0.015*\"c\"\n",
      "INFO : topic #2 (0.250): 0.011*\"excel\" + 0.010*\"powerpoint\" + 0.009*\"word\" + 0.007*\"computer\" + 0.006*\"r\" + 0.005*\"sas\" + 0.005*\"access\" + 0.005*\"sql\" + 0.005*\"spss\" + 0.004*\"project\"\n",
      "INFO : topic #3 (0.250): 0.005*\"skills\" + 0.004*\"technical\" + 0.004*\"unix\" + 0.003*\"sql\" + 0.002*\"j.\" + 0.002*\"linux\" + 0.002*\"m.\" + 0.002*\"data\" + 0.002*\"s.\" + 0.002*\"powerpoint\"\n",
      "INFO : topic diff=0.013744, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.669 per-word bound, 407.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=4, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=4, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (545 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (609 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 9; 640 documents processed (673 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (579 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 10; 704 documents processed (792 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (456 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (577 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (821 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (253 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (464 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (688 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (449 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (310 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (568 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (525 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (317 virtual)\n",
      "DEBUG : completed batch 11; 768 documents processed (857 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (589 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (885 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 3; 256 documents processed (513 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (885 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 192 documents processed (192 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (384 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 526 documents processed (673 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (654 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 9; 640 documents processed (695 virtual)\n",
      "DEBUG : finished all batches; 526 documents processed (673 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 640 documents processed (695 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (654 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (512 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (512 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (632 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (669 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (669 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 4; 320 documents processed (374 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 256 documents processed (317 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 256 documents processed (513 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (632 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 320 documents processed (374 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 12; 832 documents processed (1039 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 8; 576 documents processed (908 virtual)\n",
      "DEBUG : finished all batches; 832 documents processed (1039 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (908 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (590 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (590 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : accumulated word occurrence stats for 9037 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12335/12537 documents converged within 50 iterations\n",
      "  9%|▊         | 2/23 [00:48<08:31, 24.34s/it]INFO : using symmetric alpha at 0.2\n",
      "INFO : using symmetric eta at 0.2\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 5 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 387/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 2929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 2877/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 2810/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.020*\"sql\" + 0.019*\"r\" + 0.019*\"python\" + 0.011*\"hive\" + 0.009*\"sas\" + 0.009*\"hadoop\" + 0.009*\"java\" + 0.008*\"technical\" + 0.008*\"c++\" + 0.008*\"excel\"\n",
      "INFO : topic #1 (0.200): 0.029*\"python\" + 0.023*\"r\" + 0.020*\"sql\" + 0.019*\"java\" + 0.016*\"technical\" + 0.014*\"c++\" + 0.014*\"c\" + 0.012*\"tableau\" + 0.011*\"matlab\" + 0.010*\"mysql\"\n",
      "INFO : topic #2 (0.200): 0.017*\"r\" + 0.014*\"python\" + 0.012*\"sql\" + 0.011*\"c++\" + 0.010*\"sas\" + 0.009*\"linux\" + 0.008*\"c\" + 0.007*\"java\" + 0.007*\"programming\" + 0.007*\"tableau\"\n",
      "INFO : topic #3 (0.200): 0.014*\"python\" + 0.014*\"sql\" + 0.013*\"technical\" + 0.012*\"r\" + 0.009*\"unix\" + 0.008*\"java\" + 0.008*\"tableau\" + 0.006*\"linux\" + 0.006*\"hadoop\" + 0.006*\"c\"\n",
      "INFO : topic #4 (0.200): 0.027*\"sql\" + 0.026*\"r\" + 0.025*\"python\" + 0.013*\"matlab\" + 0.013*\"tableau\" + 0.013*\"technical\" + 0.012*\"sas\" + 0.012*\"hadoop\" + 0.011*\"c++\" + 0.010*\"c\"\n",
      "INFO : topic diff=2.943794, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.041 per-word bound, 526.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 500/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3610/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3590/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3640/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.018*\"sql\" + 0.017*\"python\" + 0.017*\"r\" + 0.011*\"hive\" + 0.010*\"hadoop\" + 0.009*\"java\" + 0.008*\"sas\" + 0.008*\"technical\" + 0.008*\"pig\" + 0.008*\"spark\"\n",
      "INFO : topic #1 (0.200): 0.029*\"python\" + 0.024*\"r\" + 0.021*\"sql\" + 0.019*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.012*\"tableau\" + 0.011*\"matlab\" + 0.011*\"mysql\"\n",
      "INFO : topic #2 (0.200): 0.015*\"r\" + 0.012*\"python\" + 0.011*\"sql\" + 0.010*\"c++\" + 0.008*\"sas\" + 0.008*\"linux\" + 0.007*\"c\" + 0.006*\"java\" + 0.006*\"programming\" + 0.006*\"tableau\"\n",
      "INFO : topic #3 (0.200): 0.012*\"sql\" + 0.012*\"technical\" + 0.011*\"python\" + 0.010*\"r\" + 0.009*\"unix\" + 0.007*\"tableau\" + 0.007*\"java\" + 0.006*\"linux\" + 0.005*\"c\" + 0.005*\"hadoop\"\n",
      "INFO : topic #4 (0.200): 0.028*\"sql\" + 0.028*\"r\" + 0.027*\"python\" + 0.014*\"matlab\" + 0.014*\"sas\" + 0.013*\"tableau\" + 0.013*\"technical\" + 0.011*\"hadoop\" + 0.011*\"c++\" + 0.010*\"c\"\n",
      "INFO : topic diff=0.282319, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.906 per-word bound, 479.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 512/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3714/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3680/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3759/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.017*\"sql\" + 0.016*\"python\" + 0.015*\"r\" + 0.011*\"hive\" + 0.010*\"hadoop\" + 0.009*\"java\" + 0.009*\"technical\" + 0.008*\"pig\" + 0.008*\"oracle\" + 0.008*\"sas\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #1 (0.200): 0.030*\"python\" + 0.024*\"r\" + 0.022*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.012*\"tableau\" + 0.011*\"matlab\" + 0.011*\"mysql\"\n",
      "INFO : topic #2 (0.200): 0.013*\"r\" + 0.011*\"python\" + 0.009*\"sql\" + 0.009*\"c++\" + 0.008*\"linux\" + 0.007*\"sas\" + 0.007*\"c\" + 0.005*\"java\" + 0.005*\"programming\" + 0.005*\"windows\"\n",
      "INFO : topic #3 (0.200): 0.011*\"technical\" + 0.011*\"sql\" + 0.009*\"python\" + 0.008*\"unix\" + 0.008*\"r\" + 0.006*\"tableau\" + 0.006*\"java\" + 0.006*\"linux\" + 0.004*\"c\" + 0.004*\"skills\"\n",
      "INFO : topic #4 (0.200): 0.030*\"r\" + 0.030*\"sql\" + 0.029*\"python\" + 0.016*\"sas\" + 0.015*\"matlab\" + 0.014*\"tableau\" + 0.013*\"technical\" + 0.012*\"c++\" + 0.011*\"excel\" + 0.011*\"hadoop\"\n",
      "INFO : topic diff=0.214837, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.839 per-word bound, 458.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 518/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3786/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3729/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3761/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.016*\"sql\" + 0.015*\"python\" + 0.014*\"r\" + 0.012*\"hive\" + 0.010*\"hadoop\" + 0.009*\"java\" + 0.009*\"technical\" + 0.009*\"oracle\" + 0.009*\"pig\" + 0.008*\"mysql\"\n",
      "INFO : topic #1 (0.200): 0.030*\"python\" + 0.024*\"r\" + 0.022*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.012*\"tableau\" + 0.011*\"matlab\" + 0.011*\"mysql\"\n",
      "INFO : topic #2 (0.200): 0.012*\"r\" + 0.009*\"python\" + 0.008*\"c++\" + 0.008*\"sql\" + 0.007*\"linux\" + 0.006*\"sas\" + 0.006*\"c\" + 0.005*\"windows\" + 0.005*\"programming\" + 0.005*\"java\"\n",
      "INFO : topic #3 (0.200): 0.010*\"technical\" + 0.009*\"sql\" + 0.008*\"unix\" + 0.008*\"python\" + 0.007*\"r\" + 0.006*\"tableau\" + 0.006*\"linux\" + 0.005*\"java\" + 0.004*\"c\" + 0.004*\"skills\"\n",
      "INFO : topic #4 (0.200): 0.032*\"r\" + 0.030*\"sql\" + 0.030*\"python\" + 0.017*\"sas\" + 0.016*\"matlab\" + 0.014*\"tableau\" + 0.013*\"technical\" + 0.012*\"excel\" + 0.012*\"c++\" + 0.011*\"hadoop\"\n",
      "INFO : topic diff=0.159585, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.803 per-word bound, 446.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 517/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3801/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3823/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3782/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.016*\"sql\" + 0.014*\"python\" + 0.013*\"r\" + 0.012*\"hive\" + 0.010*\"hadoop\" + 0.009*\"java\" + 0.009*\"oracle\" + 0.009*\"pig\" + 0.009*\"technical\" + 0.007*\"mysql\"\n",
      "INFO : topic #1 (0.200): 0.031*\"python\" + 0.025*\"r\" + 0.022*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"matlab\" + 0.011*\"mysql\"\n",
      "INFO : topic #2 (0.200): 0.010*\"r\" + 0.008*\"python\" + 0.008*\"c++\" + 0.007*\"sql\" + 0.007*\"linux\" + 0.006*\"c\" + 0.006*\"sas\" + 0.005*\"windows\" + 0.005*\"computer\" + 0.004*\"programming\"\n",
      "INFO : topic #3 (0.200): 0.009*\"technical\" + 0.008*\"sql\" + 0.007*\"unix\" + 0.006*\"python\" + 0.005*\"r\" + 0.005*\"linux\" + 0.005*\"tableau\" + 0.004*\"java\" + 0.004*\"skills\" + 0.004*\"c\"\n",
      "INFO : topic #4 (0.200): 0.033*\"r\" + 0.031*\"sql\" + 0.031*\"python\" + 0.019*\"sas\" + 0.016*\"matlab\" + 0.015*\"tableau\" + 0.013*\"excel\" + 0.013*\"c++\" + 0.013*\"technical\" + 0.011*\"spss\"\n",
      "INFO : topic diff=0.119885, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.781 per-word bound, 439.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 514/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3775/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3837/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3848/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.015*\"sql\" + 0.013*\"python\" + 0.012*\"r\" + 0.012*\"hive\" + 0.009*\"hadoop\" + 0.009*\"java\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.009*\"pig\" + 0.007*\"mysql\"\n",
      "INFO : topic #1 (0.200): 0.031*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"matlab\"\n",
      "INFO : topic #2 (0.200): 0.009*\"r\" + 0.007*\"c++\" + 0.007*\"python\" + 0.007*\"sql\" + 0.007*\"linux\" + 0.006*\"c\" + 0.005*\"sas\" + 0.005*\"windows\" + 0.004*\"computer\" + 0.004*\"programming\"\n",
      "INFO : topic #3 (0.200): 0.008*\"technical\" + 0.007*\"sql\" + 0.007*\"unix\" + 0.005*\"python\" + 0.005*\"linux\" + 0.005*\"r\" + 0.005*\"tableau\" + 0.004*\"java\" + 0.004*\"skills\" + 0.003*\"c\"\n",
      "INFO : topic #4 (0.200): 0.034*\"r\" + 0.032*\"sql\" + 0.031*\"python\" + 0.020*\"sas\" + 0.017*\"matlab\" + 0.015*\"tableau\" + 0.014*\"excel\" + 0.013*\"c++\" + 0.013*\"technical\" + 0.012*\"spss\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.091719, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.764 per-word bound, 434.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 522/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3810/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3860/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3872/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.015*\"sql\" + 0.012*\"python\" + 0.011*\"hive\" + 0.011*\"r\" + 0.010*\"oracle\" + 0.009*\"java\" + 0.009*\"hadoop\" + 0.009*\"technical\" + 0.009*\"pig\" + 0.007*\"c\"\n",
      "INFO : topic #1 (0.200): 0.032*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"matlab\"\n",
      "INFO : topic #2 (0.200): 0.008*\"r\" + 0.007*\"c++\" + 0.006*\"python\" + 0.006*\"linux\" + 0.006*\"sql\" + 0.005*\"c\" + 0.004*\"windows\" + 0.004*\"sas\" + 0.004*\"computer\" + 0.004*\"excel\"\n",
      "INFO : topic #3 (0.200): 0.008*\"technical\" + 0.007*\"unix\" + 0.007*\"sql\" + 0.005*\"linux\" + 0.004*\"python\" + 0.004*\"tableau\" + 0.004*\"r\" + 0.004*\"skills\" + 0.003*\"java\" + 0.003*\"windows\"\n",
      "INFO : topic #4 (0.200): 0.035*\"r\" + 0.032*\"sql\" + 0.031*\"python\" + 0.021*\"sas\" + 0.017*\"matlab\" + 0.015*\"tableau\" + 0.015*\"excel\" + 0.013*\"c++\" + 0.013*\"technical\" + 0.012*\"spss\"\n",
      "INFO : topic diff=0.071671, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.751 per-word bound, 430.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 521/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3863/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3838/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3863/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.014*\"sql\" + 0.012*\"python\" + 0.011*\"hive\" + 0.011*\"r\" + 0.010*\"oracle\" + 0.009*\"java\" + 0.009*\"hadoop\" + 0.009*\"technical\" + 0.009*\"pig\" + 0.007*\"c\"\n",
      "INFO : topic #1 (0.200): 0.032*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"matlab\"\n",
      "INFO : topic #2 (0.200): 0.008*\"r\" + 0.006*\"c++\" + 0.006*\"linux\" + 0.006*\"python\" + 0.005*\"sql\" + 0.005*\"c\" + 0.004*\"windows\" + 0.004*\"computer\" + 0.004*\"sas\" + 0.003*\"excel\"\n",
      "INFO : topic #3 (0.200): 0.007*\"technical\" + 0.006*\"unix\" + 0.006*\"sql\" + 0.004*\"linux\" + 0.004*\"tableau\" + 0.004*\"python\" + 0.003*\"skills\" + 0.003*\"r\" + 0.003*\"windows\" + 0.003*\"java\"\n",
      "INFO : topic #4 (0.200): 0.035*\"r\" + 0.033*\"sql\" + 0.032*\"python\" + 0.021*\"sas\" + 0.017*\"matlab\" + 0.015*\"excel\" + 0.015*\"tableau\" + 0.013*\"c++\" + 0.013*\"technical\" + 0.012*\"spss\"\n",
      "INFO : topic diff=0.057072, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.740 per-word bound, 427.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 522/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3868/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3861/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3872/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.014*\"sql\" + 0.011*\"python\" + 0.011*\"hive\" + 0.010*\"oracle\" + 0.010*\"r\" + 0.009*\"java\" + 0.009*\"technical\" + 0.009*\"hadoop\" + 0.009*\"pig\" + 0.007*\"c\"\n",
      "INFO : topic #1 (0.200): 0.032*\"python\" + 0.026*\"r\" + 0.023*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"matlab\"\n",
      "INFO : topic #2 (0.200): 0.007*\"r\" + 0.006*\"c++\" + 0.006*\"linux\" + 0.005*\"python\" + 0.005*\"sql\" + 0.005*\"c\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"sas\" + 0.003*\"data\"\n",
      "INFO : topic #3 (0.200): 0.007*\"technical\" + 0.006*\"unix\" + 0.005*\"sql\" + 0.004*\"linux\" + 0.003*\"tableau\" + 0.003*\"skills\" + 0.003*\"python\" + 0.003*\"windows\" + 0.003*\"r\" + 0.003*\"c\"\n",
      "INFO : topic #4 (0.200): 0.036*\"r\" + 0.033*\"sql\" + 0.032*\"python\" + 0.022*\"sas\" + 0.018*\"matlab\" + 0.016*\"excel\" + 0.015*\"tableau\" + 0.014*\"c++\" + 0.013*\"technical\" + 0.012*\"spss\"\n",
      "INFO : topic diff=0.046417, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.731 per-word bound, 425.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 522/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3861/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3880/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3885/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.014*\"sql\" + 0.011*\"hive\" + 0.011*\"python\" + 0.010*\"oracle\" + 0.009*\"r\" + 0.009*\"java\" + 0.009*\"technical\" + 0.009*\"hadoop\" + 0.009*\"pig\" + 0.007*\"c\"\n",
      "INFO : topic #1 (0.200): 0.032*\"python\" + 0.026*\"r\" + 0.023*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"matlab\"\n",
      "INFO : topic #2 (0.200): 0.006*\"r\" + 0.006*\"c++\" + 0.005*\"linux\" + 0.005*\"python\" + 0.004*\"c\" + 0.004*\"sql\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.003*\"data\" + 0.003*\"project\"\n",
      "INFO : topic #3 (0.200): 0.006*\"technical\" + 0.006*\"unix\" + 0.005*\"sql\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"windows\" + 0.003*\"python\" + 0.002*\"r\" + 0.002*\"c\"\n",
      "INFO : topic #4 (0.200): 0.036*\"r\" + 0.033*\"sql\" + 0.032*\"python\" + 0.023*\"sas\" + 0.018*\"matlab\" + 0.016*\"excel\" + 0.015*\"tableau\" + 0.014*\"c++\" + 0.013*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.038560, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.725 per-word bound, 423.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3868/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3885/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.014*\"sql\" + 0.011*\"hive\" + 0.010*\"python\" + 0.010*\"oracle\" + 0.009*\"technical\" + 0.009*\"java\" + 0.009*\"r\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.200): 0.033*\"python\" + 0.026*\"r\" + 0.023*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"matlab\"\n",
      "INFO : topic #2 (0.200): 0.006*\"r\" + 0.005*\"c++\" + 0.005*\"linux\" + 0.004*\"python\" + 0.004*\"c\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"sql\" + 0.003*\"data\" + 0.003*\"project\"\n",
      "INFO : topic #3 (0.200): 0.006*\"technical\" + 0.006*\"unix\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"windows\" + 0.002*\"python\" + 0.002*\"r\" + 0.002*\"c\"\n",
      "INFO : topic #4 (0.200): 0.036*\"r\" + 0.033*\"sql\" + 0.032*\"python\" + 0.023*\"sas\" + 0.018*\"matlab\" + 0.017*\"excel\" + 0.016*\"tableau\" + 0.014*\"c++\" + 0.013*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.032675, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.719 per-word bound, 421.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3886/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3907/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.014*\"sql\" + 0.011*\"hive\" + 0.011*\"oracle\" + 0.010*\"python\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.009*\"r\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.200): 0.033*\"python\" + 0.026*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"matlab\"\n",
      "INFO : topic #2 (0.200): 0.005*\"r\" + 0.005*\"c++\" + 0.005*\"linux\" + 0.004*\"computer\" + 0.004*\"c\" + 0.004*\"python\" + 0.004*\"windows\" + 0.003*\"sql\" + 0.003*\"project\" + 0.003*\"data\"\n",
      "INFO : topic #3 (0.200): 0.006*\"technical\" + 0.006*\"unix\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"windows\" + 0.002*\"c\" + 0.002*\"j.\" + 0.002*\"r\"\n",
      "INFO : topic #4 (0.200): 0.037*\"r\" + 0.033*\"sql\" + 0.032*\"python\" + 0.023*\"sas\" + 0.018*\"matlab\" + 0.017*\"excel\" + 0.016*\"tableau\" + 0.014*\"c++\" + 0.013*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.028244, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.713 per-word bound, 419.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3884/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3910/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.013*\"sql\" + 0.011*\"hive\" + 0.011*\"oracle\" + 0.010*\"python\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.008*\"r\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.200): 0.033*\"python\" + 0.026*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"matlab\"\n",
      "INFO : topic #2 (0.200): 0.005*\"r\" + 0.005*\"c++\" + 0.005*\"linux\" + 0.004*\"computer\" + 0.004*\"c\" + 0.004*\"windows\" + 0.003*\"python\" + 0.003*\"project\" + 0.003*\"data\" + 0.003*\"sql\"\n",
      "INFO : topic #3 (0.200): 0.005*\"technical\" + 0.005*\"unix\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"windows\" + 0.002*\"j.\" + 0.002*\"c\" + 0.002*\"data\"\n",
      "INFO : topic #4 (0.200): 0.037*\"r\" + 0.033*\"sql\" + 0.032*\"python\" + 0.024*\"sas\" + 0.018*\"matlab\" + 0.018*\"excel\" + 0.016*\"tableau\" + 0.014*\"c++\" + 0.013*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.024708, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.709 per-word bound, 418.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3893/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.013*\"sql\" + 0.011*\"oracle\" + 0.011*\"hive\" + 0.010*\"technical\" + 0.010*\"python\" + 0.009*\"java\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.008*\"r\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.200): 0.033*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"matlab\"\n",
      "INFO : topic #2 (0.200): 0.005*\"r\" + 0.005*\"c++\" + 0.004*\"linux\" + 0.004*\"computer\" + 0.004*\"c\" + 0.003*\"windows\" + 0.003*\"project\" + 0.003*\"python\" + 0.003*\"data\" + 0.003*\"microsoft\"\n",
      "INFO : topic #3 (0.200): 0.005*\"unix\" + 0.005*\"technical\" + 0.004*\"linux\" + 0.003*\"sql\" + 0.003*\"skills\" + 0.002*\"windows\" + 0.002*\"tableau\" + 0.002*\"j.\" + 0.002*\"m.\" + 0.002*\"s.\"\n",
      "INFO : topic #4 (0.200): 0.037*\"r\" + 0.034*\"sql\" + 0.032*\"python\" + 0.024*\"sas\" + 0.018*\"matlab\" + 0.018*\"excel\" + 0.016*\"tableau\" + 0.014*\"c++\" + 0.013*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.022000, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.705 per-word bound, 417.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.013*\"sql\" + 0.011*\"oracle\" + 0.011*\"hive\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"python\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.008*\"c\" + 0.008*\"r\"\n",
      "INFO : topic #1 (0.200): 0.034*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"hadoop\"\n",
      "INFO : topic #2 (0.200): 0.004*\"c++\" + 0.004*\"r\" + 0.004*\"linux\" + 0.004*\"computer\" + 0.003*\"c\" + 0.003*\"project\" + 0.003*\"windows\" + 0.003*\"data\" + 0.003*\"python\" + 0.003*\"microsoft\"\n",
      "INFO : topic #3 (0.200): 0.005*\"unix\" + 0.005*\"technical\" + 0.003*\"linux\" + 0.003*\"sql\" + 0.003*\"skills\" + 0.002*\"windows\" + 0.002*\"tableau\" + 0.002*\"j.\" + 0.002*\"m.\" + 0.002*\"s.\"\n",
      "INFO : topic #4 (0.200): 0.037*\"r\" + 0.034*\"sql\" + 0.032*\"python\" + 0.024*\"sas\" + 0.018*\"matlab\" + 0.018*\"excel\" + 0.016*\"tableau\" + 0.014*\"c++\" + 0.013*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.019775, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.701 per-word bound, 416.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3900/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3923/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3908/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.013*\"sql\" + 0.011*\"oracle\" + 0.011*\"hive\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"python\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.008*\"c\" + 0.008*\"r\"\n",
      "INFO : topic #1 (0.200): 0.034*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"hadoop\"\n",
      "INFO : topic #2 (0.200): 0.004*\"c++\" + 0.004*\"linux\" + 0.004*\"r\" + 0.004*\"computer\" + 0.003*\"project\" + 0.003*\"c\" + 0.003*\"windows\" + 0.003*\"data\" + 0.003*\"microsoft\" + 0.003*\"python\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #3 (0.200): 0.005*\"unix\" + 0.005*\"technical\" + 0.003*\"linux\" + 0.003*\"skills\" + 0.003*\"sql\" + 0.002*\"j.\" + 0.002*\"windows\" + 0.002*\"m.\" + 0.002*\"tableau\" + 0.002*\"s.\"\n",
      "INFO : topic #4 (0.200): 0.037*\"r\" + 0.034*\"sql\" + 0.032*\"python\" + 0.025*\"sas\" + 0.019*\"excel\" + 0.018*\"matlab\" + 0.016*\"tableau\" + 0.014*\"c++\" + 0.013*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.018023, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.698 per-word bound, 415.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3917/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.013*\"sql\" + 0.011*\"oracle\" + 0.011*\"hive\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"python\" + 0.009*\"pig\" + 0.008*\"hadoop\" + 0.008*\"c\" + 0.007*\"r\"\n",
      "INFO : topic #1 (0.200): 0.034*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.012*\"mysql\" + 0.012*\"hadoop\"\n",
      "INFO : topic #2 (0.200): 0.004*\"c++\" + 0.004*\"linux\" + 0.004*\"r\" + 0.004*\"computer\" + 0.003*\"project\" + 0.003*\"windows\" + 0.003*\"data\" + 0.003*\"c\" + 0.003*\"microsoft\" + 0.003*\"software\"\n",
      "INFO : topic #3 (0.200): 0.005*\"unix\" + 0.005*\"technical\" + 0.003*\"linux\" + 0.003*\"skills\" + 0.003*\"sql\" + 0.002*\"j.\" + 0.002*\"m.\" + 0.002*\"windows\" + 0.002*\"s.\" + 0.002*\"tableau\"\n",
      "INFO : topic #4 (0.200): 0.037*\"r\" + 0.034*\"sql\" + 0.031*\"python\" + 0.025*\"sas\" + 0.019*\"excel\" + 0.019*\"matlab\" + 0.016*\"tableau\" + 0.014*\"c++\" + 0.014*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.016481, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.696 per-word bound, 414.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3905/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3917/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.013*\"sql\" + 0.011*\"oracle\" + 0.010*\"hive\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"python\" + 0.009*\"pig\" + 0.008*\"hadoop\" + 0.008*\"c\" + 0.007*\"html\"\n",
      "INFO : topic #1 (0.200): 0.034*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.013*\"mysql\" + 0.013*\"hadoop\"\n",
      "INFO : topic #2 (0.200): 0.004*\"linux\" + 0.004*\"c++\" + 0.004*\"computer\" + 0.003*\"r\" + 0.003*\"project\" + 0.003*\"data\" + 0.003*\"windows\" + 0.003*\"c\" + 0.003*\"microsoft\" + 0.003*\"software\"\n",
      "INFO : topic #3 (0.200): 0.004*\"unix\" + 0.004*\"technical\" + 0.003*\"skills\" + 0.003*\"linux\" + 0.003*\"sql\" + 0.002*\"j.\" + 0.002*\"m.\" + 0.002*\"s.\" + 0.002*\"windows\" + 0.002*\"tableau\"\n",
      "INFO : topic #4 (0.200): 0.037*\"r\" + 0.034*\"sql\" + 0.031*\"python\" + 0.025*\"sas\" + 0.019*\"excel\" + 0.019*\"matlab\" + 0.016*\"tableau\" + 0.014*\"c++\" + 0.014*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.015176, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.693 per-word bound, 413.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.200): 0.013*\"sql\" + 0.011*\"oracle\" + 0.010*\"hive\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"python\" + 0.009*\"pig\" + 0.008*\"hadoop\" + 0.008*\"c\" + 0.007*\"html\"\n",
      "INFO : topic #1 (0.200): 0.034*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.013*\"hadoop\" + 0.013*\"mysql\"\n",
      "INFO : topic #2 (0.200): 0.004*\"linux\" + 0.004*\"c++\" + 0.004*\"computer\" + 0.003*\"project\" + 0.003*\"r\" + 0.003*\"data\" + 0.003*\"windows\" + 0.003*\"c\" + 0.003*\"microsoft\" + 0.002*\"software\"\n",
      "INFO : topic #3 (0.200): 0.004*\"unix\" + 0.004*\"technical\" + 0.003*\"skills\" + 0.003*\"linux\" + 0.002*\"sql\" + 0.002*\"j.\" + 0.002*\"m.\" + 0.002*\"s.\" + 0.002*\"windows\" + 0.002*\"d.\"\n",
      "INFO : topic #4 (0.200): 0.037*\"r\" + 0.034*\"sql\" + 0.031*\"python\" + 0.025*\"sas\" + 0.019*\"excel\" + 0.019*\"matlab\" + 0.016*\"tableau\" + 0.014*\"c++\" + 0.014*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.013999, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.691 per-word bound, 413.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.200): 0.013*\"sql\" + 0.011*\"oracle\" + 0.010*\"hive\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"pig\" + 0.009*\"python\" + 0.008*\"hadoop\" + 0.008*\"c\" + 0.007*\"html\"\n",
      "INFO : topic #1 (0.200): 0.034*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.013*\"tableau\" + 0.013*\"hadoop\" + 0.013*\"mysql\"\n",
      "INFO : topic #2 (0.200): 0.003*\"computer\" + 0.003*\"linux\" + 0.003*\"project\" + 0.003*\"c++\" + 0.003*\"r\" + 0.003*\"data\" + 0.003*\"windows\" + 0.003*\"c\" + 0.003*\"microsoft\" + 0.002*\"software\"\n",
      "INFO : topic #3 (0.200): 0.004*\"unix\" + 0.004*\"technical\" + 0.003*\"skills\" + 0.003*\"linux\" + 0.002*\"j.\" + 0.002*\"sql\" + 0.002*\"m.\" + 0.002*\"s.\" + 0.002*\"d.\" + 0.002*\"b.\"\n",
      "INFO : topic #4 (0.200): 0.037*\"r\" + 0.034*\"sql\" + 0.031*\"python\" + 0.025*\"sas\" + 0.019*\"excel\" + 0.019*\"matlab\" + 0.016*\"tableau\" + 0.014*\"spss\" + 0.014*\"c++\" + 0.012*\"technical\"\n",
      "INFO : topic diff=0.012975, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.689 per-word bound, 412.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=5, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=5, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (545 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 6; 448 documents processed (473 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (451 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (567 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (328 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (464 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (576 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (629 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (609 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (317 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (591 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (567 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (365 virtual)\n",
      "DEBUG : completed batch 9; 640 documents processed (673 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (449 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (685 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (708 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (440 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (708 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 9; 640 documents processed (774 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (440 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 6; 448 documents processed (755 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 5; 384 documents processed (392 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (774 virtual)\n",
      "DEBUG : completed batch 9; 597 documents processed (776 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (392 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (755 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 4; 320 documents processed (508 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 597 documents processed (776 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (513 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 5; 384 documents processed (493 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (592 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 10; 704 documents processed (893 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (449 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (672 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 256 documents processed (513 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 8; 576 documents processed (694 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (508 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (449 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 384 documents processed (385 virtual)\n",
      "DEBUG : finished all batches; 384 documents processed (493 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 704 documents processed (893 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (592 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 576 documents processed (672 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 576 documents processed (694 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9044 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12303/12537 documents converged within 50 iterations\n",
      " 13%|█▎        | 3/23 [01:13<08:12, 24.62s/it]INFO : using symmetric alpha at 0.16666666666666666\n",
      "INFO : using symmetric eta at 0.16666666666666666\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 6 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 394/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 2935/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3045/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 2917/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.167): 0.030*\"python\" + 0.024*\"r\" + 0.021*\"sql\" + 0.019*\"java\" + 0.016*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.012*\"tableau\" + 0.012*\"matlab\" + 0.010*\"mysql\"\n",
      "INFO : topic #0 (0.167): 0.020*\"r\" + 0.020*\"sql\" + 0.019*\"python\" + 0.011*\"hive\" + 0.010*\"hadoop\" + 0.009*\"java\" + 0.009*\"sas\" + 0.009*\"c++\" + 0.008*\"spark\" + 0.008*\"matlab\"\n",
      "INFO : topic #5 (0.167): 0.018*\"sql\" + 0.012*\"r\" + 0.011*\"python\" + 0.011*\"technical\" + 0.010*\"sas\" + 0.007*\"java\" + 0.007*\"tableau\" + 0.007*\"excel\" + 0.007*\"hadoop\" + 0.006*\"linux\"\n",
      "INFO : topic #4 (0.167): 0.027*\"sql\" + 0.027*\"python\" + 0.027*\"r\" + 0.014*\"matlab\" + 0.013*\"tableau\" + 0.013*\"technical\" + 0.012*\"sas\" + 0.012*\"hadoop\" + 0.011*\"c++\" + 0.011*\"c\"\n",
      "INFO : topic #3 (0.167): 0.015*\"python\" + 0.014*\"sql\" + 0.014*\"technical\" + 0.013*\"r\" + 0.010*\"unix\" + 0.008*\"java\" + 0.008*\"tableau\" + 0.007*\"linux\" + 0.006*\"hadoop\" + 0.006*\"c\"\n",
      "INFO : topic diff=3.645091, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.053 per-word bound, 531.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 499/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3611/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3648/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3663/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.167): 0.016*\"r\" + 0.013*\"python\" + 0.011*\"sql\" + 0.011*\"c++\" + 0.008*\"sas\" + 0.008*\"linux\" + 0.008*\"c\" + 0.007*\"java\" + 0.007*\"programming\" + 0.006*\"tableau\"\n",
      "INFO : topic #0 (0.167): 0.018*\"sql\" + 0.018*\"python\" + 0.018*\"r\" + 0.012*\"hive\" + 0.010*\"hadoop\" + 0.010*\"java\" + 0.008*\"c++\" + 0.008*\"spark\" + 0.008*\"pig\" + 0.008*\"sas\"\n",
      "INFO : topic #5 (0.167): 0.016*\"sql\" + 0.010*\"r\" + 0.010*\"technical\" + 0.010*\"sas\" + 0.009*\"python\" + 0.007*\"excel\" + 0.006*\"tableau\" + 0.006*\"java\" + 0.005*\"hadoop\" + 0.005*\"linux\"\n",
      "INFO : topic #1 (0.167): 0.031*\"python\" + 0.025*\"r\" + 0.022*\"sql\" + 0.020*\"java\" + 0.016*\"technical\" + 0.016*\"c++\" + 0.016*\"c\" + 0.012*\"tableau\" + 0.012*\"matlab\" + 0.011*\"mysql\"\n",
      "INFO : topic #3 (0.167): 0.012*\"sql\" + 0.012*\"technical\" + 0.012*\"python\" + 0.010*\"r\" + 0.009*\"unix\" + 0.007*\"tableau\" + 0.007*\"java\" + 0.007*\"linux\" + 0.005*\"c\" + 0.005*\"hadoop\"\n",
      "INFO : topic diff=0.298550, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.908 per-word bound, 480.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 518/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3765/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3730/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3785/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.167): 0.011*\"technical\" + 0.011*\"sql\" + 0.010*\"python\" + 0.009*\"unix\" + 0.009*\"r\" + 0.006*\"tableau\" + 0.006*\"linux\" + 0.006*\"java\" + 0.004*\"c\" + 0.004*\"skills\"\n",
      "INFO : topic #2 (0.167): 0.014*\"r\" + 0.011*\"python\" + 0.010*\"sql\" + 0.010*\"c++\" + 0.008*\"linux\" + 0.007*\"sas\" + 0.007*\"c\" + 0.006*\"java\" + 0.006*\"programming\" + 0.005*\"html\"\n",
      "INFO : topic #1 (0.167): 0.031*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.016*\"c++\" + 0.016*\"c\" + 0.013*\"tableau\" + 0.012*\"matlab\" + 0.011*\"mysql\"\n",
      "INFO : topic #5 (0.167): 0.014*\"sql\" + 0.009*\"technical\" + 0.009*\"r\" + 0.009*\"sas\" + 0.008*\"python\" + 0.007*\"excel\" + 0.005*\"tableau\" + 0.005*\"java\" + 0.004*\"hadoop\" + 0.004*\"access\"\n",
      "INFO : topic #4 (0.167): 0.032*\"r\" + 0.031*\"python\" + 0.030*\"sql\" + 0.016*\"sas\" + 0.016*\"matlab\" + 0.015*\"tableau\" + 0.013*\"technical\" + 0.013*\"c++\" + 0.012*\"excel\" + 0.011*\"hadoop\"\n",
      "INFO : topic diff=0.228447, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.839 per-word bound, 458.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3806/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3771/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3830/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.167): 0.013*\"sql\" + 0.009*\"technical\" + 0.008*\"sas\" + 0.007*\"r\" + 0.006*\"python\" + 0.006*\"excel\" + 0.004*\"tableau\" + 0.004*\"java\" + 0.004*\"access\" + 0.004*\"oracle\"\n",
      "INFO : topic #2 (0.167): 0.012*\"r\" + 0.010*\"python\" + 0.009*\"c++\" + 0.009*\"sql\" + 0.007*\"linux\" + 0.007*\"c\" + 0.007*\"sas\" + 0.006*\"java\" + 0.006*\"programming\" + 0.005*\"windows\"\n",
      "INFO : topic #1 (0.167): 0.032*\"python\" + 0.026*\"r\" + 0.023*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.016*\"c++\" + 0.016*\"c\" + 0.013*\"tableau\" + 0.012*\"matlab\" + 0.011*\"mysql\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #0 (0.167): 0.016*\"sql\" + 0.015*\"python\" + 0.014*\"r\" + 0.012*\"hive\" + 0.010*\"java\" + 0.010*\"hadoop\" + 0.009*\"pig\" + 0.008*\"technical\" + 0.008*\"oracle\" + 0.008*\"mysql\"\n",
      "INFO : topic #4 (0.167): 0.033*\"r\" + 0.032*\"python\" + 0.031*\"sql\" + 0.018*\"sas\" + 0.017*\"matlab\" + 0.015*\"tableau\" + 0.013*\"c++\" + 0.013*\"technical\" + 0.013*\"excel\" + 0.011*\"c\"\n",
      "INFO : topic diff=0.174852, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.800 per-word bound, 445.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3835/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3802/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3848/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.167): 0.035*\"r\" + 0.033*\"python\" + 0.032*\"sql\" + 0.019*\"sas\" + 0.018*\"matlab\" + 0.015*\"tableau\" + 0.014*\"c++\" + 0.013*\"excel\" + 0.013*\"technical\" + 0.011*\"spss\"\n",
      "INFO : topic #1 (0.167): 0.032*\"python\" + 0.026*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.016*\"c\" + 0.016*\"c++\" + 0.013*\"tableau\" + 0.012*\"matlab\" + 0.012*\"mysql\"\n",
      "INFO : topic #0 (0.167): 0.016*\"sql\" + 0.014*\"python\" + 0.013*\"r\" + 0.012*\"hive\" + 0.010*\"java\" + 0.010*\"hadoop\" + 0.009*\"pig\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.008*\"mysql\"\n",
      "INFO : topic #3 (0.167): 0.009*\"technical\" + 0.008*\"sql\" + 0.008*\"unix\" + 0.007*\"python\" + 0.006*\"r\" + 0.005*\"linux\" + 0.005*\"tableau\" + 0.004*\"java\" + 0.004*\"skills\" + 0.003*\"word\"\n",
      "INFO : topic #5 (0.167): 0.011*\"sql\" + 0.008*\"technical\" + 0.007*\"sas\" + 0.006*\"r\" + 0.006*\"excel\" + 0.005*\"python\" + 0.004*\"access\" + 0.004*\"tableau\" + 0.004*\"oracle\" + 0.004*\"powerpoint\"\n",
      "INFO : topic diff=0.133721, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.774 per-word bound, 437.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3822/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3875/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3872/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.167): 0.008*\"technical\" + 0.008*\"unix\" + 0.007*\"sql\" + 0.006*\"python\" + 0.005*\"r\" + 0.005*\"linux\" + 0.004*\"tableau\" + 0.004*\"java\" + 0.004*\"skills\" + 0.003*\"word\"\n",
      "INFO : topic #1 (0.167): 0.033*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.016*\"c\" + 0.016*\"c++\" + 0.013*\"tableau\" + 0.012*\"matlab\" + 0.012*\"mysql\"\n",
      "INFO : topic #5 (0.167): 0.010*\"sql\" + 0.007*\"technical\" + 0.006*\"sas\" + 0.005*\"excel\" + 0.005*\"r\" + 0.004*\"python\" + 0.004*\"access\" + 0.003*\"oracle\" + 0.003*\"tableau\" + 0.003*\"powerpoint\"\n",
      "INFO : topic #4 (0.167): 0.036*\"r\" + 0.033*\"python\" + 0.033*\"sql\" + 0.020*\"sas\" + 0.018*\"matlab\" + 0.016*\"tableau\" + 0.014*\"excel\" + 0.014*\"c++\" + 0.013*\"technical\" + 0.012*\"spss\"\n",
      "INFO : topic #2 (0.167): 0.010*\"r\" + 0.008*\"c++\" + 0.008*\"python\" + 0.007*\"sql\" + 0.007*\"linux\" + 0.006*\"c\" + 0.005*\"sas\" + 0.005*\"programming\" + 0.005*\"java\" + 0.005*\"windows\"\n",
      "INFO : topic diff=0.103337, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.756 per-word bound, 432.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3841/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3888/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3877/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.167): 0.033*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.016*\"c\" + 0.016*\"c++\" + 0.014*\"tableau\" + 0.012*\"matlab\" + 0.012*\"mysql\"\n",
      "INFO : topic #2 (0.167): 0.009*\"r\" + 0.008*\"c++\" + 0.007*\"python\" + 0.006*\"sql\" + 0.006*\"linux\" + 0.005*\"c\" + 0.005*\"sas\" + 0.004*\"windows\" + 0.004*\"programming\" + 0.004*\"computer\"\n",
      "INFO : topic #0 (0.167): 0.015*\"sql\" + 0.013*\"python\" + 0.012*\"hive\" + 0.011*\"r\" + 0.010*\"java\" + 0.010*\"hadoop\" + 0.010*\"pig\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.008*\"c\"\n",
      "INFO : topic #5 (0.167): 0.009*\"sql\" + 0.007*\"technical\" + 0.006*\"sas\" + 0.005*\"excel\" + 0.004*\"r\" + 0.004*\"python\" + 0.003*\"access\" + 0.003*\"oracle\" + 0.003*\"powerpoint\" + 0.003*\"unix\"\n",
      "INFO : topic #4 (0.167): 0.036*\"r\" + 0.034*\"python\" + 0.033*\"sql\" + 0.021*\"sas\" + 0.019*\"matlab\" + 0.016*\"tableau\" + 0.015*\"excel\" + 0.014*\"c++\" + 0.013*\"technical\" + 0.012*\"spss\"\n",
      "INFO : topic diff=0.080888, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.742 per-word bound, 428.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3862/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3876/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3883/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.167): 0.008*\"r\" + 0.007*\"c++\" + 0.006*\"python\" + 0.006*\"linux\" + 0.006*\"sql\" + 0.005*\"c\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"programming\" + 0.004*\"sas\"\n",
      "INFO : topic #1 (0.167): 0.034*\"python\" + 0.027*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.016*\"c\" + 0.016*\"c++\" + 0.014*\"tableau\" + 0.012*\"matlab\" + 0.012*\"mysql\"\n",
      "INFO : topic #3 (0.167): 0.007*\"technical\" + 0.007*\"unix\" + 0.006*\"sql\" + 0.004*\"linux\" + 0.004*\"python\" + 0.004*\"r\" + 0.004*\"tableau\" + 0.003*\"skills\" + 0.003*\"word\" + 0.003*\"windows\"\n",
      "INFO : topic #5 (0.167): 0.009*\"sql\" + 0.007*\"technical\" + 0.005*\"sas\" + 0.005*\"excel\" + 0.004*\"r\" + 0.003*\"access\" + 0.003*\"oracle\" + 0.003*\"python\" + 0.003*\"powerpoint\" + 0.003*\"k\"\n",
      "INFO : topic #0 (0.167): 0.014*\"sql\" + 0.012*\"hive\" + 0.012*\"python\" + 0.011*\"r\" + 0.010*\"java\" + 0.010*\"oracle\" + 0.010*\"pig\" + 0.010*\"hadoop\" + 0.009*\"technical\" + 0.008*\"c\"\n",
      "INFO : topic diff=0.064195, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.731 per-word bound, 424.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3869/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3887/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3875/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.167): 0.038*\"r\" + 0.034*\"python\" + 0.034*\"sql\" + 0.022*\"sas\" + 0.019*\"matlab\" + 0.017*\"excel\" + 0.016*\"tableau\" + 0.015*\"c++\" + 0.013*\"spss\" + 0.013*\"technical\"\n",
      "INFO : topic #1 (0.167): 0.034*\"python\" + 0.027*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.012*\"matlab\" + 0.012*\"mysql\"\n",
      "INFO : topic #2 (0.167): 0.008*\"r\" + 0.007*\"c++\" + 0.006*\"python\" + 0.006*\"linux\" + 0.005*\"sql\" + 0.005*\"c\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"programming\" + 0.004*\"sas\"\n",
      "INFO : topic #0 (0.167): 0.014*\"sql\" + 0.012*\"hive\" + 0.011*\"python\" + 0.010*\"java\" + 0.010*\"r\" + 0.010*\"oracle\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.009*\"technical\" + 0.008*\"c\"\n",
      "INFO : topic #5 (0.167): 0.008*\"sql\" + 0.006*\"technical\" + 0.005*\"sas\" + 0.004*\"excel\" + 0.003*\"r\" + 0.003*\"access\" + 0.003*\"oracle\" + 0.003*\"stat\" + 0.003*\"k\" + 0.003*\"powerpoint\"\n",
      "INFO : topic diff=0.051936, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.722 per-word bound, 422.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3876/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3905/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3890/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.167): 0.034*\"python\" + 0.028*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.012*\"hadoop\" + 0.012*\"mysql\"\n",
      "INFO : topic #2 (0.167): 0.007*\"r\" + 0.007*\"c++\" + 0.005*\"linux\" + 0.005*\"python\" + 0.005*\"sql\" + 0.005*\"c\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"programming\" + 0.003*\"sas\"\n",
      "INFO : topic #0 (0.167): 0.014*\"sql\" + 0.012*\"hive\" + 0.011*\"python\" + 0.010*\"java\" + 0.010*\"oracle\" + 0.010*\"r\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.009*\"technical\" + 0.008*\"c\"\n",
      "INFO : topic #5 (0.167): 0.007*\"sql\" + 0.006*\"technical\" + 0.004*\"sas\" + 0.004*\"excel\" + 0.003*\"access\" + 0.003*\"oracle\" + 0.003*\"r\" + 0.003*\"stat\" + 0.003*\"k\" + 0.002*\"skills\"\n",
      "INFO : topic #4 (0.167): 0.038*\"r\" + 0.034*\"sql\" + 0.034*\"python\" + 0.023*\"sas\" + 0.019*\"matlab\" + 0.017*\"excel\" + 0.016*\"tableau\" + 0.015*\"c++\" + 0.013*\"spss\" + 0.013*\"technical\"\n",
      "INFO : topic diff=0.042829, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.715 per-word bound, 420.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3887/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3905/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3917/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.167): 0.006*\"r\" + 0.006*\"c++\" + 0.005*\"linux\" + 0.005*\"python\" + 0.004*\"c\" + 0.004*\"sql\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"programming\" + 0.003*\"microsoft\"\n",
      "INFO : topic #3 (0.167): 0.006*\"unix\" + 0.006*\"technical\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"r\" + 0.003*\"windows\" + 0.002*\"python\" + 0.002*\"word\"\n",
      "INFO : topic #5 (0.167): 0.007*\"sql\" + 0.006*\"technical\" + 0.004*\"sas\" + 0.004*\"excel\" + 0.003*\"stat\" + 0.003*\"access\" + 0.003*\"oracle\" + 0.003*\"r\" + 0.002*\"k\" + 0.002*\"skills\"\n",
      "INFO : topic #1 (0.167): 0.034*\"python\" + 0.028*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.012*\"hadoop\" + 0.012*\"mysql\"\n",
      "INFO : topic #0 (0.167): 0.014*\"sql\" + 0.012*\"hive\" + 0.011*\"python\" + 0.010*\"java\" + 0.010*\"oracle\" + 0.009*\"pig\" + 0.009*\"technical\" + 0.009*\"hadoop\" + 0.009*\"r\" + 0.009*\"c\"\n",
      "INFO : topic diff=0.036002, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.709 per-word bound, 418.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3877/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3910/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.167): 0.014*\"sql\" + 0.012*\"hive\" + 0.010*\"oracle\" + 0.010*\"java\" + 0.010*\"python\" + 0.009*\"pig\" + 0.009*\"technical\" + 0.009*\"hadoop\" + 0.009*\"r\" + 0.009*\"c\"\n",
      "INFO : topic #2 (0.167): 0.006*\"c++\" + 0.006*\"r\" + 0.005*\"linux\" + 0.004*\"python\" + 0.004*\"c\" + 0.004*\"computer\" + 0.004*\"sql\" + 0.004*\"windows\" + 0.003*\"microsoft\" + 0.003*\"programming\"\n",
      "INFO : topic #3 (0.167): 0.006*\"unix\" + 0.006*\"technical\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"windows\" + 0.002*\"r\" + 0.002*\"word\" + 0.002*\"python\"\n",
      "INFO : topic #5 (0.167): 0.006*\"sql\" + 0.006*\"technical\" + 0.004*\"sas\" + 0.004*\"excel\" + 0.003*\"stat\" + 0.003*\"access\" + 0.003*\"oracle\" + 0.002*\"k\" + 0.002*\"skills\" + 0.002*\"taleo\"\n",
      "INFO : topic #4 (0.167): 0.039*\"r\" + 0.035*\"sql\" + 0.034*\"python\" + 0.024*\"sas\" + 0.020*\"matlab\" + 0.018*\"excel\" + 0.016*\"tableau\" + 0.015*\"c++\" + 0.013*\"spss\" + 0.013*\"technical\"\n",
      "INFO : topic diff=0.030701, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.703 per-word bound, 416.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.167): 0.035*\"python\" + 0.028*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.013*\"hadoop\" + 0.012*\"mysql\"\n",
      "INFO : topic #5 (0.167): 0.006*\"sql\" + 0.005*\"technical\" + 0.004*\"sas\" + 0.003*\"excel\" + 0.003*\"stat\" + 0.003*\"access\" + 0.003*\"oracle\" + 0.002*\"skills\" + 0.002*\"k\" + 0.002*\"taleo\"\n",
      "INFO : topic #3 (0.167): 0.006*\"unix\" + 0.005*\"technical\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.002*\"windows\" + 0.002*\"j.\" + 0.002*\"r\" + 0.002*\"word\"\n",
      "INFO : topic #0 (0.167): 0.013*\"sql\" + 0.011*\"hive\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.010*\"python\" + 0.009*\"technical\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.009*\"c\" + 0.008*\"r\"\n",
      "INFO : topic #4 (0.167): 0.039*\"r\" + 0.035*\"sql\" + 0.034*\"python\" + 0.024*\"sas\" + 0.020*\"matlab\" + 0.019*\"excel\" + 0.016*\"tableau\" + 0.015*\"c++\" + 0.014*\"spss\" + 0.013*\"technical\"\n",
      "INFO : topic diff=0.026669, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.698 per-word bound, 415.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.167): 0.039*\"r\" + 0.035*\"sql\" + 0.034*\"python\" + 0.025*\"sas\" + 0.020*\"matlab\" + 0.019*\"excel\" + 0.016*\"tableau\" + 0.015*\"c++\" + 0.014*\"spss\" + 0.013*\"technical\"\n",
      "INFO : topic #5 (0.167): 0.006*\"sql\" + 0.005*\"technical\" + 0.003*\"sas\" + 0.003*\"excel\" + 0.003*\"stat\" + 0.002*\"oracle\" + 0.002*\"access\" + 0.002*\"taleo\" + 0.002*\"skills\" + 0.002*\"k\"\n",
      "INFO : topic #0 (0.167): 0.013*\"sql\" + 0.011*\"hive\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.010*\"python\" + 0.009*\"technical\" + 0.009*\"pig\" + 0.009*\"hadoop\" + 0.009*\"c\" + 0.008*\"r\"\n",
      "INFO : topic #3 (0.167): 0.006*\"unix\" + 0.005*\"technical\" + 0.003*\"linux\" + 0.003*\"sql\" + 0.003*\"skills\" + 0.002*\"tableau\" + 0.002*\"windows\" + 0.002*\"j.\" + 0.002*\"macintosh_hd\" + 0.002*\"word\"\n",
      "INFO : topic #2 (0.167): 0.006*\"c++\" + 0.005*\"r\" + 0.004*\"linux\" + 0.004*\"computer\" + 0.004*\"c\" + 0.004*\"python\" + 0.003*\"windows\" + 0.003*\"microsoft\" + 0.003*\"data\" + 0.003*\"programming\"\n",
      "INFO : topic diff=0.023415, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.694 per-word bound, 414.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3916/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.167): 0.005*\"sql\" + 0.005*\"technical\" + 0.003*\"stat\" + 0.003*\"sas\" + 0.003*\"excel\" + 0.002*\"oracle\" + 0.002*\"taleo\" + 0.002*\"access\" + 0.002*\"skills\" + 0.002*\"graph\"\n",
      "INFO : topic #1 (0.167): 0.035*\"python\" + 0.028*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.013*\"hadoop\" + 0.012*\"mysql\"\n",
      "INFO : topic #0 (0.167): 0.013*\"sql\" + 0.011*\"hive\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.010*\"technical\" + 0.009*\"python\" + 0.009*\"pig\" + 0.009*\"c\" + 0.009*\"hadoop\" + 0.008*\"html\"\n",
      "INFO : topic #2 (0.167): 0.005*\"c++\" + 0.005*\"r\" + 0.004*\"linux\" + 0.004*\"computer\" + 0.004*\"c\" + 0.003*\"python\" + 0.003*\"microsoft\" + 0.003*\"windows\" + 0.003*\"data\" + 0.003*\"programming\"\n",
      "INFO : topic #3 (0.167): 0.006*\"unix\" + 0.005*\"technical\" + 0.003*\"linux\" + 0.003*\"sql\" + 0.003*\"skills\" + 0.002*\"j.\" + 0.002*\"windows\" + 0.002*\"tableau\" + 0.002*\"macintosh_hd\" + 0.002*\"m.\"\n",
      "INFO : topic diff=0.020915, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.690 per-word bound, 413.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.167): 0.006*\"unix\" + 0.005*\"technical\" + 0.003*\"linux\" + 0.003*\"skills\" + 0.003*\"sql\" + 0.002*\"j.\" + 0.002*\"windows\" + 0.002*\"tableau\" + 0.002*\"macintosh_hd\" + 0.002*\"m.\"\n",
      "INFO : topic #5 (0.167): 0.005*\"sql\" + 0.005*\"technical\" + 0.003*\"stat\" + 0.003*\"sas\" + 0.003*\"excel\" + 0.002*\"taleo\" + 0.002*\"skills\" + 0.002*\"oracle\" + 0.002*\"graph\" + 0.002*\"access\"\n",
      "INFO : topic #0 (0.167): 0.013*\"sql\" + 0.011*\"hive\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.010*\"technical\" + 0.009*\"python\" + 0.009*\"pig\" + 0.009*\"c\" + 0.009*\"hadoop\" + 0.008*\"html\"\n",
      "INFO : topic #1 (0.167): 0.035*\"python\" + 0.028*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.013*\"hadoop\" + 0.012*\"mysql\"\n",
      "INFO : topic #4 (0.167): 0.039*\"r\" + 0.035*\"sql\" + 0.034*\"python\" + 0.025*\"sas\" + 0.020*\"matlab\" + 0.020*\"excel\" + 0.017*\"tableau\" + 0.015*\"c++\" + 0.014*\"spss\" + 0.013*\"technical\"\n",
      "INFO : topic diff=0.018878, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.687 per-word bound, 412.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.167): 0.035*\"python\" + 0.029*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.014*\"hadoop\" + 0.012*\"mysql\"\n",
      "INFO : topic #5 (0.167): 0.005*\"sql\" + 0.005*\"technical\" + 0.003*\"stat\" + 0.003*\"sas\" + 0.003*\"excel\" + 0.002*\"taleo\" + 0.002*\"skills\" + 0.002*\"graph\" + 0.002*\"oracle\" + 0.002*\"access\"\n",
      "INFO : topic #2 (0.167): 0.005*\"c++\" + 0.004*\"r\" + 0.004*\"linux\" + 0.004*\"computer\" + 0.003*\"microsoft\" + 0.003*\"c\" + 0.003*\"windows\" + 0.003*\"data\" + 0.003*\"python\" + 0.003*\"project\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #3 (0.167): 0.005*\"unix\" + 0.004*\"technical\" + 0.003*\"skills\" + 0.003*\"linux\" + 0.003*\"sql\" + 0.002*\"j.\" + 0.002*\"m.\" + 0.002*\"macintosh_hd\" + 0.002*\"windows\" + 0.002*\"s.\"\n",
      "INFO : topic #4 (0.167): 0.040*\"r\" + 0.035*\"sql\" + 0.034*\"python\" + 0.025*\"sas\" + 0.020*\"matlab\" + 0.020*\"excel\" + 0.017*\"tableau\" + 0.015*\"c++\" + 0.014*\"spss\" + 0.013*\"technical\"\n",
      "INFO : topic diff=0.017172, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.684 per-word bound, 411.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.167): 0.035*\"python\" + 0.029*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.014*\"hadoop\" + 0.012*\"mysql\"\n",
      "INFO : topic #5 (0.167): 0.004*\"technical\" + 0.004*\"sql\" + 0.003*\"stat\" + 0.003*\"excel\" + 0.003*\"sas\" + 0.002*\"taleo\" + 0.002*\"graph\" + 0.002*\"skills\" + 0.002*\"oracle\" + 0.002*\"core\"\n",
      "INFO : topic #4 (0.167): 0.040*\"r\" + 0.035*\"sql\" + 0.034*\"python\" + 0.025*\"sas\" + 0.020*\"excel\" + 0.020*\"matlab\" + 0.017*\"tableau\" + 0.015*\"c++\" + 0.014*\"spss\" + 0.013*\"technical\"\n",
      "INFO : topic #2 (0.167): 0.005*\"c++\" + 0.004*\"r\" + 0.004*\"linux\" + 0.004*\"computer\" + 0.003*\"microsoft\" + 0.003*\"c\" + 0.003*\"data\" + 0.003*\"windows\" + 0.003*\"project\" + 0.003*\"python\"\n",
      "INFO : topic #0 (0.167): 0.013*\"sql\" + 0.011*\"oracle\" + 0.011*\"hive\" + 0.011*\"java\" + 0.010*\"technical\" + 0.009*\"c\" + 0.009*\"pig\" + 0.009*\"python\" + 0.009*\"hadoop\" + 0.008*\"html\"\n",
      "INFO : topic diff=0.015718, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.681 per-word bound, 410.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.167): 0.005*\"c++\" + 0.004*\"linux\" + 0.004*\"r\" + 0.004*\"computer\" + 0.003*\"microsoft\" + 0.003*\"c\" + 0.003*\"data\" + 0.003*\"windows\" + 0.003*\"project\" + 0.003*\"software\"\n",
      "INFO : topic #4 (0.167): 0.040*\"r\" + 0.035*\"sql\" + 0.034*\"python\" + 0.026*\"sas\" + 0.021*\"excel\" + 0.020*\"matlab\" + 0.017*\"tableau\" + 0.015*\"c++\" + 0.014*\"spss\" + 0.013*\"technical\"\n",
      "INFO : topic #3 (0.167): 0.005*\"unix\" + 0.004*\"technical\" + 0.003*\"skills\" + 0.003*\"linux\" + 0.003*\"j.\" + 0.002*\"sql\" + 0.002*\"m.\" + 0.002*\"s.\" + 0.002*\"d.\" + 0.002*\"macintosh_hd\"\n",
      "INFO : topic #5 (0.167): 0.004*\"technical\" + 0.004*\"sql\" + 0.003*\"stat\" + 0.002*\"taleo\" + 0.002*\"excel\" + 0.002*\"sas\" + 0.002*\"graph\" + 0.002*\"skills\" + 0.002*\"core\" + 0.002*\"key\"\n",
      "INFO : topic #0 (0.167): 0.013*\"sql\" + 0.011*\"oracle\" + 0.011*\"hive\" + 0.011*\"java\" + 0.010*\"technical\" + 0.009*\"c\" + 0.009*\"pig\" + 0.009*\"python\" + 0.009*\"hadoop\" + 0.008*\"html\"\n",
      "INFO : topic diff=0.014489, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.679 per-word bound, 410.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.167): 0.004*\"c++\" + 0.004*\"linux\" + 0.003*\"r\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"data\" + 0.003*\"c\" + 0.003*\"project\" + 0.003*\"windows\" + 0.003*\"core\"\n",
      "INFO : topic #1 (0.167): 0.036*\"python\" + 0.029*\"r\" + 0.025*\"sql\" + 0.020*\"java\" + 0.017*\"technical\" + 0.015*\"c++\" + 0.015*\"c\" + 0.014*\"tableau\" + 0.014*\"hadoop\" + 0.012*\"spark\"\n",
      "INFO : topic #3 (0.167): 0.005*\"unix\" + 0.004*\"technical\" + 0.003*\"skills\" + 0.003*\"j.\" + 0.003*\"linux\" + 0.002*\"sql\" + 0.002*\"m.\" + 0.002*\"d.\" + 0.002*\"s.\" + 0.002*\"macintosh_hd\"\n",
      "INFO : topic #4 (0.167): 0.040*\"r\" + 0.035*\"sql\" + 0.034*\"python\" + 0.026*\"sas\" + 0.021*\"excel\" + 0.020*\"matlab\" + 0.017*\"tableau\" + 0.015*\"c++\" + 0.014*\"spss\" + 0.012*\"technical\"\n",
      "INFO : topic #0 (0.167): 0.013*\"sql\" + 0.011*\"oracle\" + 0.011*\"hive\" + 0.011*\"java\" + 0.010*\"technical\" + 0.009*\"c\" + 0.009*\"pig\" + 0.009*\"python\" + 0.009*\"hadoop\" + 0.008*\"html\"\n",
      "INFO : topic diff=0.013368, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.678 per-word bound, 409.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=6, decay=0.5, chunksize=4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=6, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (400 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (435 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (513 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (439 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (200 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (452 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (612 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (499 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (602 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (525 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (644 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (622 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (514 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (721 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (721 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (677 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (676 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (525 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (677 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (676 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (705 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 466 documents processed (536 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (525 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 3; 256 documents processed (265 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (438 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (642 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (705 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 576 documents processed (864 virtual)\n",
      "DEBUG : finished all batches; 466 documents processed (536 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (438 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 512 documents processed (642 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (864 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 9; 640 documents processed (686 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (514 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 256 documents processed (265 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 576 documents processed (576 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (650 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 640 documents processed (686 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (630 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (650 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (630 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (576 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9105 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12351/12537 documents converged within 50 iterations\n",
      " 17%|█▋        | 4/23 [01:38<07:47, 24.60s/it]INFO : using symmetric alpha at 0.14285714285714285\n",
      "INFO : using symmetric eta at 0.14285714285714285\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 7 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 414/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3089/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3008/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3040/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.143): 0.027*\"sql\" + 0.025*\"python\" + 0.024*\"r\" + 0.013*\"matlab\" + 0.013*\"tableau\" + 0.012*\"technical\" + 0.011*\"c++\" + 0.011*\"java\" + 0.011*\"hadoop\" + 0.011*\"c\"\n",
      "INFO : topic #1 (0.143): 0.029*\"python\" + 0.022*\"r\" + 0.021*\"sql\" + 0.021*\"java\" + 0.017*\"technical\" + 0.016*\"c\" + 0.015*\"c++\" + 0.011*\"tableau\" + 0.011*\"matlab\" + 0.010*\"html\"\n",
      "INFO : topic #2 (0.143): 0.015*\"r\" + 0.013*\"python\" + 0.013*\"sql\" + 0.011*\"c++\" + 0.008*\"c\" + 0.008*\"linux\" + 0.007*\"java\" + 0.007*\"hive\" + 0.007*\"sas\" + 0.007*\"tableau\"\n",
      "INFO : topic #0 (0.143): 0.019*\"sql\" + 0.017*\"python\" + 0.017*\"r\" + 0.012*\"hive\" + 0.010*\"java\" + 0.010*\"hadoop\" + 0.009*\"c++\" + 0.008*\"html\" + 0.008*\"technical\" + 0.008*\"javascript\"\n",
      "INFO : topic #6 (0.143): 0.027*\"python\" + 0.026*\"r\" + 0.020*\"sql\" + 0.016*\"sas\" + 0.012*\"matlab\" + 0.012*\"tableau\" + 0.011*\"technical\" + 0.011*\"c++\" + 0.011*\"mysql\" + 0.010*\"java\"\n",
      "INFO : topic diff=4.362486, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.087 per-word bound, 543.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 505/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3682/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3698/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3699/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.143): 0.018*\"sql\" + 0.015*\"python\" + 0.014*\"r\" + 0.011*\"hive\" + 0.010*\"java\" + 0.009*\"hadoop\" + 0.008*\"technical\" + 0.008*\"html\" + 0.008*\"c++\" + 0.008*\"javascript\"\n",
      "INFO : topic #4 (0.143): 0.028*\"sql\" + 0.026*\"python\" + 0.025*\"r\" + 0.014*\"matlab\" + 0.013*\"tableau\" + 0.012*\"technical\" + 0.012*\"c++\" + 0.011*\"java\" + 0.011*\"c\" + 0.011*\"sas\"\n",
      "INFO : topic #5 (0.143): 0.016*\"sql\" + 0.009*\"r\" + 0.008*\"technical\" + 0.008*\"excel\" + 0.008*\"sas\" + 0.008*\"python\" + 0.006*\"java\" + 0.006*\"tableau\" + 0.005*\"powerpoint\" + 0.005*\"access\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.023*\"r\" + 0.022*\"java\" + 0.022*\"sql\" + 0.017*\"c\" + 0.017*\"technical\" + 0.016*\"c++\" + 0.011*\"html\" + 0.011*\"matlab\" + 0.011*\"tableau\"\n",
      "INFO : topic #6 (0.143): 0.028*\"python\" + 0.028*\"r\" + 0.022*\"sql\" + 0.016*\"sas\" + 0.013*\"tableau\" + 0.012*\"matlab\" + 0.012*\"technical\" + 0.011*\"c++\" + 0.010*\"mysql\" + 0.010*\"hadoop\"\n",
      "INFO : topic diff=0.308454, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.929 per-word bound, 487.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 516/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3797/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3783/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3838/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.023*\"java\" + 0.023*\"r\" + 0.022*\"sql\" + 0.018*\"c\" + 0.017*\"c++\" + 0.017*\"technical\" + 0.012*\"html\" + 0.012*\"matlab\" + 0.010*\"tableau\"\n",
      "INFO : topic #5 (0.143): 0.014*\"sql\" + 0.008*\"r\" + 0.008*\"excel\" + 0.007*\"technical\" + 0.007*\"sas\" + 0.006*\"python\" + 0.005*\"access\" + 0.005*\"powerpoint\" + 0.005*\"tableau\" + 0.005*\"java\"\n",
      "INFO : topic #2 (0.143): 0.011*\"r\" + 0.010*\"sql\" + 0.009*\"python\" + 0.009*\"c++\" + 0.007*\"c\" + 0.006*\"linux\" + 0.005*\"java\" + 0.005*\"sas\" + 0.005*\"hive\" + 0.005*\"html\"\n",
      "INFO : topic #6 (0.143): 0.029*\"python\" + 0.029*\"r\" + 0.024*\"sql\" + 0.016*\"sas\" + 0.014*\"tableau\" + 0.013*\"technical\" + 0.012*\"matlab\" + 0.011*\"hadoop\" + 0.011*\"c++\" + 0.010*\"mysql\"\n",
      "INFO : topic #4 (0.143): 0.028*\"sql\" + 0.026*\"python\" + 0.026*\"r\" + 0.014*\"matlab\" + 0.012*\"tableau\" + 0.012*\"c++\" + 0.012*\"sas\" + 0.012*\"technical\" + 0.011*\"java\" + 0.011*\"c\"\n",
      "INFO : topic diff=0.240795, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.847 per-word bound, 460.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 522/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3830/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3867/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3831/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.143): 0.030*\"python\" + 0.030*\"r\" + 0.025*\"sql\" + 0.016*\"sas\" + 0.015*\"tableau\" + 0.013*\"technical\" + 0.013*\"matlab\" + 0.012*\"hadoop\" + 0.011*\"c++\" + 0.010*\"java\"\n",
      "INFO : topic #5 (0.143): 0.013*\"sql\" + 0.008*\"excel\" + 0.007*\"r\" + 0.007*\"technical\" + 0.007*\"sas\" + 0.005*\"access\" + 0.005*\"powerpoint\" + 0.005*\"python\" + 0.004*\"tableau\" + 0.004*\"java\"\n",
      "INFO : topic #3 (0.143): 0.009*\"technical\" + 0.008*\"sql\" + 0.007*\"unix\" + 0.006*\"python\" + 0.005*\"r\" + 0.005*\"tableau\" + 0.005*\"linux\" + 0.004*\"java\" + 0.004*\"word\" + 0.004*\"windows\"\n",
      "INFO : topic #0 (0.143): 0.015*\"sql\" + 0.012*\"python\" + 0.011*\"r\" + 0.010*\"hive\" + 0.010*\"java\" + 0.009*\"oracle\" + 0.008*\"technical\" + 0.008*\"html\" + 0.008*\"hadoop\" + 0.008*\"c\"\n",
      "INFO : topic #4 (0.143): 0.028*\"sql\" + 0.027*\"python\" + 0.027*\"r\" + 0.015*\"matlab\" + 0.013*\"sas\" + 0.013*\"c++\" + 0.012*\"tableau\" + 0.011*\"technical\" + 0.011*\"excel\" + 0.011*\"java\"\n",
      "INFO : topic diff=0.186118, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.801 per-word bound, 446.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3858/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3864/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3863/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.143): 0.014*\"sql\" + 0.011*\"python\" + 0.010*\"r\" + 0.010*\"java\" + 0.010*\"hive\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.008*\"html\" + 0.008*\"hadoop\" + 0.008*\"c\"\n",
      "INFO : topic #5 (0.143): 0.011*\"sql\" + 0.007*\"excel\" + 0.006*\"technical\" + 0.006*\"sas\" + 0.006*\"r\" + 0.005*\"access\" + 0.005*\"powerpoint\" + 0.004*\"python\" + 0.004*\"tableau\" + 0.003*\"oracle\"\n",
      "INFO : topic #2 (0.143): 0.009*\"r\" + 0.008*\"c++\" + 0.007*\"sql\" + 0.007*\"python\" + 0.005*\"linux\" + 0.005*\"c\" + 0.004*\"computer\" + 0.004*\"java\" + 0.004*\"windows\" + 0.004*\"sas\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #4 (0.143): 0.029*\"sql\" + 0.027*\"r\" + 0.027*\"python\" + 0.015*\"matlab\" + 0.014*\"sas\" + 0.013*\"c++\" + 0.012*\"excel\" + 0.012*\"tableau\" + 0.011*\"spss\" + 0.011*\"technical\"\n",
      "INFO : topic #3 (0.143): 0.008*\"technical\" + 0.007*\"sql\" + 0.006*\"unix\" + 0.005*\"linux\" + 0.005*\"python\" + 0.005*\"tableau\" + 0.004*\"r\" + 0.004*\"word\" + 0.004*\"windows\" + 0.004*\"java\"\n",
      "INFO : topic diff=0.144224, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.771 per-word bound, 436.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3880/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3881/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3879/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.143): 0.010*\"sql\" + 0.007*\"excel\" + 0.006*\"technical\" + 0.006*\"sas\" + 0.005*\"r\" + 0.005*\"access\" + 0.005*\"powerpoint\" + 0.003*\"tableau\" + 0.003*\"python\" + 0.003*\"word\"\n",
      "INFO : topic #0 (0.143): 0.014*\"sql\" + 0.010*\"python\" + 0.010*\"java\" + 0.010*\"hive\" + 0.009*\"oracle\" + 0.009*\"r\" + 0.009*\"technical\" + 0.008*\"html\" + 0.008*\"c\" + 0.008*\"hadoop\"\n",
      "INFO : topic #2 (0.143): 0.008*\"r\" + 0.007*\"c++\" + 0.007*\"sql\" + 0.006*\"python\" + 0.005*\"linux\" + 0.005*\"c\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"data\" + 0.004*\"java\"\n",
      "INFO : topic #4 (0.143): 0.029*\"sql\" + 0.027*\"r\" + 0.027*\"python\" + 0.015*\"matlab\" + 0.015*\"sas\" + 0.014*\"excel\" + 0.013*\"c++\" + 0.012*\"tableau\" + 0.012*\"spss\" + 0.011*\"technical\"\n",
      "INFO : topic #3 (0.143): 0.008*\"technical\" + 0.006*\"sql\" + 0.006*\"unix\" + 0.005*\"linux\" + 0.004*\"tableau\" + 0.004*\"python\" + 0.004*\"windows\" + 0.004*\"r\" + 0.004*\"word\" + 0.003*\"skills\"\n",
      "INFO : topic diff=0.111995, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.751 per-word bound, 431.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3883/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3893/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.143): 0.013*\"sql\" + 0.010*\"java\" + 0.009*\"oracle\" + 0.009*\"hive\" + 0.009*\"python\" + 0.009*\"technical\" + 0.008*\"html\" + 0.008*\"r\" + 0.008*\"c\" + 0.008*\"hadoop\"\n",
      "INFO : topic #3 (0.143): 0.007*\"technical\" + 0.006*\"unix\" + 0.006*\"sql\" + 0.005*\"linux\" + 0.004*\"tableau\" + 0.004*\"windows\" + 0.003*\"word\" + 0.003*\"python\" + 0.003*\"skills\" + 0.003*\"r\"\n",
      "INFO : topic #6 (0.143): 0.032*\"python\" + 0.032*\"r\" + 0.027*\"sql\" + 0.017*\"tableau\" + 0.016*\"sas\" + 0.015*\"technical\" + 0.014*\"hadoop\" + 0.013*\"matlab\" + 0.011*\"hive\" + 0.011*\"spark\"\n",
      "INFO : topic #4 (0.143): 0.029*\"sql\" + 0.028*\"r\" + 0.027*\"python\" + 0.016*\"sas\" + 0.015*\"matlab\" + 0.015*\"excel\" + 0.013*\"c++\" + 0.012*\"tableau\" + 0.012*\"spss\" + 0.010*\"technical\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.025*\"java\" + 0.022*\"r\" + 0.021*\"sql\" + 0.020*\"c\" + 0.020*\"c++\" + 0.016*\"technical\" + 0.015*\"html\" + 0.014*\"javascript\" + 0.012*\"matlab\"\n",
      "INFO : topic diff=0.087458, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.737 per-word bound, 426.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3892/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.143): 0.033*\"python\" + 0.032*\"r\" + 0.027*\"sql\" + 0.017*\"tableau\" + 0.016*\"sas\" + 0.015*\"technical\" + 0.014*\"hadoop\" + 0.013*\"matlab\" + 0.012*\"hive\" + 0.011*\"spark\"\n",
      "INFO : topic #3 (0.143): 0.007*\"technical\" + 0.006*\"unix\" + 0.005*\"sql\" + 0.004*\"linux\" + 0.004*\"windows\" + 0.004*\"tableau\" + 0.003*\"word\" + 0.003*\"skills\" + 0.003*\"python\" + 0.003*\"project\"\n",
      "INFO : topic #4 (0.143): 0.029*\"sql\" + 0.028*\"r\" + 0.027*\"python\" + 0.016*\"sas\" + 0.016*\"excel\" + 0.015*\"matlab\" + 0.013*\"c++\" + 0.012*\"spss\" + 0.012*\"tableau\" + 0.010*\"technical\"\n",
      "INFO : topic #5 (0.143): 0.009*\"sql\" + 0.006*\"excel\" + 0.005*\"technical\" + 0.005*\"sas\" + 0.004*\"access\" + 0.004*\"powerpoint\" + 0.004*\"r\" + 0.003*\"tableau\" + 0.003*\"key\" + 0.003*\"core\"\n",
      "INFO : topic #2 (0.143): 0.007*\"r\" + 0.006*\"c++\" + 0.005*\"sql\" + 0.005*\"python\" + 0.004*\"linux\" + 0.004*\"c\" + 0.004*\"computer\" + 0.004*\"data\" + 0.003*\"windows\" + 0.003*\"microsoft\"\n",
      "INFO : topic diff=0.069052, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.726 per-word bound, 423.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3899/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.143): 0.029*\"sql\" + 0.028*\"r\" + 0.026*\"python\" + 0.017*\"sas\" + 0.017*\"excel\" + 0.015*\"matlab\" + 0.013*\"spss\" + 0.013*\"c++\" + 0.012*\"tableau\" + 0.011*\"powerpoint\"\n",
      "INFO : topic #0 (0.143): 0.013*\"sql\" + 0.010*\"java\" + 0.010*\"oracle\" + 0.009*\"hive\" + 0.009*\"technical\" + 0.008*\"html\" + 0.008*\"python\" + 0.008*\"c\" + 0.008*\"hadoop\" + 0.007*\"xml\"\n",
      "INFO : topic #2 (0.143): 0.006*\"r\" + 0.006*\"c++\" + 0.005*\"sql\" + 0.004*\"python\" + 0.004*\"linux\" + 0.004*\"c\" + 0.004*\"data\" + 0.003*\"computer\" + 0.003*\"windows\" + 0.003*\"microsoft\"\n",
      "INFO : topic #6 (0.143): 0.033*\"python\" + 0.032*\"r\" + 0.027*\"sql\" + 0.017*\"tableau\" + 0.016*\"sas\" + 0.015*\"technical\" + 0.015*\"hadoop\" + 0.013*\"matlab\" + 0.012*\"hive\" + 0.012*\"spark\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.025*\"java\" + 0.022*\"r\" + 0.021*\"c\" + 0.021*\"sql\" + 0.021*\"c++\" + 0.016*\"html\" + 0.016*\"technical\" + 0.015*\"javascript\" + 0.013*\"matlab\"\n",
      "INFO : topic diff=0.055319, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.717 per-word bound, 420.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3923/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.143): 0.007*\"sql\" + 0.006*\"excel\" + 0.004*\"technical\" + 0.004*\"sas\" + 0.004*\"access\" + 0.004*\"powerpoint\" + 0.003*\"r\" + 0.003*\"core\" + 0.003*\"key\" + 0.002*\"taleo\"\n",
      "INFO : topic #3 (0.143): 0.006*\"technical\" + 0.006*\"unix\" + 0.004*\"linux\" + 0.004*\"sql\" + 0.004*\"windows\" + 0.003*\"tableau\" + 0.003*\"skills\" + 0.003*\"word\" + 0.003*\"project\" + 0.002*\"macintosh_hd\"\n",
      "INFO : topic #4 (0.143): 0.030*\"sql\" + 0.029*\"r\" + 0.026*\"python\" + 0.018*\"excel\" + 0.018*\"sas\" + 0.016*\"matlab\" + 0.013*\"spss\" + 0.013*\"c++\" + 0.012*\"tableau\" + 0.012*\"powerpoint\"\n",
      "INFO : topic #6 (0.143): 0.033*\"python\" + 0.033*\"r\" + 0.028*\"sql\" + 0.018*\"tableau\" + 0.016*\"sas\" + 0.015*\"technical\" + 0.015*\"hadoop\" + 0.013*\"matlab\" + 0.012*\"hive\" + 0.012*\"spark\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.026*\"java\" + 0.021*\"r\" + 0.021*\"c\" + 0.021*\"c++\" + 0.020*\"sql\" + 0.016*\"html\" + 0.016*\"technical\" + 0.015*\"javascript\" + 0.013*\"matlab\"\n",
      "INFO : topic diff=0.044997, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.710 per-word bound, 418.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3917/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.143): 0.034*\"python\" + 0.033*\"r\" + 0.028*\"sql\" + 0.018*\"tableau\" + 0.016*\"sas\" + 0.015*\"technical\" + 0.015*\"hadoop\" + 0.013*\"matlab\" + 0.012*\"hive\" + 0.012*\"spark\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.026*\"java\" + 0.022*\"c\" + 0.021*\"c++\" + 0.021*\"r\" + 0.020*\"sql\" + 0.017*\"html\" + 0.016*\"javascript\" + 0.015*\"technical\" + 0.013*\"css\"\n",
      "INFO : topic #2 (0.143): 0.005*\"r\" + 0.005*\"c++\" + 0.004*\"sql\" + 0.004*\"python\" + 0.003*\"data\" + 0.003*\"linux\" + 0.003*\"computer\" + 0.003*\"c\" + 0.003*\"windows\" + 0.003*\"microsoft\"\n",
      "INFO : topic #3 (0.143): 0.006*\"technical\" + 0.005*\"unix\" + 0.004*\"linux\" + 0.004*\"sql\" + 0.003*\"windows\" + 0.003*\"tableau\" + 0.003*\"skills\" + 0.003*\"project\" + 0.003*\"word\" + 0.002*\"macintosh_hd\"\n",
      "INFO : topic #0 (0.143): 0.013*\"sql\" + 0.010*\"oracle\" + 0.010*\"java\" + 0.009*\"technical\" + 0.009*\"hive\" + 0.008*\"html\" + 0.008*\"c\" + 0.008*\"xml\" + 0.008*\"python\" + 0.008*\"hadoop\"\n",
      "INFO : topic diff=0.037272, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.704 per-word bound, 417.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3917/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3916/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.143): 0.030*\"sql\" + 0.029*\"r\" + 0.026*\"python\" + 0.020*\"excel\" + 0.019*\"sas\" + 0.016*\"matlab\" + 0.014*\"spss\" + 0.014*\"powerpoint\" + 0.013*\"c++\" + 0.012*\"tableau\"\n",
      "INFO : topic #3 (0.143): 0.005*\"unix\" + 0.005*\"technical\" + 0.004*\"linux\" + 0.003*\"windows\" + 0.003*\"sql\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"project\" + 0.002*\"macintosh_hd\" + 0.002*\"word\"\n",
      "INFO : topic #6 (0.143): 0.034*\"python\" + 0.033*\"r\" + 0.028*\"sql\" + 0.018*\"tableau\" + 0.016*\"sas\" + 0.015*\"technical\" + 0.015*\"hadoop\" + 0.013*\"matlab\" + 0.012*\"hive\" + 0.012*\"spark\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.026*\"java\" + 0.022*\"c\" + 0.022*\"c++\" + 0.021*\"r\" + 0.020*\"sql\" + 0.017*\"html\" + 0.016*\"javascript\" + 0.015*\"technical\" + 0.013*\"css\"\n",
      "INFO : topic #5 (0.143): 0.006*\"sql\" + 0.005*\"excel\" + 0.004*\"technical\" + 0.004*\"access\" + 0.004*\"sas\" + 0.003*\"powerpoint\" + 0.003*\"core\" + 0.003*\"key\" + 0.003*\"taleo\" + 0.002*\"r\"\n",
      "INFO : topic diff=0.031261, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.700 per-word bound, 415.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3908/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.143): 0.034*\"python\" + 0.033*\"r\" + 0.028*\"sql\" + 0.018*\"tableau\" + 0.016*\"sas\" + 0.015*\"technical\" + 0.015*\"hadoop\" + 0.013*\"matlab\" + 0.013*\"hive\" + 0.012*\"spark\"\n",
      "INFO : topic #3 (0.143): 0.005*\"unix\" + 0.005*\"technical\" + 0.004*\"linux\" + 0.003*\"windows\" + 0.003*\"sql\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"macintosh_hd\" + 0.003*\"project\" + 0.002*\"j.\"\n",
      "INFO : topic #2 (0.143): 0.005*\"r\" + 0.004*\"c++\" + 0.003*\"data\" + 0.003*\"sql\" + 0.003*\"computer\" + 0.003*\"python\" + 0.003*\"linux\" + 0.003*\"microsoft\" + 0.003*\"c\" + 0.003*\"windows\"\n",
      "INFO : topic #4 (0.143): 0.030*\"sql\" + 0.029*\"r\" + 0.026*\"python\" + 0.021*\"excel\" + 0.019*\"sas\" + 0.016*\"matlab\" + 0.014*\"powerpoint\" + 0.014*\"spss\" + 0.013*\"c++\" + 0.012*\"tableau\"\n",
      "INFO : topic #5 (0.143): 0.006*\"sql\" + 0.004*\"excel\" + 0.004*\"technical\" + 0.003*\"access\" + 0.003*\"sas\" + 0.003*\"powerpoint\" + 0.003*\"core\" + 0.003*\"key\" + 0.003*\"taleo\" + 0.002*\"business\"\n",
      "INFO : topic diff=0.026624, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.695 per-word bound, 414.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3915/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.143): 0.030*\"sql\" + 0.029*\"r\" + 0.026*\"python\" + 0.022*\"excel\" + 0.020*\"sas\" + 0.016*\"matlab\" + 0.015*\"powerpoint\" + 0.014*\"spss\" + 0.012*\"c++\" + 0.012*\"tableau\"\n",
      "INFO : topic #0 (0.143): 0.012*\"sql\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.009*\"technical\" + 0.009*\"hive\" + 0.008*\"c\" + 0.008*\"html\" + 0.008*\"xml\" + 0.007*\"hadoop\" + 0.007*\"pig\"\n",
      "INFO : topic #6 (0.143): 0.034*\"python\" + 0.034*\"r\" + 0.028*\"sql\" + 0.018*\"tableau\" + 0.016*\"technical\" + 0.016*\"hadoop\" + 0.015*\"sas\" + 0.013*\"matlab\" + 0.013*\"hive\" + 0.012*\"spark\"\n",
      "INFO : topic #5 (0.143): 0.005*\"sql\" + 0.004*\"excel\" + 0.003*\"technical\" + 0.003*\"access\" + 0.003*\"sas\" + 0.003*\"core\" + 0.003*\"key\" + 0.003*\"powerpoint\" + 0.003*\"taleo\" + 0.002*\"business\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.026*\"java\" + 0.022*\"c\" + 0.022*\"c++\" + 0.020*\"r\" + 0.020*\"sql\" + 0.018*\"html\" + 0.017*\"javascript\" + 0.015*\"technical\" + 0.014*\"css\"\n",
      "INFO : topic diff=0.022967, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.692 per-word bound, 413.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3916/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.143): 0.034*\"python\" + 0.034*\"r\" + 0.028*\"sql\" + 0.018*\"tableau\" + 0.016*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.013*\"matlab\" + 0.013*\"hive\" + 0.013*\"spark\"\n",
      "INFO : topic #5 (0.143): 0.005*\"sql\" + 0.004*\"excel\" + 0.003*\"technical\" + 0.003*\"core\" + 0.003*\"sas\" + 0.003*\"access\" + 0.003*\"key\" + 0.003*\"taleo\" + 0.002*\"powerpoint\" + 0.002*\"business\"\n",
      "INFO : topic #0 (0.143): 0.012*\"sql\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.009*\"technical\" + 0.009*\"hive\" + 0.008*\"c\" + 0.008*\"xml\" + 0.008*\"html\" + 0.007*\"hadoop\" + 0.007*\"pig\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.027*\"java\" + 0.023*\"c\" + 0.022*\"c++\" + 0.020*\"r\" + 0.020*\"sql\" + 0.018*\"html\" + 0.018*\"javascript\" + 0.015*\"technical\" + 0.014*\"css\"\n",
      "INFO : topic #2 (0.143): 0.004*\"r\" + 0.004*\"c++\" + 0.003*\"data\" + 0.003*\"sql\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"linux\" + 0.003*\"python\" + 0.002*\"project\" + 0.002*\"windows\"\n",
      "INFO : topic diff=0.020229, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.689 per-word bound, 412.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3928/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.143): 0.005*\"unix\" + 0.004*\"technical\" + 0.004*\"linux\" + 0.003*\"windows\" + 0.003*\"macintosh_hd\" + 0.003*\"skills\" + 0.003*\"j.\" + 0.002*\"project\" + 0.002*\"sql\" + 0.002*\"tableau\"\n",
      "INFO : topic #2 (0.143): 0.004*\"r\" + 0.004*\"c++\" + 0.003*\"data\" + 0.003*\"computer\" + 0.003*\"sql\" + 0.003*\"microsoft\" + 0.003*\"linux\" + 0.002*\"project\" + 0.002*\"python\" + 0.002*\"software\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.027*\"java\" + 0.023*\"c\" + 0.023*\"c++\" + 0.020*\"r\" + 0.020*\"sql\" + 0.018*\"html\" + 0.018*\"javascript\" + 0.015*\"technical\" + 0.014*\"css\"\n",
      "INFO : topic #5 (0.143): 0.005*\"sql\" + 0.004*\"excel\" + 0.003*\"technical\" + 0.003*\"core\" + 0.003*\"key\" + 0.003*\"taleo\" + 0.003*\"sas\" + 0.003*\"access\" + 0.002*\"business\" + 0.002*\"powerpoint\"\n",
      "INFO : topic #6 (0.143): 0.034*\"python\" + 0.034*\"r\" + 0.028*\"sql\" + 0.018*\"tableau\" + 0.016*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.013*\"matlab\" + 0.013*\"hive\" + 0.013*\"spark\"\n",
      "INFO : topic diff=0.018019, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.686 per-word bound, 411.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.143): 0.005*\"sql\" + 0.003*\"excel\" + 0.003*\"core\" + 0.003*\"technical\" + 0.003*\"taleo\" + 0.003*\"key\" + 0.003*\"sas\" + 0.002*\"access\" + 0.002*\"business\" + 0.002*\"jobvite\"\n",
      "INFO : topic #2 (0.143): 0.004*\"r\" + 0.004*\"c++\" + 0.003*\"data\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"sql\" + 0.002*\"project\" + 0.002*\"linux\" + 0.002*\"software\" + 0.002*\"research\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.027*\"java\" + 0.023*\"c\" + 0.023*\"c++\" + 0.020*\"r\" + 0.019*\"sql\" + 0.018*\"javascript\" + 0.018*\"html\" + 0.015*\"technical\" + 0.014*\"css\"\n",
      "INFO : topic #0 (0.143): 0.012*\"sql\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.010*\"technical\" + 0.009*\"hive\" + 0.009*\"c\" + 0.008*\"xml\" + 0.008*\"html\" + 0.007*\"hadoop\" + 0.007*\"pig\"\n",
      "INFO : topic #4 (0.143): 0.030*\"sql\" + 0.030*\"r\" + 0.025*\"python\" + 0.024*\"excel\" + 0.021*\"sas\" + 0.017*\"powerpoint\" + 0.016*\"matlab\" + 0.015*\"spss\" + 0.013*\"word\" + 0.012*\"tableau\"\n",
      "INFO : topic diff=0.016216, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.683 per-word bound, 411.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.143): 0.004*\"sql\" + 0.003*\"core\" + 0.003*\"excel\" + 0.003*\"taleo\" + 0.003*\"technical\" + 0.003*\"key\" + 0.002*\"business\" + 0.002*\"sas\" + 0.002*\"access\" + 0.002*\"jobvite\"\n",
      "INFO : topic #2 (0.143): 0.004*\"r\" + 0.003*\"c++\" + 0.003*\"data\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.002*\"project\" + 0.002*\"sql\" + 0.002*\"linux\" + 0.002*\"software\" + 0.002*\"research\"\n",
      "INFO : topic #3 (0.143): 0.005*\"unix\" + 0.004*\"technical\" + 0.004*\"linux\" + 0.003*\"windows\" + 0.003*\"j.\" + 0.003*\"macintosh_hd\" + 0.003*\"skills\" + 0.002*\"project\" + 0.002*\"s.\" + 0.002*\"tableau\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.027*\"java\" + 0.023*\"c\" + 0.023*\"c++\" + 0.020*\"r\" + 0.019*\"sql\" + 0.019*\"javascript\" + 0.018*\"html\" + 0.014*\"technical\" + 0.014*\"css\"\n",
      "INFO : topic #6 (0.143): 0.035*\"python\" + 0.034*\"r\" + 0.029*\"sql\" + 0.019*\"tableau\" + 0.016*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.013*\"hive\" + 0.013*\"matlab\" + 0.013*\"spark\"\n",
      "INFO : topic diff=0.014731, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.681 per-word bound, 410.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.143): 0.012*\"sql\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.010*\"technical\" + 0.009*\"hive\" + 0.009*\"c\" + 0.008*\"xml\" + 0.008*\"html\" + 0.007*\"hadoop\" + 0.007*\"pig\"\n",
      "INFO : topic #6 (0.143): 0.035*\"python\" + 0.034*\"r\" + 0.029*\"sql\" + 0.019*\"tableau\" + 0.016*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.013*\"hive\" + 0.013*\"matlab\" + 0.013*\"spark\"\n",
      "INFO : topic #1 (0.143): 0.030*\"python\" + 0.027*\"java\" + 0.023*\"c\" + 0.023*\"c++\" + 0.020*\"r\" + 0.019*\"sql\" + 0.019*\"javascript\" + 0.019*\"html\" + 0.015*\"css\" + 0.014*\"technical\"\n",
      "INFO : topic #2 (0.143): 0.003*\"r\" + 0.003*\"c++\" + 0.003*\"data\" + 0.003*\"microsoft\" + 0.003*\"computer\" + 0.002*\"project\" + 0.002*\"sql\" + 0.002*\"research\" + 0.002*\"software\" + 0.002*\"linux\"\n",
      "INFO : topic #5 (0.143): 0.004*\"sql\" + 0.003*\"core\" + 0.003*\"excel\" + 0.003*\"taleo\" + 0.003*\"key\" + 0.003*\"technical\" + 0.002*\"business\" + 0.002*\"jobvite\" + 0.002*\"sas\" + 0.002*\"access\"\n",
      "INFO : topic diff=0.013476, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.680 per-word bound, 410.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.143): 0.012*\"sql\" + 0.011*\"oracle\" + 0.010*\"technical\" + 0.010*\"java\" + 0.009*\"hive\" + 0.009*\"c\" + 0.008*\"xml\" + 0.008*\"html\" + 0.007*\"hadoop\" + 0.007*\"pig\"\n",
      "INFO : topic #4 (0.143): 0.031*\"sql\" + 0.030*\"r\" + 0.026*\"excel\" + 0.025*\"python\" + 0.023*\"sas\" + 0.018*\"powerpoint\" + 0.016*\"matlab\" + 0.015*\"spss\" + 0.014*\"word\" + 0.013*\"tableau\"\n",
      "INFO : topic #5 (0.143): 0.004*\"sql\" + 0.003*\"core\" + 0.003*\"taleo\" + 0.003*\"key\" + 0.003*\"excel\" + 0.003*\"technical\" + 0.002*\"business\" + 0.002*\"jobvite\" + 0.002*\"sas\" + 0.002*\"access\"\n",
      "INFO : topic #3 (0.143): 0.005*\"unix\" + 0.004*\"technical\" + 0.004*\"linux\" + 0.003*\"j.\" + 0.003*\"windows\" + 0.003*\"macintosh_hd\" + 0.003*\"skills\" + 0.002*\"s.\" + 0.002*\"m.\" + 0.002*\"project\"\n",
      "INFO : topic #6 (0.143): 0.035*\"python\" + 0.034*\"r\" + 0.029*\"sql\" + 0.019*\"tableau\" + 0.016*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.013*\"hive\" + 0.013*\"matlab\" + 0.013*\"spark\"\n",
      "INFO : topic diff=0.012447, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.678 per-word bound, 409.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=7, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=7, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (579 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (439 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (449 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (704 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (325 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (350 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (504 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (641 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (565 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (564 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (592 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (636 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (545 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (568 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (545 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (513 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (545 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (513 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (892 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (526 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (716 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (545 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (526 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (716 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (568 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (568 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 4; 320 documents processed (629 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (656 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (629 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (656 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (713 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (713 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (892 virtual)\n",
      "DEBUG : completed batch 6; 446 documents processed (621 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (568 virtual)\n",
      "DEBUG : finished all batches; 446 documents processed (621 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 576 documents processed (628 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (406 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (623 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 384 documents processed (623 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : finished all batches; 576 documents processed (628 virtual)\n",
      "DEBUG : finished all batches; 320 documents processed (406 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9149 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12374/12537 documents converged within 50 iterations\n",
      " 22%|██▏       | 5/23 [02:03<07:26, 24.78s/it]INFO : using symmetric alpha at 0.125\n",
      "INFO : using symmetric eta at 0.125\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 8 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 413/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3174/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3047/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3027/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.125): 0.028*\"python\" + 0.022*\"r\" + 0.021*\"sql\" + 0.021*\"java\" + 0.017*\"technical\" + 0.016*\"c\" + 0.015*\"c++\" + 0.012*\"tableau\" + 0.011*\"html\" + 0.010*\"matlab\"\n",
      "INFO : topic #5 (0.125): 0.019*\"sql\" + 0.012*\"r\" + 0.012*\"technical\" + 0.010*\"python\" + 0.010*\"sas\" + 0.008*\"excel\" + 0.008*\"java\" + 0.007*\"tableau\" + 0.006*\"linux\" + 0.006*\"hadoop\"\n",
      "INFO : topic #3 (0.125): 0.015*\"technical\" + 0.013*\"sql\" + 0.012*\"python\" + 0.011*\"r\" + 0.008*\"tableau\" + 0.008*\"unix\" + 0.008*\"java\" + 0.006*\"linux\" + 0.005*\"c++\" + 0.005*\"c\"\n",
      "INFO : topic #2 (0.125): 0.015*\"r\" + 0.013*\"python\" + 0.013*\"sql\" + 0.011*\"c++\" + 0.008*\"c\" + 0.007*\"java\" + 0.007*\"sas\" + 0.007*\"html\" + 0.007*\"linux\" + 0.007*\"hive\"\n",
      "INFO : topic #7 (0.125): 0.018*\"python\" + 0.018*\"sql\" + 0.014*\"hadoop\" + 0.012*\"c++\" + 0.012*\"linux\" + 0.012*\"r\" + 0.012*\"hive\" + 0.010*\"c\" + 0.010*\"matlab\" + 0.009*\"java\"\n",
      "INFO : topic diff=5.121609, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.106 per-word bound, 551.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 512/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3713/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3697/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3746/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.125): 0.019*\"sql\" + 0.016*\"python\" + 0.016*\"r\" + 0.010*\"hive\" + 0.010*\"java\" + 0.009*\"html\" + 0.009*\"javascript\" + 0.008*\"technical\" + 0.008*\"oracle\" + 0.008*\"hadoop\"\n",
      "INFO : topic #6 (0.125): 0.029*\"r\" + 0.029*\"python\" + 0.022*\"sql\" + 0.016*\"sas\" + 0.014*\"tableau\" + 0.013*\"matlab\" + 0.012*\"technical\" + 0.011*\"c++\" + 0.011*\"mysql\" + 0.010*\"java\"\n",
      "INFO : topic #7 (0.125): 0.016*\"python\" + 0.016*\"sql\" + 0.013*\"hadoop\" + 0.011*\"c++\" + 0.011*\"linux\" + 0.011*\"hive\" + 0.010*\"r\" + 0.010*\"c\" + 0.009*\"matlab\" + 0.009*\"java\"\n",
      "INFO : topic #2 (0.125): 0.014*\"r\" + 0.011*\"python\" + 0.011*\"sql\" + 0.010*\"c++\" + 0.007*\"c\" + 0.006*\"sas\" + 0.006*\"linux\" + 0.006*\"java\" + 0.006*\"html\" + 0.006*\"programming\"\n",
      "INFO : topic #5 (0.125): 0.017*\"sql\" + 0.011*\"technical\" + 0.010*\"r\" + 0.009*\"sas\" + 0.008*\"python\" + 0.007*\"excel\" + 0.006*\"java\" + 0.006*\"tableau\" + 0.005*\"linux\" + 0.005*\"access\"\n",
      "INFO : topic diff=0.322230, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.930 per-word bound, 487.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 522/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3789/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3781/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3854/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.125): 0.017*\"sql\" + 0.014*\"python\" + 0.014*\"r\" + 0.010*\"java\" + 0.010*\"hive\" + 0.009*\"html\" + 0.009*\"oracle\" + 0.009*\"javascript\" + 0.008*\"technical\" + 0.008*\"hadoop\"\n",
      "INFO : topic #3 (0.125): 0.012*\"technical\" + 0.010*\"sql\" + 0.008*\"python\" + 0.008*\"unix\" + 0.006*\"r\" + 0.006*\"tableau\" + 0.006*\"linux\" + 0.005*\"java\" + 0.004*\"c\" + 0.004*\"skills\"\n",
      "INFO : topic #5 (0.125): 0.015*\"sql\" + 0.010*\"technical\" + 0.009*\"sas\" + 0.008*\"r\" + 0.007*\"excel\" + 0.007*\"python\" + 0.005*\"access\" + 0.005*\"linux\" + 0.005*\"tableau\" + 0.005*\"java\"\n",
      "INFO : topic #2 (0.125): 0.012*\"r\" + 0.010*\"python\" + 0.010*\"sql\" + 0.009*\"c++\" + 0.007*\"c\" + 0.006*\"linux\" + 0.006*\"sas\" + 0.006*\"html\" + 0.006*\"programming\" + 0.005*\"java\"\n",
      "INFO : topic #7 (0.125): 0.015*\"sql\" + 0.014*\"python\" + 0.011*\"hadoop\" + 0.010*\"c++\" + 0.010*\"linux\" + 0.009*\"hive\" + 0.009*\"r\" + 0.009*\"c\" + 0.008*\"matlab\" + 0.008*\"java\"\n",
      "INFO : topic diff=0.256018, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.845 per-word bound, 460.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3849/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3830/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.125): 0.013*\"sql\" + 0.013*\"python\" + 0.010*\"hadoop\" + 0.009*\"c++\" + 0.009*\"linux\" + 0.008*\"hive\" + 0.008*\"c\" + 0.008*\"r\" + 0.007*\"matlab\" + 0.007*\"java\"\n",
      "INFO : topic #4 (0.125): 0.029*\"r\" + 0.029*\"sql\" + 0.027*\"python\" + 0.015*\"matlab\" + 0.013*\"sas\" + 0.013*\"tableau\" + 0.012*\"c++\" + 0.012*\"technical\" + 0.012*\"excel\" + 0.012*\"java\"\n",
      "INFO : topic #3 (0.125): 0.011*\"technical\" + 0.008*\"sql\" + 0.007*\"unix\" + 0.006*\"python\" + 0.006*\"linux\" + 0.006*\"tableau\" + 0.005*\"r\" + 0.004*\"java\" + 0.004*\"windows\" + 0.004*\"word\"\n",
      "INFO : topic #2 (0.125): 0.011*\"r\" + 0.009*\"sql\" + 0.009*\"python\" + 0.008*\"c++\" + 0.006*\"c\" + 0.006*\"linux\" + 0.005*\"sas\" + 0.005*\"programming\" + 0.005*\"html\" + 0.005*\"excel\"\n",
      "INFO : topic #5 (0.125): 0.014*\"sql\" + 0.009*\"technical\" + 0.009*\"sas\" + 0.007*\"excel\" + 0.007*\"r\" + 0.006*\"python\" + 0.005*\"access\" + 0.005*\"oracle\" + 0.005*\"linux\" + 0.004*\"tableau\"\n",
      "INFO : topic diff=0.200884, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.798 per-word bound, 445.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : 3867/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3887/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3900/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.125): 0.010*\"technical\" + 0.007*\"sql\" + 0.007*\"unix\" + 0.005*\"linux\" + 0.005*\"python\" + 0.005*\"tableau\" + 0.004*\"r\" + 0.004*\"windows\" + 0.004*\"word\" + 0.004*\"skills\"\n",
      "INFO : topic #0 (0.125): 0.015*\"sql\" + 0.012*\"python\" + 0.011*\"r\" + 0.010*\"java\" + 0.010*\"oracle\" + 0.009*\"html\" + 0.009*\"hive\" + 0.008*\"javascript\" + 0.008*\"technical\" + 0.008*\"c\"\n",
      "INFO : topic #1 (0.125): 0.029*\"python\" + 0.024*\"java\" + 0.021*\"sql\" + 0.021*\"r\" + 0.020*\"c\" + 0.019*\"c++\" + 0.018*\"technical\" + 0.015*\"html\" + 0.013*\"javascript\" + 0.012*\"mysql\"\n",
      "INFO : topic #7 (0.125): 0.012*\"sql\" + 0.011*\"python\" + 0.009*\"hadoop\" + 0.009*\"c++\" + 0.008*\"linux\" + 0.008*\"c\" + 0.007*\"hive\" + 0.007*\"r\" + 0.006*\"matlab\" + 0.006*\"java\"\n",
      "INFO : topic #4 (0.125): 0.029*\"r\" + 0.029*\"sql\" + 0.027*\"python\" + 0.015*\"matlab\" + 0.014*\"sas\" + 0.013*\"excel\" + 0.013*\"tableau\" + 0.012*\"c++\" + 0.012*\"technical\" + 0.012*\"java\"\n",
      "INFO : topic diff=0.156577, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.768 per-word bound, 436.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3890/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3905/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.125): 0.009*\"r\" + 0.007*\"c++\" + 0.007*\"sql\" + 0.007*\"python\" + 0.005*\"c\" + 0.005*\"linux\" + 0.005*\"computer\" + 0.004*\"programming\" + 0.004*\"excel\" + 0.004*\"matlab\"\n",
      "INFO : topic #3 (0.125): 0.009*\"technical\" + 0.007*\"unix\" + 0.006*\"sql\" + 0.005*\"linux\" + 0.005*\"tableau\" + 0.004*\"python\" + 0.004*\"windows\" + 0.004*\"word\" + 0.004*\"skills\" + 0.004*\"r\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #0 (0.125): 0.014*\"sql\" + 0.011*\"python\" + 0.010*\"java\" + 0.010*\"oracle\" + 0.009*\"r\" + 0.009*\"html\" + 0.009*\"hive\" + 0.008*\"technical\" + 0.008*\"javascript\" + 0.008*\"c\"\n",
      "INFO : topic #5 (0.125): 0.012*\"sql\" + 0.008*\"sas\" + 0.008*\"technical\" + 0.007*\"excel\" + 0.005*\"access\" + 0.005*\"r\" + 0.004*\"oracle\" + 0.004*\"stat\" + 0.004*\"linux\" + 0.004*\"python\"\n",
      "INFO : topic #6 (0.125): 0.033*\"python\" + 0.033*\"r\" + 0.027*\"sql\" + 0.017*\"tableau\" + 0.016*\"sas\" + 0.014*\"technical\" + 0.014*\"hadoop\" + 0.013*\"matlab\" + 0.011*\"java\" + 0.011*\"hive\"\n",
      "INFO : topic diff=0.122049, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.748 per-word bound, 430.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3905/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.125): 0.010*\"sql\" + 0.009*\"python\" + 0.007*\"c++\" + 0.007*\"hadoop\" + 0.007*\"linux\" + 0.006*\"c\" + 0.006*\"hive\" + 0.005*\"r\" + 0.005*\"matlab\" + 0.005*\"java\"\n",
      "INFO : topic #3 (0.125): 0.009*\"technical\" + 0.007*\"unix\" + 0.006*\"sql\" + 0.005*\"linux\" + 0.004*\"tableau\" + 0.004*\"windows\" + 0.004*\"python\" + 0.004*\"word\" + 0.004*\"skills\" + 0.003*\"project\"\n",
      "INFO : topic #2 (0.125): 0.008*\"r\" + 0.007*\"c++\" + 0.006*\"sql\" + 0.006*\"python\" + 0.005*\"c\" + 0.005*\"computer\" + 0.004*\"linux\" + 0.004*\"programming\" + 0.004*\"matlab\" + 0.004*\"excel\"\n",
      "INFO : topic #4 (0.125): 0.031*\"r\" + 0.030*\"sql\" + 0.027*\"python\" + 0.016*\"sas\" + 0.016*\"excel\" + 0.016*\"matlab\" + 0.013*\"c++\" + 0.013*\"tableau\" + 0.012*\"spss\" + 0.011*\"technical\"\n",
      "INFO : topic #6 (0.125): 0.034*\"python\" + 0.033*\"r\" + 0.027*\"sql\" + 0.017*\"tableau\" + 0.016*\"sas\" + 0.015*\"technical\" + 0.014*\"hadoop\" + 0.013*\"matlab\" + 0.012*\"hive\" + 0.012*\"java\"\n",
      "INFO : topic diff=0.095639, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.733 per-word bound, 425.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3904/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3902/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3907/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.125): 0.013*\"sql\" + 0.010*\"oracle\" + 0.010*\"java\" + 0.009*\"python\" + 0.009*\"html\" + 0.009*\"hive\" + 0.008*\"technical\" + 0.008*\"c\" + 0.008*\"javascript\" + 0.008*\"r\"\n",
      "INFO : topic #5 (0.125): 0.011*\"sql\" + 0.008*\"sas\" + 0.007*\"technical\" + 0.006*\"excel\" + 0.005*\"access\" + 0.005*\"stat\" + 0.004*\"oracle\" + 0.004*\"r\" + 0.004*\"linux\" + 0.004*\"powerpoint\"\n",
      "INFO : topic #4 (0.125): 0.031*\"r\" + 0.030*\"sql\" + 0.027*\"python\" + 0.017*\"sas\" + 0.017*\"excel\" + 0.016*\"matlab\" + 0.013*\"c++\" + 0.013*\"tableau\" + 0.013*\"spss\" + 0.011*\"powerpoint\"\n",
      "INFO : topic #7 (0.125): 0.009*\"sql\" + 0.008*\"python\" + 0.007*\"c++\" + 0.007*\"linux\" + 0.007*\"hadoop\" + 0.006*\"c\" + 0.005*\"hive\" + 0.005*\"matlab\" + 0.005*\"r\" + 0.005*\"java\"\n",
      "INFO : topic #2 (0.125): 0.007*\"r\" + 0.006*\"c++\" + 0.005*\"sql\" + 0.005*\"python\" + 0.004*\"computer\" + 0.004*\"c\" + 0.004*\"linux\" + 0.004*\"matlab\" + 0.004*\"programming\" + 0.004*\"excel\"\n",
      "INFO : topic diff=0.075816, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.721 per-word bound, 422.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3897/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3916/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.125): 0.010*\"sql\" + 0.007*\"sas\" + 0.007*\"technical\" + 0.006*\"excel\" + 0.006*\"stat\" + 0.005*\"access\" + 0.004*\"oracle\" + 0.004*\"base\" + 0.004*\"linux\" + 0.004*\"r\"\n",
      "INFO : topic #2 (0.125): 0.007*\"r\" + 0.006*\"c++\" + 0.005*\"sql\" + 0.005*\"python\" + 0.004*\"computer\" + 0.004*\"c\" + 0.004*\"linux\" + 0.004*\"matlab\" + 0.004*\"programming\" + 0.003*\"excel\"\n",
      "INFO : topic #3 (0.125): 0.008*\"technical\" + 0.006*\"unix\" + 0.005*\"linux\" + 0.004*\"sql\" + 0.004*\"windows\" + 0.004*\"tableau\" + 0.004*\"skills\" + 0.003*\"word\" + 0.003*\"project\" + 0.003*\"macintosh_hd\"\n",
      "INFO : topic #1 (0.125): 0.029*\"python\" + 0.026*\"java\" + 0.022*\"c\" + 0.021*\"c++\" + 0.021*\"sql\" + 0.020*\"r\" + 0.017*\"html\" + 0.017*\"technical\" + 0.015*\"javascript\" + 0.013*\"css\"\n",
      "INFO : topic #4 (0.125): 0.032*\"r\" + 0.031*\"sql\" + 0.027*\"python\" + 0.018*\"excel\" + 0.018*\"sas\" + 0.016*\"matlab\" + 0.013*\"spss\" + 0.013*\"c++\" + 0.013*\"tableau\" + 0.012*\"powerpoint\"\n",
      "INFO : topic diff=0.060849, rho=0.287074\n",
      "DEBUG : bound: at document #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : -8.712 per-word bound, 419.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.125): 0.013*\"sql\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.009*\"html\" + 0.009*\"technical\" + 0.009*\"hive\" + 0.008*\"c\" + 0.008*\"python\" + 0.008*\"xml\" + 0.008*\"javascript\"\n",
      "INFO : topic #4 (0.125): 0.032*\"r\" + 0.031*\"sql\" + 0.027*\"python\" + 0.019*\"excel\" + 0.019*\"sas\" + 0.016*\"matlab\" + 0.013*\"spss\" + 0.013*\"powerpoint\" + 0.013*\"c++\" + 0.013*\"tableau\"\n",
      "INFO : topic #7 (0.125): 0.007*\"sql\" + 0.007*\"python\" + 0.006*\"c++\" + 0.006*\"linux\" + 0.005*\"hadoop\" + 0.005*\"c\" + 0.004*\"core\" + 0.004*\"hive\" + 0.004*\"matlab\" + 0.004*\"java\"\n",
      "INFO : topic #5 (0.125): 0.010*\"sql\" + 0.007*\"sas\" + 0.007*\"technical\" + 0.006*\"stat\" + 0.006*\"excel\" + 0.005*\"access\" + 0.004*\"base\" + 0.004*\"oracle\" + 0.004*\"linux\" + 0.004*\"graph\"\n",
      "INFO : topic #1 (0.125): 0.029*\"python\" + 0.027*\"java\" + 0.022*\"c\" + 0.021*\"c++\" + 0.020*\"sql\" + 0.020*\"r\" + 0.017*\"html\" + 0.017*\"technical\" + 0.016*\"javascript\" + 0.013*\"css\"\n",
      "INFO : topic diff=0.049551, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.706 per-word bound, 417.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.125): 0.033*\"r\" + 0.031*\"sql\" + 0.027*\"python\" + 0.020*\"excel\" + 0.020*\"sas\" + 0.016*\"matlab\" + 0.014*\"powerpoint\" + 0.014*\"spss\" + 0.013*\"c++\" + 0.013*\"tableau\"\n",
      "INFO : topic #7 (0.125): 0.007*\"sql\" + 0.006*\"python\" + 0.005*\"c++\" + 0.005*\"linux\" + 0.005*\"hadoop\" + 0.005*\"c\" + 0.004*\"core\" + 0.004*\"hive\" + 0.004*\"matlab\" + 0.003*\"java\"\n",
      "INFO : topic #1 (0.125): 0.029*\"python\" + 0.027*\"java\" + 0.022*\"c\" + 0.022*\"c++\" + 0.020*\"sql\" + 0.020*\"r\" + 0.018*\"html\" + 0.017*\"technical\" + 0.017*\"javascript\" + 0.014*\"css\"\n",
      "INFO : topic #2 (0.125): 0.006*\"r\" + 0.005*\"c++\" + 0.004*\"computer\" + 0.004*\"sql\" + 0.004*\"python\" + 0.004*\"c\" + 0.004*\"matlab\" + 0.003*\"programming\" + 0.003*\"linux\" + 0.003*\"project\"\n",
      "INFO : topic #0 (0.125): 0.013*\"sql\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.009*\"html\" + 0.009*\"technical\" + 0.009*\"hive\" + 0.008*\"c\" + 0.008*\"xml\" + 0.008*\"python\" + 0.008*\"javascript\"\n",
      "INFO : topic diff=0.041049, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.699 per-word bound, 415.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.125): 0.007*\"technical\" + 0.006*\"unix\" + 0.005*\"linux\" + 0.004*\"windows\" + 0.003*\"tableau\" + 0.003*\"skills\" + 0.003*\"sql\" + 0.003*\"project\" + 0.003*\"macintosh_hd\" + 0.003*\"word\"\n",
      "INFO : topic #7 (0.125): 0.006*\"sql\" + 0.006*\"python\" + 0.005*\"c++\" + 0.005*\"linux\" + 0.004*\"hadoop\" + 0.004*\"core\" + 0.004*\"c\" + 0.003*\"matlab\" + 0.003*\"hive\" + 0.003*\"java\"\n",
      "INFO : topic #1 (0.125): 0.029*\"python\" + 0.027*\"java\" + 0.023*\"c\" + 0.022*\"c++\" + 0.020*\"sql\" + 0.020*\"r\" + 0.018*\"html\" + 0.017*\"javascript\" + 0.016*\"technical\" + 0.014*\"css\"\n",
      "INFO : topic #5 (0.125): 0.009*\"sql\" + 0.007*\"sas\" + 0.007*\"stat\" + 0.006*\"technical\" + 0.005*\"access\" + 0.005*\"excel\" + 0.005*\"base\" + 0.004*\"graph\" + 0.004*\"oracle\" + 0.004*\"linux\"\n",
      "INFO : topic #2 (0.125): 0.005*\"r\" + 0.005*\"c++\" + 0.004*\"computer\" + 0.004*\"sql\" + 0.003*\"matlab\" + 0.003*\"c\" + 0.003*\"programming\" + 0.003*\"linux\" + 0.003*\"python\" + 0.003*\"project\"\n",
      "INFO : topic diff=0.034571, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.694 per-word bound, 414.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.125): 0.005*\"sql\" + 0.005*\"python\" + 0.005*\"c++\" + 0.005*\"linux\" + 0.004*\"core\" + 0.004*\"hadoop\" + 0.004*\"c\" + 0.003*\"matlab\" + 0.003*\"hive\" + 0.003*\"java\"\n",
      "INFO : topic #3 (0.125): 0.007*\"technical\" + 0.006*\"unix\" + 0.005*\"linux\" + 0.004*\"windows\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"macintosh_hd\" + 0.003*\"sql\" + 0.003*\"project\" + 0.003*\"rup\"\n",
      "INFO : topic #2 (0.125): 0.005*\"r\" + 0.005*\"c++\" + 0.004*\"computer\" + 0.003*\"matlab\" + 0.003*\"sql\" + 0.003*\"programming\" + 0.003*\"linux\" + 0.003*\"c\" + 0.003*\"project\" + 0.003*\"python\"\n",
      "INFO : topic #6 (0.125): 0.035*\"python\" + 0.034*\"r\" + 0.028*\"sql\" + 0.018*\"tableau\" + 0.016*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.013*\"matlab\" + 0.013*\"hive\" + 0.013*\"spark\"\n",
      "INFO : topic #5 (0.125): 0.009*\"sql\" + 0.007*\"stat\" + 0.007*\"sas\" + 0.006*\"technical\" + 0.005*\"access\" + 0.005*\"base\" + 0.005*\"excel\" + 0.004*\"graph\" + 0.004*\"oracle\" + 0.004*\"linux\"\n",
      "INFO : topic diff=0.029470, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.690 per-word bound, 412.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.125): 0.035*\"python\" + 0.034*\"r\" + 0.028*\"sql\" + 0.019*\"tableau\" + 0.016*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.013*\"matlab\" + 0.013*\"hive\" + 0.013*\"spark\"\n",
      "INFO : topic #4 (0.125): 0.034*\"r\" + 0.032*\"sql\" + 0.028*\"python\" + 0.023*\"excel\" + 0.021*\"sas\" + 0.016*\"matlab\" + 0.016*\"powerpoint\" + 0.014*\"spss\" + 0.013*\"tableau\" + 0.013*\"c++\"\n",
      "INFO : topic #7 (0.125): 0.005*\"sql\" + 0.005*\"python\" + 0.005*\"c++\" + 0.004*\"core\" + 0.004*\"linux\" + 0.004*\"c\" + 0.004*\"hadoop\" + 0.003*\"matlab\" + 0.003*\"hive\" + 0.003*\"software\"\n",
      "INFO : topic #5 (0.125): 0.008*\"sql\" + 0.007*\"stat\" + 0.006*\"sas\" + 0.006*\"technical\" + 0.005*\"base\" + 0.005*\"access\" + 0.005*\"excel\" + 0.004*\"graph\" + 0.004*\"oracle\" + 0.003*\"linux\"\n",
      "INFO : topic #1 (0.125): 0.029*\"python\" + 0.028*\"java\" + 0.023*\"c\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.019*\"r\" + 0.019*\"html\" + 0.018*\"javascript\" + 0.016*\"technical\" + 0.015*\"css\"\n",
      "INFO : topic diff=0.025586, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.686 per-word bound, 411.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.125): 0.006*\"technical\" + 0.006*\"unix\" + 0.004*\"linux\" + 0.004*\"windows\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"macintosh_hd\" + 0.003*\"rup\" + 0.003*\"project\" + 0.003*\"rad\"\n",
      "INFO : topic #0 (0.125): 0.013*\"sql\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.009*\"technical\" + 0.009*\"xml\" + 0.009*\"html\" + 0.009*\"hive\" + 0.009*\"c\" + 0.007*\"javascript\" + 0.007*\"pig\"\n",
      "INFO : topic #4 (0.125): 0.034*\"r\" + 0.032*\"sql\" + 0.028*\"python\" + 0.024*\"excel\" + 0.022*\"sas\" + 0.016*\"matlab\" + 0.016*\"powerpoint\" + 0.015*\"spss\" + 0.013*\"tableau\" + 0.013*\"word\"\n",
      "INFO : topic #5 (0.125): 0.008*\"sql\" + 0.007*\"stat\" + 0.006*\"sas\" + 0.006*\"technical\" + 0.005*\"base\" + 0.005*\"access\" + 0.005*\"graph\" + 0.004*\"excel\" + 0.004*\"oracle\" + 0.003*\"key\"\n",
      "INFO : topic #1 (0.125): 0.029*\"python\" + 0.028*\"java\" + 0.024*\"c\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.019*\"r\" + 0.019*\"html\" + 0.019*\"javascript\" + 0.016*\"technical\" + 0.015*\"css\"\n",
      "INFO : topic diff=0.022484, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.683 per-word bound, 411.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.125): 0.008*\"sql\" + 0.007*\"stat\" + 0.006*\"sas\" + 0.005*\"technical\" + 0.005*\"base\" + 0.005*\"graph\" + 0.005*\"access\" + 0.004*\"excel\" + 0.004*\"oracle\" + 0.003*\"key\"\n",
      "INFO : topic #2 (0.125): 0.004*\"c++\" + 0.004*\"r\" + 0.004*\"computer\" + 0.003*\"project\" + 0.003*\"matlab\" + 0.003*\"programming\" + 0.003*\"data\" + 0.003*\"linux\" + 0.003*\"c\" + 0.003*\"sql\"\n",
      "INFO : topic #1 (0.125): 0.030*\"python\" + 0.028*\"java\" + 0.024*\"c\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.019*\"html\" + 0.019*\"r\" + 0.019*\"javascript\" + 0.016*\"technical\" + 0.015*\"css\"\n",
      "INFO : topic #6 (0.125): 0.035*\"python\" + 0.034*\"r\" + 0.029*\"sql\" + 0.019*\"tableau\" + 0.016*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.013*\"hive\" + 0.013*\"matlab\" + 0.013*\"spark\"\n",
      "INFO : topic #4 (0.125): 0.034*\"r\" + 0.032*\"sql\" + 0.028*\"python\" + 0.024*\"excel\" + 0.022*\"sas\" + 0.017*\"powerpoint\" + 0.017*\"matlab\" + 0.015*\"spss\" + 0.013*\"word\" + 0.013*\"tableau\"\n",
      "INFO : topic diff=0.019996, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.680 per-word bound, 410.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.125): 0.036*\"python\" + 0.034*\"r\" + 0.029*\"sql\" + 0.019*\"tableau\" + 0.017*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.014*\"hive\" + 0.013*\"matlab\" + 0.013*\"spark\"\n",
      "INFO : topic #7 (0.125): 0.004*\"core\" + 0.004*\"sql\" + 0.004*\"c++\" + 0.004*\"linux\" + 0.003*\"python\" + 0.003*\"c\" + 0.003*\"hadoop\" + 0.003*\"software\" + 0.002*\"skill\" + 0.002*\"computer\"\n",
      "INFO : topic #2 (0.125): 0.004*\"c++\" + 0.004*\"r\" + 0.003*\"computer\" + 0.003*\"project\" + 0.003*\"matlab\" + 0.003*\"programming\" + 0.003*\"data\" + 0.003*\"linux\" + 0.002*\"c\" + 0.002*\"sql\"\n",
      "INFO : topic #3 (0.125): 0.006*\"unix\" + 0.006*\"technical\" + 0.004*\"linux\" + 0.004*\"windows\" + 0.003*\"skills\" + 0.003*\"macintosh_hd\" + 0.003*\"tableau\" + 0.003*\"rup\" + 0.003*\"rad\" + 0.003*\"project\"\n",
      "INFO : topic #1 (0.125): 0.030*\"python\" + 0.028*\"java\" + 0.024*\"c\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.020*\"html\" + 0.019*\"javascript\" + 0.019*\"r\" + 0.016*\"technical\" + 0.015*\"css\"\n",
      "INFO : topic diff=0.017945, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.678 per-word bound, 409.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.125): 0.035*\"r\" + 0.033*\"sql\" + 0.028*\"python\" + 0.026*\"excel\" + 0.023*\"sas\" + 0.018*\"powerpoint\" + 0.017*\"matlab\" + 0.015*\"spss\" + 0.014*\"word\" + 0.013*\"tableau\"\n",
      "INFO : topic #0 (0.125): 0.012*\"sql\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.009*\"technical\" + 0.009*\"xml\" + 0.009*\"hive\" + 0.009*\"html\" + 0.009*\"c\" + 0.007*\"pig\" + 0.007*\"pl\"\n",
      "INFO : topic #2 (0.125): 0.004*\"c++\" + 0.004*\"r\" + 0.003*\"computer\" + 0.003*\"project\" + 0.003*\"matlab\" + 0.003*\"data\" + 0.003*\"programming\" + 0.003*\"linux\" + 0.002*\"c\" + 0.002*\"microsoft\"\n",
      "INFO : topic #7 (0.125): 0.004*\"core\" + 0.004*\"c++\" + 0.004*\"sql\" + 0.003*\"linux\" + 0.003*\"python\" + 0.003*\"c\" + 0.003*\"software\" + 0.003*\"hadoop\" + 0.002*\"skill\" + 0.002*\"m.\"\n",
      "INFO : topic #6 (0.125): 0.036*\"python\" + 0.035*\"r\" + 0.029*\"sql\" + 0.019*\"tableau\" + 0.017*\"hadoop\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.014*\"hive\" + 0.013*\"matlab\" + 0.013*\"spark\"\n",
      "INFO : topic diff=0.016231, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.675 per-word bound, 408.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.125): 0.004*\"c++\" + 0.004*\"r\" + 0.003*\"computer\" + 0.003*\"project\" + 0.003*\"data\" + 0.003*\"matlab\" + 0.003*\"programming\" + 0.002*\"linux\" + 0.002*\"microsoft\" + 0.002*\"c\"\n",
      "INFO : topic #7 (0.125): 0.005*\"core\" + 0.003*\"c++\" + 0.003*\"sql\" + 0.003*\"linux\" + 0.003*\"python\" + 0.003*\"c\" + 0.003*\"software\" + 0.002*\"skill\" + 0.002*\"m.\" + 0.002*\"hadoop\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #1 (0.125): 0.030*\"python\" + 0.029*\"java\" + 0.024*\"c\" + 0.024*\"c++\" + 0.020*\"html\" + 0.020*\"javascript\" + 0.020*\"sql\" + 0.019*\"r\" + 0.016*\"css\" + 0.016*\"technical\"\n",
      "INFO : topic #0 (0.125): 0.012*\"sql\" + 0.012*\"oracle\" + 0.010*\"java\" + 0.009*\"technical\" + 0.009*\"xml\" + 0.009*\"hive\" + 0.009*\"c\" + 0.009*\"html\" + 0.007*\"pig\" + 0.007*\"pl\"\n",
      "INFO : topic #4 (0.125): 0.035*\"r\" + 0.033*\"sql\" + 0.028*\"python\" + 0.026*\"excel\" + 0.023*\"sas\" + 0.018*\"powerpoint\" + 0.017*\"matlab\" + 0.015*\"spss\" + 0.014*\"word\" + 0.013*\"tableau\"\n",
      "INFO : topic diff=0.014768, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.674 per-word bound, 408.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.125): 0.012*\"sql\" + 0.012*\"oracle\" + 0.010*\"java\" + 0.009*\"technical\" + 0.009*\"xml\" + 0.009*\"hive\" + 0.009*\"c\" + 0.009*\"html\" + 0.007*\"pig\" + 0.007*\"pl\"\n",
      "INFO : topic #1 (0.125): 0.030*\"python\" + 0.029*\"java\" + 0.025*\"c\" + 0.024*\"c++\" + 0.020*\"html\" + 0.020*\"javascript\" + 0.020*\"sql\" + 0.019*\"r\" + 0.016*\"css\" + 0.016*\"technical\"\n",
      "INFO : topic #5 (0.125): 0.008*\"stat\" + 0.007*\"sql\" + 0.006*\"base\" + 0.005*\"sas\" + 0.005*\"graph\" + 0.005*\"technical\" + 0.004*\"access\" + 0.004*\"macro\" + 0.003*\"macros\" + 0.003*\"oracle\"\n",
      "INFO : topic #2 (0.125): 0.004*\"c++\" + 0.003*\"r\" + 0.003*\"computer\" + 0.003*\"project\" + 0.003*\"data\" + 0.003*\"matlab\" + 0.003*\"programming\" + 0.002*\"linux\" + 0.002*\"microsoft\" + 0.002*\"technical\"\n",
      "INFO : topic #7 (0.125): 0.005*\"core\" + 0.003*\"c++\" + 0.003*\"sql\" + 0.003*\"linux\" + 0.003*\"python\" + 0.003*\"software\" + 0.002*\"skill\" + 0.002*\"c\" + 0.002*\"m.\" + 0.002*\"r.\"\n",
      "INFO : topic diff=0.013548, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.672 per-word bound, 407.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=8, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=8, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (153 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (576 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 9; 640 documents processed (640 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (451 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (321 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (472 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (328 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (388 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 10; 704 documents processed (761 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (532 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (350 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (536 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (861 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (712 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (604 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (437 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (452 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (325 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (436 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (508 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (508 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 4; 320 documents processed (508 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (787 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (508 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (501 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (501 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (449 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (925 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (925 virtual)\n",
      "DEBUG : completed batch 11; 768 documents processed (825 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (787 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (617 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (617 virtual)\n",
      "DEBUG : finished all batches; 768 documents processed (825 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (596 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (516 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (556 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (596 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (449 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (516 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (556 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (877 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 320 documents processed (345 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 4; 320 documents processed (402 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (402 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 434 documents processed (661 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 434 documents processed (661 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (877 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9073 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12379/12537 documents converged within 50 iterations\n",
      " 26%|██▌       | 6/23 [02:28<07:01, 24.78s/it]INFO : using symmetric alpha at 0.1111111111111111\n",
      "INFO : using symmetric eta at 0.1111111111111111\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 9 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 414/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3091/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3241/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3089/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.111): 0.018*\"sql\" + 0.016*\"python\" + 0.015*\"r\" + 0.010*\"java\" + 0.010*\"html\" + 0.009*\"javascript\" + 0.009*\"hive\" + 0.008*\"technical\" + 0.008*\"c++\" + 0.008*\"excel\"\n",
      "INFO : topic #6 (0.111): 0.026*\"python\" + 0.026*\"r\" + 0.020*\"sql\" + 0.016*\"sas\" + 0.013*\"matlab\" + 0.012*\"tableau\" + 0.012*\"mysql\" + 0.011*\"technical\" + 0.011*\"c++\" + 0.010*\"java\"\n",
      "INFO : topic #7 (0.111): 0.017*\"sql\" + 0.017*\"python\" + 0.012*\"hadoop\" + 0.011*\"linux\" + 0.011*\"c++\" + 0.010*\"hive\" + 0.010*\"r\" + 0.010*\"java\" + 0.009*\"c\" + 0.009*\"matlab\"\n",
      "INFO : topic #5 (0.111): 0.018*\"sql\" + 0.011*\"technical\" + 0.010*\"r\" + 0.010*\"python\" + 0.009*\"sas\" + 0.008*\"excel\" + 0.008*\"java\" + 0.006*\"tableau\" + 0.006*\"access\" + 0.005*\"linux\"\n",
      "INFO : topic #8 (0.111): 0.031*\"r\" + 0.029*\"python\" + 0.026*\"sql\" + 0.015*\"tableau\" + 0.014*\"hadoop\" + 0.013*\"c++\" + 0.012*\"c\" + 0.012*\"java\" + 0.012*\"hive\" + 0.012*\"technical\"\n",
      "INFO : topic diff=5.915449, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.145 per-word bound, 566.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 511/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3744/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3728/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3762/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.111): 0.012*\"r\" + 0.010*\"python\" + 0.010*\"sql\" + 0.009*\"c++\" + 0.007*\"html\" + 0.006*\"c\" + 0.006*\"java\" + 0.006*\"linux\" + 0.006*\"sas\" + 0.006*\"programming\"\n",
      "INFO : topic #4 (0.111): 0.026*\"sql\" + 0.024*\"r\" + 0.024*\"python\" + 0.013*\"matlab\" + 0.013*\"technical\" + 0.012*\"tableau\" + 0.011*\"sas\" + 0.011*\"c++\" + 0.011*\"c\" + 0.010*\"java\"\n",
      "INFO : topic #1 (0.111): 0.027*\"python\" + 0.022*\"java\" + 0.020*\"sql\" + 0.020*\"r\" + 0.018*\"technical\" + 0.017*\"c\" + 0.016*\"c++\" + 0.013*\"html\" + 0.011*\"mysql\" + 0.011*\"matlab\"\n",
      "INFO : topic #6 (0.111): 0.027*\"python\" + 0.027*\"r\" + 0.021*\"sql\" + 0.016*\"sas\" + 0.013*\"matlab\" + 0.013*\"tableau\" + 0.012*\"technical\" + 0.011*\"mysql\" + 0.011*\"c++\" + 0.010*\"java\"\n",
      "INFO : topic #7 (0.111): 0.015*\"sql\" + 0.015*\"python\" + 0.011*\"hadoop\" + 0.010*\"linux\" + 0.010*\"c++\" + 0.009*\"java\" + 0.009*\"c\" + 0.009*\"hive\" + 0.009*\"r\" + 0.009*\"matlab\"\n",
      "INFO : topic diff=0.331373, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.984 per-word bound, 506.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3817/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3861/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3791/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.111): 0.011*\"r\" + 0.009*\"python\" + 0.009*\"sql\" + 0.008*\"c++\" + 0.006*\"html\" + 0.006*\"c\" + 0.006*\"linux\" + 0.005*\"java\" + 0.005*\"sas\" + 0.005*\"computer\"\n",
      "INFO : topic #3 (0.111): 0.012*\"technical\" + 0.009*\"sql\" + 0.007*\"python\" + 0.007*\"unix\" + 0.007*\"r\" + 0.005*\"java\" + 0.005*\"skills\" + 0.005*\"linux\" + 0.004*\"tableau\" + 0.004*\"c\"\n",
      "INFO : topic #4 (0.111): 0.026*\"sql\" + 0.025*\"r\" + 0.024*\"python\" + 0.014*\"matlab\" + 0.013*\"sas\" + 0.012*\"technical\" + 0.012*\"excel\" + 0.012*\"tableau\" + 0.011*\"c++\" + 0.010*\"c\"\n",
      "INFO : topic #8 (0.111): 0.031*\"r\" + 0.030*\"python\" + 0.027*\"sql\" + 0.017*\"hadoop\" + 0.016*\"tableau\" + 0.015*\"hive\" + 0.014*\"java\" + 0.013*\"technical\" + 0.012*\"c\" + 0.012*\"c++\"\n",
      "INFO : topic #6 (0.111): 0.028*\"python\" + 0.028*\"r\" + 0.022*\"sql\" + 0.016*\"sas\" + 0.013*\"matlab\" + 0.013*\"tableau\" + 0.013*\"technical\" + 0.011*\"mysql\" + 0.011*\"c++\" + 0.010*\"pandas\"\n",
      "INFO : topic diff=0.263425, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.897 per-word bound, 476.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3828/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3871/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3885/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.111): 0.011*\"technical\" + 0.008*\"sql\" + 0.007*\"unix\" + 0.006*\"python\" + 0.005*\"r\" + 0.005*\"skills\" + 0.005*\"linux\" + 0.004*\"java\" + 0.004*\"powerpoint\" + 0.004*\"excel\"\n",
      "INFO : topic #2 (0.111): 0.010*\"r\" + 0.008*\"c++\" + 0.008*\"sql\" + 0.007*\"python\" + 0.005*\"html\" + 0.005*\"c\" + 0.005*\"computer\" + 0.005*\"linux\" + 0.005*\"sas\" + 0.005*\"matlab\"\n",
      "INFO : topic #6 (0.111): 0.029*\"python\" + 0.029*\"r\" + 0.023*\"sql\" + 0.016*\"sas\" + 0.014*\"tableau\" + 0.014*\"matlab\" + 0.013*\"technical\" + 0.011*\"pandas\" + 0.011*\"mysql\" + 0.011*\"c++\"\n",
      "INFO : topic #5 (0.111): 0.013*\"sql\" + 0.008*\"technical\" + 0.008*\"sas\" + 0.008*\"excel\" + 0.006*\"r\" + 0.006*\"access\" + 0.005*\"python\" + 0.005*\"powerpoint\" + 0.004*\"java\" + 0.004*\"tableau\"\n",
      "INFO : topic #8 (0.111): 0.031*\"r\" + 0.030*\"python\" + 0.027*\"sql\" + 0.017*\"hadoop\" + 0.016*\"tableau\" + 0.016*\"hive\" + 0.015*\"java\" + 0.013*\"technical\" + 0.013*\"c\" + 0.012*\"c++\"\n",
      "INFO : topic diff=0.206912, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.845 per-word bound, 460.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3840/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3873/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3881/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.111): 0.012*\"sql\" + 0.008*\"technical\" + 0.007*\"excel\" + 0.007*\"sas\" + 0.006*\"access\" + 0.005*\"r\" + 0.004*\"powerpoint\" + 0.004*\"python\" + 0.004*\"tableau\" + 0.004*\"oracle\"\n",
      "INFO : topic #6 (0.111): 0.030*\"python\" + 0.029*\"r\" + 0.024*\"sql\" + 0.016*\"sas\" + 0.014*\"tableau\" + 0.014*\"matlab\" + 0.014*\"technical\" + 0.012*\"pandas\" + 0.011*\"mysql\" + 0.011*\"c++\"\n",
      "INFO : topic #1 (0.111): 0.028*\"python\" + 0.024*\"java\" + 0.021*\"sql\" + 0.020*\"c\" + 0.020*\"c++\" + 0.019*\"r\" + 0.017*\"technical\" + 0.016*\"html\" + 0.013*\"javascript\" + 0.013*\"mysql\"\n",
      "INFO : topic #0 (0.111): 0.013*\"sql\" + 0.010*\"html\" + 0.009*\"python\" + 0.009*\"java\" + 0.009*\"oracle\" + 0.008*\"javascript\" + 0.008*\"r\" + 0.008*\"technical\" + 0.007*\"c\" + 0.007*\"xml\"\n",
      "INFO : topic #7 (0.111): 0.010*\"sql\" + 0.010*\"python\" + 0.008*\"linux\" + 0.007*\"c++\" + 0.007*\"hadoop\" + 0.007*\"c\" + 0.006*\"matlab\" + 0.006*\"java\" + 0.005*\"r\" + 0.005*\"hive\"\n",
      "INFO : topic diff=0.161430, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.813 per-word bound, 449.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3901/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3863/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.111): 0.028*\"python\" + 0.025*\"java\" + 0.021*\"c\" + 0.021*\"sql\" + 0.020*\"c++\" + 0.019*\"r\" + 0.017*\"technical\" + 0.017*\"html\" + 0.014*\"javascript\" + 0.013*\"css\"\n",
      "INFO : topic #0 (0.111): 0.013*\"sql\" + 0.010*\"html\" + 0.009*\"java\" + 0.009*\"oracle\" + 0.009*\"python\" + 0.008*\"javascript\" + 0.008*\"technical\" + 0.007*\"r\" + 0.007*\"xml\" + 0.007*\"c\"\n",
      "INFO : topic #8 (0.111): 0.030*\"r\" + 0.029*\"python\" + 0.026*\"sql\" + 0.018*\"hadoop\" + 0.017*\"hive\" + 0.017*\"tableau\" + 0.015*\"java\" + 0.014*\"technical\" + 0.013*\"c\" + 0.012*\"spark\"\n",
      "INFO : topic #7 (0.111): 0.009*\"python\" + 0.009*\"sql\" + 0.007*\"linux\" + 0.007*\"c++\" + 0.006*\"hadoop\" + 0.006*\"c\" + 0.006*\"matlab\" + 0.005*\"java\" + 0.005*\"hive\" + 0.005*\"r\"\n",
      "INFO : topic #3 (0.111): 0.010*\"technical\" + 0.006*\"unix\" + 0.006*\"sql\" + 0.005*\"skills\" + 0.004*\"linux\" + 0.004*\"python\" + 0.004*\"r\" + 0.004*\"excel\" + 0.004*\"powerpoint\" + 0.003*\"java\"\n",
      "INFO : topic diff=0.126382, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.789 per-word bound, 442.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3878/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3902/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3907/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.111): 0.012*\"sql\" + 0.010*\"html\" + 0.009*\"java\" + 0.009*\"oracle\" + 0.008*\"javascript\" + 0.008*\"python\" + 0.007*\"technical\" + 0.007*\"xml\" + 0.007*\"c\" + 0.006*\"r\"\n",
      "INFO : topic #3 (0.111): 0.009*\"technical\" + 0.006*\"unix\" + 0.005*\"sql\" + 0.005*\"skills\" + 0.004*\"linux\" + 0.003*\"python\" + 0.003*\"excel\" + 0.003*\"powerpoint\" + 0.003*\"project\" + 0.003*\"r\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #7 (0.111): 0.008*\"python\" + 0.008*\"sql\" + 0.007*\"linux\" + 0.006*\"c++\" + 0.006*\"c\" + 0.006*\"hadoop\" + 0.005*\"matlab\" + 0.005*\"java\" + 0.004*\"excel\" + 0.004*\"core\"\n",
      "INFO : topic #1 (0.111): 0.028*\"python\" + 0.025*\"java\" + 0.021*\"c\" + 0.021*\"c++\" + 0.021*\"sql\" + 0.019*\"r\" + 0.018*\"html\" + 0.017*\"technical\" + 0.015*\"javascript\" + 0.014*\"css\"\n",
      "INFO : topic #2 (0.111): 0.008*\"r\" + 0.006*\"c++\" + 0.005*\"python\" + 0.005*\"sql\" + 0.005*\"computer\" + 0.004*\"linux\" + 0.004*\"windows\" + 0.004*\"c\" + 0.004*\"html\" + 0.004*\"data\"\n",
      "INFO : topic diff=0.099387, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.773 per-word bound, 437.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3861/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.111): 0.012*\"sql\" + 0.010*\"html\" + 0.009*\"java\" + 0.009*\"oracle\" + 0.008*\"javascript\" + 0.008*\"xml\" + 0.007*\"technical\" + 0.007*\"python\" + 0.007*\"c\" + 0.006*\"mysql\"\n",
      "INFO : topic #8 (0.111): 0.029*\"r\" + 0.029*\"python\" + 0.026*\"sql\" + 0.019*\"hadoop\" + 0.018*\"hive\" + 0.017*\"tableau\" + 0.016*\"java\" + 0.014*\"technical\" + 0.013*\"spark\" + 0.012*\"c\"\n",
      "INFO : topic #7 (0.111): 0.007*\"python\" + 0.007*\"sql\" + 0.006*\"linux\" + 0.005*\"c++\" + 0.005*\"c\" + 0.005*\"hadoop\" + 0.005*\"matlab\" + 0.004*\"core\" + 0.004*\"java\" + 0.004*\"excel\"\n",
      "INFO : topic #2 (0.111): 0.007*\"r\" + 0.006*\"c++\" + 0.005*\"python\" + 0.004*\"sql\" + 0.004*\"computer\" + 0.004*\"linux\" + 0.004*\"windows\" + 0.003*\"data\" + 0.003*\"c\" + 0.003*\"microsoft\"\n",
      "INFO : topic #1 (0.111): 0.028*\"python\" + 0.026*\"java\" + 0.022*\"c\" + 0.022*\"c++\" + 0.021*\"sql\" + 0.019*\"r\" + 0.018*\"html\" + 0.017*\"technical\" + 0.016*\"javascript\" + 0.014*\"css\"\n",
      "INFO : topic diff=0.078919, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.762 per-word bound, 434.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3876/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3895/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3902/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.111): 0.008*\"technical\" + 0.006*\"unix\" + 0.005*\"skills\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.003*\"project\" + 0.003*\"excel\" + 0.003*\"powerpoint\" + 0.002*\"word\" + 0.002*\"python\"\n",
      "INFO : topic #5 (0.111): 0.009*\"sql\" + 0.006*\"technical\" + 0.006*\"excel\" + 0.005*\"sas\" + 0.005*\"access\" + 0.003*\"key\" + 0.003*\"powerpoint\" + 0.003*\"r\" + 0.003*\"oracle\" + 0.003*\"tableau\"\n",
      "INFO : topic #2 (0.111): 0.007*\"r\" + 0.005*\"c++\" + 0.004*\"computer\" + 0.004*\"python\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.003*\"windows\" + 0.003*\"data\" + 0.003*\"microsoft\" + 0.003*\"c\"\n",
      "INFO : topic #1 (0.111): 0.028*\"python\" + 0.026*\"java\" + 0.023*\"c\" + 0.022*\"c++\" + 0.020*\"sql\" + 0.019*\"html\" + 0.019*\"r\" + 0.017*\"technical\" + 0.017*\"javascript\" + 0.015*\"css\"\n",
      "INFO : topic #0 (0.111): 0.012*\"sql\" + 0.009*\"html\" + 0.009*\"java\" + 0.009*\"oracle\" + 0.008*\"xml\" + 0.008*\"javascript\" + 0.007*\"technical\" + 0.007*\"python\" + 0.007*\"c\" + 0.006*\"mysql\"\n",
      "INFO : topic diff=0.063537, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.754 per-word bound, 431.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3908/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3862/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.111): 0.028*\"python\" + 0.028*\"r\" + 0.025*\"sql\" + 0.019*\"hadoop\" + 0.019*\"hive\" + 0.017*\"tableau\" + 0.016*\"java\" + 0.014*\"technical\" + 0.013*\"spark\" + 0.013*\"pig\"\n",
      "INFO : topic #4 (0.111): 0.031*\"r\" + 0.031*\"sql\" + 0.027*\"python\" + 0.023*\"excel\" + 0.021*\"sas\" + 0.016*\"matlab\" + 0.016*\"powerpoint\" + 0.015*\"spss\" + 0.013*\"tableau\" + 0.012*\"word\"\n",
      "INFO : topic #0 (0.111): 0.011*\"sql\" + 0.009*\"html\" + 0.009*\"oracle\" + 0.009*\"java\" + 0.008*\"xml\" + 0.008*\"javascript\" + 0.007*\"technical\" + 0.007*\"c\" + 0.006*\"python\" + 0.006*\"mysql\"\n",
      "INFO : topic #5 (0.111): 0.008*\"sql\" + 0.006*\"technical\" + 0.005*\"excel\" + 0.005*\"sas\" + 0.004*\"access\" + 0.003*\"key\" + 0.003*\"powerpoint\" + 0.003*\"r\" + 0.003*\"oracle\" + 0.003*\"data\"\n",
      "INFO : topic #1 (0.111): 0.028*\"python\" + 0.027*\"java\" + 0.023*\"c\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.019*\"html\" + 0.019*\"r\" + 0.017*\"javascript\" + 0.017*\"technical\" + 0.015*\"css\"\n",
      "INFO : topic diff=0.051841, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.748 per-word bound, 429.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3902/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3876/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.111): 0.006*\"r\" + 0.004*\"c++\" + 0.004*\"computer\" + 0.003*\"python\" + 0.003*\"sql\" + 0.003*\"microsoft\" + 0.003*\"data\" + 0.003*\"windows\" + 0.003*\"linux\" + 0.003*\"project\"\n",
      "INFO : topic #0 (0.111): 0.011*\"sql\" + 0.009*\"html\" + 0.009*\"oracle\" + 0.009*\"java\" + 0.008*\"xml\" + 0.008*\"javascript\" + 0.007*\"technical\" + 0.007*\"c\" + 0.006*\"python\" + 0.006*\"mysql\"\n",
      "INFO : topic #1 (0.111): 0.029*\"python\" + 0.027*\"java\" + 0.024*\"c\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.020*\"html\" + 0.019*\"r\" + 0.018*\"javascript\" + 0.017*\"technical\" + 0.016*\"css\"\n",
      "INFO : topic #4 (0.111): 0.032*\"r\" + 0.031*\"sql\" + 0.027*\"python\" + 0.024*\"excel\" + 0.022*\"sas\" + 0.017*\"powerpoint\" + 0.017*\"matlab\" + 0.015*\"spss\" + 0.013*\"tableau\" + 0.012*\"word\"\n",
      "INFO : topic #8 (0.111): 0.028*\"python\" + 0.027*\"r\" + 0.025*\"sql\" + 0.020*\"hadoop\" + 0.019*\"hive\" + 0.017*\"tableau\" + 0.016*\"java\" + 0.014*\"technical\" + 0.013*\"spark\" + 0.013*\"pig\"\n",
      "INFO : topic diff=0.043070, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.742 per-word bound, 428.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.111): 0.032*\"python\" + 0.031*\"r\" + 0.026*\"sql\" + 0.015*\"sas\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"pandas\" + 0.014*\"matlab\" + 0.011*\"numpy\" + 0.011*\"hadoop\"\n",
      "INFO : topic #3 (0.111): 0.007*\"technical\" + 0.005*\"unix\" + 0.005*\"skills\" + 0.003*\"linux\" + 0.003*\"sql\" + 0.003*\"project\" + 0.002*\"excel\" + 0.002*\"powerpoint\" + 0.002*\"word\" + 0.002*\"powershell\"\n",
      "INFO : topic #7 (0.111): 0.005*\"python\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.004*\"core\" + 0.004*\"c++\" + 0.004*\"c\" + 0.003*\"hadoop\" + 0.003*\"matlab\" + 0.002*\"excel\" + 0.002*\"java\"\n",
      "INFO : topic #1 (0.111): 0.029*\"python\" + 0.028*\"java\" + 0.024*\"c\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.020*\"html\" + 0.018*\"javascript\" + 0.018*\"r\" + 0.017*\"technical\" + 0.016*\"css\"\n",
      "INFO : topic #5 (0.111): 0.007*\"sql\" + 0.005*\"technical\" + 0.004*\"excel\" + 0.004*\"sas\" + 0.004*\"access\" + 0.003*\"key\" + 0.003*\"taleo\" + 0.003*\"oracle\" + 0.002*\"powerpoint\" + 0.002*\"data\"\n",
      "INFO : topic diff=0.036268, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.738 per-word bound, 426.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3890/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.111): 0.032*\"python\" + 0.031*\"r\" + 0.026*\"sql\" + 0.015*\"tableau\" + 0.014*\"sas\" + 0.014*\"pandas\" + 0.014*\"technical\" + 0.014*\"matlab\" + 0.011*\"numpy\" + 0.011*\"hadoop\"\n",
      "INFO : topic #0 (0.111): 0.011*\"sql\" + 0.009*\"html\" + 0.009*\"oracle\" + 0.009*\"xml\" + 0.008*\"java\" + 0.008*\"javascript\" + 0.007*\"technical\" + 0.007*\"c\" + 0.006*\"pl\" + 0.005*\"eclipse\"\n",
      "INFO : topic #8 (0.111): 0.027*\"python\" + 0.027*\"r\" + 0.024*\"sql\" + 0.020*\"hadoop\" + 0.020*\"hive\" + 0.017*\"tableau\" + 0.016*\"java\" + 0.014*\"technical\" + 0.014*\"spark\" + 0.013*\"pig\"\n",
      "INFO : topic #2 (0.111): 0.005*\"r\" + 0.004*\"c++\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"data\" + 0.003*\"project\" + 0.003*\"windows\" + 0.003*\"linux\" + 0.003*\"software\" + 0.003*\"sql\"\n",
      "INFO : topic #5 (0.111): 0.007*\"sql\" + 0.005*\"technical\" + 0.004*\"excel\" + 0.004*\"sas\" + 0.004*\"access\" + 0.003*\"key\" + 0.003*\"taleo\" + 0.003*\"oracle\" + 0.002*\"data\" + 0.002*\"skills\"\n",
      "INFO : topic diff=0.030976, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.734 per-word bound, 425.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3905/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.111): 0.004*\"core\" + 0.004*\"python\" + 0.004*\"linux\" + 0.004*\"sql\" + 0.003*\"c++\" + 0.003*\"c\" + 0.002*\"matlab\" + 0.002*\"hadoop\" + 0.002*\"skill\" + 0.002*\"m.\"\n",
      "INFO : topic #2 (0.111): 0.005*\"r\" + 0.004*\"c++\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"data\" + 0.003*\"project\" + 0.003*\"software\" + 0.003*\"windows\" + 0.003*\"research\" + 0.003*\"linux\"\n",
      "INFO : topic #1 (0.111): 0.029*\"python\" + 0.028*\"java\" + 0.025*\"c\" + 0.024*\"c++\" + 0.021*\"html\" + 0.020*\"sql\" + 0.019*\"javascript\" + 0.018*\"r\" + 0.017*\"css\" + 0.016*\"technical\"\n",
      "INFO : topic #6 (0.111): 0.032*\"python\" + 0.031*\"r\" + 0.026*\"sql\" + 0.015*\"pandas\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"sas\" + 0.014*\"matlab\" + 0.012*\"numpy\" + 0.011*\"hadoop\"\n",
      "INFO : topic #0 (0.111): 0.011*\"sql\" + 0.009*\"html\" + 0.009*\"oracle\" + 0.009*\"xml\" + 0.008*\"java\" + 0.008*\"javascript\" + 0.007*\"technical\" + 0.007*\"c\" + 0.006*\"pl\" + 0.005*\"eclipse\"\n",
      "INFO : topic diff=0.026856, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.731 per-word bound, 424.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3900/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.111): 0.027*\"python\" + 0.026*\"r\" + 0.024*\"sql\" + 0.020*\"hive\" + 0.020*\"hadoop\" + 0.017*\"tableau\" + 0.016*\"java\" + 0.015*\"technical\" + 0.014*\"spark\" + 0.014*\"pig\"\n",
      "INFO : topic #2 (0.111): 0.005*\"r\" + 0.004*\"c++\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"project\" + 0.003*\"data\" + 0.003*\"research\" + 0.003*\"software\" + 0.003*\"windows\" + 0.002*\"linux\"\n",
      "INFO : topic #4 (0.111): 0.034*\"r\" + 0.033*\"sql\" + 0.028*\"python\" + 0.027*\"excel\" + 0.025*\"sas\" + 0.019*\"powerpoint\" + 0.018*\"matlab\" + 0.016*\"spss\" + 0.015*\"word\" + 0.014*\"tableau\"\n",
      "INFO : topic #6 (0.111): 0.032*\"python\" + 0.031*\"r\" + 0.026*\"sql\" + 0.015*\"pandas\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"sas\" + 0.014*\"matlab\" + 0.012*\"numpy\" + 0.011*\"hadoop\"\n",
      "INFO : topic #1 (0.111): 0.029*\"python\" + 0.029*\"java\" + 0.025*\"c\" + 0.024*\"c++\" + 0.021*\"html\" + 0.020*\"sql\" + 0.020*\"javascript\" + 0.018*\"r\" + 0.017*\"css\" + 0.016*\"technical\"\n",
      "INFO : topic diff=0.023711, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.728 per-word bound, 424.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3902/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.111): 0.004*\"core\" + 0.003*\"python\" + 0.003*\"linux\" + 0.003*\"c++\" + 0.003*\"sql\" + 0.003*\"c\" + 0.003*\"m.\" + 0.002*\"skill\" + 0.002*\"d.\" + 0.002*\"relevant\"\n",
      "INFO : topic #1 (0.111): 0.029*\"python\" + 0.029*\"java\" + 0.025*\"c\" + 0.025*\"c++\" + 0.022*\"html\" + 0.020*\"sql\" + 0.020*\"javascript\" + 0.018*\"r\" + 0.017*\"css\" + 0.016*\"technical\"\n",
      "INFO : topic #2 (0.111): 0.004*\"r\" + 0.003*\"c++\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"project\" + 0.003*\"data\" + 0.003*\"research\" + 0.003*\"software\" + 0.002*\"windows\" + 0.002*\"core\"\n",
      "INFO : topic #6 (0.111): 0.032*\"python\" + 0.031*\"r\" + 0.026*\"sql\" + 0.015*\"pandas\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"matlab\" + 0.014*\"sas\" + 0.012*\"numpy\" + 0.011*\"hadoop\"\n",
      "INFO : topic #8 (0.111): 0.026*\"python\" + 0.026*\"r\" + 0.024*\"sql\" + 0.020*\"hive\" + 0.020*\"hadoop\" + 0.016*\"tableau\" + 0.016*\"java\" + 0.015*\"technical\" + 0.014*\"pig\" + 0.014*\"spark\"\n",
      "INFO : topic diff=0.021017, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.725 per-word bound, 423.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3913/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3923/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.111): 0.004*\"core\" + 0.003*\"python\" + 0.003*\"linux\" + 0.003*\"c++\" + 0.003*\"sql\" + 0.003*\"m.\" + 0.002*\"c\" + 0.002*\"d.\" + 0.002*\"skill\" + 0.002*\"relevant\"\n",
      "INFO : topic #2 (0.111): 0.004*\"r\" + 0.003*\"c++\" + 0.003*\"computer\" + 0.003*\"project\" + 0.003*\"microsoft\" + 0.003*\"data\" + 0.003*\"research\" + 0.003*\"software\" + 0.002*\"core\" + 0.002*\"windows\"\n",
      "INFO : topic #3 (0.111): 0.006*\"technical\" + 0.005*\"skills\" + 0.004*\"unix\" + 0.003*\"project\" + 0.002*\"linux\" + 0.002*\"sql\" + 0.002*\"powershell\" + 0.002*\"research\" + 0.002*\"core\" + 0.002*\"google\"\n",
      "INFO : topic #1 (0.111): 0.030*\"python\" + 0.029*\"java\" + 0.026*\"c\" + 0.025*\"c++\" + 0.022*\"html\" + 0.021*\"javascript\" + 0.020*\"sql\" + 0.018*\"r\" + 0.017*\"css\" + 0.016*\"technical\"\n",
      "INFO : topic #8 (0.111): 0.026*\"python\" + 0.026*\"r\" + 0.024*\"sql\" + 0.021*\"hive\" + 0.020*\"hadoop\" + 0.016*\"tableau\" + 0.016*\"java\" + 0.015*\"technical\" + 0.014*\"pig\" + 0.014*\"spark\"\n",
      "INFO : topic diff=0.018909, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.723 per-word bound, 422.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.111): 0.030*\"python\" + 0.030*\"java\" + 0.026*\"c\" + 0.025*\"c++\" + 0.022*\"html\" + 0.021*\"javascript\" + 0.020*\"sql\" + 0.018*\"r\" + 0.017*\"css\" + 0.016*\"technical\"\n",
      "INFO : topic #3 (0.111): 0.006*\"technical\" + 0.005*\"skills\" + 0.004*\"unix\" + 0.003*\"project\" + 0.002*\"linux\" + 0.002*\"sql\" + 0.002*\"powershell\" + 0.002*\"research\" + 0.002*\"core\" + 0.002*\"google\"\n",
      "INFO : topic #8 (0.111): 0.026*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.021*\"hive\" + 0.020*\"hadoop\" + 0.016*\"tableau\" + 0.016*\"java\" + 0.015*\"technical\" + 0.014*\"pig\" + 0.014*\"spark\"\n",
      "INFO : topic #0 (0.111): 0.010*\"sql\" + 0.009*\"xml\" + 0.009*\"html\" + 0.009*\"oracle\" + 0.008*\"java\" + 0.007*\"javascript\" + 0.007*\"technical\" + 0.007*\"c\" + 0.006*\"pl\" + 0.005*\"agile\"\n",
      "INFO : topic #5 (0.111): 0.005*\"sql\" + 0.004*\"technical\" + 0.003*\"key\" + 0.003*\"taleo\" + 0.003*\"sas\" + 0.003*\"access\" + 0.003*\"excel\" + 0.002*\"leadership\" + 0.002*\"oracle\" + 0.002*\"skills\"\n",
      "INFO : topic diff=0.017095, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.721 per-word bound, 421.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.111): 0.005*\"sql\" + 0.004*\"technical\" + 0.003*\"key\" + 0.003*\"taleo\" + 0.003*\"sas\" + 0.003*\"access\" + 0.002*\"excel\" + 0.002*\"leadership\" + 0.002*\"skills\" + 0.002*\"oracle\"\n",
      "INFO : topic #0 (0.111): 0.010*\"sql\" + 0.009*\"xml\" + 0.009*\"oracle\" + 0.009*\"html\" + 0.008*\"java\" + 0.007*\"javascript\" + 0.007*\"technical\" + 0.006*\"c\" + 0.006*\"pl\" + 0.005*\"agile\"\n",
      "INFO : topic #7 (0.111): 0.004*\"core\" + 0.003*\"m.\" + 0.003*\"linux\" + 0.003*\"d.\" + 0.002*\"python\" + 0.002*\"c++\" + 0.002*\"skill\" + 0.002*\"sql\" + 0.002*\"relevant\" + 0.002*\"s.\"\n",
      "INFO : topic #2 (0.111): 0.004*\"r\" + 0.003*\"project\" + 0.003*\"research\" + 0.003*\"microsoft\" + 0.003*\"c++\" + 0.003*\"data\" + 0.003*\"computer\" + 0.003*\"software\" + 0.002*\"core\" + 0.002*\"analysis\"\n",
      "INFO : topic #8 (0.111): 0.026*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.021*\"hive\" + 0.021*\"hadoop\" + 0.016*\"tableau\" + 0.016*\"java\" + 0.015*\"technical\" + 0.014*\"pig\" + 0.014*\"spark\"\n",
      "INFO : topic diff=0.015635, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.719 per-word bound, 421.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3928/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.111): 0.005*\"sql\" + 0.004*\"technical\" + 0.004*\"key\" + 0.003*\"taleo\" + 0.002*\"sas\" + 0.002*\"leadership\" + 0.002*\"access\" + 0.002*\"skills\" + 0.002*\"excel\" + 0.002*\"oracle\"\n",
      "INFO : topic #6 (0.111): 0.032*\"python\" + 0.031*\"r\" + 0.026*\"sql\" + 0.016*\"pandas\" + 0.015*\"tableau\" + 0.015*\"technical\" + 0.014*\"matlab\" + 0.013*\"sas\" + 0.012*\"numpy\" + 0.012*\"hadoop\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #8 (0.111): 0.025*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.021*\"hive\" + 0.021*\"hadoop\" + 0.016*\"tableau\" + 0.016*\"java\" + 0.015*\"technical\" + 0.014*\"pig\" + 0.014*\"spark\"\n",
      "INFO : topic #1 (0.111): 0.030*\"java\" + 0.030*\"python\" + 0.026*\"c\" + 0.026*\"c++\" + 0.022*\"html\" + 0.022*\"javascript\" + 0.020*\"sql\" + 0.018*\"r\" + 0.018*\"css\" + 0.016*\"technical\"\n",
      "INFO : topic #7 (0.111): 0.004*\"core\" + 0.003*\"m.\" + 0.003*\"d.\" + 0.002*\"linux\" + 0.002*\"skill\" + 0.002*\"c++\" + 0.002*\"s.\" + 0.002*\"python\" + 0.002*\"relevant\" + 0.002*\"j.\"\n",
      "INFO : topic diff=0.014398, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.718 per-word bound, 421.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=9, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=9, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (153 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (208 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (435 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (545 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (328 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (503 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (592 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (560 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (350 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (821 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (272 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (346 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (678 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (612 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (414 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (812 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (444 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (885 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (668 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (336 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (478 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (478 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 5; 384 documents processed (641 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (876 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (641 virtual)\n",
      "DEBUG : completed batch 9; 640 documents processed (753 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (753 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 527 documents processed (753 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (427 virtual)\n",
      "DEBUG : finished all batches; 527 documents processed (753 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (876 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 320 documents processed (336 virtual)\n",
      "DEBUG : finished all batches; 384 documents processed (427 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (527 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 448 documents processed (527 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (642 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (508 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (526 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (676 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (508 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (512 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (508 virtual)\n",
      "DEBUG : finished all batches; 384 documents processed (526 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (676 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (642 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 448 documents processed (508 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 9; 640 documents processed (1067 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (1067 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9230 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12338/12537 documents converged within 50 iterations\n",
      " 30%|███       | 7/23 [02:54<06:38, 24.90s/it]INFO : using symmetric alpha at 0.1\n",
      "INFO : using symmetric eta at 0.1\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 10 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 429/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3131/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3237/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3115/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.100): 0.032*\"r\" + 0.029*\"python\" + 0.026*\"sql\" + 0.016*\"tableau\" + 0.015*\"hadoop\" + 0.013*\"hive\" + 0.012*\"c++\" + 0.012*\"java\" + 0.012*\"technical\" + 0.011*\"sas\"\n",
      "INFO : topic #6 (0.100): 0.026*\"python\" + 0.025*\"r\" + 0.020*\"sql\" + 0.016*\"sas\" + 0.013*\"matlab\" + 0.012*\"tableau\" + 0.011*\"mysql\" + 0.011*\"c++\" + 0.011*\"technical\" + 0.010*\"java\"\n",
      "INFO : topic #2 (0.100): 0.013*\"r\" + 0.011*\"sql\" + 0.011*\"python\" + 0.010*\"c++\" + 0.007*\"sas\" + 0.007*\"java\" + 0.006*\"c\" + 0.006*\"linux\" + 0.006*\"tableau\" + 0.006*\"computer\"\n",
      "INFO : topic #5 (0.100): 0.016*\"sql\" + 0.011*\"technical\" + 0.009*\"r\" + 0.008*\"sas\" + 0.008*\"python\" + 0.008*\"excel\" + 0.006*\"tableau\" + 0.006*\"java\" + 0.006*\"hadoop\" + 0.005*\"powerpoint\"\n",
      "INFO : topic #1 (0.100): 0.026*\"python\" + 0.020*\"r\" + 0.020*\"sql\" + 0.019*\"java\" + 0.017*\"technical\" + 0.014*\"c++\" + 0.013*\"c\" + 0.011*\"matlab\" + 0.011*\"tableau\" + 0.010*\"mysql\"\n",
      "INFO : topic diff=6.713493, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.159 per-word bound, 571.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 514/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3758/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3758/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3792/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.100): 0.026*\"sql\" + 0.025*\"r\" + 0.024*\"python\" + 0.014*\"matlab\" + 0.014*\"tableau\" + 0.013*\"technical\" + 0.012*\"sas\" + 0.011*\"excel\" + 0.010*\"data\" + 0.010*\"c++\"\n",
      "INFO : topic #0 (0.100): 0.015*\"sql\" + 0.013*\"python\" + 0.013*\"r\" + 0.009*\"java\" + 0.008*\"hive\" + 0.008*\"html\" + 0.007*\"technical\" + 0.007*\"javascript\" + 0.007*\"excel\" + 0.007*\"c++\"\n",
      "INFO : topic #5 (0.100): 0.014*\"sql\" + 0.009*\"technical\" + 0.007*\"sas\" + 0.007*\"r\" + 0.007*\"excel\" + 0.006*\"python\" + 0.005*\"powerpoint\" + 0.005*\"tableau\" + 0.005*\"oracle\" + 0.005*\"access\"\n",
      "INFO : topic #7 (0.100): 0.015*\"sql\" + 0.014*\"python\" + 0.011*\"linux\" + 0.010*\"hadoop\" + 0.010*\"r\" + 0.009*\"c++\" + 0.009*\"matlab\" + 0.009*\"hive\" + 0.008*\"c\" + 0.007*\"java\"\n",
      "INFO : topic #9 (0.100): 0.025*\"python\" + 0.023*\"c\" + 0.023*\"sql\" + 0.021*\"html\" + 0.020*\"r\" + 0.020*\"java\" + 0.016*\"c++\" + 0.013*\"technical\" + 0.013*\"javascript\" + 0.011*\"css\"\n",
      "INFO : topic diff=0.341754, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.992 per-word bound, 509.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3806/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3837/4000 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3848/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.100): 0.024*\"python\" + 0.018*\"sql\" + 0.018*\"r\" + 0.018*\"java\" + 0.017*\"technical\" + 0.013*\"c++\" + 0.013*\"c\" + 0.010*\"mysql\" + 0.010*\"matlab\" + 0.010*\"tableau\"\n",
      "INFO : topic #2 (0.100): 0.010*\"r\" + 0.009*\"sql\" + 0.009*\"c++\" + 0.008*\"python\" + 0.006*\"sas\" + 0.006*\"computer\" + 0.005*\"excel\" + 0.005*\"linux\" + 0.005*\"c\" + 0.005*\"matlab\"\n",
      "INFO : topic #8 (0.100): 0.032*\"r\" + 0.030*\"python\" + 0.026*\"sql\" + 0.018*\"hadoop\" + 0.017*\"tableau\" + 0.016*\"hive\" + 0.014*\"java\" + 0.013*\"technical\" + 0.012*\"spark\" + 0.011*\"c++\"\n",
      "INFO : topic #9 (0.100): 0.026*\"python\" + 0.024*\"c\" + 0.022*\"sql\" + 0.022*\"html\" + 0.021*\"java\" + 0.020*\"r\" + 0.018*\"c++\" + 0.015*\"javascript\" + 0.013*\"technical\" + 0.013*\"css\"\n",
      "INFO : topic #3 (0.100): 0.011*\"technical\" + 0.008*\"sql\" + 0.007*\"unix\" + 0.006*\"python\" + 0.006*\"tableau\" + 0.005*\"linux\" + 0.005*\"r\" + 0.004*\"java\" + 0.004*\"skills\" + 0.004*\"powerpoint\"\n",
      "INFO : topic diff=0.275321, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.905 per-word bound, 479.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3863/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3838/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3885/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.100): 0.026*\"python\" + 0.024*\"c\" + 0.023*\"java\" + 0.023*\"html\" + 0.022*\"sql\" + 0.019*\"r\" + 0.019*\"c++\" + 0.017*\"javascript\" + 0.014*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #5 (0.100): 0.012*\"sql\" + 0.008*\"technical\" + 0.007*\"excel\" + 0.006*\"sas\" + 0.005*\"r\" + 0.005*\"oracle\" + 0.005*\"powerpoint\" + 0.005*\"access\" + 0.004*\"spss\" + 0.004*\"python\"\n",
      "INFO : topic #2 (0.100): 0.009*\"r\" + 0.008*\"c++\" + 0.008*\"sql\" + 0.007*\"python\" + 0.005*\"sas\" + 0.005*\"computer\" + 0.005*\"excel\" + 0.005*\"linux\" + 0.005*\"c\" + 0.004*\"matlab\"\n",
      "INFO : topic #0 (0.100): 0.013*\"sql\" + 0.009*\"python\" + 0.009*\"r\" + 0.008*\"java\" + 0.007*\"html\" + 0.007*\"technical\" + 0.007*\"oracle\" + 0.007*\"javascript\" + 0.006*\"excel\" + 0.006*\"hive\"\n",
      "INFO : topic #4 (0.100): 0.028*\"sql\" + 0.027*\"r\" + 0.025*\"python\" + 0.016*\"sas\" + 0.015*\"excel\" + 0.015*\"matlab\" + 0.014*\"tableau\" + 0.013*\"technical\" + 0.012*\"spss\" + 0.010*\"c++\"\n",
      "INFO : topic diff=0.220641, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.852 per-word bound, 462.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3852/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.100): 0.026*\"python\" + 0.025*\"c\" + 0.024*\"java\" + 0.023*\"html\" + 0.022*\"sql\" + 0.020*\"c++\" + 0.019*\"r\" + 0.018*\"javascript\" + 0.015*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #1 (0.100): 0.022*\"python\" + 0.016*\"sql\" + 0.016*\"java\" + 0.016*\"r\" + 0.016*\"technical\" + 0.012*\"c\" + 0.012*\"c++\" + 0.010*\"mysql\" + 0.009*\"matlab\" + 0.008*\"tableau\"\n",
      "INFO : topic #2 (0.100): 0.008*\"r\" + 0.008*\"c++\" + 0.007*\"sql\" + 0.006*\"python\" + 0.005*\"computer\" + 0.005*\"sas\" + 0.004*\"excel\" + 0.004*\"linux\" + 0.004*\"c\" + 0.004*\"matlab\"\n",
      "INFO : topic #4 (0.100): 0.029*\"r\" + 0.029*\"sql\" + 0.026*\"python\" + 0.018*\"excel\" + 0.017*\"sas\" + 0.016*\"matlab\" + 0.014*\"tableau\" + 0.013*\"spss\" + 0.012*\"technical\" + 0.011*\"powerpoint\"\n",
      "INFO : topic #5 (0.100): 0.011*\"sql\" + 0.008*\"technical\" + 0.006*\"excel\" + 0.006*\"sas\" + 0.005*\"oracle\" + 0.005*\"powerpoint\" + 0.005*\"r\" + 0.005*\"access\" + 0.004*\"spss\" + 0.003*\"linux\"\n",
      "INFO : topic diff=0.175405, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.817 per-word bound, 450.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3868/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3908/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.100): 0.007*\"r\" + 0.007*\"c++\" + 0.006*\"sql\" + 0.005*\"python\" + 0.005*\"computer\" + 0.004*\"sas\" + 0.004*\"linux\" + 0.004*\"data\" + 0.004*\"excel\" + 0.004*\"windows\"\n",
      "INFO : topic #3 (0.100): 0.008*\"technical\" + 0.006*\"unix\" + 0.005*\"sql\" + 0.004*\"linux\" + 0.004*\"tableau\" + 0.004*\"skills\" + 0.003*\"python\" + 0.003*\"data\" + 0.003*\"powerpoint\" + 0.003*\"excel\"\n",
      "INFO : topic #8 (0.100): 0.029*\"r\" + 0.029*\"python\" + 0.025*\"sql\" + 0.020*\"hadoop\" + 0.019*\"hive\" + 0.018*\"tableau\" + 0.015*\"java\" + 0.014*\"technical\" + 0.014*\"spark\" + 0.013*\"pig\"\n",
      "INFO : topic #5 (0.100): 0.010*\"sql\" + 0.007*\"technical\" + 0.006*\"excel\" + 0.005*\"sas\" + 0.005*\"oracle\" + 0.004*\"access\" + 0.004*\"powerpoint\" + 0.004*\"r\" + 0.003*\"spss\" + 0.003*\"word\"\n",
      "INFO : topic #6 (0.100): 0.031*\"python\" + 0.030*\"r\" + 0.026*\"sql\" + 0.016*\"sas\" + 0.014*\"tableau\" + 0.014*\"matlab\" + 0.014*\"technical\" + 0.013*\"pandas\" + 0.011*\"c++\" + 0.010*\"hadoop\"\n",
      "INFO : topic diff=0.139788, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.791 per-word bound, 443.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3903/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3915/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3876/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.100): 0.009*\"sql\" + 0.008*\"python\" + 0.008*\"linux\" + 0.007*\"c++\" + 0.006*\"matlab\" + 0.006*\"c\" + 0.006*\"hadoop\" + 0.005*\"excel\" + 0.005*\"r\" + 0.004*\"core\"\n",
      "INFO : topic #1 (0.100): 0.019*\"python\" + 0.015*\"technical\" + 0.015*\"java\" + 0.015*\"sql\" + 0.014*\"r\" + 0.012*\"c\" + 0.011*\"c++\" + 0.009*\"mysql\" + 0.008*\"matlab\" + 0.007*\"tableau\"\n",
      "INFO : topic #9 (0.100): 0.027*\"python\" + 0.026*\"c\" + 0.025*\"java\" + 0.025*\"html\" + 0.022*\"sql\" + 0.021*\"c++\" + 0.020*\"javascript\" + 0.019*\"r\" + 0.016*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #8 (0.100): 0.029*\"r\" + 0.028*\"python\" + 0.025*\"sql\" + 0.020*\"hadoop\" + 0.020*\"hive\" + 0.018*\"tableau\" + 0.015*\"java\" + 0.014*\"spark\" + 0.014*\"technical\" + 0.013*\"pig\"\n",
      "INFO : topic #3 (0.100): 0.008*\"technical\" + 0.006*\"unix\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"data\" + 0.003*\"python\" + 0.002*\"powerpoint\" + 0.002*\"access\"\n",
      "INFO : topic diff=0.111502, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.774 per-word bound, 437.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 522/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3883/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3908/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.100): 0.032*\"r\" + 0.032*\"sql\" + 0.028*\"python\" + 0.024*\"excel\" + 0.022*\"sas\" + 0.017*\"matlab\" + 0.016*\"powerpoint\" + 0.016*\"tableau\" + 0.015*\"spss\" + 0.013*\"technical\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #9 (0.100): 0.027*\"python\" + 0.026*\"java\" + 0.026*\"c\" + 0.025*\"html\" + 0.022*\"c++\" + 0.022*\"sql\" + 0.021*\"javascript\" + 0.019*\"r\" + 0.017*\"css\" + 0.013*\"mysql\"\n",
      "INFO : topic #5 (0.100): 0.009*\"sql\" + 0.006*\"technical\" + 0.005*\"excel\" + 0.005*\"sas\" + 0.004*\"oracle\" + 0.004*\"access\" + 0.004*\"powerpoint\" + 0.003*\"r\" + 0.003*\"spss\" + 0.003*\"ms\"\n",
      "INFO : topic #8 (0.100): 0.028*\"r\" + 0.028*\"python\" + 0.025*\"sql\" + 0.020*\"hadoop\" + 0.020*\"hive\" + 0.017*\"tableau\" + 0.015*\"java\" + 0.015*\"spark\" + 0.014*\"technical\" + 0.014*\"pig\"\n",
      "INFO : topic #1 (0.100): 0.018*\"python\" + 0.014*\"technical\" + 0.014*\"java\" + 0.014*\"sql\" + 0.013*\"r\" + 0.011*\"c\" + 0.011*\"c++\" + 0.008*\"mysql\" + 0.008*\"matlab\" + 0.007*\"tableau\"\n",
      "INFO : topic diff=0.089719, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.760 per-word bound, 433.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3908/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.100): 0.034*\"r\" + 0.033*\"sql\" + 0.028*\"python\" + 0.026*\"excel\" + 0.023*\"sas\" + 0.018*\"matlab\" + 0.017*\"powerpoint\" + 0.016*\"tableau\" + 0.016*\"spss\" + 0.013*\"word\"\n",
      "INFO : topic #8 (0.100): 0.027*\"r\" + 0.027*\"python\" + 0.024*\"sql\" + 0.021*\"hadoop\" + 0.021*\"hive\" + 0.017*\"tableau\" + 0.015*\"java\" + 0.015*\"spark\" + 0.014*\"technical\" + 0.014*\"pig\"\n",
      "INFO : topic #2 (0.100): 0.006*\"c++\" + 0.006*\"r\" + 0.004*\"sql\" + 0.004*\"computer\" + 0.004*\"project\" + 0.004*\"data\" + 0.004*\"python\" + 0.004*\"linux\" + 0.003*\"windows\" + 0.003*\"research\"\n",
      "INFO : topic #7 (0.100): 0.007*\"sql\" + 0.006*\"linux\" + 0.006*\"python\" + 0.006*\"c++\" + 0.005*\"matlab\" + 0.005*\"c\" + 0.005*\"core\" + 0.005*\"excel\" + 0.004*\"hadoop\" + 0.004*\"data\"\n",
      "INFO : topic #3 (0.100): 0.007*\"technical\" + 0.005*\"unix\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"sql\" + 0.003*\"data\" + 0.002*\"tableau\" + 0.002*\"j.\" + 0.002*\"access\" + 0.002*\"visio\"\n",
      "INFO : topic diff=0.073199, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.749 per-word bound, 430.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.100): 0.006*\"technical\" + 0.005*\"unix\" + 0.003*\"linux\" + 0.003*\"skills\" + 0.003*\"sql\" + 0.003*\"data\" + 0.002*\"j.\" + 0.002*\"tableau\" + 0.002*\"visio\" + 0.002*\"access\"\n",
      "INFO : topic #8 (0.100): 0.027*\"r\" + 0.027*\"python\" + 0.024*\"sql\" + 0.021*\"hive\" + 0.021*\"hadoop\" + 0.017*\"tableau\" + 0.015*\"java\" + 0.015*\"spark\" + 0.015*\"technical\" + 0.014*\"pig\"\n",
      "INFO : topic #0 (0.100): 0.009*\"sql\" + 0.007*\"oracle\" + 0.006*\"technical\" + 0.006*\"html\" + 0.006*\"java\" + 0.005*\"xml\" + 0.005*\"javascript\" + 0.005*\"project\" + 0.005*\"r\" + 0.005*\"pl\"\n",
      "INFO : topic #4 (0.100): 0.034*\"r\" + 0.033*\"sql\" + 0.028*\"python\" + 0.027*\"excel\" + 0.025*\"sas\" + 0.018*\"powerpoint\" + 0.018*\"matlab\" + 0.016*\"tableau\" + 0.016*\"spss\" + 0.014*\"word\"\n",
      "INFO : topic #6 (0.100): 0.033*\"python\" + 0.031*\"r\" + 0.027*\"sql\" + 0.015*\"sas\" + 0.015*\"tableau\" + 0.015*\"pandas\" + 0.014*\"matlab\" + 0.014*\"technical\" + 0.012*\"numpy\" + 0.011*\"hadoop\"\n",
      "INFO : topic diff=0.060352, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.740 per-word bound, 427.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.100): 0.028*\"java\" + 0.027*\"python\" + 0.027*\"c\" + 0.026*\"html\" + 0.023*\"c++\" + 0.023*\"javascript\" + 0.021*\"sql\" + 0.018*\"r\" + 0.018*\"css\" + 0.014*\"mysql\"\n",
      "INFO : topic #7 (0.100): 0.006*\"sql\" + 0.006*\"linux\" + 0.005*\"c++\" + 0.005*\"python\" + 0.005*\"core\" + 0.004*\"matlab\" + 0.004*\"c\" + 0.004*\"excel\" + 0.004*\"hadoop\" + 0.004*\"data\"\n",
      "INFO : topic #3 (0.100): 0.006*\"technical\" + 0.005*\"unix\" + 0.003*\"skills\" + 0.003*\"linux\" + 0.002*\"data\" + 0.002*\"sql\" + 0.002*\"j.\" + 0.002*\"tableau\" + 0.002*\"visio\" + 0.002*\"powershell\"\n",
      "INFO : topic #2 (0.100): 0.005*\"c++\" + 0.005*\"r\" + 0.004*\"project\" + 0.004*\"data\" + 0.004*\"computer\" + 0.004*\"sql\" + 0.004*\"research\" + 0.003*\"windows\" + 0.003*\"linux\" + 0.003*\"python\"\n",
      "INFO : topic #0 (0.100): 0.009*\"sql\" + 0.007*\"oracle\" + 0.006*\"technical\" + 0.006*\"html\" + 0.006*\"java\" + 0.005*\"xml\" + 0.005*\"javascript\" + 0.005*\"project\" + 0.005*\"pl\" + 0.004*\"c\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.050478, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.732 per-word bound, 425.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.100): 0.005*\"c++\" + 0.004*\"r\" + 0.004*\"project\" + 0.004*\"research\" + 0.004*\"data\" + 0.003*\"computer\" + 0.003*\"sql\" + 0.003*\"windows\" + 0.003*\"linux\" + 0.003*\"python\"\n",
      "INFO : topic #3 (0.100): 0.006*\"technical\" + 0.005*\"unix\" + 0.003*\"skills\" + 0.003*\"linux\" + 0.002*\"data\" + 0.002*\"j.\" + 0.002*\"sql\" + 0.002*\"powershell\" + 0.002*\"visio\" + 0.002*\"s.\"\n",
      "INFO : topic #8 (0.100): 0.026*\"python\" + 0.026*\"r\" + 0.024*\"sql\" + 0.021*\"hive\" + 0.021*\"hadoop\" + 0.017*\"tableau\" + 0.015*\"java\" + 0.015*\"spark\" + 0.015*\"technical\" + 0.015*\"pig\"\n",
      "INFO : topic #0 (0.100): 0.009*\"sql\" + 0.007*\"oracle\" + 0.006*\"technical\" + 0.006*\"html\" + 0.005*\"xml\" + 0.005*\"java\" + 0.005*\"project\" + 0.005*\"javascript\" + 0.005*\"pl\" + 0.004*\"c\"\n",
      "INFO : topic #1 (0.100): 0.014*\"python\" + 0.012*\"technical\" + 0.011*\"java\" + 0.011*\"sql\" + 0.010*\"r\" + 0.009*\"c\" + 0.009*\"c++\" + 0.007*\"mysql\" + 0.006*\"matlab\" + 0.006*\"ms\"\n",
      "INFO : topic diff=0.042635, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.727 per-word bound, 423.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.100): 0.026*\"python\" + 0.025*\"r\" + 0.024*\"sql\" + 0.022*\"hive\" + 0.021*\"hadoop\" + 0.017*\"tableau\" + 0.015*\"java\" + 0.015*\"spark\" + 0.015*\"technical\" + 0.015*\"pig\"\n",
      "INFO : topic #4 (0.100): 0.037*\"r\" + 0.035*\"sql\" + 0.030*\"excel\" + 0.029*\"python\" + 0.028*\"sas\" + 0.020*\"powerpoint\" + 0.019*\"matlab\" + 0.017*\"spss\" + 0.017*\"tableau\" + 0.016*\"word\"\n",
      "INFO : topic #2 (0.100): 0.005*\"c++\" + 0.004*\"r\" + 0.004*\"project\" + 0.004*\"research\" + 0.003*\"data\" + 0.003*\"computer\" + 0.003*\"windows\" + 0.003*\"sql\" + 0.003*\"linux\" + 0.003*\"relevant\"\n",
      "INFO : topic #0 (0.100): 0.008*\"sql\" + 0.007*\"oracle\" + 0.006*\"technical\" + 0.005*\"html\" + 0.005*\"xml\" + 0.005*\"java\" + 0.005*\"project\" + 0.005*\"javascript\" + 0.005*\"pl\" + 0.004*\"uml\"\n",
      "INFO : topic #5 (0.100): 0.006*\"sql\" + 0.005*\"technical\" + 0.004*\"oracle\" + 0.004*\"sas\" + 0.003*\"excel\" + 0.003*\"access\" + 0.003*\"stat\" + 0.003*\"key\" + 0.003*\"graph\" + 0.003*\"base\"\n",
      "INFO : topic diff=0.036568, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.721 per-word bound, 422.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.100): 0.025*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.022*\"hive\" + 0.021*\"hadoop\" + 0.017*\"tableau\" + 0.015*\"java\" + 0.015*\"spark\" + 0.015*\"pig\" + 0.015*\"technical\"\n",
      "INFO : topic #7 (0.100): 0.005*\"core\" + 0.005*\"linux\" + 0.004*\"sql\" + 0.004*\"c++\" + 0.004*\"c\" + 0.004*\"python\" + 0.004*\"matlab\" + 0.003*\"data\" + 0.003*\"skill\" + 0.003*\"hadoop\"\n",
      "INFO : topic #6 (0.100): 0.034*\"python\" + 0.032*\"r\" + 0.027*\"sql\" + 0.016*\"pandas\" + 0.015*\"tableau\" + 0.015*\"matlab\" + 0.015*\"technical\" + 0.014*\"sas\" + 0.013*\"numpy\" + 0.012*\"hadoop\"\n",
      "INFO : topic #9 (0.100): 0.029*\"java\" + 0.028*\"c\" + 0.027*\"python\" + 0.027*\"html\" + 0.024*\"javascript\" + 0.024*\"c++\" + 0.021*\"sql\" + 0.019*\"css\" + 0.018*\"r\" + 0.015*\"mysql\"\n",
      "INFO : topic #3 (0.100): 0.005*\"technical\" + 0.004*\"unix\" + 0.003*\"skills\" + 0.002*\"j.\" + 0.002*\"linux\" + 0.002*\"data\" + 0.002*\"sql\" + 0.002*\"s.\" + 0.002*\"powershell\" + 0.002*\"p.\"\n",
      "INFO : topic diff=0.031681, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.716 per-word bound, 420.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #0 (0.100): 0.008*\"sql\" + 0.007*\"oracle\" + 0.005*\"xml\" + 0.005*\"technical\" + 0.005*\"html\" + 0.005*\"project\" + 0.005*\"java\" + 0.005*\"pl\" + 0.004*\"javascript\" + 0.004*\"uml\"\n",
      "INFO : topic #7 (0.100): 0.005*\"core\" + 0.004*\"linux\" + 0.004*\"c++\" + 0.004*\"sql\" + 0.003*\"c\" + 0.003*\"matlab\" + 0.003*\"data\" + 0.003*\"python\" + 0.003*\"skill\" + 0.003*\"hadoop\"\n",
      "INFO : topic #5 (0.100): 0.006*\"sql\" + 0.004*\"technical\" + 0.004*\"oracle\" + 0.003*\"sas\" + 0.003*\"key\" + 0.003*\"stat\" + 0.003*\"graph\" + 0.003*\"access\" + 0.003*\"excel\" + 0.003*\"base\"\n",
      "INFO : topic #3 (0.100): 0.005*\"technical\" + 0.004*\"unix\" + 0.003*\"skills\" + 0.003*\"j.\" + 0.002*\"data\" + 0.002*\"linux\" + 0.002*\"s.\" + 0.002*\"powershell\" + 0.002*\"sql\" + 0.002*\"p.\"\n",
      "INFO : topic #1 (0.100): 0.011*\"python\" + 0.011*\"technical\" + 0.009*\"java\" + 0.009*\"sql\" + 0.008*\"r\" + 0.008*\"c\" + 0.008*\"c++\" + 0.006*\"ms\" + 0.006*\"mysql\" + 0.005*\"matlab\"\n",
      "INFO : topic diff=0.027792, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.713 per-word bound, 419.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.100): 0.034*\"python\" + 0.032*\"r\" + 0.027*\"sql\" + 0.016*\"pandas\" + 0.015*\"tableau\" + 0.015*\"technical\" + 0.015*\"matlab\" + 0.014*\"sas\" + 0.013*\"numpy\" + 0.012*\"hadoop\"\n",
      "INFO : topic #8 (0.100): 0.025*\"python\" + 0.024*\"r\" + 0.023*\"sql\" + 0.022*\"hive\" + 0.021*\"hadoop\" + 0.017*\"tableau\" + 0.015*\"spark\" + 0.015*\"pig\" + 0.015*\"java\" + 0.015*\"technical\"\n",
      "INFO : topic #9 (0.100): 0.029*\"java\" + 0.028*\"c\" + 0.028*\"python\" + 0.027*\"html\" + 0.025*\"javascript\" + 0.024*\"c++\" + 0.021*\"sql\" + 0.019*\"css\" + 0.018*\"r\" + 0.015*\"mysql\"\n",
      "INFO : topic #7 (0.100): 0.005*\"core\" + 0.004*\"linux\" + 0.004*\"c++\" + 0.004*\"sql\" + 0.003*\"c\" + 0.003*\"data\" + 0.003*\"skill\" + 0.003*\"matlab\" + 0.003*\"python\" + 0.002*\"computer\"\n",
      "INFO : topic #2 (0.100): 0.004*\"c++\" + 0.004*\"research\" + 0.004*\"project\" + 0.003*\"data\" + 0.003*\"r\" + 0.003*\"relevant\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"windows\" + 0.002*\"linux\"\n",
      "INFO : topic diff=0.024663, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.709 per-word bound, 418.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.100): 0.005*\"sql\" + 0.004*\"technical\" + 0.004*\"oracle\" + 0.003*\"key\" + 0.003*\"sas\" + 0.003*\"stat\" + 0.003*\"graph\" + 0.003*\"taleo\" + 0.002*\"base\" + 0.002*\"access\"\n",
      "INFO : topic #4 (0.100): 0.039*\"r\" + 0.037*\"sql\" + 0.032*\"excel\" + 0.030*\"python\" + 0.030*\"sas\" + 0.021*\"powerpoint\" + 0.020*\"matlab\" + 0.019*\"spss\" + 0.018*\"tableau\" + 0.017*\"word\"\n",
      "INFO : topic #9 (0.100): 0.029*\"java\" + 0.028*\"c\" + 0.028*\"python\" + 0.027*\"html\" + 0.025*\"javascript\" + 0.024*\"c++\" + 0.021*\"sql\" + 0.019*\"css\" + 0.018*\"r\" + 0.016*\"mysql\"\n",
      "INFO : topic #7 (0.100): 0.005*\"core\" + 0.004*\"c++\" + 0.004*\"linux\" + 0.003*\"sql\" + 0.003*\"data\" + 0.003*\"skill\" + 0.003*\"c\" + 0.003*\"matlab\" + 0.003*\"python\" + 0.002*\"computer\"\n",
      "INFO : topic #0 (0.100): 0.007*\"sql\" + 0.007*\"oracle\" + 0.006*\"xml\" + 0.005*\"technical\" + 0.005*\"project\" + 0.005*\"html\" + 0.005*\"pl\" + 0.005*\"java\" + 0.005*\"uml\" + 0.004*\"db2\"\n",
      "INFO : topic diff=0.022100, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.707 per-word bound, 417.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.100): 0.035*\"python\" + 0.032*\"r\" + 0.027*\"sql\" + 0.016*\"pandas\" + 0.015*\"tableau\" + 0.015*\"technical\" + 0.015*\"matlab\" + 0.014*\"sas\" + 0.013*\"numpy\" + 0.012*\"hadoop\"\n",
      "INFO : topic #0 (0.100): 0.007*\"sql\" + 0.007*\"oracle\" + 0.006*\"xml\" + 0.005*\"technical\" + 0.005*\"project\" + 0.005*\"html\" + 0.005*\"uml\" + 0.005*\"pl\" + 0.004*\"java\" + 0.004*\"db2\"\n",
      "INFO : topic #5 (0.100): 0.005*\"sql\" + 0.004*\"technical\" + 0.004*\"oracle\" + 0.003*\"key\" + 0.003*\"graph\" + 0.003*\"stat\" + 0.003*\"sas\" + 0.003*\"taleo\" + 0.002*\"base\" + 0.002*\"macros\"\n",
      "INFO : topic #9 (0.100): 0.030*\"java\" + 0.028*\"c\" + 0.028*\"python\" + 0.027*\"html\" + 0.025*\"javascript\" + 0.025*\"c++\" + 0.021*\"sql\" + 0.020*\"css\" + 0.018*\"r\" + 0.016*\"mysql\"\n",
      "INFO : topic #3 (0.100): 0.005*\"technical\" + 0.004*\"unix\" + 0.003*\"skills\" + 0.003*\"j.\" + 0.002*\"data\" + 0.002*\"s.\" + 0.002*\"powershell\" + 0.002*\"linux\" + 0.002*\"p.\" + 0.002*\"b.\"\n",
      "INFO : topic diff=0.019933, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.704 per-word bound, 416.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.100): 0.005*\"sql\" + 0.004*\"technical\" + 0.003*\"oracle\" + 0.003*\"key\" + 0.003*\"graph\" + 0.003*\"stat\" + 0.003*\"taleo\" + 0.002*\"sas\" + 0.002*\"base\" + 0.002*\"macros\"\n",
      "INFO : topic #4 (0.100): 0.040*\"r\" + 0.037*\"sql\" + 0.033*\"excel\" + 0.031*\"sas\" + 0.031*\"python\" + 0.022*\"powerpoint\" + 0.020*\"matlab\" + 0.019*\"spss\" + 0.018*\"tableau\" + 0.018*\"word\"\n",
      "INFO : topic #3 (0.100): 0.004*\"technical\" + 0.004*\"unix\" + 0.003*\"skills\" + 0.003*\"j.\" + 0.002*\"data\" + 0.002*\"s.\" + 0.002*\"powershell\" + 0.002*\"p.\" + 0.002*\"b.\" + 0.002*\"seattle\"\n",
      "INFO : topic #2 (0.100): 0.004*\"research\" + 0.004*\"project\" + 0.004*\"c++\" + 0.003*\"data\" + 0.003*\"relevant\" + 0.003*\"r\" + 0.002*\"microsoft\" + 0.002*\"computer\" + 0.002*\"windows\" + 0.002*\"datascience\"\n",
      "INFO : topic #1 (0.100): 0.009*\"technical\" + 0.009*\"python\" + 0.008*\"java\" + 0.007*\"sql\" + 0.006*\"c\" + 0.006*\"c++\" + 0.006*\"r\" + 0.006*\"ms\" + 0.004*\"mysql\" + 0.004*\"matlab\"\n",
      "INFO : topic diff=0.018106, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.701 per-word bound, 416.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #4 (0.100): 0.040*\"r\" + 0.038*\"sql\" + 0.033*\"excel\" + 0.031*\"sas\" + 0.031*\"python\" + 0.022*\"powerpoint\" + 0.020*\"matlab\" + 0.019*\"spss\" + 0.018*\"tableau\" + 0.018*\"word\"\n",
      "INFO : topic #3 (0.100): 0.004*\"technical\" + 0.003*\"unix\" + 0.003*\"j.\" + 0.003*\"skills\" + 0.002*\"data\" + 0.002*\"s.\" + 0.002*\"p.\" + 0.002*\"powershell\" + 0.002*\"b.\" + 0.002*\"seattle\"\n",
      "INFO : topic #8 (0.100): 0.024*\"python\" + 0.023*\"r\" + 0.023*\"sql\" + 0.022*\"hive\" + 0.021*\"hadoop\" + 0.017*\"tableau\" + 0.016*\"pig\" + 0.015*\"spark\" + 0.015*\"technical\" + 0.015*\"java\"\n",
      "INFO : topic #0 (0.100): 0.007*\"sql\" + 0.007*\"oracle\" + 0.006*\"xml\" + 0.005*\"project\" + 0.005*\"technical\" + 0.005*\"uml\" + 0.005*\"html\" + 0.004*\"pl\" + 0.004*\"db2\" + 0.004*\"agile\"\n",
      "INFO : topic #2 (0.100): 0.004*\"research\" + 0.004*\"project\" + 0.004*\"c++\" + 0.003*\"data\" + 0.003*\"relevant\" + 0.003*\"r\" + 0.002*\"microsoft\" + 0.002*\"datascience\" + 0.002*\"computer\" + 0.002*\"windows\"\n",
      "INFO : topic diff=0.016600, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.699 per-word bound, 415.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=10, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=10, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (545 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (473 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (515 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (392 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (193 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (580 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (302 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (468 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (579 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (439 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (453 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (883 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (302 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (414 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (820 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (508 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (643 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (377 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (607 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (500 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (586 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (500 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (586 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 9; 640 documents processed (655 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (655 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (321 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (321 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (964 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (964 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (641 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (478 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (641 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (478 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (572 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (572 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (607 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (707 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (630 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 576 documents processed (707 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (454 virtual)\n",
      "DEBUG : completed batch 6; 432 documents processed (607 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (630 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (454 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 9; 640 documents processed (1093 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 640 documents processed (1093 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 432 documents processed (607 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9263 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12386/12537 documents converged within 50 iterations\n",
      " 35%|███▍      | 8/23 [03:19<06:14, 24.99s/it]INFO : using symmetric alpha at 0.09090909090909091\n",
      "INFO : using symmetric eta at 0.09090909090909091\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 11 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 421/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3308/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3120/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3110/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.091): 0.014*\"technical\" + 0.012*\"sql\" + 0.011*\"python\" + 0.010*\"r\" + 0.009*\"unix\" + 0.008*\"tableau\" + 0.007*\"java\" + 0.006*\"linux\" + 0.005*\"hive\" + 0.004*\"skills\"\n",
      "INFO : topic #9 (0.091): 0.026*\"python\" + 0.023*\"sql\" + 0.022*\"c\" + 0.020*\"r\" + 0.018*\"java\" + 0.018*\"html\" + 0.015*\"c++\" + 0.014*\"technical\" + 0.011*\"javascript\" + 0.009*\"matlab\"\n",
      "INFO : topic #8 (0.091): 0.032*\"r\" + 0.030*\"python\" + 0.027*\"sql\" + 0.016*\"tableau\" + 0.015*\"hadoop\" + 0.012*\"java\" + 0.012*\"hive\" + 0.012*\"c++\" + 0.011*\"technical\" + 0.010*\"c\"\n",
      "INFO : topic #2 (0.091): 0.012*\"r\" + 0.011*\"sql\" + 0.011*\"python\" + 0.010*\"c++\" + 0.007*\"c\" + 0.007*\"sas\" + 0.007*\"java\" + 0.006*\"programming\" + 0.006*\"linux\" + 0.006*\"matlab\"\n",
      "INFO : topic #7 (0.091): 0.017*\"sql\" + 0.016*\"python\" + 0.013*\"hadoop\" + 0.012*\"linux\" + 0.012*\"hive\" + 0.011*\"r\" + 0.010*\"c++\" + 0.009*\"matlab\" + 0.009*\"java\" + 0.008*\"c\"\n",
      "INFO : topic diff=7.517137, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.166 per-word bound, 574.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3731/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3750/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3800/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.091): 0.028*\"python\" + 0.027*\"r\" + 0.021*\"sql\" + 0.016*\"sas\" + 0.014*\"tableau\" + 0.013*\"matlab\" + 0.012*\"technical\" + 0.011*\"mysql\" + 0.011*\"c++\" + 0.010*\"hadoop\"\n",
      "INFO : topic #2 (0.091): 0.011*\"r\" + 0.010*\"sql\" + 0.010*\"python\" + 0.009*\"c++\" + 0.006*\"c\" + 0.006*\"sas\" + 0.006*\"java\" + 0.006*\"programming\" + 0.005*\"computer\" + 0.005*\"linux\"\n",
      "INFO : topic #10 (0.091): 0.015*\"r\" + 0.012*\"sas\" + 0.011*\"excel\" + 0.011*\"sql\" + 0.008*\"mysql\" + 0.007*\"python\" + 0.007*\"c++\" + 0.007*\"powerpoint\" + 0.007*\"spss\" + 0.006*\"java\"\n",
      "INFO : topic #9 (0.091): 0.026*\"python\" + 0.023*\"c\" + 0.023*\"sql\" + 0.020*\"java\" + 0.019*\"r\" + 0.019*\"html\" + 0.017*\"c++\" + 0.013*\"technical\" + 0.013*\"javascript\" + 0.010*\"css\"\n",
      "INFO : topic #7 (0.091): 0.015*\"sql\" + 0.014*\"python\" + 0.011*\"hadoop\" + 0.011*\"linux\" + 0.010*\"hive\" + 0.010*\"c++\" + 0.010*\"r\" + 0.009*\"matlab\" + 0.008*\"java\" + 0.007*\"c\"\n",
      "INFO : topic diff=0.345406, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.984 per-word bound, 506.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3835/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3837/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.091): 0.030*\"python\" + 0.029*\"r\" + 0.023*\"sql\" + 0.016*\"sas\" + 0.014*\"tableau\" + 0.014*\"matlab\" + 0.013*\"technical\" + 0.011*\"mysql\" + 0.011*\"c++\" + 0.011*\"pandas\"\n",
      "INFO : topic #4 (0.091): 0.027*\"sql\" + 0.024*\"python\" + 0.024*\"r\" + 0.015*\"matlab\" + 0.014*\"sas\" + 0.013*\"tableau\" + 0.012*\"technical\" + 0.012*\"excel\" + 0.011*\"c++\" + 0.010*\"spss\"\n",
      "INFO : topic #0 (0.091): 0.015*\"sql\" + 0.012*\"python\" + 0.012*\"r\" + 0.009*\"java\" + 0.008*\"html\" + 0.008*\"hive\" + 0.008*\"oracle\" + 0.007*\"technical\" + 0.007*\"excel\" + 0.007*\"javascript\"\n",
      "INFO : topic #1 (0.091): 0.025*\"python\" + 0.020*\"sql\" + 0.020*\"r\" + 0.019*\"java\" + 0.018*\"technical\" + 0.013*\"c\" + 0.013*\"c++\" + 0.011*\"mysql\" + 0.011*\"matlab\" + 0.011*\"tableau\"\n",
      "INFO : topic #3 (0.091): 0.011*\"technical\" + 0.009*\"sql\" + 0.008*\"unix\" + 0.007*\"python\" + 0.006*\"r\" + 0.005*\"tableau\" + 0.005*\"linux\" + 0.004*\"skills\" + 0.004*\"java\" + 0.004*\"word\"\n",
      "INFO : topic diff=0.285350, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.894 per-word bound, 475.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3853/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3871/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : updating topics\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #1 (0.091): 0.024*\"python\" + 0.020*\"sql\" + 0.020*\"r\" + 0.018*\"java\" + 0.017*\"technical\" + 0.013*\"c\" + 0.012*\"c++\" + 0.011*\"mysql\" + 0.010*\"matlab\" + 0.010*\"tableau\"\n",
      "INFO : topic #3 (0.091): 0.010*\"technical\" + 0.008*\"sql\" + 0.008*\"unix\" + 0.005*\"python\" + 0.005*\"linux\" + 0.005*\"r\" + 0.004*\"tableau\" + 0.004*\"skills\" + 0.004*\"word\" + 0.004*\"excel\"\n",
      "INFO : topic #6 (0.091): 0.031*\"python\" + 0.030*\"r\" + 0.024*\"sql\" + 0.016*\"sas\" + 0.015*\"tableau\" + 0.014*\"matlab\" + 0.014*\"technical\" + 0.012*\"pandas\" + 0.011*\"c++\" + 0.011*\"mysql\"\n",
      "INFO : topic #5 (0.091): 0.013*\"sql\" + 0.009*\"technical\" + 0.008*\"excel\" + 0.007*\"sas\" + 0.006*\"r\" + 0.005*\"python\" + 0.005*\"tableau\" + 0.005*\"powerpoint\" + 0.005*\"access\" + 0.005*\"oracle\"\n",
      "INFO : topic #8 (0.091): 0.030*\"r\" + 0.030*\"python\" + 0.026*\"sql\" + 0.019*\"hadoop\" + 0.018*\"hive\" + 0.017*\"tableau\" + 0.014*\"java\" + 0.013*\"spark\" + 0.013*\"technical\" + 0.011*\"pig\"\n",
      "INFO : topic diff=0.231067, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.839 per-word bound, 458.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 3868/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3904/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3883/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.091): 0.012*\"sql\" + 0.009*\"technical\" + 0.007*\"excel\" + 0.007*\"sas\" + 0.005*\"r\" + 0.005*\"powerpoint\" + 0.005*\"tableau\" + 0.005*\"oracle\" + 0.004*\"access\" + 0.004*\"python\"\n",
      "INFO : topic #4 (0.091): 0.029*\"sql\" + 0.027*\"r\" + 0.026*\"python\" + 0.017*\"sas\" + 0.016*\"matlab\" + 0.015*\"excel\" + 0.014*\"tableau\" + 0.013*\"spss\" + 0.012*\"technical\" + 0.011*\"c++\"\n",
      "INFO : topic #6 (0.091): 0.032*\"python\" + 0.031*\"r\" + 0.025*\"sql\" + 0.016*\"sas\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"matlab\" + 0.012*\"pandas\" + 0.011*\"hadoop\" + 0.011*\"c++\"\n",
      "INFO : topic #3 (0.091): 0.009*\"technical\" + 0.008*\"unix\" + 0.007*\"sql\" + 0.005*\"linux\" + 0.004*\"python\" + 0.004*\"skills\" + 0.004*\"word\" + 0.004*\"tableau\" + 0.004*\"r\" + 0.003*\"excel\"\n",
      "INFO : topic #7 (0.091): 0.010*\"sql\" + 0.009*\"python\" + 0.008*\"linux\" + 0.008*\"hadoop\" + 0.007*\"c++\" + 0.006*\"matlab\" + 0.006*\"hive\" + 0.006*\"r\" + 0.006*\"excel\" + 0.005*\"java\"\n",
      "INFO : topic diff=0.184962, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.804 per-word bound, 447.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3881/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.091): 0.009*\"technical\" + 0.007*\"unix\" + 0.007*\"sql\" + 0.004*\"linux\" + 0.004*\"skills\" + 0.004*\"python\" + 0.004*\"word\" + 0.003*\"windows\" + 0.003*\"powerpoint\" + 0.003*\"excel\"\n",
      "INFO : topic #5 (0.091): 0.011*\"sql\" + 0.009*\"technical\" + 0.007*\"excel\" + 0.006*\"sas\" + 0.005*\"r\" + 0.004*\"powerpoint\" + 0.004*\"oracle\" + 0.004*\"access\" + 0.004*\"tableau\" + 0.004*\"key\"\n",
      "INFO : topic #4 (0.091): 0.030*\"sql\" + 0.029*\"r\" + 0.027*\"python\" + 0.019*\"sas\" + 0.017*\"excel\" + 0.017*\"matlab\" + 0.014*\"tableau\" + 0.014*\"spss\" + 0.012*\"technical\" + 0.012*\"c++\"\n",
      "INFO : topic #0 (0.091): 0.012*\"sql\" + 0.008*\"python\" + 0.008*\"r\" + 0.008*\"oracle\" + 0.008*\"java\" + 0.008*\"html\" + 0.007*\"technical\" + 0.006*\"javascript\" + 0.006*\"excel\" + 0.005*\"hive\"\n",
      "INFO : topic #7 (0.091): 0.009*\"sql\" + 0.008*\"python\" + 0.008*\"linux\" + 0.007*\"hadoop\" + 0.006*\"c++\" + 0.006*\"matlab\" + 0.005*\"excel\" + 0.005*\"hive\" + 0.005*\"r\" + 0.005*\"c\"\n",
      "INFO : topic diff=0.148290, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.781 per-word bound, 439.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3886/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3915/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.091): 0.027*\"python\" + 0.027*\"r\" + 0.025*\"sql\" + 0.020*\"hadoop\" + 0.020*\"hive\" + 0.017*\"tableau\" + 0.015*\"java\" + 0.014*\"spark\" + 0.014*\"technical\" + 0.013*\"pig\"\n",
      "INFO : topic #2 (0.091): 0.007*\"r\" + 0.006*\"c++\" + 0.005*\"python\" + 0.005*\"sql\" + 0.005*\"computer\" + 0.004*\"programming\" + 0.004*\"c\" + 0.004*\"sas\" + 0.004*\"matlab\" + 0.004*\"microsoft\"\n",
      "INFO : topic #7 (0.091): 0.008*\"sql\" + 0.007*\"python\" + 0.007*\"linux\" + 0.006*\"hadoop\" + 0.005*\"c++\" + 0.005*\"matlab\" + 0.005*\"excel\" + 0.005*\"core\" + 0.004*\"r\" + 0.004*\"hive\"\n",
      "INFO : topic #6 (0.091): 0.033*\"python\" + 0.032*\"r\" + 0.026*\"sql\" + 0.016*\"tableau\" + 0.016*\"sas\" + 0.015*\"technical\" + 0.015*\"matlab\" + 0.014*\"pandas\" + 0.012*\"hadoop\" + 0.011*\"c++\"\n",
      "INFO : topic #0 (0.091): 0.011*\"sql\" + 0.008*\"oracle\" + 0.007*\"java\" + 0.007*\"python\" + 0.007*\"html\" + 0.007*\"r\" + 0.007*\"technical\" + 0.006*\"javascript\" + 0.005*\"excel\" + 0.005*\"c\"\n",
      "INFO : topic diff=0.118980, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.762 per-word bound, 434.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3895/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.091): 0.027*\"python\" + 0.027*\"c\" + 0.026*\"java\" + 0.023*\"html\" + 0.023*\"c++\" + 0.021*\"javascript\" + 0.021*\"sql\" + 0.018*\"r\" + 0.015*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #0 (0.091): 0.011*\"sql\" + 0.008*\"oracle\" + 0.007*\"html\" + 0.007*\"java\" + 0.007*\"python\" + 0.007*\"technical\" + 0.006*\"r\" + 0.006*\"javascript\" + 0.005*\"xml\" + 0.005*\"excel\"\n",
      "INFO : topic #5 (0.091): 0.010*\"sql\" + 0.008*\"technical\" + 0.006*\"excel\" + 0.005*\"sas\" + 0.004*\"oracle\" + 0.004*\"key\" + 0.004*\"access\" + 0.004*\"powerpoint\" + 0.004*\"r\" + 0.004*\"tableau\"\n",
      "INFO : topic #8 (0.091): 0.027*\"python\" + 0.027*\"r\" + 0.025*\"sql\" + 0.020*\"hive\" + 0.020*\"hadoop\" + 0.017*\"tableau\" + 0.015*\"java\" + 0.015*\"spark\" + 0.014*\"pig\" + 0.014*\"technical\"\n",
      "INFO : topic #1 (0.091): 0.019*\"python\" + 0.017*\"sql\" + 0.016*\"r\" + 0.016*\"java\" + 0.016*\"technical\" + 0.011*\"c\" + 0.010*\"c++\" + 0.009*\"mysql\" + 0.009*\"html\" + 0.008*\"matlab\"\n",
      "INFO : topic diff=0.096252, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.748 per-word bound, 430.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.091): 0.009*\"sql\" + 0.007*\"technical\" + 0.005*\"sas\" + 0.005*\"excel\" + 0.004*\"key\" + 0.004*\"oracle\" + 0.004*\"access\" + 0.003*\"powerpoint\" + 0.003*\"tableau\" + 0.003*\"taleo\"\n",
      "INFO : topic #6 (0.091): 0.034*\"python\" + 0.033*\"r\" + 0.027*\"sql\" + 0.016*\"tableau\" + 0.015*\"technical\" + 0.015*\"sas\" + 0.015*\"matlab\" + 0.015*\"pandas\" + 0.012*\"hadoop\" + 0.012*\"numpy\"\n",
      "INFO : topic #3 (0.091): 0.007*\"technical\" + 0.007*\"unix\" + 0.005*\"sql\" + 0.004*\"skills\" + 0.004*\"linux\" + 0.003*\"word\" + 0.003*\"windows\" + 0.002*\"oracle\" + 0.002*\"data\" + 0.002*\"powerpoint\"\n",
      "INFO : topic #4 (0.091): 0.033*\"sql\" + 0.033*\"r\" + 0.029*\"python\" + 0.024*\"sas\" + 0.023*\"excel\" + 0.019*\"matlab\" + 0.016*\"spss\" + 0.016*\"tableau\" + 0.015*\"powerpoint\" + 0.012*\"c++\"\n",
      "INFO : topic #10 (0.091): 0.009*\"excel\" + 0.008*\"sas\" + 0.007*\"r\" + 0.007*\"english\" + 0.006*\"powerpoint\" + 0.006*\"sql\" + 0.005*\"access\" + 0.004*\"word\" + 0.004*\"data\" + 0.004*\"spss\"\n",
      "INFO : topic diff=0.078472, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.737 per-word bound, 426.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.091): 0.010*\"sql\" + 0.008*\"oracle\" + 0.007*\"html\" + 0.007*\"java\" + 0.006*\"technical\" + 0.006*\"javascript\" + 0.006*\"xml\" + 0.005*\"python\" + 0.005*\"r\" + 0.005*\"c\"\n",
      "INFO : topic #5 (0.091): 0.008*\"sql\" + 0.007*\"technical\" + 0.005*\"sas\" + 0.004*\"excel\" + 0.004*\"key\" + 0.004*\"oracle\" + 0.003*\"stat\" + 0.003*\"taleo\" + 0.003*\"access\" + 0.003*\"powerpoint\"\n",
      "INFO : topic #4 (0.091): 0.034*\"r\" + 0.034*\"sql\" + 0.029*\"python\" + 0.025*\"sas\" + 0.025*\"excel\" + 0.019*\"matlab\" + 0.017*\"spss\" + 0.017*\"powerpoint\" + 0.016*\"tableau\" + 0.012*\"c++\"\n",
      "INFO : topic #3 (0.091): 0.007*\"technical\" + 0.007*\"unix\" + 0.004*\"sql\" + 0.004*\"skills\" + 0.004*\"linux\" + 0.003*\"windows\" + 0.003*\"word\" + 0.002*\"j.\" + 0.002*\"oracle\" + 0.002*\"data\"\n",
      "INFO : topic #2 (0.091): 0.006*\"r\" + 0.005*\"c++\" + 0.004*\"python\" + 0.004*\"computer\" + 0.004*\"sql\" + 0.004*\"project\" + 0.003*\"microsoft\" + 0.003*\"programming\" + 0.003*\"research\" + 0.003*\"windows\"\n",
      "INFO : topic diff=0.064628, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.728 per-word bound, 424.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.091): 0.007*\"unix\" + 0.007*\"technical\" + 0.004*\"sql\" + 0.004*\"skills\" + 0.004*\"linux\" + 0.003*\"windows\" + 0.002*\"j.\" + 0.002*\"word\" + 0.002*\"oracle\" + 0.002*\"data\"\n",
      "INFO : topic #1 (0.091): 0.016*\"python\" + 0.015*\"sql\" + 0.014*\"technical\" + 0.014*\"java\" + 0.014*\"r\" + 0.010*\"c\" + 0.009*\"c++\" + 0.008*\"html\" + 0.008*\"mysql\" + 0.007*\"matlab\"\n",
      "INFO : topic #5 (0.091): 0.008*\"sql\" + 0.007*\"technical\" + 0.004*\"sas\" + 0.004*\"key\" + 0.004*\"excel\" + 0.004*\"oracle\" + 0.004*\"stat\" + 0.003*\"taleo\" + 0.003*\"access\" + 0.003*\"graph\"\n",
      "INFO : topic #10 (0.091): 0.008*\"excel\" + 0.007*\"english\" + 0.007*\"sas\" + 0.005*\"r\" + 0.005*\"powerpoint\" + 0.005*\"access\" + 0.005*\"sql\" + 0.004*\"data\" + 0.004*\"project\" + 0.004*\"word\"\n",
      "INFO : topic #0 (0.091): 0.009*\"sql\" + 0.008*\"oracle\" + 0.007*\"html\" + 0.006*\"java\" + 0.006*\"technical\" + 0.006*\"xml\" + 0.005*\"javascript\" + 0.005*\"python\" + 0.005*\"r\" + 0.005*\"c\"\n",
      "INFO : topic diff=0.053840, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.720 per-word bound, 421.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.091): 0.005*\"core\" + 0.005*\"linux\" + 0.004*\"sql\" + 0.004*\"python\" + 0.003*\"hadoop\" + 0.003*\"excel\" + 0.003*\"matlab\" + 0.003*\"c++\" + 0.003*\"software\" + 0.003*\"skill\"\n",
      "INFO : topic #8 (0.091): 0.025*\"python\" + 0.024*\"r\" + 0.023*\"sql\" + 0.021*\"hive\" + 0.021*\"hadoop\" + 0.016*\"tableau\" + 0.015*\"java\" + 0.015*\"pig\" + 0.015*\"spark\" + 0.014*\"technical\"\n",
      "INFO : topic #2 (0.091): 0.005*\"r\" + 0.004*\"c++\" + 0.004*\"computer\" + 0.004*\"python\" + 0.004*\"project\" + 0.003*\"research\" + 0.003*\"microsoft\" + 0.003*\"programming\" + 0.003*\"sql\" + 0.003*\"software\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #6 (0.091): 0.035*\"python\" + 0.033*\"r\" + 0.027*\"sql\" + 0.016*\"tableau\" + 0.016*\"technical\" + 0.015*\"pandas\" + 0.015*\"matlab\" + 0.015*\"sas\" + 0.013*\"hadoop\" + 0.013*\"numpy\"\n",
      "INFO : topic #4 (0.091): 0.036*\"r\" + 0.035*\"sql\" + 0.030*\"python\" + 0.028*\"sas\" + 0.027*\"excel\" + 0.020*\"matlab\" + 0.018*\"powerpoint\" + 0.018*\"spss\" + 0.017*\"tableau\" + 0.014*\"word\"\n",
      "INFO : topic diff=0.045516, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.713 per-word bound, 419.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.091): 0.009*\"sql\" + 0.008*\"oracle\" + 0.007*\"html\" + 0.006*\"java\" + 0.006*\"technical\" + 0.006*\"xml\" + 0.005*\"javascript\" + 0.005*\"uml\" + 0.005*\"project\" + 0.005*\"unix\"\n",
      "INFO : topic #1 (0.091): 0.015*\"python\" + 0.014*\"sql\" + 0.013*\"technical\" + 0.013*\"java\" + 0.012*\"r\" + 0.009*\"c\" + 0.008*\"c++\" + 0.007*\"html\" + 0.007*\"mysql\" + 0.006*\"tableau\"\n",
      "INFO : topic #9 (0.091): 0.028*\"python\" + 0.028*\"c\" + 0.028*\"java\" + 0.025*\"c++\" + 0.024*\"html\" + 0.024*\"javascript\" + 0.021*\"sql\" + 0.018*\"r\" + 0.017*\"css\" + 0.014*\"mysql\"\n",
      "INFO : topic #3 (0.091): 0.007*\"unix\" + 0.006*\"technical\" + 0.004*\"skills\" + 0.003*\"linux\" + 0.003*\"sql\" + 0.003*\"j.\" + 0.002*\"windows\" + 0.002*\"powershell\" + 0.002*\"oracle\" + 0.002*\"word\"\n",
      "INFO : topic #10 (0.091): 0.008*\"english\" + 0.007*\"excel\" + 0.006*\"sas\" + 0.004*\"data\" + 0.004*\"access\" + 0.004*\"powerpoint\" + 0.004*\"r\" + 0.004*\"project\" + 0.004*\"sql\" + 0.004*\"research\"\n",
      "INFO : topic diff=0.038962, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.707 per-word bound, 418.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3928/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.091): 0.028*\"java\" + 0.028*\"python\" + 0.028*\"c\" + 0.025*\"c++\" + 0.025*\"html\" + 0.024*\"javascript\" + 0.021*\"sql\" + 0.018*\"r\" + 0.017*\"css\" + 0.015*\"mysql\"\n",
      "INFO : topic #10 (0.091): 0.008*\"english\" + 0.006*\"excel\" + 0.005*\"sas\" + 0.004*\"data\" + 0.004*\"access\" + 0.004*\"project\" + 0.004*\"powerpoint\" + 0.004*\"research\" + 0.004*\"r\" + 0.003*\"sql\"\n",
      "INFO : topic #8 (0.091): 0.024*\"python\" + 0.023*\"r\" + 0.023*\"sql\" + 0.022*\"hive\" + 0.021*\"hadoop\" + 0.016*\"tableau\" + 0.015*\"pig\" + 0.015*\"java\" + 0.015*\"spark\" + 0.014*\"technical\"\n",
      "INFO : topic #0 (0.091): 0.008*\"sql\" + 0.008*\"oracle\" + 0.006*\"html\" + 0.006*\"xml\" + 0.006*\"technical\" + 0.006*\"java\" + 0.005*\"javascript\" + 0.005*\"uml\" + 0.005*\"project\" + 0.005*\"unix\"\n",
      "INFO : topic #2 (0.091): 0.004*\"r\" + 0.004*\"c++\" + 0.004*\"project\" + 0.003*\"computer\" + 0.003*\"research\" + 0.003*\"python\" + 0.003*\"microsoft\" + 0.003*\"programming\" + 0.003*\"software\" + 0.003*\"windows\"\n",
      "INFO : topic diff=0.033683, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.702 per-word bound, 416.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 536/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.091): 0.024*\"python\" + 0.023*\"r\" + 0.023*\"sql\" + 0.022*\"hive\" + 0.021*\"hadoop\" + 0.016*\"tableau\" + 0.015*\"pig\" + 0.015*\"java\" + 0.015*\"spark\" + 0.015*\"technical\"\n",
      "INFO : topic #4 (0.091): 0.039*\"r\" + 0.037*\"sql\" + 0.032*\"python\" + 0.030*\"sas\" + 0.030*\"excel\" + 0.021*\"matlab\" + 0.020*\"powerpoint\" + 0.018*\"spss\" + 0.018*\"tableau\" + 0.015*\"word\"\n",
      "INFO : topic #6 (0.091): 0.035*\"python\" + 0.033*\"r\" + 0.028*\"sql\" + 0.016*\"tableau\" + 0.016*\"pandas\" + 0.016*\"technical\" + 0.015*\"matlab\" + 0.014*\"sas\" + 0.013*\"numpy\" + 0.013*\"hadoop\"\n",
      "INFO : topic #9 (0.091): 0.028*\"java\" + 0.028*\"c\" + 0.028*\"python\" + 0.025*\"c++\" + 0.025*\"html\" + 0.024*\"javascript\" + 0.021*\"sql\" + 0.018*\"r\" + 0.018*\"css\" + 0.015*\"mysql\"\n",
      "INFO : topic #2 (0.091): 0.004*\"r\" + 0.004*\"c++\" + 0.004*\"project\" + 0.003*\"research\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"python\" + 0.003*\"software\" + 0.003*\"programming\" + 0.002*\"windows\"\n",
      "INFO : topic diff=0.029444, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.697 per-word bound, 415.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.091): 0.009*\"english\" + 0.006*\"excel\" + 0.004*\"sas\" + 0.004*\"data\" + 0.004*\"project\" + 0.004*\"research\" + 0.004*\"access\" + 0.003*\"mandarin\" + 0.003*\"powerpoint\" + 0.003*\"business\"\n",
      "INFO : topic #3 (0.091): 0.007*\"unix\" + 0.005*\"technical\" + 0.004*\"skills\" + 0.003*\"linux\" + 0.003*\"j.\" + 0.003*\"sql\" + 0.002*\"powershell\" + 0.002*\"windows\" + 0.002*\"b.\" + 0.002*\"s.\"\n",
      "INFO : topic #2 (0.091): 0.004*\"r\" + 0.004*\"project\" + 0.003*\"c++\" + 0.003*\"research\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"python\" + 0.003*\"software\" + 0.002*\"programming\" + 0.002*\"windows\"\n",
      "INFO : topic #1 (0.091): 0.013*\"python\" + 0.012*\"technical\" + 0.012*\"sql\" + 0.011*\"java\" + 0.010*\"r\" + 0.008*\"c\" + 0.007*\"c++\" + 0.007*\"html\" + 0.006*\"mysql\" + 0.005*\"ms\"\n",
      "INFO : topic #7 (0.091): 0.005*\"core\" + 0.003*\"linux\" + 0.003*\"skill\" + 0.003*\"software\" + 0.003*\"sql\" + 0.002*\"python\" + 0.002*\"mapreduce\" + 0.002*\"excel\" + 0.002*\"project\" + 0.002*\"hadoop\"\n",
      "INFO : topic diff=0.026065, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.693 per-word bound, 413.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.091): 0.005*\"core\" + 0.003*\"linux\" + 0.003*\"skill\" + 0.003*\"software\" + 0.003*\"sql\" + 0.002*\"project\" + 0.002*\"mapreduce\" + 0.002*\"ats\" + 0.002*\"excel\" + 0.002*\"python\"\n",
      "INFO : topic #8 (0.091): 0.023*\"python\" + 0.022*\"sql\" + 0.022*\"hive\" + 0.022*\"r\" + 0.021*\"hadoop\" + 0.016*\"tableau\" + 0.016*\"pig\" + 0.015*\"java\" + 0.015*\"spark\" + 0.015*\"technical\"\n",
      "INFO : topic #0 (0.091): 0.008*\"oracle\" + 0.008*\"sql\" + 0.006*\"html\" + 0.006*\"xml\" + 0.006*\"technical\" + 0.005*\"java\" + 0.005*\"javascript\" + 0.005*\"uml\" + 0.005*\"project\" + 0.005*\"agile\"\n",
      "INFO : topic #9 (0.091): 0.029*\"java\" + 0.029*\"c\" + 0.028*\"python\" + 0.025*\"c++\" + 0.025*\"html\" + 0.025*\"javascript\" + 0.020*\"sql\" + 0.018*\"css\" + 0.018*\"r\" + 0.015*\"mysql\"\n",
      "INFO : topic #2 (0.091): 0.004*\"project\" + 0.004*\"r\" + 0.003*\"research\" + 0.003*\"c++\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"python\" + 0.003*\"software\" + 0.002*\"programming\" + 0.002*\"data\"\n",
      "INFO : topic diff=0.023239, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.690 per-word bound, 413.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.091): 0.006*\"unix\" + 0.005*\"technical\" + 0.004*\"skills\" + 0.003*\"j.\" + 0.003*\"linux\" + 0.002*\"sql\" + 0.002*\"powershell\" + 0.002*\"b.\" + 0.002*\"m.\" + 0.002*\"s.\"\n",
      "INFO : topic #6 (0.091): 0.035*\"python\" + 0.033*\"r\" + 0.028*\"sql\" + 0.017*\"tableau\" + 0.016*\"pandas\" + 0.016*\"technical\" + 0.015*\"matlab\" + 0.014*\"sas\" + 0.013*\"numpy\" + 0.013*\"hadoop\"\n",
      "INFO : topic #5 (0.091): 0.005*\"technical\" + 0.005*\"sql\" + 0.004*\"stat\" + 0.004*\"key\" + 0.004*\"taleo\" + 0.003*\"graph\" + 0.003*\"base\" + 0.003*\"oracle\" + 0.003*\"jobvite\" + 0.003*\"sas\"\n",
      "INFO : topic #10 (0.091): 0.009*\"english\" + 0.005*\"excel\" + 0.004*\"project\" + 0.004*\"data\" + 0.004*\"sas\" + 0.004*\"research\" + 0.003*\"mandarin\" + 0.003*\"business\" + 0.003*\"access\" + 0.003*\"salesforce\"\n",
      "INFO : topic #9 (0.091): 0.029*\"java\" + 0.029*\"c\" + 0.028*\"python\" + 0.026*\"c++\" + 0.025*\"html\" + 0.025*\"javascript\" + 0.020*\"sql\" + 0.018*\"css\" + 0.018*\"r\" + 0.015*\"mysql\"\n",
      "INFO : topic diff=0.020881, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.687 per-word bound, 412.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.091): 0.005*\"core\" + 0.003*\"skill\" + 0.003*\"software\" + 0.003*\"linux\" + 0.002*\"ats\" + 0.002*\"sql\" + 0.002*\"project\" + 0.002*\"technology\" + 0.002*\"mapreduce\" + 0.002*\"m.\"\n",
      "INFO : topic #1 (0.091): 0.011*\"technical\" + 0.011*\"python\" + 0.011*\"sql\" + 0.010*\"java\" + 0.008*\"r\" + 0.007*\"c\" + 0.006*\"html\" + 0.006*\"c++\" + 0.005*\"ms\" + 0.005*\"mysql\"\n",
      "INFO : topic #5 (0.091): 0.005*\"technical\" + 0.005*\"sql\" + 0.004*\"stat\" + 0.004*\"key\" + 0.004*\"taleo\" + 0.003*\"graph\" + 0.003*\"base\" + 0.003*\"oracle\" + 0.003*\"jobvite\" + 0.002*\"sas\"\n",
      "INFO : topic #2 (0.091): 0.004*\"project\" + 0.003*\"research\" + 0.003*\"r\" + 0.003*\"c++\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.002*\"software\" + 0.002*\"python\" + 0.002*\"data\" + 0.002*\"programming\"\n",
      "INFO : topic #4 (0.091): 0.041*\"r\" + 0.038*\"sql\" + 0.033*\"python\" + 0.032*\"sas\" + 0.031*\"excel\" + 0.022*\"matlab\" + 0.021*\"powerpoint\" + 0.019*\"spss\" + 0.018*\"tableau\" + 0.017*\"word\"\n",
      "INFO : topic diff=0.018876, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.684 per-word bound, 411.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.091): 0.011*\"technical\" + 0.010*\"sql\" + 0.010*\"python\" + 0.010*\"java\" + 0.008*\"r\" + 0.006*\"c\" + 0.006*\"html\" + 0.006*\"c++\" + 0.005*\"ms\" + 0.005*\"mysql\"\n",
      "INFO : topic #7 (0.091): 0.005*\"core\" + 0.003*\"skill\" + 0.003*\"software\" + 0.003*\"linux\" + 0.002*\"ats\" + 0.002*\"project\" + 0.002*\"technology\" + 0.002*\"sql\" + 0.002*\"mapreduce\" + 0.002*\"m.\"\n",
      "INFO : topic #8 (0.091): 0.022*\"hive\" + 0.022*\"python\" + 0.022*\"sql\" + 0.021*\"r\" + 0.021*\"hadoop\" + 0.016*\"tableau\" + 0.016*\"pig\" + 0.015*\"java\" + 0.015*\"technical\" + 0.015*\"spark\"\n",
      "INFO : topic #10 (0.091): 0.009*\"english\" + 0.004*\"excel\" + 0.004*\"project\" + 0.004*\"data\" + 0.004*\"research\" + 0.004*\"mandarin\" + 0.003*\"business\" + 0.003*\"sas\" + 0.003*\"salesforce\" + 0.003*\"access\"\n",
      "INFO : topic #6 (0.091): 0.036*\"python\" + 0.034*\"r\" + 0.028*\"sql\" + 0.017*\"tableau\" + 0.017*\"pandas\" + 0.016*\"technical\" + 0.015*\"matlab\" + 0.014*\"numpy\" + 0.013*\"hadoop\" + 0.013*\"sas\"\n",
      "INFO : topic diff=0.017205, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.682 per-word bound, 410.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=11, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=11, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (473 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (451 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (321 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (456 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (311 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (541 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (494 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (484 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (614 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (699 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (723 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (564 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (365 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (386 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (804 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (678 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (605 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (654 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (429 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 512 documents processed (558 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (774 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (654 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (605 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (558 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (774 virtual)\n",
      "DEBUG : finished all batches; 320 documents processed (429 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (331 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 5; 384 documents processed (429 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 8; 576 documents processed (718 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 320 documents processed (331 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (548 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (718 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (450 virtual)\n",
      "DEBUG : finished all batches; 384 documents processed (548 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (429 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (636 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (837 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (512 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (636 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (837 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (450 virtual)\n",
      "DEBUG : completed batch 7; 504 documents processed (909 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 504 documents processed (909 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 9; 640 documents processed (881 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (881 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9271 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12399/12537 documents converged within 50 iterations\n",
      " 39%|███▉      | 9/23 [03:45<05:51, 25.09s/it]INFO : using symmetric alpha at 0.08333333333333333\n",
      "INFO : using symmetric eta at 0.08333333333333333\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 12 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 424/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3297/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3099/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3189/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.083): 0.013*\"technical\" + 0.012*\"sql\" + 0.011*\"python\" + 0.009*\"r\" + 0.008*\"unix\" + 0.008*\"java\" + 0.007*\"tableau\" + 0.007*\"linux\" + 0.005*\"powerpoint\" + 0.005*\"c\"\n",
      "INFO : topic #2 (0.083): 0.013*\"r\" + 0.011*\"sql\" + 0.010*\"python\" + 0.010*\"c++\" + 0.007*\"html\" + 0.007*\"c\" + 0.007*\"java\" + 0.006*\"linux\" + 0.006*\"programming\" + 0.006*\"sas\"\n",
      "INFO : topic #11 (0.083): 0.032*\"python\" + 0.028*\"r\" + 0.027*\"sql\" + 0.020*\"sas\" + 0.018*\"matlab\" + 0.017*\"c++\" + 0.015*\"technical\" + 0.015*\"tableau\" + 0.014*\"java\" + 0.013*\"hadoop\"\n",
      "INFO : topic #10 (0.083): 0.014*\"r\" + 0.011*\"sql\" + 0.011*\"sas\" + 0.010*\"mysql\" + 0.008*\"excel\" + 0.007*\"c++\" + 0.007*\"html\" + 0.007*\"python\" + 0.006*\"java\" + 0.006*\"linux\"\n",
      "INFO : topic #7 (0.083): 0.015*\"sql\" + 0.015*\"python\" + 0.012*\"linux\" + 0.011*\"hadoop\" + 0.011*\"c++\" + 0.010*\"hive\" + 0.010*\"r\" + 0.009*\"matlab\" + 0.008*\"c\" + 0.007*\"java\"\n",
      "INFO : topic diff=8.340587, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.200 per-word bound, 588.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 515/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3757/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3762/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3796/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.083): 0.013*\"sql\" + 0.013*\"python\" + 0.010*\"linux\" + 0.010*\"hadoop\" + 0.009*\"c++\" + 0.009*\"hive\" + 0.009*\"r\" + 0.008*\"matlab\" + 0.007*\"c\" + 0.007*\"java\"\n",
      "INFO : topic #6 (0.083): 0.025*\"r\" + 0.024*\"python\" + 0.019*\"sql\" + 0.012*\"sas\" + 0.012*\"tableau\" + 0.012*\"technical\" + 0.011*\"mysql\" + 0.009*\"pandas\" + 0.009*\"matlab\" + 0.009*\"hadoop\"\n",
      "INFO : topic #1 (0.083): 0.023*\"python\" + 0.019*\"java\" + 0.017*\"r\" + 0.017*\"sql\" + 0.017*\"technical\" + 0.013*\"c\" + 0.012*\"c++\" + 0.010*\"mysql\" + 0.009*\"tableau\" + 0.009*\"html\"\n",
      "INFO : topic #5 (0.083): 0.014*\"sql\" + 0.009*\"technical\" + 0.008*\"r\" + 0.007*\"excel\" + 0.007*\"python\" + 0.006*\"tableau\" + 0.006*\"sas\" + 0.005*\"access\" + 0.005*\"java\" + 0.004*\"spss\"\n",
      "INFO : topic #0 (0.083): 0.016*\"sql\" + 0.013*\"python\" + 0.013*\"r\" + 0.010*\"hive\" + 0.009*\"technical\" + 0.009*\"java\" + 0.008*\"html\" + 0.008*\"oracle\" + 0.008*\"javascript\" + 0.007*\"c++\"\n",
      "INFO : topic diff=0.350514, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.014 per-word bound, 516.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3879/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3810/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3878/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.083): 0.024*\"python\" + 0.023*\"html\" + 0.023*\"c\" + 0.021*\"sql\" + 0.021*\"java\" + 0.018*\"javascript\" + 0.017*\"r\" + 0.015*\"c++\" + 0.014*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #3 (0.083): 0.010*\"technical\" + 0.008*\"sql\" + 0.007*\"unix\" + 0.006*\"python\" + 0.006*\"linux\" + 0.005*\"r\" + 0.005*\"tableau\" + 0.005*\"java\" + 0.005*\"powerpoint\" + 0.004*\"skills\"\n",
      "INFO : topic #8 (0.083): 0.027*\"r\" + 0.026*\"python\" + 0.023*\"sql\" + 0.017*\"hadoop\" + 0.016*\"hive\" + 0.016*\"tableau\" + 0.012*\"java\" + 0.012*\"technical\" + 0.012*\"spark\" + 0.010*\"pig\"\n",
      "INFO : topic #4 (0.083): 0.021*\"sql\" + 0.019*\"r\" + 0.019*\"python\" + 0.011*\"technical\" + 0.010*\"matlab\" + 0.009*\"tableau\" + 0.009*\"data\" + 0.008*\"java\" + 0.008*\"excel\" + 0.008*\"c++\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #6 (0.083): 0.025*\"python\" + 0.025*\"r\" + 0.020*\"sql\" + 0.012*\"tableau\" + 0.012*\"technical\" + 0.012*\"sas\" + 0.011*\"pandas\" + 0.011*\"mysql\" + 0.010*\"hadoop\" + 0.009*\"matlab\"\n",
      "INFO : topic diff=0.291399, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.914 per-word bound, 482.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : 3846/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.083): 0.009*\"r\" + 0.008*\"sas\" + 0.008*\"sql\" + 0.007*\"excel\" + 0.006*\"mysql\" + 0.006*\"powerpoint\" + 0.005*\"word\" + 0.005*\"data\" + 0.005*\"spss\" + 0.005*\"html\"\n",
      "INFO : topic #2 (0.083): 0.009*\"r\" + 0.008*\"sql\" + 0.008*\"c++\" + 0.006*\"python\" + 0.006*\"html\" + 0.005*\"data\" + 0.005*\"c\" + 0.005*\"linux\" + 0.005*\"computer\" + 0.004*\"java\"\n",
      "INFO : topic #11 (0.083): 0.039*\"python\" + 0.039*\"r\" + 0.035*\"sql\" + 0.026*\"sas\" + 0.023*\"matlab\" + 0.020*\"c++\" + 0.018*\"tableau\" + 0.016*\"excel\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #0 (0.083): 0.014*\"sql\" + 0.010*\"python\" + 0.010*\"r\" + 0.009*\"technical\" + 0.008*\"oracle\" + 0.008*\"java\" + 0.008*\"hive\" + 0.008*\"html\" + 0.007*\"javascript\" + 0.006*\"c++\"\n",
      "INFO : topic #8 (0.083): 0.026*\"r\" + 0.026*\"python\" + 0.022*\"sql\" + 0.018*\"hadoop\" + 0.018*\"hive\" + 0.016*\"tableau\" + 0.013*\"java\" + 0.012*\"spark\" + 0.012*\"technical\" + 0.012*\"pig\"\n",
      "INFO : topic diff=0.239468, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.856 per-word bound, 463.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3896/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3871/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.083): 0.010*\"sql\" + 0.007*\"technical\" + 0.006*\"excel\" + 0.005*\"access\" + 0.005*\"r\" + 0.004*\"sas\" + 0.004*\"tableau\" + 0.004*\"k\" + 0.004*\"oracle\" + 0.003*\"spss\"\n",
      "INFO : topic #9 (0.083): 0.025*\"html\" + 0.023*\"python\" + 0.023*\"c\" + 0.022*\"java\" + 0.021*\"javascript\" + 0.020*\"sql\" + 0.017*\"c++\" + 0.017*\"css\" + 0.015*\"r\" + 0.013*\"technical\"\n",
      "INFO : topic #11 (0.083): 0.041*\"r\" + 0.040*\"python\" + 0.037*\"sql\" + 0.027*\"sas\" + 0.024*\"matlab\" + 0.020*\"c++\" + 0.019*\"tableau\" + 0.018*\"excel\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #6 (0.083): 0.026*\"python\" + 0.025*\"r\" + 0.021*\"sql\" + 0.013*\"pandas\" + 0.013*\"technical\" + 0.013*\"tableau\" + 0.011*\"sas\" + 0.011*\"hadoop\" + 0.010*\"numpy\" + 0.010*\"mysql\"\n",
      "INFO : topic #4 (0.083): 0.018*\"sql\" + 0.017*\"r\" + 0.016*\"python\" + 0.009*\"technical\" + 0.009*\"data\" + 0.008*\"matlab\" + 0.008*\"tableau\" + 0.008*\"c++\" + 0.008*\"excel\" + 0.007*\"java\"\n",
      "INFO : topic diff=0.194661, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.817 per-word bound, 450.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3897/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.083): 0.042*\"r\" + 0.041*\"python\" + 0.038*\"sql\" + 0.028*\"sas\" + 0.024*\"matlab\" + 0.020*\"c++\" + 0.019*\"tableau\" + 0.019*\"excel\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #5 (0.083): 0.009*\"sql\" + 0.007*\"technical\" + 0.005*\"excel\" + 0.005*\"access\" + 0.004*\"r\" + 0.004*\"sas\" + 0.004*\"k\" + 0.004*\"tableau\" + 0.004*\"oracle\" + 0.003*\"spss\"\n",
      "INFO : topic #2 (0.083): 0.007*\"r\" + 0.007*\"c++\" + 0.006*\"sql\" + 0.005*\"html\" + 0.005*\"data\" + 0.005*\"python\" + 0.004*\"computer\" + 0.004*\"c\" + 0.004*\"linux\" + 0.004*\"windows\"\n",
      "INFO : topic #8 (0.083): 0.024*\"python\" + 0.024*\"r\" + 0.021*\"sql\" + 0.020*\"hive\" + 0.019*\"hadoop\" + 0.016*\"tableau\" + 0.014*\"spark\" + 0.013*\"java\" + 0.013*\"pig\" + 0.013*\"technical\"\n",
      "INFO : topic #0 (0.083): 0.012*\"sql\" + 0.008*\"oracle\" + 0.008*\"technical\" + 0.008*\"python\" + 0.007*\"r\" + 0.007*\"java\" + 0.007*\"html\" + 0.006*\"hive\" + 0.006*\"javascript\" + 0.006*\"mysql\"\n",
      "INFO : topic diff=0.156680, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.790 per-word bound, 442.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3893/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.083): 0.006*\"english\" + 0.006*\"excel\" + 0.006*\"r\" + 0.005*\"sas\" + 0.005*\"sql\" + 0.005*\"powerpoint\" + 0.005*\"data\" + 0.004*\"word\" + 0.004*\"research\" + 0.004*\"mysql\"\n",
      "INFO : topic #7 (0.083): 0.007*\"sql\" + 0.006*\"python\" + 0.006*\"hadoop\" + 0.005*\"linux\" + 0.005*\"c++\" + 0.004*\"c\" + 0.004*\"matlab\" + 0.004*\"excel\" + 0.004*\"hive\" + 0.004*\"core\"\n",
      "INFO : topic #2 (0.083): 0.006*\"c++\" + 0.006*\"r\" + 0.006*\"sql\" + 0.005*\"data\" + 0.005*\"html\" + 0.004*\"python\" + 0.004*\"computer\" + 0.004*\"c\" + 0.004*\"linux\" + 0.003*\"windows\"\n",
      "INFO : topic #11 (0.083): 0.044*\"r\" + 0.042*\"python\" + 0.039*\"sql\" + 0.029*\"sas\" + 0.025*\"matlab\" + 0.021*\"c++\" + 0.020*\"tableau\" + 0.019*\"excel\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #1 (0.083): 0.017*\"python\" + 0.015*\"java\" + 0.014*\"technical\" + 0.013*\"sql\" + 0.012*\"r\" + 0.011*\"c\" + 0.009*\"c++\" + 0.008*\"mysql\" + 0.006*\"html\" + 0.006*\"tableau\"\n",
      "INFO : topic diff=0.125712, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.772 per-word bound, 437.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.083): 0.011*\"sql\" + 0.008*\"oracle\" + 0.008*\"technical\" + 0.007*\"html\" + 0.007*\"java\" + 0.006*\"python\" + 0.006*\"r\" + 0.005*\"javascript\" + 0.005*\"hive\" + 0.005*\"xml\"\n",
      "INFO : topic #2 (0.083): 0.006*\"c++\" + 0.006*\"r\" + 0.005*\"sql\" + 0.005*\"data\" + 0.004*\"html\" + 0.004*\"computer\" + 0.004*\"python\" + 0.003*\"c\" + 0.003*\"linux\" + 0.003*\"windows\"\n",
      "INFO : topic #9 (0.083): 0.026*\"html\" + 0.024*\"javascript\" + 0.024*\"c\" + 0.024*\"java\" + 0.023*\"python\" + 0.019*\"sql\" + 0.019*\"css\" + 0.018*\"c++\" + 0.014*\"r\" + 0.014*\"mysql\"\n",
      "INFO : topic #1 (0.083): 0.016*\"python\" + 0.014*\"java\" + 0.014*\"technical\" + 0.012*\"sql\" + 0.011*\"r\" + 0.011*\"c\" + 0.008*\"c++\" + 0.007*\"mysql\" + 0.006*\"html\" + 0.006*\"tableau\"\n",
      "INFO : topic #8 (0.083): 0.023*\"python\" + 0.023*\"r\" + 0.021*\"hive\" + 0.021*\"sql\" + 0.020*\"hadoop\" + 0.015*\"tableau\" + 0.015*\"pig\" + 0.014*\"spark\" + 0.014*\"java\" + 0.014*\"technical\"\n",
      "INFO : topic diff=0.101451, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.756 per-word bound, 432.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.083): 0.007*\"technical\" + 0.007*\"unix\" + 0.005*\"skills\" + 0.004*\"linux\" + 0.004*\"sql\" + 0.003*\"powerpoint\" + 0.003*\"tableau\" + 0.003*\"software\" + 0.002*\"windows\" + 0.002*\"project\"\n",
      "INFO : topic #4 (0.083): 0.013*\"sql\" + 0.012*\"r\" + 0.011*\"python\" + 0.008*\"data\" + 0.007*\"technical\" + 0.007*\"matlab\" + 0.006*\"c++\" + 0.006*\"excel\" + 0.006*\"computer\" + 0.005*\"spss\"\n",
      "INFO : topic #0 (0.083): 0.010*\"sql\" + 0.008*\"oracle\" + 0.007*\"technical\" + 0.007*\"html\" + 0.007*\"java\" + 0.006*\"python\" + 0.005*\"xml\" + 0.005*\"pl\" + 0.005*\"javascript\" + 0.005*\"r\"\n",
      "INFO : topic #9 (0.083): 0.027*\"html\" + 0.025*\"javascript\" + 0.025*\"java\" + 0.024*\"c\" + 0.023*\"python\" + 0.020*\"css\" + 0.019*\"sql\" + 0.019*\"c++\" + 0.014*\"mysql\" + 0.014*\"r\"\n",
      "INFO : topic #2 (0.083): 0.006*\"c++\" + 0.005*\"r\" + 0.005*\"data\" + 0.005*\"sql\" + 0.004*\"html\" + 0.004*\"computer\" + 0.003*\"python\" + 0.003*\"c\" + 0.003*\"linux\" + 0.003*\"windows\"\n",
      "INFO : topic diff=0.082211, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.745 per-word bound, 429.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.083): 0.012*\"sql\" + 0.011*\"r\" + 0.010*\"python\" + 0.007*\"data\" + 0.006*\"technical\" + 0.006*\"matlab\" + 0.006*\"excel\" + 0.006*\"c++\" + 0.005*\"computer\" + 0.005*\"spss\"\n",
      "INFO : topic #5 (0.083): 0.007*\"sql\" + 0.006*\"technical\" + 0.004*\"excel\" + 0.004*\"access\" + 0.003*\"oracle\" + 0.003*\"k\" + 0.003*\"key\" + 0.003*\"tableau\" + 0.003*\"data\" + 0.003*\"r\"\n",
      "INFO : topic #7 (0.083): 0.005*\"sql\" + 0.004*\"python\" + 0.004*\"linux\" + 0.004*\"hadoop\" + 0.004*\"c++\" + 0.004*\"core\" + 0.003*\"excel\" + 0.003*\"c\" + 0.003*\"matlab\" + 0.003*\"software\"\n",
      "INFO : topic #6 (0.083): 0.028*\"python\" + 0.026*\"r\" + 0.022*\"sql\" + 0.017*\"pandas\" + 0.014*\"technical\" + 0.014*\"numpy\" + 0.013*\"tableau\" + 0.012*\"scikit\" + 0.012*\"hadoop\" + 0.010*\"spark\"\n",
      "INFO : topic #10 (0.083): 0.009*\"english\" + 0.005*\"excel\" + 0.005*\"data\" + 0.004*\"powerpoint\" + 0.004*\"research\" + 0.004*\"sas\" + 0.004*\"sql\" + 0.004*\"r\" + 0.004*\"word\" + 0.004*\"indesign\"\n",
      "INFO : topic diff=0.067430, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.735 per-word bound, 426.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #5 (0.083): 0.007*\"sql\" + 0.005*\"technical\" + 0.004*\"excel\" + 0.004*\"access\" + 0.003*\"oracle\" + 0.003*\"key\" + 0.003*\"k\" + 0.002*\"tableau\" + 0.002*\"data\" + 0.002*\"sql_server\"\n",
      "INFO : topic #2 (0.083): 0.005*\"c++\" + 0.005*\"r\" + 0.004*\"data\" + 0.004*\"sql\" + 0.003*\"html\" + 0.003*\"computer\" + 0.003*\"project\" + 0.003*\"c\" + 0.003*\"windows\" + 0.003*\"linux\"\n",
      "INFO : topic #7 (0.083): 0.004*\"sql\" + 0.004*\"python\" + 0.004*\"core\" + 0.004*\"linux\" + 0.004*\"c++\" + 0.004*\"hadoop\" + 0.003*\"excel\" + 0.003*\"c\" + 0.003*\"software\" + 0.003*\"matlab\"\n",
      "INFO : topic #4 (0.083): 0.011*\"sql\" + 0.010*\"r\" + 0.009*\"python\" + 0.007*\"data\" + 0.006*\"technical\" + 0.006*\"matlab\" + 0.005*\"excel\" + 0.005*\"c++\" + 0.005*\"computer\" + 0.004*\"spss\"\n",
      "INFO : topic #0 (0.083): 0.009*\"sql\" + 0.009*\"oracle\" + 0.007*\"technical\" + 0.006*\"html\" + 0.006*\"java\" + 0.006*\"xml\" + 0.005*\"pl\" + 0.005*\"javascript\" + 0.005*\"windows\" + 0.005*\"linux\"\n",
      "INFO : topic diff=0.055871, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.727 per-word bound, 423.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.083): 0.029*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.018*\"pandas\" + 0.014*\"numpy\" + 0.014*\"technical\" + 0.013*\"tableau\" + 0.013*\"scikit\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #5 (0.083): 0.006*\"sql\" + 0.005*\"technical\" + 0.003*\"excel\" + 0.003*\"access\" + 0.003*\"key\" + 0.003*\"oracle\" + 0.003*\"k\" + 0.002*\"sql_server\" + 0.002*\"data\" + 0.002*\"means\"\n",
      "INFO : topic #2 (0.083): 0.005*\"c++\" + 0.004*\"data\" + 0.004*\"r\" + 0.004*\"sql\" + 0.003*\"computer\" + 0.003*\"html\" + 0.003*\"project\" + 0.003*\"analytics\" + 0.003*\"windows\" + 0.003*\"c\"\n",
      "INFO : topic #7 (0.083): 0.004*\"core\" + 0.004*\"sql\" + 0.003*\"python\" + 0.003*\"linux\" + 0.003*\"c++\" + 0.003*\"hadoop\" + 0.003*\"excel\" + 0.003*\"software\" + 0.003*\"skill\" + 0.003*\"c\"\n",
      "INFO : topic #0 (0.083): 0.009*\"sql\" + 0.009*\"oracle\" + 0.007*\"technical\" + 0.006*\"html\" + 0.006*\"java\" + 0.006*\"xml\" + 0.005*\"pl\" + 0.005*\"javascript\" + 0.005*\"windows\" + 0.005*\"linux\"\n",
      "INFO : topic diff=0.046863, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.720 per-word bound, 421.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.083): 0.006*\"unix\" + 0.006*\"technical\" + 0.005*\"skills\" + 0.003*\"linux\" + 0.002*\"salesforce\" + 0.002*\"sql\" + 0.002*\"powerpoint\" + 0.002*\"taleo\" + 0.002*\"project\" + 0.002*\"software\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #1 (0.083): 0.012*\"python\" + 0.012*\"technical\" + 0.011*\"java\" + 0.009*\"sql\" + 0.008*\"c\" + 0.008*\"r\" + 0.006*\"c++\" + 0.006*\"ms\" + 0.005*\"windows\" + 0.005*\"mysql\"\n",
      "INFO : topic #0 (0.083): 0.009*\"sql\" + 0.009*\"oracle\" + 0.007*\"technical\" + 0.006*\"html\" + 0.006*\"xml\" + 0.006*\"java\" + 0.005*\"pl\" + 0.005*\"windows\" + 0.005*\"javascript\" + 0.005*\"agile\"\n",
      "INFO : topic #11 (0.083): 0.047*\"r\" + 0.043*\"python\" + 0.042*\"sql\" + 0.032*\"sas\" + 0.026*\"matlab\" + 0.023*\"excel\" + 0.021*\"c++\" + 0.021*\"tableau\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #9 (0.083): 0.028*\"html\" + 0.027*\"javascript\" + 0.026*\"java\" + 0.025*\"c\" + 0.023*\"python\" + 0.021*\"css\" + 0.020*\"c++\" + 0.019*\"sql\" + 0.015*\"mysql\" + 0.013*\"r\"\n",
      "INFO : topic diff=0.039871, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.714 per-word bound, 419.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.083): 0.009*\"oracle\" + 0.008*\"sql\" + 0.007*\"technical\" + 0.006*\"html\" + 0.006*\"xml\" + 0.006*\"java\" + 0.006*\"pl\" + 0.005*\"windows\" + 0.005*\"uml\" + 0.005*\"agile\"\n",
      "INFO : topic #6 (0.083): 0.029*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.018*\"pandas\" + 0.015*\"numpy\" + 0.014*\"technical\" + 0.013*\"tableau\" + 0.013*\"scikit\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #1 (0.083): 0.012*\"technical\" + 0.011*\"python\" + 0.010*\"java\" + 0.009*\"sql\" + 0.008*\"c\" + 0.007*\"r\" + 0.006*\"c++\" + 0.006*\"ms\" + 0.005*\"windows\" + 0.005*\"data\"\n",
      "INFO : topic #3 (0.083): 0.006*\"unix\" + 0.006*\"technical\" + 0.005*\"skills\" + 0.003*\"linux\" + 0.002*\"salesforce\" + 0.002*\"taleo\" + 0.002*\"powerpoint\" + 0.002*\"sql\" + 0.002*\"project\" + 0.002*\"software\"\n",
      "INFO : topic #2 (0.083): 0.005*\"c++\" + 0.004*\"data\" + 0.004*\"r\" + 0.003*\"computer\" + 0.003*\"sql\" + 0.003*\"project\" + 0.003*\"html\" + 0.003*\"analytics\" + 0.003*\"core\" + 0.002*\"analysis\"\n",
      "INFO : topic diff=0.034329, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.709 per-word bound, 418.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.083): 0.004*\"c++\" + 0.004*\"data\" + 0.003*\"r\" + 0.003*\"computer\" + 0.003*\"project\" + 0.003*\"sql\" + 0.003*\"html\" + 0.003*\"analytics\" + 0.003*\"core\" + 0.002*\"analysis\"\n",
      "INFO : topic #10 (0.083): 0.011*\"english\" + 0.005*\"data\" + 0.004*\"indesign\" + 0.004*\"research\" + 0.004*\"excel\" + 0.004*\"mandarin\" + 0.004*\"spanish\" + 0.003*\"illustrator\" + 0.003*\"relevant\" + 0.003*\"photoshop\"\n",
      "INFO : topic #5 (0.083): 0.005*\"sql\" + 0.005*\"technical\" + 0.003*\"key\" + 0.003*\"access\" + 0.003*\"excel\" + 0.003*\"k\" + 0.003*\"oracle\" + 0.002*\"means\" + 0.002*\"sql_server\" + 0.002*\"teradata\"\n",
      "INFO : topic #3 (0.083): 0.006*\"unix\" + 0.006*\"technical\" + 0.005*\"skills\" + 0.003*\"linux\" + 0.003*\"salesforce\" + 0.002*\"taleo\" + 0.002*\"powerpoint\" + 0.002*\"project\" + 0.002*\"software\" + 0.002*\"sql\"\n",
      "INFO : topic #8 (0.083): 0.024*\"hive\" + 0.022*\"python\" + 0.021*\"hadoop\" + 0.020*\"r\" + 0.020*\"sql\" + 0.017*\"pig\" + 0.016*\"spark\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"java\"\n",
      "INFO : topic diff=0.029986, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.704 per-word bound, 417.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.083): 0.004*\"core\" + 0.003*\"jobvite\" + 0.003*\"skill\" + 0.003*\"software\" + 0.003*\"d.\" + 0.003*\"s.\" + 0.003*\"m.\" + 0.003*\"j.\" + 0.002*\"sql\" + 0.002*\"linux\"\n",
      "INFO : topic #11 (0.083): 0.048*\"r\" + 0.043*\"python\" + 0.042*\"sql\" + 0.032*\"sas\" + 0.026*\"matlab\" + 0.024*\"excel\" + 0.021*\"tableau\" + 0.021*\"c++\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #1 (0.083): 0.011*\"technical\" + 0.010*\"python\" + 0.009*\"java\" + 0.008*\"sql\" + 0.007*\"c\" + 0.006*\"r\" + 0.006*\"ms\" + 0.005*\"c++\" + 0.005*\"data\" + 0.005*\"windows\"\n",
      "INFO : topic #3 (0.083): 0.006*\"unix\" + 0.006*\"technical\" + 0.005*\"skills\" + 0.003*\"linux\" + 0.003*\"salesforce\" + 0.003*\"taleo\" + 0.002*\"project\" + 0.002*\"powerpoint\" + 0.002*\"powershell\" + 0.002*\"software\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #10 (0.083): 0.011*\"english\" + 0.005*\"data\" + 0.004*\"indesign\" + 0.004*\"research\" + 0.004*\"excel\" + 0.004*\"mandarin\" + 0.004*\"spanish\" + 0.003*\"illustrator\" + 0.003*\"relevant\" + 0.003*\"photoshop\"\n",
      "INFO : topic diff=0.026397, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.701 per-word bound, 416.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.083): 0.007*\"sql\" + 0.006*\"data\" + 0.006*\"r\" + 0.005*\"python\" + 0.005*\"technical\" + 0.004*\"matlab\" + 0.004*\"excel\" + 0.004*\"computer\" + 0.004*\"c++\" + 0.003*\"windows\"\n",
      "INFO : topic #6 (0.083): 0.030*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.019*\"pandas\" + 0.016*\"numpy\" + 0.015*\"technical\" + 0.013*\"scikit\" + 0.013*\"tableau\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #5 (0.083): 0.005*\"sql\" + 0.004*\"technical\" + 0.003*\"key\" + 0.003*\"access\" + 0.003*\"k\" + 0.003*\"oracle\" + 0.002*\"excel\" + 0.002*\"means\" + 0.002*\"sql_server\" + 0.002*\"teradata\"\n",
      "INFO : topic #1 (0.083): 0.011*\"technical\" + 0.009*\"python\" + 0.009*\"java\" + 0.008*\"sql\" + 0.007*\"c\" + 0.006*\"r\" + 0.006*\"ms\" + 0.005*\"c++\" + 0.005*\"data\" + 0.004*\"windows\"\n",
      "INFO : topic #0 (0.083): 0.009*\"oracle\" + 0.008*\"sql\" + 0.006*\"technical\" + 0.006*\"xml\" + 0.006*\"html\" + 0.006*\"pl\" + 0.005*\"java\" + 0.005*\"uml\" + 0.005*\"agile\" + 0.005*\"windows\"\n",
      "INFO : topic diff=0.023472, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.697 per-word bound, 414.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.083): 0.006*\"sql\" + 0.006*\"data\" + 0.005*\"r\" + 0.004*\"technical\" + 0.004*\"python\" + 0.004*\"excel\" + 0.004*\"computer\" + 0.004*\"matlab\" + 0.003*\"c++\" + 0.003*\"skills\"\n",
      "INFO : topic #11 (0.083): 0.048*\"r\" + 0.043*\"python\" + 0.043*\"sql\" + 0.033*\"sas\" + 0.027*\"matlab\" + 0.024*\"excel\" + 0.022*\"tableau\" + 0.021*\"c++\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #8 (0.083): 0.024*\"hive\" + 0.021*\"python\" + 0.021*\"hadoop\" + 0.020*\"sql\" + 0.019*\"r\" + 0.017*\"pig\" + 0.016*\"spark\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"java\"\n",
      "INFO : topic #9 (0.083): 0.029*\"html\" + 0.029*\"javascript\" + 0.027*\"java\" + 0.026*\"c\" + 0.024*\"python\" + 0.022*\"css\" + 0.021*\"c++\" + 0.019*\"sql\" + 0.016*\"mysql\" + 0.014*\"php\"\n",
      "INFO : topic #10 (0.083): 0.012*\"english\" + 0.005*\"data\" + 0.005*\"indesign\" + 0.005*\"research\" + 0.004*\"mandarin\" + 0.004*\"spanish\" + 0.004*\"excel\" + 0.004*\"illustrator\" + 0.003*\"relevant\" + 0.003*\"native\"\n",
      "INFO : topic diff=0.021006, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.694 per-word bound, 414.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3967/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.083): 0.029*\"html\" + 0.029*\"javascript\" + 0.027*\"java\" + 0.026*\"c\" + 0.024*\"python\" + 0.023*\"css\" + 0.021*\"c++\" + 0.019*\"sql\" + 0.016*\"mysql\" + 0.014*\"php\"\n",
      "INFO : topic #2 (0.083): 0.004*\"data\" + 0.004*\"c++\" + 0.003*\"project\" + 0.003*\"analytics\" + 0.003*\"computer\" + 0.003*\"core\" + 0.003*\"analysis\" + 0.002*\"areasof\" + 0.002*\"r\" + 0.002*\"team\"\n",
      "INFO : topic #11 (0.083): 0.048*\"r\" + 0.043*\"python\" + 0.043*\"sql\" + 0.033*\"sas\" + 0.027*\"matlab\" + 0.024*\"excel\" + 0.022*\"tableau\" + 0.021*\"c++\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #0 (0.083): 0.009*\"oracle\" + 0.007*\"sql\" + 0.006*\"xml\" + 0.006*\"technical\" + 0.006*\"pl\" + 0.006*\"html\" + 0.005*\"uml\" + 0.005*\"agile\" + 0.005*\"java\" + 0.005*\"windows\"\n",
      "INFO : topic #4 (0.083): 0.006*\"data\" + 0.006*\"sql\" + 0.005*\"r\" + 0.004*\"technical\" + 0.004*\"python\" + 0.004*\"excel\" + 0.004*\"computer\" + 0.004*\"matlab\" + 0.003*\"skills\" + 0.003*\"windows\"\n",
      "INFO : topic diff=0.018992, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.691 per-word bound, 413.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.083): 0.024*\"hive\" + 0.021*\"hadoop\" + 0.021*\"python\" + 0.020*\"sql\" + 0.019*\"r\" + 0.018*\"pig\" + 0.016*\"spark\" + 0.015*\"tableau\" + 0.015*\"technical\" + 0.014*\"java\"\n",
      "INFO : topic #4 (0.083): 0.006*\"data\" + 0.005*\"sql\" + 0.005*\"r\" + 0.004*\"technical\" + 0.004*\"excel\" + 0.004*\"computer\" + 0.004*\"python\" + 0.004*\"matlab\" + 0.003*\"skills\" + 0.003*\"windows\"\n",
      "INFO : topic #3 (0.083): 0.005*\"technical\" + 0.005*\"unix\" + 0.005*\"skills\" + 0.003*\"taleo\" + 0.003*\"salesforce\" + 0.002*\"powershell\" + 0.002*\"project\" + 0.002*\"linux\" + 0.002*\"bullhorn\" + 0.002*\"linkedin\"\n",
      "INFO : topic #1 (0.083): 0.010*\"technical\" + 0.008*\"java\" + 0.008*\"python\" + 0.007*\"sql\" + 0.006*\"c\" + 0.005*\"ms\" + 0.005*\"r\" + 0.004*\"data\" + 0.004*\"windows\" + 0.004*\"oracle\"\n",
      "INFO : topic #10 (0.083): 0.012*\"english\" + 0.005*\"data\" + 0.005*\"research\" + 0.005*\"indesign\" + 0.005*\"mandarin\" + 0.005*\"spanish\" + 0.004*\"illustrator\" + 0.004*\"native\" + 0.004*\"french\" + 0.003*\"relevant\"\n",
      "INFO : topic diff=0.017327, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.689 per-word bound, 412.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=12, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=12, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (451 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (576 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (264 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (449 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (311 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (801 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (527 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (429 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (329 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (640 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (548 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (500 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (504 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (404 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (375 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (701 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (375 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (865 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 8; 576 documents processed (700 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (865 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (493 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (498 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 512 documents processed (733 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (498 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (701 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (733 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (757 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (468 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (757 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 414 documents processed (572 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (568 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (468 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (568 virtual)\n",
      "DEBUG : finished all batches; 414 documents processed (572 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (700 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (564 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (493 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (564 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (768 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 5; 384 documents processed (641 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (768 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (641 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (606 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 576 documents processed (606 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9309 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12399/12537 documents converged within 50 iterations\n",
      " 43%|████▎     | 10/23 [04:11<05:27, 25.17s/it]INFO : using symmetric alpha at 0.07692307692307693\n",
      "INFO : using symmetric eta at 0.07692307692307693\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 13 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 421/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3341/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3137/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3187/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.077): 0.012*\"r\" + 0.011*\"sql\" + 0.009*\"c++\" + 0.009*\"python\" + 0.007*\"c\" + 0.007*\"linux\" + 0.006*\"sas\" + 0.006*\"html\" + 0.006*\"programming\" + 0.005*\"java\"\n",
      "INFO : topic #11 (0.077): 0.032*\"python\" + 0.028*\"r\" + 0.028*\"sql\" + 0.021*\"sas\" + 0.018*\"matlab\" + 0.016*\"c++\" + 0.016*\"technical\" + 0.015*\"tableau\" + 0.014*\"java\" + 0.013*\"hadoop\"\n",
      "INFO : topic #10 (0.077): 0.015*\"r\" + 0.012*\"sql\" + 0.010*\"mysql\" + 0.009*\"sas\" + 0.008*\"excel\" + 0.008*\"python\" + 0.006*\"linux\" + 0.006*\"html\" + 0.006*\"powerpoint\" + 0.006*\"java\"\n",
      "INFO : topic #8 (0.077): 0.031*\"r\" + 0.027*\"python\" + 0.025*\"sql\" + 0.015*\"tableau\" + 0.014*\"hadoop\" + 0.012*\"hive\" + 0.011*\"java\" + 0.011*\"technical\" + 0.010*\"c++\" + 0.010*\"c\"\n",
      "INFO : topic #12 (0.077): 0.019*\"python\" + 0.016*\"r\" + 0.014*\"java\" + 0.014*\"sql\" + 0.012*\"hive\" + 0.011*\"hadoop\" + 0.011*\"tableau\" + 0.011*\"mysql\" + 0.011*\"c\" + 0.010*\"spark\"\n",
      "INFO : topic diff=9.165663, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.224 per-word bound, 597.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 521/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3765/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3769/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3797/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.077): 0.013*\"technical\" + 0.012*\"sql\" + 0.009*\"unix\" + 0.009*\"python\" + 0.008*\"r\" + 0.007*\"tableau\" + 0.006*\"linux\" + 0.006*\"java\" + 0.004*\"pl\" + 0.004*\"c\"\n",
      "INFO : topic #0 (0.077): 0.017*\"sql\" + 0.013*\"python\" + 0.013*\"r\" + 0.008*\"technical\" + 0.008*\"html\" + 0.008*\"hive\" + 0.008*\"java\" + 0.008*\"oracle\" + 0.008*\"javascript\" + 0.007*\"hadoop\"\n",
      "INFO : topic #6 (0.077): 0.026*\"python\" + 0.025*\"r\" + 0.020*\"sql\" + 0.013*\"sas\" + 0.012*\"tableau\" + 0.012*\"technical\" + 0.011*\"pandas\" + 0.011*\"matlab\" + 0.010*\"mysql\" + 0.009*\"c++\"\n",
      "INFO : topic #7 (0.077): 0.015*\"sql\" + 0.013*\"python\" + 0.011*\"linux\" + 0.010*\"hadoop\" + 0.009*\"c++\" + 0.009*\"r\" + 0.009*\"hive\" + 0.008*\"matlab\" + 0.008*\"java\" + 0.007*\"c\"\n",
      "INFO : topic #9 (0.077): 0.024*\"python\" + 0.023*\"c\" + 0.022*\"html\" + 0.021*\"sql\" + 0.020*\"java\" + 0.018*\"r\" + 0.015*\"c++\" + 0.015*\"javascript\" + 0.013*\"technical\" + 0.012*\"css\"\n",
      "INFO : topic diff=0.355147, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.021 per-word bound, 519.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3847/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3840/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3874/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.077): 0.037*\"python\" + 0.035*\"r\" + 0.034*\"sql\" + 0.026*\"sas\" + 0.022*\"matlab\" + 0.018*\"c++\" + 0.018*\"tableau\" + 0.016*\"java\" + 0.016*\"technical\" + 0.015*\"excel\"\n",
      "INFO : topic #9 (0.077): 0.024*\"python\" + 0.024*\"c\" + 0.023*\"html\" + 0.021*\"java\" + 0.020*\"sql\" + 0.017*\"r\" + 0.017*\"javascript\" + 0.016*\"c++\" + 0.014*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #8 (0.077): 0.028*\"r\" + 0.026*\"python\" + 0.024*\"sql\" + 0.017*\"hadoop\" + 0.016*\"hive\" + 0.014*\"tableau\" + 0.012*\"java\" + 0.011*\"technical\" + 0.011*\"spark\" + 0.011*\"pig\"\n",
      "INFO : topic #4 (0.077): 0.021*\"sql\" + 0.019*\"r\" + 0.019*\"python\" + 0.012*\"technical\" + 0.010*\"data\" + 0.009*\"tableau\" + 0.009*\"matlab\" + 0.008*\"excel\" + 0.008*\"java\" + 0.008*\"sas\"\n",
      "INFO : topic #12 (0.077): 0.016*\"python\" + 0.014*\"r\" + 0.013*\"hive\" + 0.013*\"java\" + 0.012*\"sql\" + 0.011*\"tableau\" + 0.011*\"hadoop\" + 0.010*\"spark\" + 0.010*\"c\" + 0.009*\"mysql\"\n",
      "INFO : topic diff=0.299155, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.923 per-word bound, 485.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3875/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3915/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3885/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.077): 0.014*\"sql\" + 0.010*\"python\" + 0.009*\"r\" + 0.008*\"oracle\" + 0.008*\"technical\" + 0.008*\"html\" + 0.007*\"java\" + 0.007*\"javascript\" + 0.007*\"hive\" + 0.006*\"c\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #2 (0.077): 0.008*\"r\" + 0.007*\"sql\" + 0.006*\"c++\" + 0.005*\"data\" + 0.004*\"sas\" + 0.004*\"python\" + 0.004*\"html\" + 0.004*\"project\" + 0.004*\"c\" + 0.004*\"programming\"\n",
      "INFO : topic #8 (0.077): 0.027*\"r\" + 0.025*\"python\" + 0.023*\"sql\" + 0.018*\"hadoop\" + 0.017*\"hive\" + 0.014*\"tableau\" + 0.012*\"java\" + 0.012*\"pig\" + 0.012*\"spark\" + 0.012*\"technical\"\n",
      "INFO : topic #5 (0.077): 0.011*\"sql\" + 0.008*\"technical\" + 0.006*\"excel\" + 0.006*\"r\" + 0.005*\"sas\" + 0.004*\"tableau\" + 0.004*\"powerpoint\" + 0.004*\"python\" + 0.004*\"access\" + 0.004*\"java\"\n",
      "INFO : topic #10 (0.077): 0.010*\"r\" + 0.009*\"excel\" + 0.007*\"sql\" + 0.007*\"powerpoint\" + 0.007*\"mysql\" + 0.006*\"word\" + 0.006*\"sas\" + 0.006*\"access\" + 0.005*\"project\" + 0.004*\"linux\"\n",
      "INFO : topic diff=0.248949, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.867 per-word bound, 466.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3903/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3900/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3908/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.077): 0.010*\"sql\" + 0.009*\"linux\" + 0.008*\"python\" + 0.007*\"c++\" + 0.007*\"hadoop\" + 0.006*\"matlab\" + 0.005*\"r\" + 0.005*\"hive\" + 0.005*\"c\" + 0.005*\"excel\"\n",
      "INFO : topic #1 (0.077): 0.021*\"python\" + 0.016*\"java\" + 0.015*\"r\" + 0.014*\"technical\" + 0.014*\"sql\" + 0.011*\"c\" + 0.011*\"c++\" + 0.009*\"mysql\" + 0.008*\"html\" + 0.008*\"tableau\"\n",
      "INFO : topic #12 (0.077): 0.014*\"python\" + 0.013*\"hive\" + 0.012*\"r\" + 0.012*\"java\" + 0.010*\"tableau\" + 0.010*\"sql\" + 0.010*\"spark\" + 0.010*\"hadoop\" + 0.009*\"c\" + 0.008*\"pig\"\n",
      "INFO : topic #5 (0.077): 0.010*\"sql\" + 0.007*\"technical\" + 0.006*\"excel\" + 0.005*\"r\" + 0.004*\"sas\" + 0.004*\"powerpoint\" + 0.004*\"tableau\" + 0.003*\"access\" + 0.003*\"k\" + 0.003*\"python\"\n",
      "INFO : topic #10 (0.077): 0.009*\"excel\" + 0.008*\"r\" + 0.007*\"powerpoint\" + 0.006*\"word\" + 0.006*\"sql\" + 0.006*\"access\" + 0.006*\"mysql\" + 0.006*\"sas\" + 0.005*\"project\" + 0.004*\"data\"\n",
      "INFO : topic diff=0.204236, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.829 per-word bound, 454.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3904/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3910/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.077): 0.008*\"excel\" + 0.007*\"r\" + 0.007*\"powerpoint\" + 0.006*\"word\" + 0.006*\"access\" + 0.005*\"sql\" + 0.005*\"project\" + 0.005*\"sas\" + 0.005*\"mysql\" + 0.004*\"data\"\n",
      "INFO : topic #3 (0.077): 0.010*\"technical\" + 0.008*\"unix\" + 0.008*\"sql\" + 0.005*\"linux\" + 0.005*\"tableau\" + 0.004*\"pl\" + 0.004*\"python\" + 0.004*\"r\" + 0.004*\"java\" + 0.003*\"project\"\n",
      "INFO : topic #1 (0.077): 0.019*\"python\" + 0.015*\"java\" + 0.014*\"technical\" + 0.014*\"r\" + 0.013*\"sql\" + 0.011*\"c\" + 0.010*\"c++\" + 0.009*\"mysql\" + 0.008*\"html\" + 0.008*\"tableau\"\n",
      "INFO : topic #12 (0.077): 0.013*\"python\" + 0.013*\"hive\" + 0.011*\"r\" + 0.011*\"java\" + 0.010*\"tableau\" + 0.010*\"sql\" + 0.009*\"spark\" + 0.009*\"hadoop\" + 0.008*\"pig\" + 0.008*\"c\"\n",
      "INFO : topic #0 (0.077): 0.013*\"sql\" + 0.009*\"oracle\" + 0.008*\"technical\" + 0.008*\"python\" + 0.007*\"html\" + 0.007*\"r\" + 0.007*\"java\" + 0.006*\"javascript\" + 0.006*\"hive\" + 0.006*\"c\"\n",
      "INFO : topic diff=0.166226, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.803 per-word bound, 446.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3902/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.077): 0.043*\"r\" + 0.041*\"python\" + 0.040*\"sql\" + 0.030*\"sas\" + 0.024*\"matlab\" + 0.020*\"tableau\" + 0.020*\"c++\" + 0.019*\"excel\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #10 (0.077): 0.008*\"excel\" + 0.007*\"powerpoint\" + 0.006*\"word\" + 0.006*\"r\" + 0.005*\"access\" + 0.005*\"project\" + 0.004*\"sql\" + 0.004*\"sas\" + 0.004*\"mysql\" + 0.004*\"skills\"\n",
      "INFO : topic #7 (0.077): 0.008*\"linux\" + 0.008*\"sql\" + 0.006*\"python\" + 0.006*\"c++\" + 0.005*\"hadoop\" + 0.005*\"matlab\" + 0.004*\"core\" + 0.004*\"excel\" + 0.004*\"c\" + 0.004*\"data\"\n",
      "INFO : topic #8 (0.077): 0.024*\"r\" + 0.023*\"python\" + 0.022*\"sql\" + 0.020*\"hive\" + 0.019*\"hadoop\" + 0.014*\"pig\" + 0.014*\"spark\" + 0.013*\"tableau\" + 0.013*\"java\" + 0.013*\"technical\"\n",
      "INFO : topic #3 (0.077): 0.010*\"technical\" + 0.008*\"unix\" + 0.007*\"sql\" + 0.005*\"linux\" + 0.004*\"tableau\" + 0.004*\"pl\" + 0.003*\"project\" + 0.003*\"skills\" + 0.003*\"java\" + 0.003*\"python\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.134741, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.783 per-word bound, 440.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.077): 0.005*\"r\" + 0.004*\"sql\" + 0.004*\"project\" + 0.004*\"data\" + 0.004*\"c++\" + 0.003*\"core\" + 0.003*\"technical\" + 0.003*\"sas\" + 0.003*\"microsoft\" + 0.003*\"windows\"\n",
      "INFO : topic #8 (0.077): 0.023*\"r\" + 0.022*\"python\" + 0.021*\"sql\" + 0.020*\"hive\" + 0.020*\"hadoop\" + 0.015*\"pig\" + 0.014*\"spark\" + 0.013*\"java\" + 0.013*\"tableau\" + 0.013*\"technical\"\n",
      "INFO : topic #10 (0.077): 0.008*\"excel\" + 0.007*\"powerpoint\" + 0.006*\"word\" + 0.005*\"project\" + 0.005*\"access\" + 0.005*\"r\" + 0.004*\"skills\" + 0.004*\"research\" + 0.004*\"sas\" + 0.004*\"data\"\n",
      "INFO : topic #5 (0.077): 0.007*\"sql\" + 0.006*\"technical\" + 0.005*\"excel\" + 0.003*\"powerpoint\" + 0.003*\"key\" + 0.003*\"r\" + 0.003*\"scrum\" + 0.003*\"sas\" + 0.003*\"tableau\" + 0.003*\"k\"\n",
      "INFO : topic #7 (0.077): 0.008*\"linux\" + 0.007*\"sql\" + 0.005*\"c++\" + 0.005*\"python\" + 0.005*\"hadoop\" + 0.005*\"core\" + 0.004*\"matlab\" + 0.004*\"excel\" + 0.004*\"data\" + 0.004*\"software\"\n",
      "INFO : topic diff=0.109610, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.769 per-word bound, 436.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.077): 0.009*\"technical\" + 0.008*\"unix\" + 0.006*\"sql\" + 0.005*\"linux\" + 0.004*\"pl\" + 0.003*\"tableau\" + 0.003*\"project\" + 0.003*\"skills\" + 0.003*\"windows\" + 0.003*\"data\"\n",
      "INFO : topic #12 (0.077): 0.011*\"hive\" + 0.011*\"python\" + 0.010*\"tableau\" + 0.009*\"java\" + 0.009*\"r\" + 0.008*\"spark\" + 0.008*\"pig\" + 0.008*\"sql\" + 0.008*\"hadoop\" + 0.007*\"hdfs\"\n",
      "INFO : topic #1 (0.077): 0.016*\"python\" + 0.013*\"java\" + 0.012*\"technical\" + 0.011*\"r\" + 0.011*\"sql\" + 0.010*\"c\" + 0.009*\"c++\" + 0.007*\"mysql\" + 0.007*\"html\" + 0.006*\"tableau\"\n",
      "INFO : topic #11 (0.077): 0.045*\"r\" + 0.041*\"python\" + 0.041*\"sql\" + 0.031*\"sas\" + 0.025*\"matlab\" + 0.021*\"tableau\" + 0.021*\"excel\" + 0.020*\"c++\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #0 (0.077): 0.011*\"sql\" + 0.009*\"oracle\" + 0.008*\"technical\" + 0.007*\"html\" + 0.006*\"xml\" + 0.006*\"java\" + 0.006*\"python\" + 0.005*\"javascript\" + 0.005*\"pl\" + 0.005*\"ms\"\n",
      "INFO : topic diff=0.089509, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.759 per-word bound, 433.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.077): 0.012*\"sql\" + 0.011*\"r\" + 0.010*\"data\" + 0.009*\"python\" + 0.009*\"technical\" + 0.007*\"english\" + 0.006*\"matlab\" + 0.006*\"excel\" + 0.005*\"computer\" + 0.005*\"spss\"\n",
      "INFO : topic #11 (0.077): 0.045*\"r\" + 0.042*\"python\" + 0.041*\"sql\" + 0.032*\"sas\" + 0.025*\"matlab\" + 0.021*\"tableau\" + 0.021*\"excel\" + 0.020*\"c++\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #1 (0.077): 0.015*\"python\" + 0.012*\"java\" + 0.012*\"technical\" + 0.010*\"r\" + 0.010*\"sql\" + 0.009*\"c\" + 0.009*\"c++\" + 0.007*\"mysql\" + 0.007*\"html\" + 0.006*\"ms\"\n",
      "INFO : topic #8 (0.077): 0.022*\"r\" + 0.022*\"hive\" + 0.022*\"python\" + 0.021*\"sql\" + 0.020*\"hadoop\" + 0.016*\"pig\" + 0.015*\"spark\" + 0.014*\"java\" + 0.013*\"technical\" + 0.013*\"oracle\"\n",
      "INFO : topic #2 (0.077): 0.004*\"project\" + 0.004*\"r\" + 0.004*\"data\" + 0.003*\"sql\" + 0.003*\"c++\" + 0.003*\"core\" + 0.002*\"may\" + 0.002*\"microsoft\" + 0.002*\"technical\" + 0.002*\"software\"\n",
      "INFO : topic diff=0.073761, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.750 per-word bound, 430.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.077): 0.010*\"hive\" + 0.009*\"python\" + 0.009*\"tableau\" + 0.008*\"java\" + 0.007*\"pig\" + 0.007*\"r\" + 0.007*\"spark\" + 0.007*\"sql\" + 0.007*\"hdfs\" + 0.007*\"hadoop\"\n",
      "INFO : topic #4 (0.077): 0.011*\"sql\" + 0.010*\"data\" + 0.010*\"r\" + 0.009*\"python\" + 0.008*\"technical\" + 0.007*\"english\" + 0.005*\"excel\" + 0.005*\"matlab\" + 0.005*\"computer\" + 0.004*\"spss\"\n",
      "INFO : topic #10 (0.077): 0.007*\"excel\" + 0.006*\"powerpoint\" + 0.006*\"word\" + 0.005*\"project\" + 0.005*\"access\" + 0.004*\"skills\" + 0.004*\"salesforce\" + 0.004*\"research\" + 0.004*\"visio\" + 0.003*\"data\"\n",
      "INFO : topic #1 (0.077): 0.014*\"python\" + 0.011*\"java\" + 0.011*\"technical\" + 0.009*\"sql\" + 0.009*\"r\" + 0.009*\"c\" + 0.008*\"c++\" + 0.007*\"mysql\" + 0.006*\"html\" + 0.006*\"ms\"\n",
      "INFO : topic #5 (0.077): 0.005*\"sql\" + 0.005*\"technical\" + 0.004*\"excel\" + 0.003*\"key\" + 0.003*\"powerpoint\" + 0.002*\"scrum\" + 0.002*\"datascience\" + 0.002*\"k\" + 0.002*\"agile\" + 0.002*\"sql_server\"\n",
      "INFO : topic diff=0.061486, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.743 per-word bound, 428.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #4 (0.077): 0.010*\"data\" + 0.010*\"sql\" + 0.009*\"r\" + 0.008*\"technical\" + 0.008*\"english\" + 0.008*\"python\" + 0.005*\"excel\" + 0.005*\"matlab\" + 0.005*\"computer\" + 0.004*\"spss\"\n",
      "INFO : topic #9 (0.077): 0.027*\"html\" + 0.026*\"javascript\" + 0.026*\"java\" + 0.026*\"c\" + 0.024*\"python\" + 0.021*\"c++\" + 0.020*\"css\" + 0.018*\"sql\" + 0.015*\"mysql\" + 0.014*\"r\"\n",
      "INFO : topic #3 (0.077): 0.008*\"technical\" + 0.007*\"unix\" + 0.005*\"linux\" + 0.004*\"sql\" + 0.003*\"pl\" + 0.003*\"project\" + 0.003*\"skills\" + 0.003*\"tableau\" + 0.003*\"data\" + 0.002*\"t\"\n",
      "INFO : topic #0 (0.077): 0.010*\"sql\" + 0.009*\"oracle\" + 0.007*\"technical\" + 0.007*\"html\" + 0.007*\"xml\" + 0.006*\"pl\" + 0.006*\"ms\" + 0.005*\"java\" + 0.005*\"db2\" + 0.005*\"windows\"\n",
      "INFO : topic #6 (0.077): 0.031*\"python\" + 0.028*\"r\" + 0.024*\"sql\" + 0.019*\"pandas\" + 0.015*\"numpy\" + 0.015*\"technical\" + 0.014*\"tableau\" + 0.013*\"scikit\" + 0.013*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic diff=0.051863, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.737 per-word bound, 426.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.077): 0.004*\"sql\" + 0.004*\"technical\" + 0.003*\"key\" + 0.003*\"excel\" + 0.002*\"datascience\" + 0.002*\"scrum\" + 0.002*\"powerpoint\" + 0.002*\"agile\" + 0.002*\"k\" + 0.002*\"sql_server\"\n",
      "INFO : topic #10 (0.077): 0.007*\"excel\" + 0.006*\"powerpoint\" + 0.006*\"word\" + 0.005*\"project\" + 0.005*\"salesforce\" + 0.004*\"access\" + 0.004*\"skills\" + 0.004*\"research\" + 0.004*\"visio\" + 0.003*\"data\"\n",
      "INFO : topic #1 (0.077): 0.012*\"python\" + 0.010*\"technical\" + 0.010*\"java\" + 0.008*\"sql\" + 0.008*\"r\" + 0.008*\"c\" + 0.007*\"c++\" + 0.006*\"mysql\" + 0.006*\"ms\" + 0.006*\"html\"\n",
      "INFO : topic #7 (0.077): 0.006*\"linux\" + 0.005*\"core\" + 0.004*\"sql\" + 0.004*\"c++\" + 0.003*\"software\" + 0.003*\"data\" + 0.003*\"skill\" + 0.003*\"jobvite\" + 0.003*\"taleo\" + 0.003*\"hadoop\"\n",
      "INFO : topic #11 (0.077): 0.047*\"r\" + 0.042*\"sql\" + 0.042*\"python\" + 0.033*\"sas\" + 0.025*\"matlab\" + 0.022*\"excel\" + 0.022*\"tableau\" + 0.020*\"c++\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic diff=0.044216, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.731 per-word bound, 425.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.077): 0.004*\"technical\" + 0.004*\"sql\" + 0.003*\"key\" + 0.003*\"excel\" + 0.002*\"datascience\" + 0.002*\"scrum\" + 0.002*\"agile\" + 0.002*\"powerpoint\" + 0.002*\"sql_server\" + 0.002*\"ddl\"\n",
      "INFO : topic #11 (0.077): 0.047*\"r\" + 0.042*\"sql\" + 0.042*\"python\" + 0.033*\"sas\" + 0.025*\"matlab\" + 0.023*\"excel\" + 0.022*\"tableau\" + 0.020*\"c++\" + 0.016*\"technical\" + 0.016*\"java\"\n",
      "INFO : topic #4 (0.077): 0.010*\"data\" + 0.009*\"english\" + 0.009*\"sql\" + 0.008*\"r\" + 0.008*\"technical\" + 0.006*\"python\" + 0.004*\"excel\" + 0.004*\"matlab\" + 0.004*\"computer\" + 0.004*\"windows\"\n",
      "INFO : topic #1 (0.077): 0.011*\"python\" + 0.010*\"technical\" + 0.010*\"java\" + 0.008*\"sql\" + 0.008*\"r\" + 0.007*\"c\" + 0.007*\"c++\" + 0.006*\"ms\" + 0.005*\"mysql\" + 0.005*\"html\"\n",
      "INFO : topic #6 (0.077): 0.032*\"python\" + 0.028*\"r\" + 0.025*\"sql\" + 0.019*\"pandas\" + 0.016*\"numpy\" + 0.015*\"technical\" + 0.014*\"tableau\" + 0.013*\"scikit\" + 0.013*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic diff=0.038204, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.727 per-word bound, 423.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.077): 0.004*\"project\" + 0.003*\"data\" + 0.003*\"may\" + 0.003*\"core\" + 0.002*\"socialmedia\" + 0.002*\"software\" + 0.002*\"microsoft\" + 0.002*\"r\" + 0.002*\"c++\" + 0.002*\"sql\"\n",
      "INFO : topic #5 (0.077): 0.004*\"technical\" + 0.003*\"sql\" + 0.003*\"key\" + 0.003*\"excel\" + 0.002*\"datascience\" + 0.002*\"scrum\" + 0.002*\"agile\" + 0.002*\"ddl\" + 0.002*\"sql_server\" + 0.002*\"etl\"\n",
      "INFO : topic #12 (0.077): 0.009*\"tableau\" + 0.008*\"hive\" + 0.008*\"python\" + 0.007*\"excel\" + 0.007*\"pig\" + 0.006*\"hdfs\" + 0.006*\"java\" + 0.006*\"sql\" + 0.006*\"spark\" + 0.006*\"hadoop\"\n",
      "INFO : topic #8 (0.077): 0.024*\"hive\" + 0.021*\"hadoop\" + 0.020*\"python\" + 0.020*\"r\" + 0.020*\"sql\" + 0.018*\"pig\" + 0.016*\"spark\" + 0.014*\"java\" + 0.014*\"oracle\" + 0.014*\"technical\"\n",
      "INFO : topic #11 (0.077): 0.047*\"r\" + 0.042*\"sql\" + 0.042*\"python\" + 0.033*\"sas\" + 0.025*\"matlab\" + 0.023*\"excel\" + 0.022*\"tableau\" + 0.020*\"c++\" + 0.016*\"spss\" + 0.016*\"technical\"\n",
      "INFO : topic diff=0.033323, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.722 per-word bound, 422.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.077): 0.009*\"tableau\" + 0.008*\"hive\" + 0.007*\"python\" + 0.007*\"excel\" + 0.006*\"pig\" + 0.006*\"hdfs\" + 0.006*\"java\" + 0.006*\"sql\" + 0.006*\"spark\" + 0.005*\"hadoop\"\n",
      "INFO : topic #1 (0.077): 0.010*\"python\" + 0.009*\"technical\" + 0.009*\"java\" + 0.007*\"sql\" + 0.007*\"c\" + 0.007*\"r\" + 0.006*\"c++\" + 0.006*\"ms\" + 0.005*\"mysql\" + 0.005*\"html\"\n",
      "INFO : topic #11 (0.077): 0.048*\"r\" + 0.043*\"sql\" + 0.042*\"python\" + 0.033*\"sas\" + 0.025*\"matlab\" + 0.023*\"excel\" + 0.022*\"tableau\" + 0.020*\"c++\" + 0.016*\"spss\" + 0.016*\"technical\"\n",
      "INFO : topic #9 (0.077): 0.028*\"html\" + 0.028*\"javascript\" + 0.027*\"java\" + 0.026*\"c\" + 0.024*\"python\" + 0.021*\"c++\" + 0.021*\"css\" + 0.018*\"sql\" + 0.016*\"mysql\" + 0.014*\"r\"\n",
      "INFO : topic #6 (0.077): 0.032*\"python\" + 0.029*\"r\" + 0.025*\"sql\" + 0.020*\"pandas\" + 0.016*\"numpy\" + 0.015*\"technical\" + 0.014*\"tableau\" + 0.014*\"scikit\" + 0.013*\"hadoop\" + 0.012*\"spark\"\n",
      "INFO : topic diff=0.029296, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.719 per-word bound, 421.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.077): 0.032*\"python\" + 0.029*\"r\" + 0.025*\"sql\" + 0.020*\"pandas\" + 0.016*\"numpy\" + 0.015*\"technical\" + 0.014*\"tableau\" + 0.014*\"scikit\" + 0.013*\"hadoop\" + 0.012*\"spark\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #4 (0.077): 0.009*\"english\" + 0.009*\"data\" + 0.007*\"technical\" + 0.007*\"sql\" + 0.006*\"r\" + 0.005*\"python\" + 0.004*\"excel\" + 0.004*\"matlab\" + 0.004*\"windows\" + 0.003*\"computer\"\n",
      "INFO : topic #5 (0.077): 0.003*\"technical\" + 0.003*\"key\" + 0.003*\"sql\" + 0.003*\"datascience\" + 0.002*\"excel\" + 0.002*\"ddl\" + 0.002*\"scrum\" + 0.002*\"agile\" + 0.002*\"dml\" + 0.002*\"sql_server\"\n",
      "INFO : topic #1 (0.077): 0.009*\"python\" + 0.009*\"technical\" + 0.008*\"java\" + 0.006*\"c\" + 0.006*\"sql\" + 0.006*\"r\" + 0.006*\"c++\" + 0.005*\"ms\" + 0.004*\"html\" + 0.004*\"mysql\"\n",
      "INFO : topic #3 (0.077): 0.007*\"technical\" + 0.007*\"unix\" + 0.004*\"linux\" + 0.003*\"project\" + 0.003*\"sql\" + 0.003*\"skills\" + 0.003*\"pl\" + 0.002*\"powershell\" + 0.002*\"data\" + 0.002*\"customer\"\n",
      "INFO : topic diff=0.026009, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.715 per-word bound, 420.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3968/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.077): 0.010*\"english\" + 0.009*\"data\" + 0.007*\"technical\" + 0.006*\"sql\" + 0.006*\"r\" + 0.004*\"python\" + 0.004*\"excel\" + 0.003*\"windows\" + 0.003*\"matlab\" + 0.003*\"computer\"\n",
      "INFO : topic #12 (0.077): 0.009*\"tableau\" + 0.008*\"hive\" + 0.007*\"excel\" + 0.007*\"python\" + 0.006*\"pig\" + 0.006*\"hdfs\" + 0.006*\"sql\" + 0.005*\"java\" + 0.005*\"spark\" + 0.005*\"hadoop\"\n",
      "INFO : topic #5 (0.077): 0.003*\"key\" + 0.003*\"technical\" + 0.003*\"datascience\" + 0.002*\"sql\" + 0.002*\"excel\" + 0.002*\"ddl\" + 0.002*\"scrum\" + 0.002*\"agile\" + 0.002*\"dml\" + 0.002*\"sql_server\"\n",
      "INFO : topic #9 (0.077): 0.029*\"html\" + 0.028*\"javascript\" + 0.028*\"java\" + 0.027*\"c\" + 0.024*\"python\" + 0.022*\"css\" + 0.022*\"c++\" + 0.018*\"sql\" + 0.016*\"mysql\" + 0.014*\"r\"\n",
      "INFO : topic #2 (0.077): 0.004*\"project\" + 0.003*\"may\" + 0.003*\"data\" + 0.003*\"core\" + 0.002*\"socialmedia\" + 0.002*\"december\" + 0.002*\"software\" + 0.002*\"april\" + 0.002*\"microsoft\" + 0.002*\"research\"\n",
      "INFO : topic diff=0.023340, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.712 per-word bound, 419.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3969/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.077): 0.025*\"hive\" + 0.022*\"hadoop\" + 0.020*\"python\" + 0.020*\"sql\" + 0.019*\"r\" + 0.019*\"pig\" + 0.016*\"spark\" + 0.014*\"oracle\" + 0.014*\"java\" + 0.014*\"technical\"\n",
      "INFO : topic #3 (0.077): 0.007*\"technical\" + 0.007*\"unix\" + 0.004*\"linux\" + 0.003*\"project\" + 0.003*\"skills\" + 0.003*\"sql\" + 0.003*\"pl\" + 0.002*\"powershell\" + 0.002*\"customer\" + 0.002*\"data\"\n",
      "INFO : topic #4 (0.077): 0.010*\"english\" + 0.009*\"data\" + 0.007*\"technical\" + 0.006*\"sql\" + 0.005*\"r\" + 0.004*\"python\" + 0.003*\"excel\" + 0.003*\"windows\" + 0.003*\"french\" + 0.003*\"mandarin\"\n",
      "INFO : topic #7 (0.077): 0.005*\"core\" + 0.004*\"linux\" + 0.003*\"software\" + 0.003*\"jobvite\" + 0.003*\"skill\" + 0.003*\"sql\" + 0.003*\"taleo\" + 0.002*\"data\" + 0.002*\"self\" + 0.002*\"c++\"\n",
      "INFO : topic #9 (0.077): 0.029*\"html\" + 0.028*\"javascript\" + 0.028*\"java\" + 0.027*\"c\" + 0.024*\"python\" + 0.022*\"css\" + 0.022*\"c++\" + 0.018*\"sql\" + 0.016*\"mysql\" + 0.014*\"r\"\n",
      "INFO : topic diff=0.021029, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.709 per-word bound, 418.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3968/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.077): 0.025*\"hive\" + 0.022*\"hadoop\" + 0.020*\"python\" + 0.020*\"sql\" + 0.019*\"pig\" + 0.019*\"r\" + 0.016*\"spark\" + 0.014*\"oracle\" + 0.014*\"java\" + 0.014*\"technical\"\n",
      "INFO : topic #2 (0.077): 0.004*\"project\" + 0.004*\"may\" + 0.003*\"core\" + 0.003*\"data\" + 0.003*\"december\" + 0.002*\"socialmedia\" + 0.002*\"april\" + 0.002*\"software\" + 0.002*\"microsoft\" + 0.002*\"research\"\n",
      "INFO : topic #7 (0.077): 0.005*\"core\" + 0.004*\"linux\" + 0.003*\"software\" + 0.003*\"jobvite\" + 0.003*\"skill\" + 0.003*\"taleo\" + 0.002*\"self\" + 0.002*\"data\" + 0.002*\"sql\" + 0.002*\"m.\"\n",
      "INFO : topic #3 (0.077): 0.007*\"technical\" + 0.007*\"unix\" + 0.004*\"linux\" + 0.003*\"project\" + 0.003*\"skills\" + 0.003*\"sql\" + 0.002*\"powershell\" + 0.002*\"pl\" + 0.002*\"customer\" + 0.002*\"data\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #6 (0.077): 0.033*\"python\" + 0.029*\"r\" + 0.025*\"sql\" + 0.020*\"pandas\" + 0.016*\"numpy\" + 0.016*\"technical\" + 0.015*\"tableau\" + 0.014*\"scikit\" + 0.013*\"hadoop\" + 0.012*\"spark\"\n",
      "INFO : topic diff=0.019080, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.706 per-word bound, 417.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=13, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=13, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (153 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (323 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (439 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (429 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (392 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (516 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (417 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (441 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (545 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (581 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (494 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (656 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (666 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (372 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (584 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (514 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (582 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (510 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (494 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (660 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 4; 320 documents processed (481 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (660 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 8; 576 documents processed (580 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (733 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 576 documents processed (580 virtual)\n",
      "DEBUG : finished all batches; 320 documents processed (481 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (733 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (648 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (648 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (494 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (720 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (720 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (578 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 5; 384 documents processed (741 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (578 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (645 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (575 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 384 documents processed (645 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (741 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (575 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (659 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (632 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (659 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (632 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 509 documents processed (746 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 509 documents processed (746 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9340 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12408/12537 documents converged within 50 iterations\n",
      " 48%|████▊     | 11/23 [04:38<05:03, 25.31s/it]INFO : using symmetric alpha at 0.07142857142857142\n",
      "INFO : using symmetric eta at 0.07142857142857142\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 14 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 429/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3204/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3335/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3167/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.071): 0.018*\"python\" + 0.016*\"r\" + 0.015*\"java\" + 0.015*\"sql\" + 0.012*\"hive\" + 0.012*\"mysql\" + 0.011*\"c\" + 0.011*\"hadoop\" + 0.010*\"tableau\" + 0.010*\"c++\"\n",
      "INFO : topic #6 (0.071): 0.025*\"python\" + 0.024*\"r\" + 0.019*\"sql\" + 0.012*\"sas\" + 0.011*\"mysql\" + 0.011*\"matlab\" + 0.011*\"technical\" + 0.010*\"tableau\" + 0.010*\"c++\" + 0.008*\"java\"\n",
      "INFO : topic #13 (0.071): 0.022*\"python\" + 0.021*\"sql\" + 0.018*\"r\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.015*\"tableau\" + 0.013*\"java\" + 0.011*\"c\" + 0.011*\"html\" + 0.011*\"c++\"\n",
      "INFO : topic #1 (0.071): 0.024*\"python\" + 0.018*\"r\" + 0.018*\"sql\" + 0.018*\"java\" + 0.016*\"technical\" + 0.013*\"c++\" + 0.012*\"c\" + 0.010*\"mysql\" + 0.010*\"matlab\" + 0.010*\"tableau\"\n",
      "INFO : topic #7 (0.071): 0.016*\"sql\" + 0.014*\"python\" + 0.013*\"linux\" + 0.011*\"hadoop\" + 0.010*\"r\" + 0.010*\"hive\" + 0.009*\"c++\" + 0.008*\"matlab\" + 0.007*\"excel\" + 0.007*\"java\"\n",
      "INFO : topic diff=10.013437, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.252 per-word bound, 609.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 517/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3747/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3791/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3808/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.071): 0.017*\"r\" + 0.011*\"sql\" + 0.010*\"sas\" + 0.010*\"excel\" + 0.008*\"mysql\" + 0.007*\"python\" + 0.007*\"word\" + 0.007*\"powerpoint\" + 0.006*\"c++\" + 0.006*\"spss\"\n",
      "INFO : topic #3 (0.071): 0.011*\"technical\" + 0.010*\"sql\" + 0.009*\"python\" + 0.007*\"r\" + 0.007*\"unix\" + 0.006*\"java\" + 0.005*\"linux\" + 0.005*\"tableau\" + 0.005*\"javascript\" + 0.004*\"c++\"\n",
      "INFO : topic #13 (0.071): 0.021*\"python\" + 0.020*\"sql\" + 0.018*\"r\" + 0.016*\"technical\" + 0.015*\"tableau\" + 0.015*\"sas\" + 0.012*\"java\" + 0.012*\"html\" + 0.011*\"c\" + 0.010*\"c++\"\n",
      "INFO : topic #0 (0.071): 0.016*\"sql\" + 0.013*\"r\" + 0.012*\"python\" + 0.008*\"technical\" + 0.008*\"hive\" + 0.008*\"java\" + 0.008*\"html\" + 0.007*\"javascript\" + 0.007*\"oracle\" + 0.007*\"hadoop\"\n",
      "INFO : topic #2 (0.071): 0.011*\"r\" + 0.009*\"sql\" + 0.008*\"python\" + 0.007*\"c++\" + 0.006*\"linux\" + 0.006*\"c\" + 0.006*\"java\" + 0.006*\"computer\" + 0.005*\"html\" + 0.005*\"windows\"\n",
      "INFO : topic diff=0.357683, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.059 per-word bound, 533.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3839/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3856/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3879/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.071): 0.009*\"r\" + 0.008*\"sql\" + 0.007*\"python\" + 0.006*\"linux\" + 0.006*\"c++\" + 0.005*\"c\" + 0.005*\"computer\" + 0.005*\"windows\" + 0.005*\"html\" + 0.005*\"java\"\n",
      "INFO : topic #12 (0.071): 0.016*\"python\" + 0.014*\"sql\" + 0.014*\"java\" + 0.014*\"r\" + 0.013*\"hive\" + 0.011*\"mysql\" + 0.010*\"tableau\" + 0.010*\"hadoop\" + 0.010*\"c\" + 0.009*\"technical\"\n",
      "INFO : topic #5 (0.071): 0.011*\"sql\" + 0.009*\"technical\" + 0.007*\"r\" + 0.006*\"excel\" + 0.005*\"python\" + 0.005*\"sas\" + 0.005*\"access\" + 0.004*\"k\" + 0.004*\"oracle\" + 0.004*\"linux\"\n",
      "INFO : topic #7 (0.071): 0.012*\"sql\" + 0.010*\"linux\" + 0.010*\"python\" + 0.008*\"hadoop\" + 0.008*\"r\" + 0.008*\"c++\" + 0.007*\"hive\" + 0.007*\"matlab\" + 0.006*\"c\" + 0.006*\"excel\"\n",
      "INFO : topic #0 (0.071): 0.014*\"sql\" + 0.011*\"r\" + 0.011*\"python\" + 0.008*\"html\" + 0.008*\"technical\" + 0.008*\"java\" + 0.008*\"hive\" + 0.007*\"oracle\" + 0.007*\"javascript\" + 0.006*\"mysql\"\n",
      "INFO : topic diff=0.307857, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.959 per-word bound, 497.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3864/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3878/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.071): 0.010*\"sql\" + 0.008*\"technical\" + 0.006*\"r\" + 0.005*\"excel\" + 0.004*\"python\" + 0.004*\"access\" + 0.004*\"sas\" + 0.004*\"k\" + 0.004*\"oracle\" + 0.004*\"agile\"\n",
      "INFO : topic #9 (0.071): 0.025*\"python\" + 0.024*\"c\" + 0.023*\"html\" + 0.022*\"java\" + 0.020*\"sql\" + 0.020*\"javascript\" + 0.017*\"r\" + 0.017*\"c++\" + 0.015*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #0 (0.071): 0.013*\"sql\" + 0.009*\"python\" + 0.009*\"r\" + 0.008*\"html\" + 0.008*\"technical\" + 0.008*\"java\" + 0.007*\"oracle\" + 0.007*\"hive\" + 0.007*\"javascript\" + 0.006*\"mysql\"\n",
      "INFO : topic #3 (0.071): 0.009*\"technical\" + 0.007*\"sql\" + 0.006*\"python\" + 0.006*\"unix\" + 0.004*\"r\" + 0.004*\"java\" + 0.004*\"data\" + 0.004*\"linux\" + 0.003*\"skills\" + 0.003*\"javascript\"\n",
      "INFO : topic #2 (0.071): 0.008*\"r\" + 0.007*\"sql\" + 0.006*\"linux\" + 0.006*\"python\" + 0.005*\"c++\" + 0.005*\"computer\" + 0.005*\"c\" + 0.005*\"windows\" + 0.005*\"data\" + 0.005*\"html\"\n",
      "INFO : topic diff=0.258221, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.898 per-word bound, 476.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3901/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.071): 0.025*\"python\" + 0.024*\"c\" + 0.024*\"html\" + 0.023*\"java\" + 0.022*\"javascript\" + 0.020*\"sql\" + 0.018*\"c++\" + 0.017*\"r\" + 0.017*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #5 (0.071): 0.008*\"sql\" + 0.007*\"technical\" + 0.005*\"excel\" + 0.005*\"r\" + 0.004*\"agile\" + 0.004*\"access\" + 0.004*\"k\" + 0.004*\"oracle\" + 0.003*\"powerpoint\" + 0.003*\"sas\"\n",
      "INFO : topic #12 (0.071): 0.014*\"python\" + 0.013*\"sql\" + 0.012*\"hive\" + 0.012*\"java\" + 0.011*\"r\" + 0.009*\"mysql\" + 0.009*\"tableau\" + 0.009*\"technical\" + 0.009*\"hadoop\" + 0.009*\"c\"\n",
      "INFO : topic #11 (0.071): 0.043*\"r\" + 0.042*\"python\" + 0.039*\"sql\" + 0.027*\"sas\" + 0.026*\"matlab\" + 0.020*\"c++\" + 0.019*\"tableau\" + 0.018*\"java\" + 0.016*\"excel\" + 0.016*\"technical\"\n",
      "INFO : topic #6 (0.071): 0.027*\"python\" + 0.025*\"r\" + 0.021*\"sql\" + 0.015*\"pandas\" + 0.013*\"technical\" + 0.012*\"tableau\" + 0.012*\"numpy\" + 0.010*\"hadoop\" + 0.010*\"mysql\" + 0.010*\"scikit\"\n",
      "INFO : topic diff=0.212791, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.857 per-word bound, 463.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 537/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3910/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.071): 0.011*\"sql\" + 0.008*\"html\" + 0.007*\"technical\" + 0.007*\"java\" + 0.007*\"python\" + 0.007*\"r\" + 0.007*\"oracle\" + 0.006*\"javascript\" + 0.006*\"hive\" + 0.006*\"mysql\"\n",
      "INFO : topic #7 (0.071): 0.008*\"sql\" + 0.008*\"linux\" + 0.006*\"python\" + 0.006*\"c++\" + 0.006*\"hadoop\" + 0.005*\"hive\" + 0.005*\"matlab\" + 0.005*\"r\" + 0.004*\"c\" + 0.004*\"excel\"\n",
      "INFO : topic #6 (0.071): 0.028*\"python\" + 0.026*\"r\" + 0.022*\"sql\" + 0.016*\"pandas\" + 0.013*\"technical\" + 0.013*\"numpy\" + 0.013*\"tableau\" + 0.011*\"scikit\" + 0.011*\"hadoop\" + 0.010*\"mysql\"\n",
      "INFO : topic #13 (0.071): 0.018*\"sql\" + 0.016*\"python\" + 0.015*\"technical\" + 0.014*\"sas\" + 0.014*\"tableau\" + 0.013*\"r\" + 0.011*\"html\" + 0.010*\"c\" + 0.010*\"java\" + 0.009*\"c++\"\n",
      "INFO : topic #1 (0.071): 0.017*\"python\" + 0.015*\"java\" + 0.014*\"sql\" + 0.013*\"technical\" + 0.011*\"r\" + 0.010*\"c\" + 0.010*\"c++\" + 0.009*\"mysql\" + 0.007*\"javascript\" + 0.007*\"html\"\n",
      "INFO : topic diff=0.172951, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.828 per-word bound, 454.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3910/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.071): 0.023*\"r\" + 0.022*\"python\" + 0.021*\"hive\" + 0.021*\"sql\" + 0.019*\"hadoop\" + 0.015*\"pig\" + 0.014*\"spark\" + 0.013*\"java\" + 0.013*\"tableau\" + 0.012*\"technical\"\n",
      "INFO : topic #4 (0.071): 0.014*\"sql\" + 0.014*\"r\" + 0.013*\"python\" + 0.007*\"matlab\" + 0.007*\"technical\" + 0.007*\"data\" + 0.006*\"english\" + 0.006*\"excel\" + 0.006*\"windows\" + 0.006*\"c++\"\n",
      "INFO : topic #11 (0.071): 0.047*\"r\" + 0.044*\"python\" + 0.041*\"sql\" + 0.029*\"sas\" + 0.027*\"matlab\" + 0.021*\"c++\" + 0.020*\"tableau\" + 0.018*\"excel\" + 0.018*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #9 (0.071): 0.025*\"html\" + 0.025*\"c\" + 0.025*\"python\" + 0.025*\"javascript\" + 0.024*\"java\" + 0.020*\"sql\" + 0.019*\"c++\" + 0.019*\"css\" + 0.016*\"r\" + 0.014*\"mysql\"\n",
      "INFO : topic #0 (0.071): 0.011*\"sql\" + 0.008*\"html\" + 0.007*\"technical\" + 0.007*\"oracle\" + 0.007*\"java\" + 0.006*\"python\" + 0.006*\"r\" + 0.006*\"javascript\" + 0.005*\"mysql\" + 0.005*\"linux\"\n",
      "INFO : topic diff=0.139750, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.807 per-word bound, 447.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.071): 0.007*\"technical\" + 0.005*\"unix\" + 0.004*\"sql\" + 0.003*\"data\" + 0.003*\"skills\" + 0.003*\"python\" + 0.002*\"d.\" + 0.002*\"powershell\" + 0.002*\"j.\" + 0.002*\"linux\"\n",
      "INFO : topic #12 (0.071): 0.012*\"python\" + 0.011*\"sql\" + 0.011*\"hive\" + 0.009*\"tableau\" + 0.009*\"r\" + 0.009*\"java\" + 0.009*\"technical\" + 0.008*\"pig\" + 0.008*\"excel\" + 0.007*\"mysql\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #5 (0.071): 0.006*\"technical\" + 0.006*\"sql\" + 0.004*\"agile\" + 0.004*\"excel\" + 0.003*\"key\" + 0.003*\"k\" + 0.003*\"scrum\" + 0.003*\"data\" + 0.003*\"access\" + 0.003*\"oracle\"\n",
      "INFO : topic #10 (0.071): 0.014*\"excel\" + 0.012*\"powerpoint\" + 0.012*\"word\" + 0.008*\"access\" + 0.008*\"r\" + 0.007*\"project\" + 0.006*\"sas\" + 0.006*\"outlook\" + 0.005*\"data\" + 0.005*\"computer\"\n",
      "INFO : topic #2 (0.071): 0.006*\"linux\" + 0.005*\"r\" + 0.005*\"computer\" + 0.004*\"windows\" + 0.004*\"sql\" + 0.004*\"data\" + 0.004*\"c++\" + 0.004*\"c\" + 0.004*\"unix\" + 0.004*\"python\"\n",
      "INFO : topic diff=0.113255, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.790 per-word bound, 442.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.071): 0.009*\"sql\" + 0.008*\"html\" + 0.007*\"oracle\" + 0.007*\"technical\" + 0.006*\"java\" + 0.006*\"javascript\" + 0.005*\"linux\" + 0.005*\"python\" + 0.005*\"r\" + 0.005*\"mysql\"\n",
      "INFO : topic #8 (0.071): 0.023*\"hive\" + 0.021*\"r\" + 0.021*\"python\" + 0.020*\"hadoop\" + 0.020*\"sql\" + 0.016*\"pig\" + 0.015*\"spark\" + 0.013*\"java\" + 0.013*\"oracle\" + 0.013*\"technical\"\n",
      "INFO : topic #9 (0.071): 0.026*\"html\" + 0.026*\"javascript\" + 0.026*\"c\" + 0.025*\"java\" + 0.025*\"python\" + 0.020*\"css\" + 0.020*\"c++\" + 0.019*\"sql\" + 0.016*\"mysql\" + 0.016*\"r\"\n",
      "INFO : topic #4 (0.071): 0.012*\"sql\" + 0.011*\"r\" + 0.010*\"python\" + 0.008*\"english\" + 0.006*\"matlab\" + 0.006*\"technical\" + 0.006*\"data\" + 0.006*\"windows\" + 0.005*\"excel\" + 0.005*\"computer\"\n",
      "INFO : topic #2 (0.071): 0.006*\"linux\" + 0.005*\"r\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"data\" + 0.004*\"sql\" + 0.004*\"c\" + 0.004*\"c++\" + 0.004*\"unix\" + 0.003*\"python\"\n",
      "INFO : topic diff=0.092140, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.776 per-word bound, 438.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.071): 0.015*\"excel\" + 0.013*\"powerpoint\" + 0.012*\"word\" + 0.009*\"access\" + 0.007*\"project\" + 0.006*\"outlook\" + 0.006*\"r\" + 0.005*\"data\" + 0.005*\"sas\" + 0.005*\"skills\"\n",
      "INFO : topic #3 (0.071): 0.006*\"technical\" + 0.005*\"unix\" + 0.003*\"skills\" + 0.003*\"data\" + 0.003*\"d.\" + 0.003*\"j.\" + 0.003*\"sql\" + 0.002*\"s.\" + 0.002*\"powershell\" + 0.002*\"m.\"\n",
      "INFO : topic #12 (0.071): 0.010*\"python\" + 0.010*\"hive\" + 0.010*\"sql\" + 0.009*\"tableau\" + 0.008*\"technical\" + 0.008*\"r\" + 0.008*\"pig\" + 0.008*\"excel\" + 0.008*\"java\" + 0.007*\"hdfs\"\n",
      "INFO : topic #2 (0.071): 0.005*\"linux\" + 0.005*\"r\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"data\" + 0.004*\"c\" + 0.004*\"sql\" + 0.004*\"c++\" + 0.004*\"unix\" + 0.003*\"html\"\n",
      "INFO : topic #7 (0.071): 0.006*\"linux\" + 0.005*\"sql\" + 0.004*\"core\" + 0.004*\"c++\" + 0.004*\"python\" + 0.004*\"matlab\" + 0.003*\"excel\" + 0.003*\"hive\" + 0.003*\"hadoop\" + 0.003*\"c\"\n",
      "INFO : topic diff=0.075523, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.766 per-word bound, 435.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.071): 0.024*\"hive\" + 0.020*\"python\" + 0.020*\"hadoop\" + 0.020*\"r\" + 0.019*\"sql\" + 0.017*\"pig\" + 0.015*\"spark\" + 0.014*\"java\" + 0.013*\"oracle\" + 0.013*\"technical\"\n",
      "INFO : topic #4 (0.071): 0.010*\"sql\" + 0.009*\"r\" + 0.009*\"english\" + 0.008*\"python\" + 0.006*\"data\" + 0.006*\"matlab\" + 0.006*\"windows\" + 0.005*\"technical\" + 0.005*\"computer\" + 0.005*\"excel\"\n",
      "INFO : topic #12 (0.071): 0.010*\"hive\" + 0.010*\"python\" + 0.010*\"sql\" + 0.009*\"tableau\" + 0.008*\"technical\" + 0.008*\"excel\" + 0.008*\"r\" + 0.008*\"pig\" + 0.007*\"hdfs\" + 0.007*\"java\"\n",
      "INFO : topic #0 (0.071): 0.009*\"sql\" + 0.007*\"html\" + 0.007*\"oracle\" + 0.006*\"technical\" + 0.006*\"java\" + 0.005*\"javascript\" + 0.005*\"unix\" + 0.005*\"xml\" + 0.005*\"linux\" + 0.005*\"mysql\"\n",
      "INFO : topic #1 (0.071): 0.011*\"java\" + 0.011*\"sql\" + 0.011*\"python\" + 0.011*\"technical\" + 0.008*\"c\" + 0.007*\"c++\" + 0.007*\"r\" + 0.006*\"ms\" + 0.006*\"mysql\" + 0.006*\"css\"\n",
      "INFO : topic diff=0.062623, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.756 per-word bound, 432.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.071): 0.005*\"linux\" + 0.004*\"computer\" + 0.004*\"data\" + 0.004*\"windows\" + 0.004*\"r\" + 0.003*\"unix\" + 0.003*\"c\" + 0.003*\"c++\" + 0.003*\"sql\" + 0.003*\"project\"\n",
      "INFO : topic #9 (0.071): 0.028*\"javascript\" + 0.028*\"html\" + 0.026*\"c\" + 0.026*\"java\" + 0.025*\"python\" + 0.021*\"css\" + 0.020*\"c++\" + 0.019*\"sql\" + 0.017*\"mysql\" + 0.015*\"r\"\n",
      "INFO : topic #8 (0.071): 0.024*\"hive\" + 0.021*\"hadoop\" + 0.020*\"python\" + 0.020*\"r\" + 0.019*\"sql\" + 0.018*\"pig\" + 0.015*\"spark\" + 0.014*\"java\" + 0.013*\"oracle\" + 0.013*\"technical\"\n",
      "INFO : topic #3 (0.071): 0.006*\"technical\" + 0.005*\"unix\" + 0.003*\"d.\" + 0.003*\"j.\" + 0.003*\"skills\" + 0.003*\"data\" + 0.003*\"s.\" + 0.003*\"m.\" + 0.003*\"p.\" + 0.002*\"powershell\"\n",
      "INFO : topic #5 (0.071): 0.005*\"technical\" + 0.004*\"agile\" + 0.004*\"key\" + 0.004*\"sql\" + 0.003*\"scrum\" + 0.003*\"taleo\" + 0.003*\"excel\" + 0.003*\"k\" + 0.003*\"waterfall\" + 0.002*\"data\"\n",
      "INFO : topic diff=0.052512, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.748 per-word bound, 430.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.071): 0.010*\"java\" + 0.010*\"sql\" + 0.010*\"technical\" + 0.009*\"python\" + 0.007*\"c\" + 0.006*\"ms\" + 0.006*\"c++\" + 0.006*\"r\" + 0.005*\"mysql\" + 0.005*\"windows\"\n",
      "INFO : topic #4 (0.071): 0.010*\"english\" + 0.008*\"sql\" + 0.008*\"r\" + 0.007*\"python\" + 0.006*\"windows\" + 0.006*\"data\" + 0.005*\"matlab\" + 0.005*\"technical\" + 0.004*\"computer\" + 0.004*\"linux\"\n",
      "INFO : topic #9 (0.071): 0.029*\"javascript\" + 0.028*\"html\" + 0.027*\"java\" + 0.027*\"c\" + 0.025*\"python\" + 0.022*\"css\" + 0.021*\"c++\" + 0.019*\"sql\" + 0.017*\"mysql\" + 0.015*\"r\"\n",
      "INFO : topic #11 (0.071): 0.050*\"r\" + 0.046*\"python\" + 0.044*\"sql\" + 0.031*\"sas\" + 0.028*\"matlab\" + 0.022*\"c++\" + 0.022*\"tableau\" + 0.021*\"excel\" + 0.018*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #10 (0.071): 0.016*\"excel\" + 0.014*\"powerpoint\" + 0.013*\"word\" + 0.009*\"access\" + 0.008*\"project\" + 0.007*\"outlook\" + 0.005*\"data\" + 0.005*\"indesign\" + 0.005*\"skills\" + 0.005*\"illustrator\"\n",
      "INFO : topic diff=0.044606, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.742 per-word bound, 428.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.071): 0.010*\"java\" + 0.010*\"technical\" + 0.010*\"sql\" + 0.009*\"python\" + 0.006*\"c\" + 0.006*\"ms\" + 0.006*\"c++\" + 0.005*\"r\" + 0.005*\"windows\" + 0.005*\"mysql\"\n",
      "INFO : topic #8 (0.071): 0.025*\"hive\" + 0.021*\"hadoop\" + 0.020*\"python\" + 0.019*\"r\" + 0.019*\"sql\" + 0.018*\"pig\" + 0.016*\"spark\" + 0.014*\"oracle\" + 0.014*\"java\" + 0.013*\"hbase\"\n",
      "INFO : topic #0 (0.071): 0.008*\"sql\" + 0.007*\"html\" + 0.007*\"oracle\" + 0.006*\"technical\" + 0.005*\"java\" + 0.005*\"xml\" + 0.005*\"unix\" + 0.005*\"javascript\" + 0.005*\"spring\" + 0.005*\"linux\"\n",
      "INFO : topic #13 (0.071): 0.014*\"sql\" + 0.013*\"technical\" + 0.011*\"sas\" + 0.010*\"tableau\" + 0.009*\"html\" + 0.009*\"python\" + 0.008*\"data\" + 0.008*\"c\" + 0.007*\"c++\" + 0.007*\"r\"\n",
      "INFO : topic #3 (0.071): 0.005*\"technical\" + 0.005*\"unix\" + 0.004*\"d.\" + 0.004*\"j.\" + 0.003*\"s.\" + 0.003*\"m.\" + 0.003*\"skills\" + 0.003*\"data\" + 0.003*\"p.\" + 0.003*\"b.\"\n",
      "INFO : topic diff=0.038426, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.735 per-word bound, 426.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.071): 0.011*\"english\" + 0.007*\"sql\" + 0.007*\"r\" + 0.006*\"windows\" + 0.005*\"data\" + 0.005*\"python\" + 0.005*\"matlab\" + 0.004*\"technical\" + 0.004*\"computer\" + 0.004*\"linux\"\n",
      "INFO : topic #13 (0.071): 0.014*\"sql\" + 0.013*\"technical\" + 0.011*\"sas\" + 0.010*\"tableau\" + 0.009*\"html\" + 0.009*\"data\" + 0.008*\"python\" + 0.008*\"c\" + 0.007*\"c++\" + 0.006*\"java\"\n",
      "INFO : topic #5 (0.071): 0.004*\"agile\" + 0.004*\"technical\" + 0.004*\"key\" + 0.003*\"taleo\" + 0.003*\"scrum\" + 0.003*\"sql\" + 0.003*\"waterfall\" + 0.003*\"k\" + 0.002*\"excel\" + 0.002*\"data\"\n",
      "INFO : topic #3 (0.071): 0.005*\"technical\" + 0.005*\"unix\" + 0.004*\"j.\" + 0.004*\"d.\" + 0.004*\"m.\" + 0.004*\"s.\" + 0.003*\"skills\" + 0.003*\"p.\" + 0.003*\"data\" + 0.003*\"b.\"\n",
      "INFO : topic #2 (0.071): 0.005*\"linux\" + 0.004*\"computer\" + 0.004*\"data\" + 0.004*\"windows\" + 0.003*\"unix\" + 0.003*\"r\" + 0.003*\"project\" + 0.003*\"c\" + 0.003*\"c++\" + 0.003*\"etl\"\n",
      "INFO : topic diff=0.033483, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.730 per-word bound, 424.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.071): 0.004*\"agile\" + 0.004*\"technical\" + 0.004*\"key\" + 0.003*\"taleo\" + 0.003*\"scrum\" + 0.003*\"waterfall\" + 0.003*\"k\" + 0.003*\"sql\" + 0.002*\"data\" + 0.002*\"a\"\n",
      "INFO : topic #10 (0.071): 0.016*\"excel\" + 0.014*\"powerpoint\" + 0.013*\"word\" + 0.009*\"access\" + 0.008*\"project\" + 0.007*\"outlook\" + 0.005*\"indesign\" + 0.005*\"illustrator\" + 0.005*\"data\" + 0.005*\"skills\"\n",
      "INFO : topic #6 (0.071): 0.030*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.021*\"pandas\" + 0.017*\"numpy\" + 0.015*\"technical\" + 0.014*\"scikit\" + 0.014*\"tableau\" + 0.013*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #12 (0.071): 0.009*\"hive\" + 0.009*\"tableau\" + 0.008*\"sql\" + 0.008*\"excel\" + 0.008*\"python\" + 0.007*\"pig\" + 0.007*\"technical\" + 0.007*\"hdfs\" + 0.006*\"visio\" + 0.006*\"r\"\n",
      "INFO : topic #2 (0.071): 0.005*\"linux\" + 0.004*\"computer\" + 0.004*\"data\" + 0.004*\"windows\" + 0.003*\"unix\" + 0.003*\"project\" + 0.003*\"r\" + 0.003*\"c\" + 0.003*\"analytics\" + 0.003*\"etl\"\n",
      "INFO : topic diff=0.029454, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.726 per-word bound, 423.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.071): 0.026*\"hive\" + 0.021*\"hadoop\" + 0.019*\"python\" + 0.019*\"pig\" + 0.018*\"sql\" + 0.018*\"r\" + 0.016*\"spark\" + 0.014*\"oracle\" + 0.014*\"java\" + 0.014*\"hbase\"\n",
      "INFO : topic #1 (0.071): 0.009*\"technical\" + 0.008*\"java\" + 0.008*\"sql\" + 0.007*\"python\" + 0.006*\"ms\" + 0.005*\"c\" + 0.005*\"jira\" + 0.005*\"windows\" + 0.005*\"c++\" + 0.005*\"oracle\"\n",
      "INFO : topic #5 (0.071): 0.005*\"agile\" + 0.004*\"key\" + 0.004*\"technical\" + 0.003*\"taleo\" + 0.003*\"scrum\" + 0.003*\"waterfall\" + 0.003*\"k\" + 0.002*\"sql\" + 0.002*\"data\" + 0.002*\"a\"\n",
      "INFO : topic #2 (0.071): 0.005*\"linux\" + 0.004*\"computer\" + 0.004*\"data\" + 0.004*\"windows\" + 0.003*\"unix\" + 0.003*\"project\" + 0.003*\"analytics\" + 0.003*\"etl\" + 0.003*\"r\" + 0.003*\"c\"\n",
      "INFO : topic #6 (0.071): 0.030*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.021*\"pandas\" + 0.017*\"numpy\" + 0.015*\"technical\" + 0.015*\"scikit\" + 0.014*\"tableau\" + 0.013*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic diff=0.026139, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.722 per-word bound, 422.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #13 (0.071): 0.013*\"sql\" + 0.013*\"technical\" + 0.010*\"sas\" + 0.009*\"tableau\" + 0.009*\"data\" + 0.008*\"html\" + 0.007*\"c\" + 0.007*\"python\" + 0.006*\"c++\" + 0.005*\"java\"\n",
      "INFO : topic #6 (0.071): 0.030*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.021*\"pandas\" + 0.017*\"numpy\" + 0.015*\"technical\" + 0.015*\"scikit\" + 0.014*\"tableau\" + 0.013*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #0 (0.071): 0.007*\"oracle\" + 0.006*\"sql\" + 0.006*\"html\" + 0.005*\"xml\" + 0.005*\"technical\" + 0.005*\"unix\" + 0.005*\"spring\" + 0.005*\"java\" + 0.005*\"jsp\" + 0.005*\"hibernate\"\n",
      "INFO : topic #12 (0.071): 0.008*\"tableau\" + 0.008*\"hive\" + 0.008*\"excel\" + 0.007*\"sql\" + 0.007*\"python\" + 0.007*\"pig\" + 0.007*\"visio\" + 0.006*\"hdfs\" + 0.006*\"technical\" + 0.005*\"windows\"\n",
      "INFO : topic #1 (0.071): 0.009*\"technical\" + 0.008*\"java\" + 0.008*\"sql\" + 0.006*\"ms\" + 0.006*\"python\" + 0.005*\"jira\" + 0.005*\"c\" + 0.005*\"windows\" + 0.004*\"oracle\" + 0.004*\"c++\"\n",
      "INFO : topic diff=0.023484, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.718 per-word bound, 421.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 536/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3969/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.071): 0.007*\"oracle\" + 0.006*\"sql\" + 0.006*\"html\" + 0.005*\"xml\" + 0.005*\"technical\" + 0.005*\"spring\" + 0.005*\"unix\" + 0.005*\"jsp\" + 0.005*\"hibernate\" + 0.005*\"java\"\n",
      "INFO : topic #3 (0.071): 0.005*\"d.\" + 0.005*\"j.\" + 0.004*\"unix\" + 0.004*\"m.\" + 0.004*\"s.\" + 0.004*\"technical\" + 0.003*\"p.\" + 0.003*\"b.\" + 0.003*\"skills\" + 0.003*\"e.\"\n",
      "INFO : topic #9 (0.071): 0.031*\"javascript\" + 0.029*\"html\" + 0.028*\"java\" + 0.027*\"c\" + 0.026*\"python\" + 0.023*\"css\" + 0.022*\"c++\" + 0.019*\"sql\" + 0.018*\"mysql\" + 0.015*\"r\"\n",
      "INFO : topic #8 (0.071): 0.026*\"hive\" + 0.022*\"hadoop\" + 0.019*\"pig\" + 0.019*\"python\" + 0.018*\"sql\" + 0.018*\"r\" + 0.016*\"spark\" + 0.014*\"oracle\" + 0.014*\"hbase\" + 0.014*\"java\"\n",
      "INFO : topic #5 (0.071): 0.005*\"agile\" + 0.004*\"key\" + 0.003*\"technical\" + 0.003*\"taleo\" + 0.003*\"scrum\" + 0.003*\"waterfall\" + 0.003*\"k\" + 0.002*\"a\" + 0.002*\"data\" + 0.002*\"management\"\n",
      "INFO : topic diff=0.021186, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.715 per-word bound, 420.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.071): 0.012*\"english\" + 0.005*\"windows\" + 0.005*\"data\" + 0.005*\"sql\" + 0.005*\"r\" + 0.004*\"spanish\" + 0.004*\"french\" + 0.004*\"matlab\" + 0.004*\"linux\" + 0.004*\"computer\"\n",
      "INFO : topic #0 (0.071): 0.007*\"oracle\" + 0.006*\"html\" + 0.006*\"sql\" + 0.005*\"xml\" + 0.005*\"technical\" + 0.005*\"spring\" + 0.005*\"unix\" + 0.005*\"jsp\" + 0.005*\"hibernate\" + 0.005*\"soap\"\n",
      "INFO : topic #3 (0.071): 0.005*\"d.\" + 0.005*\"j.\" + 0.005*\"m.\" + 0.004*\"unix\" + 0.004*\"s.\" + 0.004*\"technical\" + 0.003*\"p.\" + 0.003*\"b.\" + 0.003*\"skills\" + 0.003*\"c.\"\n",
      "INFO : topic #11 (0.071): 0.052*\"r\" + 0.047*\"python\" + 0.045*\"sql\" + 0.033*\"sas\" + 0.028*\"matlab\" + 0.023*\"excel\" + 0.023*\"tableau\" + 0.022*\"c++\" + 0.018*\"java\" + 0.017*\"technical\"\n",
      "INFO : topic #9 (0.071): 0.031*\"javascript\" + 0.030*\"html\" + 0.028*\"java\" + 0.028*\"c\" + 0.026*\"python\" + 0.023*\"css\" + 0.022*\"c++\" + 0.019*\"sql\" + 0.018*\"mysql\" + 0.015*\"r\"\n",
      "INFO : topic diff=0.019348, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.712 per-word bound, 419.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=14, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=14, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (473 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (336 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (549 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (557 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (392 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (311 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (499 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (257 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (430 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (730 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (389 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (658 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (705 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (582 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (436 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (396 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (494 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (918 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (456 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (646 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 8; 576 documents processed (621 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (453 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (456 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (720 virtual)\n",
      "DEBUG : finished all batches; 384 documents processed (453 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 512 documents processed (646 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 4; 320 documents processed (429 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (593 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 512 documents processed (780 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (593 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (720 virtual)\n",
      "DEBUG : finished all batches; 320 documents processed (429 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (563 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 512 documents processed (780 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (460 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 448 documents processed (563 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (463 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (460 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 320 documents processed (463 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 9; 640 documents processed (722 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (722 virtual)\n",
      "INFO : serializing accumulator to return to master...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : finished all batches; 576 documents processed (621 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (709 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (571 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (709 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (571 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 506 documents processed (1151 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 506 documents processed (1151 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9337 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12419/12537 documents converged within 50 iterations\n",
      " 52%|█████▏    | 12/23 [05:05<04:40, 25.47s/it]INFO : using symmetric alpha at 0.06666666666666667\n",
      "INFO : using symmetric eta at 0.06666666666666667\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 15 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 426/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3369/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3216/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3177/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.067): 0.012*\"technical\" + 0.011*\"sql\" + 0.010*\"python\" + 0.009*\"r\" + 0.007*\"unix\" + 0.007*\"tableau\" + 0.006*\"java\" + 0.006*\"linux\" + 0.005*\"word\" + 0.005*\"excel\"\n",
      "INFO : topic #8 (0.067): 0.031*\"r\" + 0.028*\"python\" + 0.026*\"sql\" + 0.015*\"hadoop\" + 0.014*\"tableau\" + 0.011*\"hive\" + 0.011*\"c++\" + 0.010*\"java\" + 0.010*\"technical\" + 0.010*\"c\"\n",
      "INFO : topic #13 (0.067): 0.023*\"python\" + 0.020*\"sql\" + 0.019*\"r\" + 0.017*\"technical\" + 0.017*\"tableau\" + 0.016*\"sas\" + 0.012*\"java\" + 0.011*\"c\" + 0.011*\"html\" + 0.011*\"c++\"\n",
      "INFO : topic #4 (0.067): 0.023*\"sql\" + 0.021*\"python\" + 0.021*\"r\" + 0.011*\"matlab\" + 0.011*\"technical\" + 0.011*\"tableau\" + 0.009*\"java\" + 0.009*\"data\" + 0.009*\"c++\" + 0.009*\"sas\"\n",
      "INFO : topic #9 (0.067): 0.026*\"python\" + 0.023*\"sql\" + 0.023*\"c\" + 0.020*\"r\" + 0.019*\"html\" + 0.018*\"java\" + 0.013*\"c++\" + 0.012*\"technical\" + 0.012*\"javascript\" + 0.010*\"css\"\n",
      "INFO : topic diff=10.882138, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.308 per-word bound, 633.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 512/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3742/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3758/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3808/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #14 (0.067): 0.022*\"r\" + 0.021*\"sql\" + 0.020*\"python\" + 0.013*\"java\" + 0.013*\"c++\" + 0.012*\"tableau\" + 0.012*\"technical\" + 0.011*\"matlab\" + 0.011*\"c\" + 0.010*\"hadoop\"\n",
      "INFO : topic #13 (0.067): 0.021*\"python\" + 0.019*\"sql\" + 0.018*\"r\" + 0.017*\"technical\" + 0.016*\"tableau\" + 0.015*\"sas\" + 0.011*\"html\" + 0.011*\"c\" + 0.011*\"java\" + 0.010*\"c++\"\n",
      "INFO : topic #2 (0.067): 0.012*\"r\" + 0.010*\"python\" + 0.009*\"sql\" + 0.008*\"c++\" + 0.008*\"linux\" + 0.007*\"c\" + 0.007*\"windows\" + 0.006*\"html\" + 0.006*\"computer\" + 0.006*\"sas\"\n",
      "INFO : topic #8 (0.067): 0.031*\"r\" + 0.028*\"python\" + 0.026*\"sql\" + 0.017*\"hadoop\" + 0.015*\"tableau\" + 0.013*\"hive\" + 0.011*\"java\" + 0.011*\"technical\" + 0.010*\"c++\" + 0.010*\"spark\"\n",
      "INFO : topic #12 (0.067): 0.020*\"python\" + 0.016*\"r\" + 0.016*\"java\" + 0.015*\"sql\" + 0.014*\"hive\" + 0.012*\"hadoop\" + 0.011*\"mysql\" + 0.011*\"spark\" + 0.010*\"c\" + 0.010*\"c++\"\n",
      "INFO : topic diff=0.352701, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.098 per-word bound, 547.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3874/4000 documents converged within 50 iterations\n",
      "DEBUG : 3890/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3835/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.067): 0.030*\"r\" + 0.028*\"python\" + 0.026*\"sql\" + 0.018*\"hadoop\" + 0.015*\"hive\" + 0.015*\"tableau\" + 0.012*\"java\" + 0.012*\"spark\" + 0.011*\"technical\" + 0.010*\"pig\"\n",
      "INFO : topic #9 (0.067): 0.027*\"python\" + 0.025*\"c\" + 0.023*\"html\" + 0.023*\"java\" + 0.022*\"sql\" + 0.019*\"javascript\" + 0.019*\"r\" + 0.017*\"c++\" + 0.015*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #4 (0.067): 0.020*\"sql\" + 0.019*\"r\" + 0.018*\"python\" + 0.010*\"matlab\" + 0.010*\"technical\" + 0.010*\"tableau\" + 0.009*\"data\" + 0.008*\"java\" + 0.008*\"c++\" + 0.008*\"spss\"\n",
      "INFO : topic #6 (0.067): 0.027*\"python\" + 0.026*\"r\" + 0.021*\"sql\" + 0.012*\"pandas\" + 0.012*\"technical\" + 0.012*\"tableau\" + 0.012*\"sas\" + 0.011*\"matlab\" + 0.010*\"hadoop\" + 0.010*\"mysql\"\n",
      "INFO : topic #12 (0.067): 0.019*\"python\" + 0.015*\"r\" + 0.015*\"java\" + 0.015*\"hive\" + 0.015*\"sql\" + 0.011*\"hadoop\" + 0.011*\"spark\" + 0.011*\"mysql\" + 0.010*\"c\" + 0.009*\"pig\"\n",
      "INFO : topic diff=0.309988, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.985 per-word bound, 506.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3881/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3886/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.067): 0.018*\"python\" + 0.015*\"hive\" + 0.014*\"sql\" + 0.014*\"java\" + 0.014*\"r\" + 0.011*\"spark\" + 0.011*\"hadoop\" + 0.010*\"mysql\" + 0.010*\"pig\" + 0.009*\"technical\"\n",
      "INFO : topic #11 (0.067): 0.040*\"r\" + 0.039*\"python\" + 0.036*\"sql\" + 0.028*\"sas\" + 0.023*\"matlab\" + 0.019*\"c++\" + 0.018*\"tableau\" + 0.018*\"excel\" + 0.016*\"technical\" + 0.016*\"java\"\n",
      "INFO : topic #2 (0.067): 0.009*\"r\" + 0.007*\"linux\" + 0.007*\"python\" + 0.006*\"c++\" + 0.006*\"windows\" + 0.006*\"c\" + 0.006*\"sql\" + 0.005*\"computer\" + 0.005*\"data\" + 0.005*\"html\"\n",
      "INFO : topic #3 (0.067): 0.009*\"technical\" + 0.006*\"sql\" + 0.006*\"unix\" + 0.005*\"python\" + 0.005*\"r\" + 0.004*\"linux\" + 0.004*\"powerpoint\" + 0.003*\"tableau\" + 0.003*\"word\" + 0.003*\"excel\"\n",
      "INFO : topic #0 (0.067): 0.013*\"sql\" + 0.009*\"oracle\" + 0.009*\"python\" + 0.008*\"r\" + 0.008*\"java\" + 0.007*\"technical\" + 0.007*\"html\" + 0.007*\"javascript\" + 0.006*\"hive\" + 0.006*\"mysql\"\n",
      "INFO : topic diff=0.264424, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.919 per-word bound, 484.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3928/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.067): 0.028*\"r\" + 0.028*\"python\" + 0.025*\"sql\" + 0.021*\"hadoop\" + 0.019*\"hive\" + 0.015*\"tableau\" + 0.014*\"spark\" + 0.013*\"java\" + 0.013*\"pig\" + 0.012*\"technical\"\n",
      "INFO : topic #7 (0.067): 0.010*\"sql\" + 0.008*\"python\" + 0.008*\"linux\" + 0.006*\"c++\" + 0.005*\"matlab\" + 0.005*\"hadoop\" + 0.005*\"java\" + 0.005*\"hive\" + 0.004*\"c\" + 0.004*\"r\"\n",
      "INFO : topic #4 (0.067): 0.016*\"sql\" + 0.015*\"r\" + 0.015*\"python\" + 0.009*\"matlab\" + 0.008*\"technical\" + 0.008*\"tableau\" + 0.008*\"data\" + 0.007*\"c++\" + 0.007*\"excel\" + 0.007*\"spss\"\n",
      "INFO : topic #0 (0.067): 0.012*\"sql\" + 0.009*\"oracle\" + 0.007*\"python\" + 0.007*\"java\" + 0.007*\"technical\" + 0.007*\"r\" + 0.007*\"html\" + 0.007*\"javascript\" + 0.006*\"hive\" + 0.005*\"mysql\"\n",
      "INFO : topic #11 (0.067): 0.043*\"r\" + 0.041*\"python\" + 0.038*\"sql\" + 0.030*\"sas\" + 0.024*\"matlab\" + 0.020*\"excel\" + 0.019*\"c++\" + 0.019*\"tableau\" + 0.017*\"technical\" + 0.016*\"java\"\n",
      "INFO : topic diff=0.221269, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.874 per-word bound, 469.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : getting a new job\n",
      "DEBUG : 3915/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.067): 0.044*\"r\" + 0.041*\"python\" + 0.039*\"sql\" + 0.031*\"sas\" + 0.025*\"matlab\" + 0.021*\"excel\" + 0.020*\"tableau\" + 0.020*\"c++\" + 0.017*\"technical\" + 0.016*\"java\"\n",
      "INFO : topic #8 (0.067): 0.028*\"r\" + 0.027*\"python\" + 0.025*\"sql\" + 0.021*\"hadoop\" + 0.020*\"hive\" + 0.015*\"tableau\" + 0.015*\"spark\" + 0.014*\"pig\" + 0.014*\"java\" + 0.013*\"technical\"\n",
      "INFO : topic #13 (0.067): 0.016*\"sql\" + 0.015*\"python\" + 0.014*\"technical\" + 0.014*\"tableau\" + 0.013*\"r\" + 0.013*\"sas\" + 0.010*\"c\" + 0.010*\"html\" + 0.009*\"c++\" + 0.008*\"java\"\n",
      "INFO : topic #4 (0.067): 0.015*\"sql\" + 0.014*\"r\" + 0.013*\"python\" + 0.008*\"matlab\" + 0.008*\"data\" + 0.008*\"technical\" + 0.008*\"tableau\" + 0.007*\"c++\" + 0.006*\"excel\" + 0.006*\"spss\"\n",
      "INFO : topic #5 (0.067): 0.008*\"sql\" + 0.007*\"technical\" + 0.006*\"excel\" + 0.005*\"oracle\" + 0.004*\"key\" + 0.004*\"k\" + 0.004*\"r\" + 0.004*\"access\" + 0.003*\"powerpoint\" + 0.003*\"taleo\"\n",
      "INFO : topic diff=0.182294, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.843 per-word bound, 459.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.067): 0.007*\"sql\" + 0.007*\"linux\" + 0.006*\"python\" + 0.005*\"c++\" + 0.004*\"matlab\" + 0.004*\"core\" + 0.004*\"hadoop\" + 0.004*\"java\" + 0.004*\"data\" + 0.003*\"c\"\n",
      "INFO : topic #3 (0.067): 0.007*\"technical\" + 0.005*\"unix\" + 0.004*\"sql\" + 0.003*\"linux\" + 0.003*\"oracle\" + 0.003*\"powershell\" + 0.003*\"powerpoint\" + 0.003*\"python\" + 0.003*\"skills\" + 0.002*\"pl\"\n",
      "INFO : topic #2 (0.067): 0.006*\"linux\" + 0.006*\"r\" + 0.005*\"windows\" + 0.005*\"c++\" + 0.005*\"c\" + 0.005*\"computer\" + 0.005*\"data\" + 0.004*\"python\" + 0.004*\"project\" + 0.004*\"microsoft\"\n",
      "INFO : topic #6 (0.067): 0.029*\"python\" + 0.028*\"r\" + 0.023*\"sql\" + 0.017*\"pandas\" + 0.014*\"technical\" + 0.014*\"numpy\" + 0.013*\"tableau\" + 0.012*\"scikit\" + 0.012*\"hadoop\" + 0.011*\"matlab\"\n",
      "INFO : topic #10 (0.067): 0.007*\"excel\" + 0.007*\"r\" + 0.006*\"powerpoint\" + 0.005*\"sql\" + 0.005*\"sas\" + 0.005*\"project\" + 0.005*\"word\" + 0.005*\"indesign\" + 0.004*\"data\" + 0.004*\"research\"\n",
      "INFO : topic diff=0.148817, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.820 per-word bound, 452.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.067): 0.014*\"python\" + 0.013*\"sql\" + 0.011*\"technical\" + 0.011*\"java\" + 0.009*\"r\" + 0.008*\"c\" + 0.007*\"c++\" + 0.006*\"ms\" + 0.006*\"mysql\" + 0.006*\"html\"\n",
      "INFO : topic #5 (0.067): 0.007*\"sql\" + 0.007*\"technical\" + 0.005*\"excel\" + 0.004*\"key\" + 0.004*\"oracle\" + 0.004*\"taleo\" + 0.004*\"k\" + 0.003*\"access\" + 0.003*\"powerpoint\" + 0.003*\"sql_server\"\n",
      "INFO : topic #10 (0.067): 0.007*\"excel\" + 0.006*\"r\" + 0.006*\"powerpoint\" + 0.005*\"project\" + 0.005*\"indesign\" + 0.005*\"research\" + 0.004*\"sql\" + 0.004*\"word\" + 0.004*\"data\" + 0.004*\"sas\"\n",
      "INFO : topic #12 (0.067): 0.014*\"python\" + 0.013*\"hive\" + 0.011*\"sql\" + 0.011*\"java\" + 0.010*\"r\" + 0.010*\"pig\" + 0.009*\"spark\" + 0.009*\"hdfs\" + 0.009*\"technical\" + 0.008*\"tableau\"\n",
      "INFO : topic #3 (0.067): 0.007*\"technical\" + 0.005*\"unix\" + 0.004*\"sql\" + 0.003*\"linux\" + 0.003*\"powershell\" + 0.003*\"oracle\" + 0.003*\"skills\" + 0.002*\"t\" + 0.002*\"pl\" + 0.002*\"powerpoint\"\n",
      "INFO : topic diff=0.121428, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.802 per-word bound, 446.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.067): 0.010*\"sql\" + 0.009*\"oracle\" + 0.007*\"technical\" + 0.006*\"xml\" + 0.006*\"java\" + 0.006*\"html\" + 0.005*\"javascript\" + 0.005*\"pl\" + 0.005*\"uml\" + 0.005*\"windows\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #14 (0.067): 0.015*\"sql\" + 0.014*\"r\" + 0.012*\"python\" + 0.009*\"english\" + 0.009*\"c++\" + 0.009*\"matlab\" + 0.009*\"tableau\" + 0.008*\"c\" + 0.008*\"java\" + 0.008*\"technical\"\n",
      "INFO : topic #1 (0.067): 0.013*\"python\" + 0.012*\"sql\" + 0.010*\"technical\" + 0.010*\"java\" + 0.009*\"r\" + 0.008*\"c\" + 0.006*\"ms\" + 0.006*\"c++\" + 0.006*\"mysql\" + 0.006*\"html\"\n",
      "INFO : topic #10 (0.067): 0.007*\"excel\" + 0.005*\"powerpoint\" + 0.005*\"indesign\" + 0.005*\"project\" + 0.005*\"r\" + 0.005*\"research\" + 0.004*\"illustrator\" + 0.004*\"data\" + 0.004*\"photoshop\" + 0.004*\"word\"\n",
      "INFO : topic #8 (0.067): 0.026*\"python\" + 0.026*\"r\" + 0.024*\"sql\" + 0.023*\"hive\" + 0.023*\"hadoop\" + 0.017*\"spark\" + 0.017*\"pig\" + 0.015*\"tableau\" + 0.015*\"java\" + 0.013*\"technical\"\n",
      "INFO : topic diff=0.099297, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.788 per-word bound, 442.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.067): 0.007*\"excel\" + 0.005*\"indesign\" + 0.005*\"powerpoint\" + 0.005*\"project\" + 0.005*\"research\" + 0.005*\"photoshop\" + 0.005*\"illustrator\" + 0.004*\"data\" + 0.004*\"r\" + 0.004*\"skills\"\n",
      "INFO : topic #1 (0.067): 0.012*\"python\" + 0.012*\"sql\" + 0.010*\"technical\" + 0.009*\"java\" + 0.008*\"r\" + 0.007*\"c\" + 0.007*\"ms\" + 0.006*\"c++\" + 0.006*\"html\" + 0.006*\"mysql\"\n",
      "INFO : topic #3 (0.067): 0.006*\"technical\" + 0.005*\"unix\" + 0.003*\"powershell\" + 0.003*\"sql\" + 0.002*\"t\" + 0.002*\"linux\" + 0.002*\"skills\" + 0.002*\"oracle\" + 0.002*\"c.\" + 0.002*\"pl\"\n",
      "INFO : topic #8 (0.067): 0.026*\"python\" + 0.025*\"r\" + 0.024*\"hive\" + 0.024*\"hadoop\" + 0.023*\"sql\" + 0.018*\"pig\" + 0.018*\"spark\" + 0.015*\"tableau\" + 0.015*\"java\" + 0.014*\"technical\"\n",
      "INFO : topic #6 (0.067): 0.031*\"python\" + 0.029*\"r\" + 0.024*\"sql\" + 0.019*\"pandas\" + 0.015*\"numpy\" + 0.014*\"technical\" + 0.014*\"tableau\" + 0.013*\"scikit\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic diff=0.081931, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.777 per-word bound, 438.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.067): 0.031*\"python\" + 0.029*\"r\" + 0.024*\"sql\" + 0.020*\"pandas\" + 0.016*\"numpy\" + 0.015*\"technical\" + 0.014*\"tableau\" + 0.014*\"scikit\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #8 (0.067): 0.026*\"python\" + 0.025*\"r\" + 0.025*\"hive\" + 0.024*\"hadoop\" + 0.023*\"sql\" + 0.018*\"pig\" + 0.018*\"spark\" + 0.015*\"java\" + 0.015*\"tableau\" + 0.014*\"technical\"\n",
      "INFO : topic #7 (0.067): 0.005*\"linux\" + 0.005*\"sql\" + 0.004*\"core\" + 0.004*\"python\" + 0.004*\"c++\" + 0.003*\"data\" + 0.003*\"matlab\" + 0.003*\"s.\" + 0.003*\"d.\" + 0.003*\"software\"\n",
      "INFO : topic #12 (0.067): 0.012*\"python\" + 0.011*\"hive\" + 0.010*\"sql\" + 0.009*\"java\" + 0.009*\"pig\" + 0.008*\"hdfs\" + 0.008*\"r\" + 0.008*\"spark\" + 0.008*\"technical\" + 0.008*\"tableau\"\n",
      "INFO : topic #5 (0.067): 0.006*\"technical\" + 0.005*\"sql\" + 0.005*\"key\" + 0.004*\"taleo\" + 0.004*\"excel\" + 0.004*\"oracle\" + 0.003*\"k\" + 0.003*\"jobvite\" + 0.003*\"teradata\" + 0.003*\"sql_server\"\n",
      "INFO : topic diff=0.068316, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.769 per-word bound, 436.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.067): 0.009*\"oracle\" + 0.009*\"sql\" + 0.007*\"xml\" + 0.007*\"technical\" + 0.005*\"html\" + 0.005*\"java\" + 0.005*\"pl\" + 0.005*\"uml\" + 0.005*\"db2\" + 0.005*\"javascript\"\n",
      "INFO : topic #5 (0.067): 0.005*\"technical\" + 0.005*\"key\" + 0.005*\"sql\" + 0.004*\"taleo\" + 0.004*\"excel\" + 0.004*\"oracle\" + 0.003*\"k\" + 0.003*\"jobvite\" + 0.003*\"teradata\" + 0.002*\"sql_server\"\n",
      "INFO : topic #12 (0.067): 0.011*\"python\" + 0.011*\"hive\" + 0.009*\"sql\" + 0.009*\"java\" + 0.008*\"pig\" + 0.008*\"hdfs\" + 0.008*\"r\" + 0.008*\"tableau\" + 0.007*\"spark\" + 0.007*\"technical\"\n",
      "INFO : topic #10 (0.067): 0.006*\"excel\" + 0.006*\"indesign\" + 0.006*\"research\" + 0.005*\"project\" + 0.005*\"photoshop\" + 0.005*\"powerpoint\" + 0.005*\"illustrator\" + 0.004*\"skills\" + 0.004*\"data\" + 0.004*\"word\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #4 (0.067): 0.008*\"sql\" + 0.007*\"python\" + 0.007*\"r\" + 0.006*\"windows\" + 0.006*\"data\" + 0.006*\"technical\" + 0.005*\"matlab\" + 0.005*\"c++\" + 0.005*\"linux\" + 0.004*\"tableau\"\n",
      "INFO : topic diff=0.057606, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.761 per-word bound, 433.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #13 (0.067): 0.011*\"sql\" + 0.011*\"technical\" + 0.010*\"sas\" + 0.010*\"tableau\" + 0.008*\"c\" + 0.008*\"python\" + 0.008*\"html\" + 0.008*\"r\" + 0.007*\"c++\" + 0.006*\"data\"\n",
      "INFO : topic #7 (0.067): 0.004*\"linux\" + 0.004*\"core\" + 0.004*\"sql\" + 0.003*\"data\" + 0.003*\"c++\" + 0.003*\"s.\" + 0.003*\"d.\" + 0.003*\"python\" + 0.002*\"software\" + 0.002*\"matlab\"\n",
      "INFO : topic #8 (0.067): 0.026*\"hive\" + 0.025*\"python\" + 0.025*\"hadoop\" + 0.024*\"r\" + 0.023*\"sql\" + 0.019*\"pig\" + 0.018*\"spark\" + 0.015*\"java\" + 0.015*\"tableau\" + 0.014*\"technical\"\n",
      "INFO : topic #12 (0.067): 0.010*\"python\" + 0.010*\"hive\" + 0.009*\"sql\" + 0.008*\"java\" + 0.008*\"pig\" + 0.008*\"hdfs\" + 0.008*\"tableau\" + 0.007*\"technical\" + 0.007*\"r\" + 0.007*\"spark\"\n",
      "INFO : topic #9 (0.067): 0.030*\"java\" + 0.029*\"html\" + 0.029*\"javascript\" + 0.028*\"python\" + 0.028*\"c\" + 0.023*\"c++\" + 0.023*\"css\" + 0.020*\"sql\" + 0.018*\"mysql\" + 0.017*\"r\"\n",
      "INFO : topic diff=0.049094, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.754 per-word bound, 431.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.067): 0.026*\"hive\" + 0.025*\"python\" + 0.025*\"hadoop\" + 0.024*\"r\" + 0.023*\"sql\" + 0.019*\"pig\" + 0.019*\"spark\" + 0.016*\"java\" + 0.015*\"tableau\" + 0.014*\"technical\"\n",
      "INFO : topic #0 (0.067): 0.009*\"oracle\" + 0.008*\"sql\" + 0.007*\"xml\" + 0.006*\"technical\" + 0.005*\"pl\" + 0.005*\"uml\" + 0.005*\"html\" + 0.005*\"db2\" + 0.005*\"java\" + 0.005*\"agile\"\n",
      "INFO : topic #12 (0.067): 0.010*\"python\" + 0.010*\"hive\" + 0.008*\"sql\" + 0.008*\"pig\" + 0.008*\"hdfs\" + 0.008*\"java\" + 0.008*\"tableau\" + 0.007*\"technical\" + 0.007*\"spark\" + 0.007*\"r\"\n",
      "INFO : topic #7 (0.067): 0.004*\"core\" + 0.004*\"linux\" + 0.004*\"sql\" + 0.003*\"d.\" + 0.003*\"s.\" + 0.003*\"data\" + 0.003*\"c++\" + 0.003*\"python\" + 0.002*\"m.\" + 0.002*\"software\"\n",
      "INFO : topic #10 (0.067): 0.006*\"indesign\" + 0.006*\"excel\" + 0.006*\"research\" + 0.005*\"project\" + 0.005*\"photoshop\" + 0.005*\"illustrator\" + 0.005*\"skills\" + 0.004*\"powerpoint\" + 0.004*\"data\" + 0.004*\"relevant\"\n",
      "INFO : topic diff=0.042226, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.746 per-word bound, 429.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3969/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #14 (0.067): 0.013*\"english\" + 0.011*\"sql\" + 0.010*\"r\" + 0.008*\"python\" + 0.007*\"matlab\" + 0.007*\"c++\" + 0.006*\"c\" + 0.006*\"tableau\" + 0.006*\"data\" + 0.006*\"technical\"\n",
      "INFO : topic #11 (0.067): 0.050*\"r\" + 0.044*\"sql\" + 0.043*\"python\" + 0.035*\"sas\" + 0.027*\"matlab\" + 0.027*\"excel\" + 0.022*\"tableau\" + 0.021*\"c++\" + 0.017*\"spss\" + 0.017*\"technical\"\n",
      "INFO : topic #12 (0.067): 0.009*\"python\" + 0.009*\"hive\" + 0.008*\"sql\" + 0.008*\"hdfs\" + 0.008*\"tableau\" + 0.007*\"pig\" + 0.007*\"java\" + 0.007*\"excel\" + 0.006*\"technical\" + 0.006*\"spark\"\n",
      "INFO : topic #10 (0.067): 0.006*\"indesign\" + 0.006*\"research\" + 0.006*\"excel\" + 0.006*\"project\" + 0.005*\"illustrator\" + 0.005*\"photoshop\" + 0.005*\"skills\" + 0.004*\"powerpoint\" + 0.004*\"data\" + 0.004*\"relevant\"\n",
      "INFO : topic #9 (0.067): 0.030*\"java\" + 0.030*\"javascript\" + 0.030*\"html\" + 0.029*\"python\" + 0.028*\"c\" + 0.023*\"c++\" + 0.023*\"css\" + 0.020*\"sql\" + 0.018*\"mysql\" + 0.017*\"r\"\n",
      "INFO : topic diff=0.036729, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.741 per-word bound, 427.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3967/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.067): 0.004*\"core\" + 0.004*\"linux\" + 0.004*\"d.\" + 0.003*\"s.\" + 0.003*\"sql\" + 0.003*\"data\" + 0.003*\"m.\" + 0.003*\"c++\" + 0.003*\"r.\" + 0.003*\"j.\"\n",
      "INFO : topic #11 (0.067): 0.050*\"r\" + 0.044*\"sql\" + 0.043*\"python\" + 0.035*\"sas\" + 0.027*\"matlab\" + 0.027*\"excel\" + 0.022*\"tableau\" + 0.021*\"c++\" + 0.018*\"spss\" + 0.017*\"technical\"\n",
      "INFO : topic #2 (0.067): 0.004*\"linux\" + 0.004*\"windows\" + 0.004*\"project\" + 0.004*\"data\" + 0.003*\"computer\" + 0.003*\"microsoft\" + 0.003*\"c++\" + 0.003*\"c\" + 0.003*\"r\" + 0.002*\"research\"\n",
      "INFO : topic #0 (0.067): 0.010*\"oracle\" + 0.008*\"sql\" + 0.007*\"xml\" + 0.006*\"technical\" + 0.006*\"pl\" + 0.006*\"uml\" + 0.005*\"db2\" + 0.005*\"html\" + 0.005*\"agile\" + 0.005*\"java\"\n",
      "INFO : topic #14 (0.067): 0.014*\"english\" + 0.010*\"sql\" + 0.009*\"r\" + 0.007*\"python\" + 0.007*\"matlab\" + 0.006*\"c++\" + 0.006*\"data\" + 0.006*\"c\" + 0.005*\"tableau\" + 0.005*\"technical\"\n",
      "INFO : topic diff=0.032218, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.737 per-word bound, 426.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.067): 0.006*\"indesign\" + 0.006*\"research\" + 0.006*\"project\" + 0.006*\"excel\" + 0.005*\"illustrator\" + 0.005*\"photoshop\" + 0.005*\"skills\" + 0.004*\"relevant\" + 0.004*\"data\" + 0.004*\"facebook\"\n",
      "INFO : topic #14 (0.067): 0.014*\"english\" + 0.010*\"sql\" + 0.009*\"r\" + 0.007*\"python\" + 0.006*\"matlab\" + 0.006*\"c++\" + 0.006*\"data\" + 0.006*\"c\" + 0.005*\"tableau\" + 0.005*\"technical\"\n",
      "INFO : topic #11 (0.067): 0.050*\"r\" + 0.044*\"sql\" + 0.044*\"python\" + 0.036*\"sas\" + 0.027*\"matlab\" + 0.027*\"excel\" + 0.022*\"tableau\" + 0.021*\"c++\" + 0.018*\"spss\" + 0.017*\"technical\"\n",
      "INFO : topic #5 (0.067): 0.005*\"key\" + 0.005*\"taleo\" + 0.004*\"technical\" + 0.004*\"sql\" + 0.003*\"jobvite\" + 0.003*\"oracle\" + 0.003*\"k\" + 0.003*\"excel\" + 0.002*\"linear\" + 0.002*\"teradata\"\n",
      "INFO : topic #7 (0.067): 0.004*\"core\" + 0.004*\"d.\" + 0.004*\"linux\" + 0.004*\"s.\" + 0.003*\"sql\" + 0.003*\"data\" + 0.003*\"m.\" + 0.003*\"j.\" + 0.003*\"r.\" + 0.003*\"c++\"\n",
      "INFO : topic diff=0.028560, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.732 per-word bound, 425.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.067): 0.006*\"indesign\" + 0.006*\"research\" + 0.006*\"project\" + 0.005*\"excel\" + 0.005*\"illustrator\" + 0.005*\"photoshop\" + 0.005*\"skills\" + 0.004*\"relevant\" + 0.004*\"facebook\" + 0.004*\"salesforce\"\n",
      "INFO : topic #13 (0.067): 0.010*\"technical\" + 0.010*\"sql\" + 0.009*\"sas\" + 0.008*\"tableau\" + 0.007*\"c\" + 0.007*\"html\" + 0.006*\"c++\" + 0.006*\"data\" + 0.006*\"unix\" + 0.005*\"r\"\n",
      "INFO : topic #7 (0.067): 0.004*\"core\" + 0.004*\"d.\" + 0.004*\"s.\" + 0.004*\"linux\" + 0.003*\"sql\" + 0.003*\"j.\" + 0.003*\"m.\" + 0.003*\"data\" + 0.003*\"r.\" + 0.002*\"c++\"\n",
      "INFO : topic #9 (0.067): 0.031*\"javascript\" + 0.031*\"java\" + 0.030*\"html\" + 0.029*\"python\" + 0.029*\"c\" + 0.024*\"css\" + 0.024*\"c++\" + 0.020*\"sql\" + 0.019*\"mysql\" + 0.017*\"r\"\n",
      "INFO : topic #5 (0.067): 0.006*\"key\" + 0.005*\"taleo\" + 0.004*\"technical\" + 0.003*\"sql\" + 0.003*\"jobvite\" + 0.003*\"oracle\" + 0.003*\"k\" + 0.002*\"excel\" + 0.002*\"linear\" + 0.002*\"teradata\"\n",
      "INFO : topic diff=0.025478, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.728 per-word bound, 424.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.067): 0.005*\"unix\" + 0.004*\"technical\" + 0.003*\"powershell\" + 0.002*\"c.\" + 0.002*\"t\" + 0.002*\"skills\" + 0.002*\"highlightsof\" + 0.002*\"j.\" + 0.002*\"p.\" + 0.002*\"development\"\n",
      "INFO : topic #2 (0.067): 0.004*\"project\" + 0.004*\"windows\" + 0.004*\"data\" + 0.004*\"linux\" + 0.003*\"microsoft\" + 0.003*\"computer\" + 0.002*\"research\" + 0.002*\"c++\" + 0.002*\"c\" + 0.002*\"January\"\n",
      "INFO : topic #5 (0.067): 0.006*\"key\" + 0.005*\"taleo\" + 0.004*\"technical\" + 0.003*\"sql\" + 0.003*\"jobvite\" + 0.003*\"k\" + 0.003*\"oracle\" + 0.002*\"linear\" + 0.002*\"teradata\" + 0.002*\"excel\"\n",
      "INFO : topic #1 (0.067): 0.007*\"sql\" + 0.007*\"technical\" + 0.006*\"ms\" + 0.006*\"python\" + 0.005*\"java\" + 0.004*\"c\" + 0.004*\"jira\" + 0.004*\"oracle\" + 0.003*\"t\" + 0.003*\"r\"\n",
      "INFO : topic #12 (0.067): 0.008*\"python\" + 0.008*\"hive\" + 0.007*\"tableau\" + 0.007*\"hdfs\" + 0.007*\"pig\" + 0.007*\"excel\" + 0.006*\"sql\" + 0.006*\"java\" + 0.006*\"visio\" + 0.005*\"technical\"\n",
      "INFO : topic diff=0.022986, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.725 per-word bound, 423.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3969/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.067): 0.004*\"project\" + 0.003*\"data\" + 0.003*\"windows\" + 0.003*\"linux\" + 0.003*\"microsoft\" + 0.002*\"computer\" + 0.002*\"research\" + 0.002*\"c++\" + 0.002*\"c\" + 0.002*\"January\"\n",
      "INFO : topic #1 (0.067): 0.007*\"sql\" + 0.007*\"technical\" + 0.006*\"ms\" + 0.006*\"python\" + 0.005*\"java\" + 0.004*\"jira\" + 0.004*\"oracle\" + 0.004*\"c\" + 0.003*\"t\" + 0.003*\"pl\"\n",
      "INFO : topic #9 (0.067): 0.031*\"javascript\" + 0.031*\"java\" + 0.031*\"html\" + 0.029*\"python\" + 0.029*\"c\" + 0.024*\"c++\" + 0.024*\"css\" + 0.020*\"sql\" + 0.019*\"mysql\" + 0.017*\"r\"\n",
      "INFO : topic #8 (0.067): 0.028*\"hive\" + 0.026*\"hadoop\" + 0.025*\"python\" + 0.023*\"r\" + 0.023*\"sql\" + 0.021*\"pig\" + 0.019*\"spark\" + 0.016*\"java\" + 0.015*\"tableau\" + 0.015*\"technical\"\n",
      "INFO : topic #13 (0.067): 0.010*\"technical\" + 0.009*\"sql\" + 0.009*\"sas\" + 0.007*\"tableau\" + 0.007*\"c\" + 0.006*\"html\" + 0.006*\"data\" + 0.006*\"c++\" + 0.005*\"unix\" + 0.005*\"r\"\n",
      "INFO : topic diff=0.020802, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.722 per-word bound, 422.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=15, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=15, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (272 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (435 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (441 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (336 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (580 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (375 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (517 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (350 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (449 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (412 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (629 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (493 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (493 virtual)\n",
      "DEBUG : completed batch 9; 640 documents processed (778 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (513 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (557 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (481 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (576 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (576 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (592 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (592 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (487 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (499 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (499 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (487 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (738 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 5; 384 documents processed (555 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (448 virtual)\n",
      "DEBUG : finished all batches; 384 documents processed (555 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (723 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (557 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (693 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 448 documents processed (557 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (693 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 10; 704 documents processed (842 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (738 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 704 documents processed (842 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (766 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (723 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (766 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 576 documents processed (590 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 576 documents processed (590 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 498 documents processed (782 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 498 documents processed (782 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9329 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12418/12537 documents converged within 50 iterations\n",
      " 57%|█████▋    | 13/23 [05:32<04:15, 25.55s/it]INFO : using symmetric alpha at 0.0625\n",
      "INFO : using symmetric eta at 0.0625\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 16 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 438/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3379/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3240/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3202/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #15 (0.062): 0.028*\"sql\" + 0.027*\"python\" + 0.025*\"r\" + 0.016*\"matlab\" + 0.015*\"c\" + 0.015*\"java\" + 0.014*\"tableau\" + 0.014*\"hadoop\" + 0.013*\"c++\" + 0.011*\"hive\"\n",
      "INFO : topic #5 (0.062): 0.018*\"sql\" + 0.011*\"python\" + 0.011*\"r\" + 0.010*\"technical\" + 0.008*\"sas\" + 0.006*\"linux\" + 0.006*\"java\" + 0.006*\"excel\" + 0.006*\"tableau\" + 0.005*\"oracle\"\n",
      "INFO : topic #9 (0.062): 0.024*\"python\" + 0.022*\"sql\" + 0.021*\"c\" + 0.019*\"html\" + 0.019*\"r\" + 0.017*\"java\" + 0.013*\"c++\" + 0.012*\"technical\" + 0.012*\"javascript\" + 0.010*\"css\"\n",
      "INFO : topic #1 (0.062): 0.022*\"python\" + 0.017*\"java\" + 0.016*\"sql\" + 0.016*\"technical\" + 0.015*\"r\" + 0.011*\"c++\" + 0.010*\"c\" + 0.009*\"mysql\" + 0.009*\"html\" + 0.008*\"tableau\"\n",
      "INFO : topic #14 (0.062): 0.022*\"r\" + 0.020*\"sql\" + 0.018*\"python\" + 0.013*\"c++\" + 0.012*\"java\" + 0.011*\"tableau\" + 0.011*\"c\" + 0.011*\"matlab\" + 0.010*\"technical\" + 0.009*\"mysql\"\n",
      "INFO : topic diff=11.750755, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.304 per-word bound, 631.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3781/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3825/4000 documents converged within 50 iterations\n",
      "DEBUG : 3753/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.062): 0.015*\"r\" + 0.011*\"sql\" + 0.011*\"excel\" + 0.010*\"sas\" + 0.007*\"powerpoint\" + 0.007*\"spss\" + 0.007*\"word\" + 0.007*\"mysql\" + 0.007*\"access\" + 0.006*\"linux\"\n",
      "INFO : topic #8 (0.062): 0.031*\"r\" + 0.029*\"python\" + 0.025*\"sql\" + 0.014*\"hadoop\" + 0.013*\"tableau\" + 0.012*\"java\" + 0.011*\"c++\" + 0.010*\"hive\" + 0.010*\"technical\" + 0.010*\"c\"\n",
      "INFO : topic #2 (0.062): 0.012*\"r\" + 0.009*\"sql\" + 0.008*\"python\" + 0.008*\"c++\" + 0.007*\"linux\" + 0.006*\"html\" + 0.006*\"sas\" + 0.005*\"programming\" + 0.005*\"c\" + 0.004*\"powerpoint\"\n",
      "INFO : topic #12 (0.062): 0.016*\"python\" + 0.012*\"r\" + 0.012*\"java\" + 0.012*\"sql\" + 0.010*\"hive\" + 0.010*\"tableau\" + 0.010*\"mysql\" + 0.009*\"hadoop\" + 0.008*\"c\" + 0.008*\"c++\"\n",
      "INFO : topic #0 (0.062): 0.015*\"sql\" + 0.012*\"python\" + 0.012*\"r\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.009*\"javascript\" + 0.009*\"html\" + 0.007*\"java\" + 0.007*\"c++\" + 0.007*\"hive\"\n",
      "INFO : topic diff=0.352130, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.073 per-word bound, 538.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3841/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3886/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3810/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.062): 0.026*\"python\" + 0.025*\"r\" + 0.020*\"sql\" + 0.013*\"pandas\" + 0.012*\"sas\" + 0.011*\"technical\" + 0.010*\"tableau\" + 0.010*\"matlab\" + 0.010*\"mysql\" + 0.010*\"numpy\"\n",
      "INFO : topic #5 (0.062): 0.014*\"sql\" + 0.010*\"technical\" + 0.008*\"python\" + 0.008*\"r\" + 0.006*\"sas\" + 0.005*\"excel\" + 0.005*\"k\" + 0.005*\"oracle\" + 0.005*\"linux\" + 0.004*\"data\"\n",
      "INFO : topic #0 (0.062): 0.014*\"sql\" + 0.010*\"python\" + 0.010*\"r\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.009*\"javascript\" + 0.008*\"html\" + 0.007*\"java\" + 0.007*\"c++\" + 0.007*\"hive\"\n",
      "INFO : topic #7 (0.062): 0.012*\"linux\" + 0.011*\"sql\" + 0.008*\"python\" + 0.008*\"hadoop\" + 0.007*\"hive\" + 0.007*\"c++\" + 0.006*\"c\" + 0.006*\"r\" + 0.005*\"mapreduce\" + 0.005*\"matlab\"\n",
      "INFO : topic #2 (0.062): 0.010*\"r\" + 0.008*\"sql\" + 0.007*\"c++\" + 0.007*\"python\" + 0.006*\"linux\" + 0.006*\"html\" + 0.005*\"sas\" + 0.005*\"programming\" + 0.005*\"c\" + 0.004*\"data\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.306823, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.958 per-word bound, 497.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3881/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3910/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3859/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #15 (0.062): 0.030*\"python\" + 0.028*\"r\" + 0.028*\"sql\" + 0.018*\"java\" + 0.018*\"hadoop\" + 0.017*\"matlab\" + 0.016*\"c\" + 0.016*\"hive\" + 0.016*\"c++\" + 0.016*\"tableau\"\n",
      "INFO : topic #0 (0.062): 0.013*\"sql\" + 0.010*\"oracle\" + 0.009*\"python\" + 0.009*\"technical\" + 0.008*\"javascript\" + 0.008*\"r\" + 0.008*\"html\" + 0.007*\"java\" + 0.006*\"hive\" + 0.006*\"c++\"\n",
      "INFO : topic #11 (0.062): 0.038*\"r\" + 0.038*\"python\" + 0.035*\"sql\" + 0.029*\"sas\" + 0.021*\"matlab\" + 0.018*\"tableau\" + 0.018*\"excel\" + 0.017*\"technical\" + 0.016*\"c++\" + 0.014*\"spss\"\n",
      "INFO : topic #8 (0.062): 0.029*\"r\" + 0.028*\"python\" + 0.024*\"sql\" + 0.014*\"hadoop\" + 0.013*\"tableau\" + 0.012*\"java\" + 0.011*\"hive\" + 0.011*\"technical\" + 0.010*\"c++\" + 0.010*\"spark\"\n",
      "INFO : topic #5 (0.062): 0.013*\"sql\" + 0.009*\"technical\" + 0.007*\"python\" + 0.007*\"r\" + 0.005*\"k\" + 0.005*\"excel\" + 0.005*\"sas\" + 0.005*\"oracle\" + 0.005*\"linux\" + 0.004*\"data\"\n",
      "INFO : topic diff=0.261571, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.889 per-word bound, 474.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3874/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3890/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.062): 0.011*\"sql\" + 0.009*\"technical\" + 0.006*\"r\" + 0.006*\"python\" + 0.005*\"k\" + 0.005*\"excel\" + 0.005*\"oracle\" + 0.004*\"sas\" + 0.004*\"linux\" + 0.004*\"data\"\n",
      "INFO : topic #13 (0.062): 0.015*\"technical\" + 0.015*\"python\" + 0.014*\"sql\" + 0.014*\"sas\" + 0.013*\"r\" + 0.012*\"tableau\" + 0.011*\"html\" + 0.010*\"java\" + 0.010*\"c\" + 0.009*\"c++\"\n",
      "INFO : topic #4 (0.062): 0.015*\"r\" + 0.015*\"sql\" + 0.015*\"python\" + 0.009*\"technical\" + 0.009*\"data\" + 0.007*\"matlab\" + 0.007*\"tableau\" + 0.007*\"excel\" + 0.006*\"java\" + 0.005*\"javascript\"\n",
      "INFO : topic #0 (0.062): 0.012*\"sql\" + 0.010*\"oracle\" + 0.009*\"technical\" + 0.008*\"javascript\" + 0.008*\"html\" + 0.008*\"python\" + 0.007*\"java\" + 0.007*\"r\" + 0.006*\"hive\" + 0.006*\"c++\"\n",
      "INFO : topic #9 (0.062): 0.027*\"html\" + 0.026*\"python\" + 0.025*\"c\" + 0.025*\"java\" + 0.024*\"javascript\" + 0.020*\"sql\" + 0.019*\"c++\" + 0.019*\"css\" + 0.016*\"r\" + 0.014*\"mysql\"\n",
      "INFO : topic diff=0.218813, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.840 per-word bound, 458.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3899/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.062): 0.029*\"python\" + 0.027*\"r\" + 0.022*\"sql\" + 0.018*\"pandas\" + 0.014*\"numpy\" + 0.012*\"scikit\" + 0.012*\"technical\" + 0.012*\"tableau\" + 0.011*\"sas\" + 0.010*\"matlab\"\n",
      "INFO : topic #12 (0.062): 0.011*\"python\" + 0.010*\"tableau\" + 0.010*\"hive\" + 0.009*\"sql\" + 0.008*\"hadoop\" + 0.008*\"pig\" + 0.008*\"java\" + 0.008*\"r\" + 0.008*\"hdfs\" + 0.007*\"excel\"\n",
      "INFO : topic #15 (0.062): 0.030*\"python\" + 0.029*\"r\" + 0.028*\"sql\" + 0.020*\"hadoop\" + 0.019*\"java\" + 0.018*\"hive\" + 0.017*\"c\" + 0.016*\"matlab\" + 0.016*\"c++\" + 0.016*\"tableau\"\n",
      "INFO : topic #14 (0.062): 0.015*\"r\" + 0.015*\"sql\" + 0.013*\"python\" + 0.010*\"c++\" + 0.009*\"technical\" + 0.008*\"c\" + 0.008*\"java\" + 0.008*\"tableau\" + 0.007*\"matlab\" + 0.006*\"mysql\"\n",
      "INFO : topic #0 (0.062): 0.011*\"sql\" + 0.010*\"oracle\" + 0.009*\"technical\" + 0.008*\"javascript\" + 0.008*\"html\" + 0.007*\"java\" + 0.007*\"python\" + 0.006*\"r\" + 0.006*\"xml\" + 0.006*\"hive\"\n",
      "INFO : topic diff=0.181116, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.808 per-word bound, 448.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3902/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.062): 0.009*\"technical\" + 0.007*\"unix\" + 0.005*\"project\" + 0.004*\"sql\" + 0.003*\"linux\" + 0.003*\"python\" + 0.003*\"powershell\" + 0.002*\"pl\" + 0.002*\"word\" + 0.002*\"skills\"\n",
      "INFO : topic #9 (0.062): 0.028*\"html\" + 0.027*\"python\" + 0.027*\"java\" + 0.027*\"javascript\" + 0.026*\"c\" + 0.021*\"css\" + 0.021*\"c++\" + 0.020*\"sql\" + 0.016*\"r\" + 0.016*\"mysql\"\n",
      "INFO : topic #0 (0.062): 0.011*\"sql\" + 0.010*\"oracle\" + 0.009*\"technical\" + 0.007*\"javascript\" + 0.007*\"html\" + 0.007*\"java\" + 0.007*\"xml\" + 0.006*\"python\" + 0.006*\"pl\" + 0.006*\"hive\"\n",
      "INFO : topic #15 (0.062): 0.030*\"python\" + 0.029*\"r\" + 0.028*\"sql\" + 0.021*\"hadoop\" + 0.019*\"java\" + 0.018*\"hive\" + 0.017*\"c\" + 0.016*\"matlab\" + 0.016*\"c++\" + 0.016*\"tableau\"\n",
      "INFO : topic #6 (0.062): 0.029*\"python\" + 0.027*\"r\" + 0.022*\"sql\" + 0.019*\"pandas\" + 0.015*\"numpy\" + 0.013*\"scikit\" + 0.013*\"technical\" + 0.012*\"tableau\" + 0.011*\"sas\" + 0.010*\"scipy\"\n",
      "INFO : topic diff=0.148704, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.782 per-word bound, 440.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.062): 0.010*\"tableau\" + 0.010*\"python\" + 0.009*\"hive\" + 0.008*\"pig\" + 0.008*\"sql\" + 0.008*\"hdfs\" + 0.008*\"hadoop\" + 0.007*\"excel\" + 0.007*\"java\" + 0.007*\"r\"\n",
      "INFO : topic #14 (0.062): 0.013*\"sql\" + 0.013*\"r\" + 0.011*\"python\" + 0.009*\"c++\" + 0.008*\"technical\" + 0.008*\"c\" + 0.007*\"java\" + 0.007*\"english\" + 0.006*\"tableau\" + 0.006*\"matlab\"\n",
      "INFO : topic #2 (0.062): 0.006*\"r\" + 0.005*\"sql\" + 0.005*\"linux\" + 0.004*\"c++\" + 0.004*\"data\" + 0.004*\"html\" + 0.003*\"python\" + 0.003*\"microsoft\" + 0.003*\"unix\" + 0.003*\"computer\"\n",
      "INFO : topic #4 (0.062): 0.011*\"sql\" + 0.010*\"r\" + 0.010*\"python\" + 0.009*\"data\" + 0.008*\"technical\" + 0.005*\"excel\" + 0.005*\"matlab\" + 0.005*\"tableau\" + 0.004*\"windows\" + 0.004*\"powerpoint\"\n",
      "INFO : topic #11 (0.062): 0.046*\"r\" + 0.042*\"python\" + 0.041*\"sql\" + 0.035*\"sas\" + 0.024*\"excel\" + 0.024*\"matlab\" + 0.021*\"tableau\" + 0.017*\"spss\" + 0.017*\"c++\" + 0.017*\"technical\"\n",
      "INFO : topic diff=0.121784, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.762 per-word bound, 434.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3915/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3928/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #15 (0.062): 0.030*\"python\" + 0.028*\"r\" + 0.027*\"sql\" + 0.022*\"hadoop\" + 0.020*\"hive\" + 0.020*\"java\" + 0.017*\"c\" + 0.016*\"spark\" + 0.016*\"c++\" + 0.016*\"tableau\"\n",
      "INFO : topic #11 (0.062): 0.047*\"r\" + 0.042*\"sql\" + 0.042*\"python\" + 0.036*\"sas\" + 0.025*\"excel\" + 0.024*\"matlab\" + 0.021*\"tableau\" + 0.018*\"spss\" + 0.017*\"c++\" + 0.017*\"technical\"\n",
      "INFO : topic #8 (0.062): 0.025*\"r\" + 0.024*\"python\" + 0.021*\"sql\" + 0.014*\"hadoop\" + 0.012*\"tableau\" + 0.012*\"hive\" + 0.011*\"java\" + 0.011*\"technical\" + 0.011*\"spark\" + 0.009*\"oracle\"\n",
      "INFO : topic #4 (0.062): 0.009*\"sql\" + 0.009*\"r\" + 0.009*\"data\" + 0.009*\"python\" + 0.007*\"technical\" + 0.005*\"excel\" + 0.005*\"matlab\" + 0.005*\"tableau\" + 0.004*\"windows\" + 0.004*\"powerpoint\"\n",
      "INFO : topic #10 (0.062): 0.013*\"excel\" + 0.010*\"word\" + 0.009*\"powerpoint\" + 0.007*\"r\" + 0.007*\"access\" + 0.006*\"project\" + 0.006*\"photoshop\" + 0.006*\"illustrator\" + 0.005*\"computer\" + 0.005*\"indesign\"\n",
      "INFO : topic diff=0.100097, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.748 per-word bound, 429.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3904/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : 3925/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.062): 0.008*\"linux\" + 0.004*\"core\" + 0.004*\"sql\" + 0.003*\"s.\" + 0.003*\"windows\" + 0.003*\"d.\" + 0.003*\"j.\" + 0.003*\"hive\" + 0.003*\"data\" + 0.003*\"hadoop\"\n",
      "INFO : topic #8 (0.062): 0.024*\"r\" + 0.023*\"python\" + 0.021*\"sql\" + 0.014*\"hadoop\" + 0.012*\"hive\" + 0.012*\"tableau\" + 0.011*\"java\" + 0.011*\"technical\" + 0.011*\"spark\" + 0.009*\"oracle\"\n",
      "INFO : topic #4 (0.062): 0.009*\"sql\" + 0.008*\"data\" + 0.008*\"r\" + 0.007*\"python\" + 0.007*\"technical\" + 0.005*\"excel\" + 0.004*\"tableau\" + 0.004*\"matlab\" + 0.004*\"windows\" + 0.004*\"powerpoint\"\n",
      "INFO : topic #2 (0.062): 0.005*\"r\" + 0.004*\"linux\" + 0.004*\"sql\" + 0.004*\"c++\" + 0.004*\"data\" + 0.003*\"html\" + 0.003*\"unix\" + 0.003*\"microsoft\" + 0.003*\"project\" + 0.003*\"computer\"\n",
      "INFO : topic #14 (0.062): 0.012*\"sql\" + 0.012*\"r\" + 0.009*\"python\" + 0.008*\"english\" + 0.008*\"c++\" + 0.007*\"c\" + 0.007*\"technical\" + 0.006*\"java\" + 0.006*\"analytics\" + 0.006*\"matlab\"\n",
      "INFO : topic diff=0.082660, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.736 per-word bound, 426.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3928/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.062): 0.012*\"excel\" + 0.010*\"word\" + 0.009*\"powerpoint\" + 0.007*\"photoshop\" + 0.006*\"illustrator\" + 0.006*\"r\" + 0.006*\"access\" + 0.006*\"project\" + 0.006*\"indesign\" + 0.005*\"salesforce\"\n",
      "INFO : topic #3 (0.062): 0.008*\"technical\" + 0.006*\"unix\" + 0.005*\"project\" + 0.003*\"powershell\" + 0.003*\"sql\" + 0.002*\"skills\" + 0.002*\"customer\" + 0.002*\"pl\" + 0.002*\"datamodeling\" + 0.002*\"hp\"\n",
      "INFO : topic #5 (0.062): 0.007*\"sql\" + 0.007*\"technical\" + 0.005*\"k\" + 0.004*\"taleo\" + 0.004*\"oracle\" + 0.003*\"jobvite\" + 0.003*\"key\" + 0.003*\"excel\" + 0.003*\"skills\" + 0.003*\"relevant\"\n",
      "INFO : topic #15 (0.062): 0.029*\"python\" + 0.028*\"r\" + 0.027*\"sql\" + 0.023*\"hadoop\" + 0.021*\"hive\" + 0.020*\"java\" + 0.017*\"c\" + 0.017*\"spark\" + 0.016*\"c++\" + 0.016*\"tableau\"\n",
      "INFO : topic #4 (0.062): 0.008*\"data\" + 0.008*\"sql\" + 0.007*\"r\" + 0.006*\"technical\" + 0.006*\"python\" + 0.004*\"excel\" + 0.004*\"tableau\" + 0.004*\"windows\" + 0.004*\"matlab\" + 0.003*\"powerpoint\"\n",
      "INFO : topic diff=0.068978, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.725 per-word bound, 423.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.062): 0.031*\"python\" + 0.028*\"r\" + 0.024*\"sql\" + 0.022*\"pandas\" + 0.018*\"numpy\" + 0.015*\"scikit\" + 0.014*\"technical\" + 0.013*\"tableau\" + 0.012*\"scipy\" + 0.011*\"matplotlib\"\n",
      "INFO : topic #7 (0.062): 0.007*\"linux\" + 0.005*\"core\" + 0.004*\"j.\" + 0.004*\"d.\" + 0.004*\"s.\" + 0.003*\"windows\" + 0.003*\"m.\" + 0.003*\"sql\" + 0.003*\"skill\" + 0.003*\"data\"\n",
      "INFO : topic #14 (0.062): 0.011*\"sql\" + 0.010*\"r\" + 0.010*\"english\" + 0.008*\"python\" + 0.008*\"c++\" + 0.007*\"c\" + 0.006*\"technical\" + 0.006*\"analytics\" + 0.006*\"java\" + 0.005*\"matlab\"\n",
      "INFO : topic #4 (0.062): 0.008*\"data\" + 0.007*\"sql\" + 0.006*\"r\" + 0.006*\"technical\" + 0.006*\"python\" + 0.004*\"excel\" + 0.004*\"windows\" + 0.004*\"tableau\" + 0.004*\"matlab\" + 0.003*\"powerpoint\"\n",
      "INFO : topic #8 (0.062): 0.023*\"r\" + 0.022*\"python\" + 0.020*\"sql\" + 0.014*\"hadoop\" + 0.012*\"hive\" + 0.011*\"tableau\" + 0.011*\"technical\" + 0.011*\"java\" + 0.011*\"spark\" + 0.010*\"oracle\"\n",
      "INFO : topic diff=0.058103, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.717 per-word bound, 420.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.062): 0.010*\"tableau\" + 0.009*\"hive\" + 0.008*\"pig\" + 0.008*\"hdfs\" + 0.008*\"python\" + 0.007*\"databases\" + 0.007*\"excel\" + 0.007*\"sql\" + 0.006*\"unix\" + 0.006*\"bi\"\n",
      "INFO : topic #9 (0.062): 0.032*\"javascript\" + 0.031*\"html\" + 0.030*\"java\" + 0.029*\"python\" + 0.028*\"c\" + 0.025*\"css\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.019*\"mysql\" + 0.016*\"php\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #1 (0.062): 0.012*\"technical\" + 0.009*\"sql\" + 0.009*\"java\" + 0.009*\"python\" + 0.006*\"c\" + 0.006*\"c++\" + 0.005*\"ms\" + 0.005*\"oracle\" + 0.004*\"jira\" + 0.004*\"r\"\n",
      "INFO : topic #5 (0.062): 0.006*\"sql\" + 0.006*\"technical\" + 0.005*\"k\" + 0.004*\"taleo\" + 0.004*\"jobvite\" + 0.004*\"oracle\" + 0.004*\"key\" + 0.003*\"excel\" + 0.003*\"skills\" + 0.003*\"relevant\"\n",
      "INFO : topic #0 (0.062): 0.011*\"oracle\" + 0.009*\"sql\" + 0.009*\"xml\" + 0.008*\"technical\" + 0.008*\"pl\" + 0.007*\"html\" + 0.006*\"java\" + 0.006*\"javascript\" + 0.006*\"unix\" + 0.006*\"jsp\"\n",
      "INFO : topic diff=0.049469, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.709 per-word bound, 418.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.062): 0.008*\"data\" + 0.006*\"sql\" + 0.006*\"technical\" + 0.005*\"r\" + 0.004*\"python\" + 0.004*\"windows\" + 0.004*\"excel\" + 0.003*\"tableau\" + 0.003*\"matlab\" + 0.003*\"ms\"\n",
      "INFO : topic #7 (0.062): 0.007*\"linux\" + 0.005*\"core\" + 0.004*\"j.\" + 0.004*\"d.\" + 0.004*\"s.\" + 0.004*\"m.\" + 0.003*\"windows\" + 0.003*\"p.\" + 0.003*\"skill\" + 0.003*\"g.\"\n",
      "INFO : topic #10 (0.062): 0.011*\"excel\" + 0.008*\"word\" + 0.008*\"powerpoint\" + 0.007*\"photoshop\" + 0.007*\"illustrator\" + 0.006*\"salesforce\" + 0.006*\"indesign\" + 0.006*\"project\" + 0.006*\"research\" + 0.005*\"access\"\n",
      "INFO : topic #1 (0.062): 0.011*\"technical\" + 0.009*\"sql\" + 0.008*\"java\" + 0.008*\"python\" + 0.006*\"c\" + 0.005*\"ms\" + 0.005*\"c++\" + 0.005*\"oracle\" + 0.004*\"jira\" + 0.004*\"r\"\n",
      "INFO : topic #6 (0.062): 0.032*\"python\" + 0.029*\"r\" + 0.024*\"sql\" + 0.023*\"pandas\" + 0.019*\"numpy\" + 0.016*\"scikit\" + 0.014*\"technical\" + 0.013*\"tableau\" + 0.012*\"scipy\" + 0.011*\"hadoop\"\n",
      "INFO : topic diff=0.042717, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.703 per-word bound, 416.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #14 (0.062): 0.012*\"english\" + 0.009*\"sql\" + 0.009*\"r\" + 0.007*\"python\" + 0.007*\"c++\" + 0.006*\"c\" + 0.006*\"analytics\" + 0.005*\"technical\" + 0.005*\"java\" + 0.004*\"matlab\"\n",
      "INFO : topic #0 (0.062): 0.011*\"oracle\" + 0.009*\"sql\" + 0.009*\"xml\" + 0.008*\"technical\" + 0.008*\"pl\" + 0.007*\"html\" + 0.006*\"java\" + 0.006*\"unix\" + 0.006*\"jsp\" + 0.006*\"javascript\"\n",
      "INFO : topic #11 (0.062): 0.050*\"r\" + 0.044*\"sql\" + 0.043*\"python\" + 0.038*\"sas\" + 0.028*\"excel\" + 0.025*\"matlab\" + 0.023*\"tableau\" + 0.019*\"spss\" + 0.018*\"c++\" + 0.017*\"technical\"\n",
      "INFO : topic #9 (0.062): 0.032*\"javascript\" + 0.032*\"html\" + 0.031*\"java\" + 0.029*\"python\" + 0.028*\"c\" + 0.025*\"css\" + 0.024*\"c++\" + 0.020*\"sql\" + 0.019*\"mysql\" + 0.016*\"php\"\n",
      "INFO : topic #3 (0.062): 0.007*\"technical\" + 0.006*\"unix\" + 0.005*\"project\" + 0.003*\"powershell\" + 0.003*\"customer\" + 0.002*\"skills\" + 0.002*\"highlightsof\" + 0.002*\"datamodeling\" + 0.002*\"pl\" + 0.002*\"hp\"\n",
      "INFO : topic diff=0.037229, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.698 per-word bound, 415.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.062): 0.011*\"oracle\" + 0.009*\"xml\" + 0.009*\"sql\" + 0.008*\"pl\" + 0.008*\"technical\" + 0.006*\"html\" + 0.006*\"jsp\" + 0.006*\"unix\" + 0.006*\"java\" + 0.006*\"j2ee\"\n",
      "INFO : topic #2 (0.062): 0.003*\"data\" + 0.003*\"dice\" + 0.003*\"r\" + 0.003*\"linux\" + 0.003*\"detail\" + 0.003*\"software\" + 0.002*\"project\" + 0.002*\"microsoft\" + 0.002*\"careerbuilder\" + 0.002*\"c++\"\n",
      "INFO : topic #12 (0.062): 0.009*\"tableau\" + 0.008*\"hive\" + 0.008*\"pig\" + 0.008*\"hdfs\" + 0.007*\"databases\" + 0.007*\"python\" + 0.007*\"excel\" + 0.007*\"unix\" + 0.006*\"bi\" + 0.006*\"obiee\"\n",
      "INFO : topic #10 (0.062): 0.010*\"excel\" + 0.008*\"word\" + 0.008*\"photoshop\" + 0.007*\"powerpoint\" + 0.007*\"illustrator\" + 0.007*\"salesforce\" + 0.006*\"indesign\" + 0.006*\"project\" + 0.006*\"research\" + 0.005*\"access\"\n",
      "INFO : topic #3 (0.062): 0.007*\"technical\" + 0.006*\"unix\" + 0.005*\"project\" + 0.003*\"powershell\" + 0.003*\"customer\" + 0.002*\"skills\" + 0.002*\"highlightsof\" + 0.002*\"datamodeling\" + 0.002*\"pl\" + 0.002*\"hp\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.032796, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.693 per-word bound, 413.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.062): 0.010*\"technical\" + 0.007*\"sql\" + 0.007*\"java\" + 0.007*\"python\" + 0.005*\"c\" + 0.005*\"ms\" + 0.005*\"oracle\" + 0.005*\"c++\" + 0.004*\"jira\" + 0.004*\"pl\"\n",
      "INFO : topic #11 (0.062): 0.050*\"r\" + 0.045*\"sql\" + 0.043*\"python\" + 0.038*\"sas\" + 0.029*\"excel\" + 0.025*\"matlab\" + 0.023*\"tableau\" + 0.019*\"spss\" + 0.019*\"c++\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #9 (0.062): 0.033*\"javascript\" + 0.032*\"html\" + 0.031*\"java\" + 0.029*\"python\" + 0.029*\"c\" + 0.026*\"css\" + 0.024*\"c++\" + 0.020*\"sql\" + 0.020*\"mysql\" + 0.017*\"php\"\n",
      "INFO : topic #7 (0.062): 0.006*\"linux\" + 0.005*\"core\" + 0.005*\"j.\" + 0.004*\"s.\" + 0.004*\"d.\" + 0.004*\"m.\" + 0.003*\"p.\" + 0.003*\"windows\" + 0.003*\"b.\" + 0.003*\"g.\"\n",
      "INFO : topic #14 (0.062): 0.013*\"english\" + 0.008*\"sql\" + 0.008*\"r\" + 0.006*\"c++\" + 0.006*\"analytics\" + 0.006*\"c\" + 0.006*\"python\" + 0.005*\"technical\" + 0.004*\"java\" + 0.004*\"french\"\n",
      "INFO : topic diff=0.029156, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.689 per-word bound, 412.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.062): 0.051*\"r\" + 0.045*\"sql\" + 0.043*\"python\" + 0.038*\"sas\" + 0.029*\"excel\" + 0.025*\"matlab\" + 0.023*\"tableau\" + 0.019*\"spss\" + 0.019*\"c++\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #7 (0.062): 0.006*\"linux\" + 0.005*\"core\" + 0.005*\"j.\" + 0.004*\"d.\" + 0.004*\"s.\" + 0.004*\"m.\" + 0.003*\"p.\" + 0.003*\"windows\" + 0.003*\"b.\" + 0.003*\"g.\"\n",
      "INFO : topic #2 (0.062): 0.003*\"data\" + 0.003*\"dice\" + 0.003*\"r\" + 0.003*\"detail\" + 0.003*\"careerbuilder\" + 0.002*\"linux\" + 0.002*\"software\" + 0.002*\"project\" + 0.002*\"microsoft\" + 0.002*\"computer\"\n",
      "INFO : topic #6 (0.062): 0.032*\"python\" + 0.029*\"r\" + 0.024*\"sql\" + 0.023*\"pandas\" + 0.019*\"numpy\" + 0.016*\"scikit\" + 0.015*\"technical\" + 0.014*\"tableau\" + 0.012*\"scipy\" + 0.011*\"hadoop\"\n",
      "INFO : topic #4 (0.062): 0.007*\"data\" + 0.005*\"technical\" + 0.004*\"sql\" + 0.004*\"windows\" + 0.003*\"r\" + 0.003*\"excel\" + 0.003*\"areasof\" + 0.003*\"ms\" + 0.003*\"volunteer\" + 0.003*\"management\"\n",
      "INFO : topic diff=0.026164, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.686 per-word bound, 411.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.062): 0.033*\"javascript\" + 0.032*\"html\" + 0.031*\"java\" + 0.029*\"python\" + 0.029*\"c\" + 0.026*\"css\" + 0.025*\"c++\" + 0.020*\"sql\" + 0.020*\"mysql\" + 0.017*\"php\"\n",
      "INFO : topic #14 (0.062): 0.014*\"english\" + 0.008*\"sql\" + 0.007*\"r\" + 0.006*\"analytics\" + 0.006*\"c++\" + 0.005*\"c\" + 0.005*\"python\" + 0.005*\"technical\" + 0.004*\"french\" + 0.004*\"java\"\n",
      "INFO : topic #3 (0.062): 0.006*\"technical\" + 0.005*\"unix\" + 0.005*\"project\" + 0.003*\"powershell\" + 0.003*\"customer\" + 0.002*\"highlightsof\" + 0.002*\"skills\" + 0.002*\"datamodeling\" + 0.002*\"pl\" + 0.002*\"datascientist\"\n",
      "INFO : topic #12 (0.062): 0.009*\"tableau\" + 0.008*\"databases\" + 0.008*\"hive\" + 0.008*\"pig\" + 0.008*\"hdfs\" + 0.007*\"unix\" + 0.007*\"bi\" + 0.007*\"excel\" + 0.007*\"python\" + 0.006*\"obiee\"\n",
      "INFO : topic #2 (0.062): 0.003*\"dice\" + 0.003*\"data\" + 0.003*\"detail\" + 0.003*\"r\" + 0.003*\"careerbuilder\" + 0.002*\"software\" + 0.002*\"project\" + 0.002*\"linux\" + 0.002*\"microsoft\" + 0.002*\"computer\"\n",
      "INFO : topic diff=0.023634, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.683 per-word bound, 411.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.062): 0.009*\"tableau\" + 0.008*\"databases\" + 0.008*\"pig\" + 0.008*\"hive\" + 0.008*\"hdfs\" + 0.007*\"unix\" + 0.007*\"bi\" + 0.007*\"excel\" + 0.007*\"obiee\" + 0.006*\"python\"\n",
      "INFO : topic #13 (0.062): 0.011*\"technical\" + 0.009*\"sas\" + 0.008*\"sql\" + 0.008*\"data\" + 0.007*\"tableau\" + 0.007*\"html\" + 0.007*\"c\" + 0.006*\"c++\" + 0.005*\"java\" + 0.005*\"python\"\n",
      "INFO : topic #11 (0.062): 0.051*\"r\" + 0.045*\"sql\" + 0.043*\"python\" + 0.038*\"sas\" + 0.030*\"excel\" + 0.025*\"matlab\" + 0.024*\"tableau\" + 0.019*\"spss\" + 0.019*\"c++\" + 0.018*\"powerpoint\"\n",
      "INFO : topic #15 (0.062): 0.028*\"python\" + 0.026*\"r\" + 0.026*\"sql\" + 0.026*\"hadoop\" + 0.025*\"hive\" + 0.020*\"java\" + 0.019*\"spark\" + 0.017*\"pig\" + 0.016*\"c\" + 0.015*\"tableau\"\n",
      "INFO : topic #8 (0.062): 0.018*\"r\" + 0.018*\"python\" + 0.016*\"sql\" + 0.012*\"hadoop\" + 0.010*\"hive\" + 0.010*\"technical\" + 0.009*\"tableau\" + 0.009*\"oracle\" + 0.009*\"java\" + 0.009*\"spark\"\n",
      "INFO : topic diff=0.021489, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.680 per-word bound, 410.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=16, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=16, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (153 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 5; 384 documents processed (515 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (388 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (400 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (392 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (464 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (494 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (595 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (794 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (404 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (579 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (675 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (590 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (582 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (475 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (501 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (660 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (858 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (659 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (590 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (659 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (453 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (590 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (453 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 9; 640 documents processed (750 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 640 documents processed (750 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (539 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (448 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (646 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (572 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (539 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 6; 448 documents processed (610 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (646 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (572 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (610 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (688 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (565 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (688 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (565 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 542 documents processed (1046 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (733 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 542 documents processed (1046 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (733 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 576 documents processed (754 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (754 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9373 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12383/12537 documents converged within 50 iterations\n",
      " 61%|██████    | 14/23 [05:59<03:51, 25.71s/it]INFO : using symmetric alpha at 0.058823529411764705\n",
      "INFO : using symmetric eta at 0.058823529411764705\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 17 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 428/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3370/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : getting a new job\n",
      "DEBUG : 3249/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3188/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.059): 0.014*\"r\" + 0.012*\"python\" + 0.010*\"c++\" + 0.010*\"sql\" + 0.008*\"linux\" + 0.007*\"html\" + 0.006*\"data\" + 0.006*\"programming\" + 0.006*\"sas\" + 0.006*\"windows\"\n",
      "INFO : topic #5 (0.059): 0.018*\"sql\" + 0.011*\"technical\" + 0.010*\"r\" + 0.008*\"excel\" + 0.008*\"python\" + 0.008*\"sas\" + 0.007*\"powerpoint\" + 0.006*\"tableau\" + 0.006*\"access\" + 0.006*\"linux\"\n",
      "INFO : topic #3 (0.059): 0.013*\"sql\" + 0.013*\"technical\" + 0.010*\"python\" + 0.008*\"r\" + 0.008*\"unix\" + 0.007*\"tableau\" + 0.006*\"linux\" + 0.005*\"java\" + 0.005*\"javascript\" + 0.004*\"html\"\n",
      "INFO : topic #0 (0.059): 0.016*\"sql\" + 0.013*\"python\" + 0.013*\"r\" + 0.009*\"technical\" + 0.009*\"hive\" + 0.008*\"java\" + 0.008*\"oracle\" + 0.008*\"javascript\" + 0.008*\"html\" + 0.007*\"linux\"\n",
      "INFO : topic #9 (0.059): 0.024*\"python\" + 0.021*\"sql\" + 0.020*\"html\" + 0.019*\"c\" + 0.018*\"r\" + 0.016*\"java\" + 0.013*\"technical\" + 0.013*\"c++\" + 0.011*\"javascript\" + 0.009*\"css\"\n",
      "INFO : topic diff=12.624210, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.356 per-word bound, 655.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 517/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3779/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3773/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3827/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.059): 0.015*\"r\" + 0.012*\"excel\" + 0.010*\"sql\" + 0.010*\"sas\" + 0.008*\"mysql\" + 0.008*\"spss\" + 0.007*\"access\" + 0.007*\"word\" + 0.006*\"powerpoint\" + 0.006*\"linux\"\n",
      "INFO : topic #0 (0.059): 0.014*\"sql\" + 0.011*\"python\" + 0.010*\"r\" + 0.009*\"technical\" + 0.008*\"oracle\" + 0.008*\"java\" + 0.008*\"javascript\" + 0.008*\"html\" + 0.007*\"hive\" + 0.006*\"linux\"\n",
      "INFO : topic #4 (0.059): 0.021*\"r\" + 0.020*\"sql\" + 0.020*\"python\" + 0.011*\"technical\" + 0.011*\"tableau\" + 0.010*\"data\" + 0.010*\"matlab\" + 0.008*\"java\" + 0.008*\"hadoop\" + 0.008*\"spss\"\n",
      "INFO : topic #6 (0.059): 0.026*\"python\" + 0.025*\"r\" + 0.020*\"sql\" + 0.013*\"sas\" + 0.013*\"technical\" + 0.011*\"pandas\" + 0.011*\"mysql\" + 0.011*\"tableau\" + 0.010*\"matlab\" + 0.009*\"statistical\"\n",
      "INFO : topic #2 (0.059): 0.012*\"r\" + 0.010*\"python\" + 0.009*\"c++\" + 0.009*\"sql\" + 0.007*\"linux\" + 0.006*\"html\" + 0.006*\"data\" + 0.005*\"windows\" + 0.005*\"programming\" + 0.005*\"excel\"\n",
      "INFO : topic diff=0.360638, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.115 per-word bound, 554.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3827/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3862/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3899/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.059): 0.020*\"r\" + 0.019*\"sql\" + 0.018*\"python\" + 0.011*\"technical\" + 0.010*\"data\" + 0.010*\"tableau\" + 0.009*\"matlab\" + 0.008*\"java\" + 0.008*\"hadoop\" + 0.008*\"spss\"\n",
      "INFO : topic #9 (0.059): 0.024*\"python\" + 0.023*\"html\" + 0.021*\"c\" + 0.020*\"java\" + 0.020*\"sql\" + 0.018*\"javascript\" + 0.017*\"r\" + 0.016*\"c++\" + 0.014*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #8 (0.059): 0.028*\"r\" + 0.027*\"python\" + 0.023*\"sql\" + 0.015*\"tableau\" + 0.015*\"hadoop\" + 0.013*\"hive\" + 0.012*\"java\" + 0.011*\"technical\" + 0.010*\"spark\" + 0.010*\"oracle\"\n",
      "INFO : topic #15 (0.059): 0.031*\"python\" + 0.029*\"sql\" + 0.028*\"r\" + 0.018*\"matlab\" + 0.017*\"c\" + 0.016*\"java\" + 0.016*\"hadoop\" + 0.016*\"c++\" + 0.015*\"tableau\" + 0.014*\"hive\"\n",
      "INFO : topic #14 (0.059): 0.019*\"r\" + 0.019*\"sql\" + 0.017*\"python\" + 0.013*\"c++\" + 0.011*\"java\" + 0.010*\"tableau\" + 0.010*\"c\" + 0.009*\"matlab\" + 0.008*\"spark\" + 0.008*\"technical\"\n",
      "INFO : topic diff=0.314092, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.992 per-word bound, 509.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3862/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3899/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3872/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #16 (0.059): 0.016*\"sql\" + 0.014*\"r\" + 0.011*\"python\" + 0.009*\"technical\" + 0.008*\"java\" + 0.006*\"sas\" + 0.006*\"c\" + 0.006*\"javascript\" + 0.005*\"pandas\" + 0.005*\"numpy\"\n",
      "INFO : topic #10 (0.059): 0.012*\"excel\" + 0.011*\"r\" + 0.008*\"sas\" + 0.008*\"sql\" + 0.008*\"access\" + 0.007*\"word\" + 0.007*\"spss\" + 0.007*\"powerpoint\" + 0.006*\"mysql\" + 0.004*\"linux\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #9 (0.059): 0.025*\"html\" + 0.025*\"python\" + 0.022*\"c\" + 0.022*\"java\" + 0.020*\"javascript\" + 0.020*\"sql\" + 0.017*\"c++\" + 0.017*\"css\" + 0.016*\"r\" + 0.013*\"technical\"\n",
      "INFO : topic #3 (0.059): 0.010*\"technical\" + 0.009*\"sql\" + 0.009*\"unix\" + 0.006*\"linux\" + 0.006*\"python\" + 0.004*\"r\" + 0.004*\"tableau\" + 0.003*\"powerpoint\" + 0.003*\"skills\" + 0.003*\"javascript\"\n",
      "INFO : topic #13 (0.059): 0.019*\"python\" + 0.017*\"sql\" + 0.017*\"r\" + 0.016*\"tableau\" + 0.016*\"technical\" + 0.015*\"sas\" + 0.010*\"html\" + 0.010*\"java\" + 0.009*\"c++\" + 0.008*\"c\"\n",
      "INFO : topic diff=0.269033, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.919 per-word bound, 483.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3883/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3881/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3910/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.059): 0.027*\"html\" + 0.025*\"python\" + 0.024*\"java\" + 0.023*\"javascript\" + 0.023*\"c\" + 0.020*\"sql\" + 0.018*\"c++\" + 0.018*\"css\" + 0.016*\"r\" + 0.014*\"mysql\"\n",
      "INFO : topic #13 (0.059): 0.018*\"python\" + 0.016*\"sql\" + 0.016*\"r\" + 0.016*\"tableau\" + 0.015*\"technical\" + 0.014*\"sas\" + 0.010*\"html\" + 0.009*\"java\" + 0.008*\"c++\" + 0.008*\"c\"\n",
      "INFO : topic #4 (0.059): 0.018*\"r\" + 0.017*\"sql\" + 0.015*\"python\" + 0.010*\"data\" + 0.010*\"technical\" + 0.008*\"matlab\" + 0.008*\"tableau\" + 0.007*\"spss\" + 0.007*\"java\" + 0.007*\"hadoop\"\n",
      "INFO : topic #10 (0.059): 0.012*\"excel\" + 0.010*\"r\" + 0.007*\"sas\" + 0.007*\"sql\" + 0.007*\"access\" + 0.007*\"word\" + 0.007*\"powerpoint\" + 0.006*\"spss\" + 0.005*\"mysql\" + 0.005*\"english\"\n",
      "INFO : topic #3 (0.059): 0.009*\"unix\" + 0.009*\"technical\" + 0.008*\"sql\" + 0.006*\"linux\" + 0.005*\"python\" + 0.004*\"r\" + 0.003*\"tableau\" + 0.003*\"skills\" + 0.003*\"powerpoint\" + 0.003*\"windows\"\n",
      "INFO : topic diff=0.226865, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.869 per-word bound, 467.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.059): 0.011*\"linux\" + 0.007*\"python\" + 0.006*\"sql\" + 0.006*\"hadoop\" + 0.005*\"c++\" + 0.005*\"hive\" + 0.004*\"windows\" + 0.004*\"mapreduce\" + 0.004*\"java\" + 0.004*\"core\"\n",
      "INFO : topic #11 (0.059): 0.042*\"r\" + 0.039*\"python\" + 0.036*\"sql\" + 0.031*\"sas\" + 0.022*\"matlab\" + 0.022*\"excel\" + 0.020*\"c++\" + 0.018*\"tableau\" + 0.015*\"technical\" + 0.015*\"java\"\n",
      "INFO : topic #15 (0.059): 0.031*\"python\" + 0.028*\"r\" + 0.028*\"sql\" + 0.019*\"hadoop\" + 0.018*\"java\" + 0.018*\"c\" + 0.017*\"matlab\" + 0.017*\"hive\" + 0.016*\"c++\" + 0.015*\"tableau\"\n",
      "INFO : topic #8 (0.059): 0.025*\"python\" + 0.025*\"r\" + 0.021*\"sql\" + 0.016*\"hadoop\" + 0.015*\"hive\" + 0.014*\"tableau\" + 0.013*\"java\" + 0.012*\"spark\" + 0.012*\"technical\" + 0.011*\"oracle\"\n",
      "INFO : topic #12 (0.059): 0.012*\"python\" + 0.010*\"hive\" + 0.009*\"java\" + 0.009*\"sql\" + 0.008*\"technical\" + 0.008*\"tableau\" + 0.008*\"r\" + 0.008*\"hdfs\" + 0.007*\"pig\" + 0.007*\"spark\"\n",
      "INFO : topic diff=0.188138, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.833 per-word bound, 456.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3913/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.059): 0.015*\"r\" + 0.014*\"sql\" + 0.013*\"python\" + 0.010*\"data\" + 0.008*\"technical\" + 0.008*\"matlab\" + 0.007*\"tableau\" + 0.006*\"spss\" + 0.006*\"c++\" + 0.006*\"java\"\n",
      "INFO : topic #13 (0.059): 0.016*\"python\" + 0.015*\"sql\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"r\" + 0.013*\"sas\" + 0.009*\"html\" + 0.008*\"java\" + 0.007*\"data\" + 0.007*\"c++\"\n",
      "INFO : topic #5 (0.059): 0.010*\"sql\" + 0.008*\"excel\" + 0.007*\"powerpoint\" + 0.007*\"technical\" + 0.006*\"access\" + 0.006*\"word\" + 0.005*\"r\" + 0.004*\"taleo\" + 0.004*\"sas\" + 0.004*\"oracle\"\n",
      "INFO : topic #16 (0.059): 0.012*\"sql\" + 0.010*\"r\" + 0.008*\"technical\" + 0.008*\"python\" + 0.006*\"java\" + 0.005*\"stat\" + 0.005*\"c\" + 0.005*\"sas\" + 0.004*\"base\" + 0.004*\"javascript\"\n",
      "INFO : topic #6 (0.059): 0.030*\"python\" + 0.028*\"r\" + 0.024*\"sql\" + 0.020*\"pandas\" + 0.016*\"technical\" + 0.015*\"numpy\" + 0.014*\"tableau\" + 0.013*\"scikit\" + 0.011*\"sas\" + 0.011*\"mysql\"\n",
      "INFO : topic diff=0.154476, rho=0.314126\n",
      "DEBUG : bound: at document #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : -8.808 per-word bound, 448.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.059): 0.011*\"python\" + 0.010*\"hive\" + 0.008*\"sql\" + 0.008*\"java\" + 0.008*\"tableau\" + 0.008*\"hdfs\" + 0.008*\"technical\" + 0.007*\"pig\" + 0.006*\"mapreduce\" + 0.006*\"r\"\n",
      "INFO : topic #0 (0.059): 0.010*\"sql\" + 0.009*\"oracle\" + 0.009*\"technical\" + 0.007*\"pl\" + 0.007*\"html\" + 0.007*\"java\" + 0.007*\"xml\" + 0.007*\"javascript\" + 0.006*\"hive\" + 0.006*\"unix\"\n",
      "INFO : topic #4 (0.059): 0.014*\"r\" + 0.013*\"sql\" + 0.011*\"python\" + 0.010*\"data\" + 0.007*\"technical\" + 0.007*\"matlab\" + 0.006*\"tableau\" + 0.006*\"spss\" + 0.005*\"c++\" + 0.005*\"java\"\n",
      "INFO : topic #1 (0.059): 0.015*\"python\" + 0.013*\"java\" + 0.013*\"technical\" + 0.012*\"sql\" + 0.009*\"c\" + 0.009*\"r\" + 0.007*\"c++\" + 0.007*\"html\" + 0.007*\"ms\" + 0.007*\"mysql\"\n",
      "INFO : topic #6 (0.059): 0.031*\"python\" + 0.028*\"r\" + 0.025*\"sql\" + 0.021*\"pandas\" + 0.016*\"technical\" + 0.016*\"numpy\" + 0.014*\"tableau\" + 0.014*\"scikit\" + 0.011*\"sas\" + 0.011*\"hadoop\"\n",
      "INFO : topic diff=0.126841, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.789 per-word bound, 442.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #16 (0.059): 0.010*\"sql\" + 0.009*\"r\" + 0.007*\"technical\" + 0.006*\"python\" + 0.006*\"stat\" + 0.005*\"java\" + 0.005*\"base\" + 0.005*\"c\" + 0.004*\"sas\" + 0.004*\"databases\"\n",
      "INFO : topic #9 (0.059): 0.031*\"html\" + 0.029*\"javascript\" + 0.028*\"java\" + 0.026*\"python\" + 0.025*\"c\" + 0.023*\"css\" + 0.021*\"c++\" + 0.020*\"sql\" + 0.017*\"mysql\" + 0.015*\"r\"\n",
      "INFO : topic #10 (0.059): 0.008*\"excel\" + 0.008*\"english\" + 0.006*\"access\" + 0.005*\"r\" + 0.005*\"french\" + 0.005*\"word\" + 0.005*\"powerpoint\" + 0.005*\"project\" + 0.005*\"spanish\" + 0.004*\"sas\"\n",
      "INFO : topic #15 (0.059): 0.030*\"python\" + 0.028*\"r\" + 0.027*\"sql\" + 0.020*\"hadoop\" + 0.019*\"hive\" + 0.018*\"java\" + 0.018*\"c\" + 0.017*\"matlab\" + 0.016*\"c++\" + 0.014*\"tableau\"\n",
      "INFO : topic #1 (0.059): 0.014*\"python\" + 0.012*\"java\" + 0.012*\"technical\" + 0.011*\"sql\" + 0.009*\"c\" + 0.008*\"r\" + 0.007*\"c++\" + 0.007*\"ms\" + 0.007*\"html\" + 0.006*\"mysql\"\n",
      "INFO : topic diff=0.104483, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.773 per-word bound, 437.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3913/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #16 (0.059): 0.010*\"sql\" + 0.008*\"r\" + 0.007*\"technical\" + 0.006*\"stat\" + 0.005*\"python\" + 0.005*\"java\" + 0.005*\"base\" + 0.004*\"c\" + 0.004*\"sas\" + 0.004*\"databases\"\n",
      "INFO : topic #13 (0.059): 0.014*\"tableau\" + 0.013*\"sql\" + 0.013*\"python\" + 0.013*\"technical\" + 0.012*\"sas\" + 0.011*\"r\" + 0.009*\"html\" + 0.008*\"data\" + 0.007*\"java\" + 0.006*\"c++\"\n",
      "INFO : topic #5 (0.059): 0.007*\"sql\" + 0.007*\"powerpoint\" + 0.007*\"excel\" + 0.006*\"technical\" + 0.006*\"access\" + 0.005*\"taleo\" + 0.005*\"word\" + 0.004*\"oracle\" + 0.003*\"jobvite\" + 0.003*\"teradata\"\n",
      "INFO : topic #3 (0.059): 0.009*\"unix\" + 0.006*\"technical\" + 0.005*\"sql\" + 0.005*\"linux\" + 0.003*\"powershell\" + 0.003*\"sunsolaris\" + 0.002*\"skills\" + 0.002*\"macintosh_hd\" + 0.002*\"ssrs\" + 0.002*\"windows\"\n",
      "INFO : topic #6 (0.059): 0.032*\"python\" + 0.029*\"r\" + 0.025*\"sql\" + 0.022*\"pandas\" + 0.017*\"numpy\" + 0.017*\"technical\" + 0.015*\"tableau\" + 0.014*\"scikit\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic diff=0.086647, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.758 per-word bound, 432.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.059): 0.006*\"r\" + 0.006*\"c++\" + 0.005*\"data\" + 0.004*\"python\" + 0.004*\"sql\" + 0.004*\"linux\" + 0.004*\"windows\" + 0.003*\"software\" + 0.003*\"project\" + 0.003*\"html\"\n",
      "INFO : topic #15 (0.059): 0.029*\"python\" + 0.027*\"r\" + 0.026*\"sql\" + 0.021*\"hadoop\" + 0.019*\"hive\" + 0.018*\"java\" + 0.018*\"c\" + 0.016*\"matlab\" + 0.016*\"c++\" + 0.014*\"spark\"\n",
      "INFO : topic #10 (0.059): 0.009*\"english\" + 0.007*\"excel\" + 0.006*\"french\" + 0.005*\"spanish\" + 0.005*\"access\" + 0.004*\"word\" + 0.004*\"powerpoint\" + 0.004*\"project\" + 0.004*\"r\" + 0.004*\"sql\"\n",
      "INFO : topic #13 (0.059): 0.013*\"tableau\" + 0.013*\"sql\" + 0.013*\"technical\" + 0.012*\"python\" + 0.011*\"sas\" + 0.010*\"r\" + 0.008*\"html\" + 0.008*\"data\" + 0.006*\"java\" + 0.006*\"c++\"\n",
      "INFO : topic #11 (0.059): 0.048*\"r\" + 0.042*\"python\" + 0.042*\"sql\" + 0.035*\"sas\" + 0.027*\"excel\" + 0.025*\"matlab\" + 0.021*\"tableau\" + 0.021*\"c++\" + 0.017*\"spss\" + 0.016*\"powerpoint\"\n",
      "INFO : topic diff=0.072619, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.748 per-word bound, 429.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.059): 0.009*\"unix\" + 0.005*\"technical\" + 0.005*\"linux\" + 0.005*\"sql\" + 0.003*\"powershell\" + 0.003*\"sunsolaris\" + 0.002*\"macintosh_hd\" + 0.002*\"skills\" + 0.002*\"ibm\" + 0.002*\"windows\"\n",
      "INFO : topic #12 (0.059): 0.009*\"hive\" + 0.008*\"python\" + 0.008*\"tableau\" + 0.007*\"hdfs\" + 0.007*\"sql\" + 0.007*\"pig\" + 0.007*\"technical\" + 0.006*\"mapreduce\" + 0.006*\"visio\" + 0.006*\"java\"\n",
      "INFO : topic #15 (0.059): 0.029*\"python\" + 0.027*\"r\" + 0.025*\"sql\" + 0.021*\"hadoop\" + 0.019*\"hive\" + 0.018*\"c\" + 0.018*\"java\" + 0.016*\"matlab\" + 0.016*\"c++\" + 0.014*\"spark\"\n",
      "INFO : topic #11 (0.059): 0.049*\"r\" + 0.043*\"python\" + 0.042*\"sql\" + 0.036*\"sas\" + 0.027*\"excel\" + 0.026*\"matlab\" + 0.021*\"tableau\" + 0.021*\"c++\" + 0.017*\"spss\" + 0.016*\"powerpoint\"\n",
      "INFO : topic #4 (0.059): 0.010*\"data\" + 0.010*\"r\" + 0.010*\"sql\" + 0.007*\"python\" + 0.006*\"matlab\" + 0.005*\"technical\" + 0.005*\"spss\" + 0.004*\"excel\" + 0.004*\"tableau\" + 0.004*\"c++\"\n",
      "INFO : topic diff=0.061491, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.739 per-word bound, 427.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.059): 0.008*\"hive\" + 0.008*\"python\" + 0.008*\"tableau\" + 0.007*\"hdfs\" + 0.007*\"sql\" + 0.007*\"pig\" + 0.006*\"technical\" + 0.006*\"mapreduce\" + 0.006*\"visio\" + 0.005*\"bigdata\"\n",
      "INFO : topic #0 (0.059): 0.010*\"oracle\" + 0.009*\"sql\" + 0.009*\"xml\" + 0.009*\"pl\" + 0.008*\"technical\" + 0.007*\"html\" + 0.007*\"java\" + 0.006*\"javascript\" + 0.006*\"unix\" + 0.006*\"db2\"\n",
      "INFO : topic #5 (0.059): 0.006*\"taleo\" + 0.006*\"powerpoint\" + 0.006*\"excel\" + 0.006*\"sql\" + 0.006*\"technical\" + 0.005*\"access\" + 0.005*\"word\" + 0.004*\"jobvite\" + 0.003*\"oracle\" + 0.003*\"icims\"\n",
      "INFO : topic #1 (0.059): 0.011*\"technical\" + 0.010*\"python\" + 0.010*\"java\" + 0.008*\"sql\" + 0.007*\"c\" + 0.007*\"ms\" + 0.005*\"r\" + 0.005*\"c++\" + 0.005*\"oracle\" + 0.005*\"html\"\n",
      "INFO : topic #16 (0.059): 0.008*\"sql\" + 0.006*\"stat\" + 0.006*\"technical\" + 0.006*\"r\" + 0.005*\"base\" + 0.004*\"macro\" + 0.004*\"java\" + 0.004*\"databases\" + 0.004*\"python\" + 0.004*\"graph\"\n",
      "INFO : topic diff=0.052595, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.733 per-word bound, 425.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.059): 0.033*\"html\" + 0.033*\"javascript\" + 0.031*\"java\" + 0.028*\"python\" + 0.028*\"c\" + 0.026*\"css\" + 0.024*\"c++\" + 0.020*\"sql\" + 0.019*\"mysql\" + 0.016*\"php\"\n",
      "INFO : topic #10 (0.059): 0.010*\"english\" + 0.007*\"spanish\" + 0.006*\"french\" + 0.006*\"excel\" + 0.005*\"access\" + 0.004*\"project\" + 0.003*\"word\" + 0.003*\"powerpoint\" + 0.003*\"indesign\" + 0.003*\"sharepoint\"\n",
      "INFO : topic #1 (0.059): 0.010*\"technical\" + 0.009*\"python\" + 0.009*\"java\" + 0.008*\"sql\" + 0.007*\"ms\" + 0.007*\"c\" + 0.005*\"r\" + 0.005*\"oracle\" + 0.005*\"c++\" + 0.005*\"html\"\n",
      "INFO : topic #2 (0.059): 0.006*\"r\" + 0.005*\"c++\" + 0.005*\"data\" + 0.003*\"sql\" + 0.003*\"python\" + 0.003*\"software\" + 0.003*\"project\" + 0.003*\"linux\" + 0.003*\"windows\" + 0.003*\"research\"\n",
      "INFO : topic #0 (0.059): 0.010*\"oracle\" + 0.009*\"sql\" + 0.009*\"xml\" + 0.009*\"pl\" + 0.008*\"technical\" + 0.007*\"html\" + 0.007*\"java\" + 0.006*\"javascript\" + 0.006*\"unix\" + 0.006*\"db2\"\n",
      "INFO : topic diff=0.045643, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.726 per-word bound, 423.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.059): 0.008*\"hive\" + 0.008*\"tableau\" + 0.007*\"python\" + 0.007*\"hdfs\" + 0.006*\"pig\" + 0.006*\"sql\" + 0.006*\"technical\" + 0.006*\"visio\" + 0.006*\"mapreduce\" + 0.005*\"excel\"\n",
      "INFO : topic #15 (0.059): 0.027*\"python\" + 0.025*\"r\" + 0.024*\"sql\" + 0.021*\"hadoop\" + 0.020*\"hive\" + 0.017*\"c\" + 0.017*\"java\" + 0.015*\"matlab\" + 0.015*\"c++\" + 0.014*\"pig\"\n",
      "INFO : topic #7 (0.059): 0.007*\"linux\" + 0.004*\"windows\" + 0.003*\"core\" + 0.003*\"xp\" + 0.003*\"volunteer\" + 0.003*\"d.\" + 0.003*\"academic\" + 0.002*\"vista\" + 0.002*\"hadoop\" + 0.002*\"skill\"\n",
      "INFO : topic #5 (0.059): 0.007*\"taleo\" + 0.006*\"powerpoint\" + 0.006*\"excel\" + 0.005*\"technical\" + 0.005*\"sql\" + 0.005*\"access\" + 0.005*\"jobvite\" + 0.004*\"word\" + 0.003*\"salesforce\" + 0.003*\"oracle\"\n",
      "INFO : topic #6 (0.059): 0.033*\"python\" + 0.030*\"r\" + 0.026*\"sql\" + 0.022*\"pandas\" + 0.018*\"numpy\" + 0.017*\"technical\" + 0.015*\"tableau\" + 0.015*\"scikit\" + 0.013*\"hadoop\" + 0.012*\"spark\"\n",
      "INFO : topic diff=0.040010, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.720 per-word bound, 421.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.059): 0.022*\"python\" + 0.020*\"r\" + 0.020*\"hive\" + 0.019*\"hadoop\" + 0.019*\"sql\" + 0.016*\"spark\" + 0.014*\"technical\" + 0.014*\"tableau\" + 0.014*\"java\" + 0.014*\"oracle\"\n",
      "INFO : topic #13 (0.059): 0.011*\"technical\" + 0.011*\"tableau\" + 0.011*\"sql\" + 0.010*\"sas\" + 0.009*\"python\" + 0.009*\"data\" + 0.007*\"r\" + 0.007*\"html\" + 0.005*\"ms\" + 0.005*\"java\"\n",
      "INFO : topic #11 (0.059): 0.051*\"r\" + 0.044*\"sql\" + 0.044*\"python\" + 0.037*\"sas\" + 0.029*\"excel\" + 0.026*\"matlab\" + 0.022*\"tableau\" + 0.021*\"c++\" + 0.018*\"spss\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #1 (0.059): 0.010*\"technical\" + 0.008*\"java\" + 0.008*\"python\" + 0.007*\"sql\" + 0.007*\"ms\" + 0.006*\"c\" + 0.005*\"oracle\" + 0.004*\"windows\" + 0.004*\"jira\" + 0.004*\"c++\"\n",
      "INFO : topic #9 (0.059): 0.034*\"javascript\" + 0.034*\"html\" + 0.032*\"java\" + 0.028*\"python\" + 0.028*\"c\" + 0.027*\"css\" + 0.025*\"c++\" + 0.020*\"sql\" + 0.020*\"mysql\" + 0.016*\"php\"\n",
      "INFO : topic diff=0.035626, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.715 per-word bound, 420.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #16 (0.059): 0.007*\"stat\" + 0.006*\"sql\" + 0.006*\"base\" + 0.005*\"technical\" + 0.005*\"macro\" + 0.004*\"r\" + 0.004*\"graph\" + 0.004*\"databases\" + 0.004*\"ets\" + 0.003*\"teradata\"\n",
      "INFO : topic #15 (0.059): 0.027*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.020*\"hadoop\" + 0.019*\"hive\" + 0.017*\"c\" + 0.017*\"java\" + 0.015*\"matlab\" + 0.015*\"c++\" + 0.015*\"pig\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #10 (0.059): 0.011*\"english\" + 0.007*\"spanish\" + 0.007*\"french\" + 0.005*\"excel\" + 0.004*\"access\" + 0.004*\"indesign\" + 0.003*\"project\" + 0.003*\"sharepoint\" + 0.003*\"powerpoint\" + 0.003*\"word\"\n",
      "INFO : topic #1 (0.059): 0.009*\"technical\" + 0.008*\"java\" + 0.007*\"python\" + 0.007*\"ms\" + 0.006*\"sql\" + 0.006*\"c\" + 0.005*\"oracle\" + 0.004*\"windows\" + 0.004*\"jira\" + 0.004*\"c++\"\n",
      "INFO : topic #14 (0.059): 0.008*\"sql\" + 0.007*\"c++\" + 0.007*\"data\" + 0.006*\"r\" + 0.006*\"english\" + 0.005*\"project\" + 0.005*\"analytics\" + 0.005*\"core\" + 0.004*\"python\" + 0.004*\"mandarin\"\n",
      "INFO : topic diff=0.031867, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.710 per-word bound, 418.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.059): 0.007*\"linux\" + 0.004*\"windows\" + 0.003*\"volunteer\" + 0.003*\"d.\" + 0.003*\"xp\" + 0.003*\"academic\" + 0.003*\"core\" + 0.003*\"vista\" + 0.002*\"skill\" + 0.002*\"qualifications\"\n",
      "INFO : topic #11 (0.059): 0.051*\"r\" + 0.044*\"sql\" + 0.044*\"python\" + 0.037*\"sas\" + 0.029*\"excel\" + 0.027*\"matlab\" + 0.023*\"tableau\" + 0.021*\"c++\" + 0.019*\"spss\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #8 (0.059): 0.022*\"python\" + 0.021*\"hive\" + 0.020*\"r\" + 0.020*\"hadoop\" + 0.019*\"sql\" + 0.016*\"spark\" + 0.015*\"technical\" + 0.014*\"oracle\" + 0.014*\"java\" + 0.014*\"tableau\"\n",
      "INFO : topic #1 (0.059): 0.009*\"technical\" + 0.007*\"java\" + 0.007*\"python\" + 0.007*\"ms\" + 0.006*\"sql\" + 0.006*\"c\" + 0.005*\"oracle\" + 0.004*\"jira\" + 0.004*\"windows\" + 0.004*\"linux\"\n",
      "INFO : topic #3 (0.059): 0.009*\"unix\" + 0.005*\"linux\" + 0.004*\"technical\" + 0.003*\"sql\" + 0.003*\"powershell\" + 0.003*\"sunsolaris\" + 0.003*\"macintosh_hd\" + 0.002*\"skills\" + 0.002*\"independent\" + 0.002*\"ibm\"\n",
      "INFO : topic diff=0.028724, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.706 per-word bound, 417.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #14 (0.059): 0.007*\"sql\" + 0.007*\"data\" + 0.006*\"c++\" + 0.006*\"english\" + 0.006*\"project\" + 0.005*\"r\" + 0.005*\"analytics\" + 0.005*\"core\" + 0.004*\"mandarin\" + 0.004*\"strategic\"\n",
      "INFO : topic #10 (0.059): 0.011*\"english\" + 0.008*\"spanish\" + 0.007*\"french\" + 0.004*\"excel\" + 0.004*\"access\" + 0.004*\"indesign\" + 0.003*\"project\" + 0.003*\"sharepoint\" + 0.003*\"illustrator\" + 0.002*\"word\"\n",
      "INFO : topic #8 (0.059): 0.022*\"python\" + 0.021*\"hive\" + 0.020*\"hadoop\" + 0.020*\"r\" + 0.019*\"sql\" + 0.017*\"spark\" + 0.015*\"technical\" + 0.014*\"oracle\" + 0.014*\"java\" + 0.014*\"pig\"\n",
      "INFO : topic #2 (0.059): 0.005*\"data\" + 0.005*\"r\" + 0.004*\"c++\" + 0.003*\"software\" + 0.003*\"project\" + 0.003*\"windows\" + 0.003*\"research\" + 0.003*\"sql\" + 0.003*\"sharepoint\" + 0.003*\"linux\"\n",
      "INFO : topic #15 (0.059): 0.026*\"python\" + 0.024*\"r\" + 0.023*\"sql\" + 0.020*\"hadoop\" + 0.019*\"hive\" + 0.017*\"c\" + 0.016*\"java\" + 0.015*\"matlab\" + 0.015*\"c++\" + 0.015*\"pig\"\n",
      "INFO : topic diff=0.026071, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.704 per-word bound, 416.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.059): 0.011*\"oracle\" + 0.010*\"xml\" + 0.010*\"pl\" + 0.009*\"sql\" + 0.008*\"technical\" + 0.007*\"html\" + 0.007*\"db2\" + 0.007*\"unix\" + 0.006*\"java\" + 0.006*\"javascript\"\n",
      "INFO : topic #7 (0.059): 0.006*\"linux\" + 0.004*\"windows\" + 0.003*\"volunteer\" + 0.003*\"d.\" + 0.003*\"xp\" + 0.003*\"academic\" + 0.003*\"core\" + 0.003*\"vista\" + 0.002*\"qualifications\" + 0.002*\"spring\"\n",
      "INFO : topic #12 (0.059): 0.008*\"tableau\" + 0.007*\"hive\" + 0.007*\"hdfs\" + 0.006*\"python\" + 0.006*\"visio\" + 0.006*\"pig\" + 0.005*\"sql\" + 0.005*\"mapreduce\" + 0.005*\"technical\" + 0.005*\"msoffice\"\n",
      "INFO : topic #13 (0.059): 0.010*\"technical\" + 0.010*\"tableau\" + 0.009*\"sql\" + 0.009*\"sas\" + 0.009*\"data\" + 0.007*\"python\" + 0.006*\"html\" + 0.005*\"r\" + 0.005*\"ms\" + 0.005*\"business\"\n",
      "INFO : topic #8 (0.059): 0.022*\"python\" + 0.022*\"hive\" + 0.021*\"hadoop\" + 0.020*\"r\" + 0.019*\"sql\" + 0.017*\"spark\" + 0.015*\"technical\" + 0.014*\"pig\" + 0.014*\"oracle\" + 0.014*\"java\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.023842, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.701 per-word bound, 416.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=17, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=17, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (153 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (643 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (388 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (282 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (520 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (503 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (374 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (612 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (707 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (564 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (429 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (763 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (641 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (508 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (449 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (346 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (567 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 8; 576 documents processed (772 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (567 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (772 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : finished all batches; 384 documents processed (384 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (800 virtual)\n",
      "DEBUG : completed batch 9; 640 documents processed (788 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (800 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (639 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (639 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (705 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (705 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (580 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (512 virtual)\n",
      "DEBUG : finished all batches; 384 documents processed (580 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (572 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (572 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (513 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (513 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 356 documents processed (557 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 356 documents processed (557 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 640 documents processed (788 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (546 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (461 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (461 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (546 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 6; 448 documents processed (983 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (983 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9379 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12397/12537 documents converged within 50 iterations\n",
      " 65%|██████▌   | 15/23 [06:27<03:26, 25.82s/it]INFO : using symmetric alpha at 0.05555555555555555\n",
      "INFO : using symmetric eta at 0.05555555555555555\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 18 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 434/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3395/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3267/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3210/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.056): 0.018*\"python\" + 0.015*\"r\" + 0.014*\"java\" + 0.014*\"sql\" + 0.011*\"mysql\" + 0.011*\"hive\" + 0.009*\"hadoop\" + 0.009*\"c\" + 0.009*\"c++\" + 0.009*\"tableau\"\n",
      "INFO : topic #14 (0.056): 0.022*\"r\" + 0.021*\"sql\" + 0.020*\"python\" + 0.014*\"c++\" + 0.014*\"java\" + 0.011*\"c\" + 0.011*\"matlab\" + 0.010*\"technical\" + 0.010*\"hadoop\" + 0.010*\"tableau\"\n",
      "INFO : topic #1 (0.056): 0.023*\"python\" + 0.017*\"java\" + 0.017*\"sql\" + 0.017*\"r\" + 0.015*\"technical\" + 0.011*\"c\" + 0.011*\"c++\" + 0.010*\"mysql\" + 0.009*\"javascript\" + 0.009*\"html\"\n",
      "INFO : topic #17 (0.056): 0.022*\"python\" + 0.019*\"r\" + 0.011*\"excel\" + 0.011*\"technical\" + 0.011*\"sql\" + 0.011*\"c++\" + 0.010*\"c\" + 0.009*\"hadoop\" + 0.009*\"java\" + 0.009*\"sas\"\n",
      "INFO : topic #15 (0.056): 0.028*\"sql\" + 0.027*\"python\" + 0.026*\"r\" + 0.015*\"c\" + 0.015*\"matlab\" + 0.015*\"java\" + 0.015*\"hadoop\" + 0.014*\"tableau\" + 0.013*\"c++\" + 0.011*\"technical\"\n",
      "INFO : topic diff=13.514152, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.330 per-word bound, 643.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3769/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3774/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3826/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #15 (0.056): 0.029*\"python\" + 0.029*\"sql\" + 0.028*\"r\" + 0.017*\"hadoop\" + 0.017*\"java\" + 0.015*\"c\" + 0.015*\"matlab\" + 0.015*\"tableau\" + 0.014*\"c++\" + 0.014*\"hive\"\n",
      "INFO : topic #13 (0.056): 0.022*\"python\" + 0.018*\"sql\" + 0.018*\"r\" + 0.017*\"technical\" + 0.015*\"sas\" + 0.015*\"tableau\" + 0.012*\"c++\" + 0.011*\"html\" + 0.011*\"java\" + 0.010*\"c\"\n",
      "INFO : topic #9 (0.056): 0.025*\"python\" + 0.022*\"c\" + 0.022*\"html\" + 0.021*\"sql\" + 0.021*\"java\" + 0.018*\"r\" + 0.016*\"c++\" + 0.016*\"javascript\" + 0.013*\"technical\" + 0.012*\"css\"\n",
      "INFO : topic #5 (0.056): 0.014*\"sql\" + 0.011*\"technical\" + 0.008*\"python\" + 0.007*\"r\" + 0.007*\"excel\" + 0.006*\"sas\" + 0.005*\"tableau\" + 0.005*\"access\" + 0.005*\"java\" + 0.004*\"linux\"\n",
      "INFO : topic #14 (0.056): 0.021*\"r\" + 0.020*\"sql\" + 0.019*\"python\" + 0.013*\"c++\" + 0.012*\"java\" + 0.010*\"technical\" + 0.010*\"matlab\" + 0.010*\"tableau\" + 0.010*\"hadoop\" + 0.010*\"c\"\n",
      "INFO : topic diff=0.356315, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.105 per-word bound, 550.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3860/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3873/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3910/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.056): 0.013*\"r\" + 0.009*\"excel\" + 0.009*\"sas\" + 0.009*\"sql\" + 0.008*\"spss\" + 0.007*\"mysql\" + 0.006*\"word\" + 0.005*\"powerpoint\" + 0.005*\"data\" + 0.005*\"access\"\n",
      "INFO : topic #5 (0.056): 0.011*\"sql\" + 0.010*\"technical\" + 0.007*\"excel\" + 0.006*\"python\" + 0.006*\"r\" + 0.005*\"access\" + 0.005*\"sas\" + 0.005*\"tableau\" + 0.004*\"data\" + 0.004*\"powerpoint\"\n",
      "INFO : topic #14 (0.056): 0.020*\"r\" + 0.019*\"sql\" + 0.018*\"python\" + 0.012*\"c++\" + 0.011*\"java\" + 0.010*\"technical\" + 0.009*\"tableau\" + 0.009*\"hadoop\" + 0.009*\"matlab\" + 0.009*\"c\"\n",
      "INFO : topic #16 (0.056): 0.018*\"sql\" + 0.015*\"r\" + 0.013*\"python\" + 0.009*\"java\" + 0.009*\"technical\" + 0.007*\"javascript\" + 0.007*\"c\" + 0.006*\"sas\" + 0.005*\"tableau\" + 0.004*\"aws\"\n",
      "INFO : topic #3 (0.056): 0.014*\"technical\" + 0.010*\"sql\" + 0.008*\"python\" + 0.007*\"r\" + 0.006*\"unix\" + 0.005*\"linux\" + 0.005*\"tableau\" + 0.005*\"java\" + 0.004*\"powerpoint\" + 0.004*\"word\"\n",
      "INFO : topic diff=0.315398, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.988 per-word bound, 507.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3925/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3902/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3881/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.056): 0.009*\"r\" + 0.008*\"linux\" + 0.008*\"sql\" + 0.007*\"c++\" + 0.006*\"python\" + 0.005*\"html\" + 0.005*\"windows\" + 0.005*\"technical\" + 0.004*\"c\" + 0.004*\"powerpoint\"\n",
      "INFO : topic #6 (0.056): 0.028*\"python\" + 0.025*\"r\" + 0.021*\"sql\" + 0.017*\"pandas\" + 0.013*\"numpy\" + 0.012*\"scikit\" + 0.012*\"technical\" + 0.012*\"tableau\" + 0.011*\"sas\" + 0.010*\"matlab\"\n",
      "INFO : topic #10 (0.056): 0.011*\"r\" + 0.009*\"excel\" + 0.008*\"sas\" + 0.008*\"sql\" + 0.007*\"spss\" + 0.006*\"mysql\" + 0.005*\"word\" + 0.005*\"data\" + 0.005*\"access\" + 0.005*\"linux\"\n",
      "INFO : topic #4 (0.056): 0.018*\"sql\" + 0.017*\"r\" + 0.016*\"python\" + 0.010*\"technical\" + 0.008*\"tableau\" + 0.008*\"matlab\" + 0.008*\"excel\" + 0.008*\"data\" + 0.007*\"javascript\" + 0.006*\"java\"\n",
      "INFO : topic #14 (0.056): 0.018*\"r\" + 0.017*\"sql\" + 0.016*\"python\" + 0.011*\"c++\" + 0.010*\"java\" + 0.009*\"technical\" + 0.009*\"tableau\" + 0.008*\"hadoop\" + 0.008*\"c\" + 0.008*\"matlab\"\n",
      "INFO : topic diff=0.273363, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.912 per-word bound, 481.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3882/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3896/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.056): 0.017*\"sql\" + 0.016*\"r\" + 0.014*\"python\" + 0.010*\"technical\" + 0.008*\"tableau\" + 0.007*\"excel\" + 0.007*\"data\" + 0.007*\"matlab\" + 0.006*\"javascript\" + 0.006*\"windows\"\n",
      "INFO : topic #5 (0.056): 0.008*\"technical\" + 0.008*\"sql\" + 0.006*\"excel\" + 0.005*\"taleo\" + 0.004*\"access\" + 0.004*\"r\" + 0.004*\"tableau\" + 0.004*\"k\" + 0.004*\"powerpoint\" + 0.004*\"data\"\n",
      "INFO : topic #0 (0.056): 0.014*\"sql\" + 0.009*\"technical\" + 0.008*\"python\" + 0.008*\"oracle\" + 0.008*\"r\" + 0.007*\"html\" + 0.007*\"java\" + 0.006*\"javascript\" + 0.006*\"linux\" + 0.006*\"mysql\"\n",
      "INFO : topic #11 (0.056): 0.043*\"r\" + 0.038*\"python\" + 0.038*\"sql\" + 0.033*\"sas\" + 0.022*\"matlab\" + 0.021*\"excel\" + 0.020*\"tableau\" + 0.016*\"c++\" + 0.016*\"technical\" + 0.016*\"spss\"\n",
      "INFO : topic #17 (0.056): 0.013*\"python\" + 0.012*\"r\" + 0.009*\"excel\" + 0.007*\"c\" + 0.007*\"technical\" + 0.007*\"c++\" + 0.007*\"sql\" + 0.005*\"matlab\" + 0.005*\"skills\" + 0.005*\"project\"\n",
      "INFO : topic diff=0.231769, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.861 per-word bound, 465.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3896/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #13 (0.056): 0.015*\"python\" + 0.014*\"technical\" + 0.014*\"sql\" + 0.012*\"sas\" + 0.012*\"tableau\" + 0.012*\"r\" + 0.010*\"html\" + 0.010*\"c++\" + 0.009*\"c\" + 0.008*\"java\"\n",
      "INFO : topic #14 (0.056): 0.015*\"r\" + 0.015*\"sql\" + 0.013*\"python\" + 0.010*\"c++\" + 0.008*\"technical\" + 0.008*\"java\" + 0.007*\"c\" + 0.007*\"tableau\" + 0.007*\"matlab\" + 0.007*\"hadoop\"\n",
      "INFO : topic #16 (0.056): 0.014*\"sql\" + 0.011*\"r\" + 0.008*\"python\" + 0.008*\"technical\" + 0.007*\"java\" + 0.006*\"c\" + 0.005*\"javascript\" + 0.004*\"sas\" + 0.004*\"oracle\" + 0.004*\"aws\"\n",
      "INFO : topic #2 (0.056): 0.007*\"r\" + 0.007*\"linux\" + 0.006*\"sql\" + 0.006*\"c++\" + 0.005*\"python\" + 0.004*\"windows\" + 0.004*\"technical\" + 0.004*\"data\" + 0.004*\"html\" + 0.004*\"computer\"\n",
      "INFO : topic #3 (0.056): 0.012*\"technical\" + 0.008*\"sql\" + 0.006*\"unix\" + 0.004*\"python\" + 0.004*\"linux\" + 0.003*\"r\" + 0.003*\"powershell\" + 0.003*\"powerpoint\" + 0.003*\"tableau\" + 0.003*\"word\"\n",
      "INFO : topic diff=0.193059, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.825 per-word bound, 453.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3923/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #6 (0.056): 0.030*\"python\" + 0.026*\"r\" + 0.022*\"sql\" + 0.022*\"pandas\" + 0.017*\"numpy\" + 0.016*\"scikit\" + 0.013*\"technical\" + 0.012*\"tableau\" + 0.011*\"scipy\" + 0.011*\"matplotlib\"\n",
      "INFO : topic #17 (0.056): 0.010*\"python\" + 0.009*\"r\" + 0.007*\"excel\" + 0.006*\"c\" + 0.006*\"technical\" + 0.006*\"c++\" + 0.005*\"project\" + 0.005*\"sql\" + 0.005*\"skills\" + 0.004*\"matlab\"\n",
      "INFO : topic #0 (0.056): 0.013*\"sql\" + 0.008*\"technical\" + 0.008*\"oracle\" + 0.007*\"html\" + 0.007*\"python\" + 0.006*\"r\" + 0.006*\"java\" + 0.006*\"pl\" + 0.006*\"javascript\" + 0.006*\"linux\"\n",
      "INFO : topic #10 (0.056): 0.007*\"excel\" + 0.007*\"r\" + 0.006*\"spss\" + 0.006*\"sas\" + 0.006*\"sql\" + 0.005*\"research\" + 0.004*\"word\" + 0.004*\"data\" + 0.004*\"skills\" + 0.004*\"linux\"\n",
      "INFO : topic #7 (0.056): 0.011*\"linux\" + 0.009*\"python\" + 0.008*\"sql\" + 0.007*\"c++\" + 0.006*\"hadoop\" + 0.005*\"c\" + 0.005*\"core\" + 0.005*\"hive\" + 0.004*\"r\" + 0.004*\"windows\"\n",
      "INFO : topic diff=0.159052, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.799 per-word bound, 445.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.056): 0.011*\"technical\" + 0.007*\"sql\" + 0.006*\"unix\" + 0.004*\"powershell\" + 0.003*\"linux\" + 0.003*\"python\" + 0.003*\"powerpoint\" + 0.003*\"testing\" + 0.002*\"oracle\" + 0.002*\"t\"\n",
      "INFO : topic #8 (0.056): 0.019*\"r\" + 0.018*\"python\" + 0.017*\"sql\" + 0.011*\"hive\" + 0.011*\"hadoop\" + 0.010*\"oracle\" + 0.010*\"technical\" + 0.009*\"java\" + 0.009*\"tableau\" + 0.009*\"c++\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #11 (0.056): 0.048*\"r\" + 0.042*\"sql\" + 0.041*\"python\" + 0.037*\"sas\" + 0.026*\"excel\" + 0.024*\"matlab\" + 0.022*\"tableau\" + 0.018*\"spss\" + 0.017*\"c++\" + 0.017*\"technical\"\n",
      "INFO : topic #14 (0.056): 0.013*\"r\" + 0.012*\"sql\" + 0.011*\"python\" + 0.008*\"english\" + 0.008*\"c++\" + 0.007*\"technical\" + 0.007*\"data\" + 0.006*\"java\" + 0.006*\"c\" + 0.006*\"tableau\"\n",
      "INFO : topic #6 (0.056): 0.030*\"python\" + 0.026*\"r\" + 0.023*\"pandas\" + 0.022*\"sql\" + 0.018*\"numpy\" + 0.016*\"scikit\" + 0.013*\"technical\" + 0.013*\"tableau\" + 0.012*\"scipy\" + 0.011*\"matplotlib\"\n",
      "INFO : topic diff=0.130593, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.779 per-word bound, 439.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #13 (0.056): 0.013*\"technical\" + 0.012*\"python\" + 0.012*\"sql\" + 0.011*\"sas\" + 0.011*\"tableau\" + 0.009*\"c++\" + 0.009*\"html\" + 0.009*\"r\" + 0.008*\"c\" + 0.007*\"linux\"\n",
      "INFO : topic #5 (0.056): 0.007*\"taleo\" + 0.007*\"technical\" + 0.005*\"sql\" + 0.005*\"jobvite\" + 0.004*\"excel\" + 0.004*\"key\" + 0.003*\"k\" + 0.003*\"icims\" + 0.003*\"access\" + 0.003*\"powerpoint\"\n",
      "INFO : topic #6 (0.056): 0.030*\"python\" + 0.026*\"r\" + 0.023*\"pandas\" + 0.023*\"sql\" + 0.018*\"numpy\" + 0.017*\"scikit\" + 0.014*\"technical\" + 0.013*\"tableau\" + 0.012*\"scipy\" + 0.011*\"matplotlib\"\n",
      "INFO : topic #9 (0.056): 0.031*\"java\" + 0.031*\"javascript\" + 0.030*\"html\" + 0.028*\"c\" + 0.028*\"python\" + 0.024*\"c++\" + 0.022*\"css\" + 0.019*\"sql\" + 0.018*\"mysql\" + 0.015*\"php\"\n",
      "INFO : topic #2 (0.056): 0.006*\"linux\" + 0.005*\"r\" + 0.004*\"sql\" + 0.004*\"c++\" + 0.004*\"windows\" + 0.003*\"data\" + 0.003*\"unix\" + 0.003*\"pl\" + 0.003*\"computer\" + 0.003*\"technical\"\n",
      "INFO : topic diff=0.107175, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.764 per-word bound, 434.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #16 (0.056): 0.010*\"sql\" + 0.007*\"r\" + 0.007*\"technical\" + 0.006*\"java\" + 0.005*\"python\" + 0.005*\"c\" + 0.004*\"db2\" + 0.004*\"oracle\" + 0.004*\"javascript\" + 0.004*\"stat\"\n",
      "INFO : topic #13 (0.056): 0.013*\"technical\" + 0.011*\"sql\" + 0.011*\"python\" + 0.010*\"sas\" + 0.010*\"tableau\" + 0.009*\"c++\" + 0.009*\"html\" + 0.008*\"r\" + 0.008*\"c\" + 0.007*\"linux\"\n",
      "INFO : topic #5 (0.056): 0.008*\"taleo\" + 0.007*\"technical\" + 0.005*\"jobvite\" + 0.004*\"sql\" + 0.004*\"excel\" + 0.004*\"key\" + 0.003*\"icims\" + 0.003*\"k\" + 0.003*\"powerpoint\" + 0.003*\"greenhouse\"\n",
      "INFO : topic #17 (0.056): 0.007*\"python\" + 0.006*\"excel\" + 0.006*\"r\" + 0.006*\"project\" + 0.005*\"skills\" + 0.005*\"c\" + 0.004*\"technical\" + 0.004*\"c++\" + 0.004*\"perl\" + 0.003*\"sql\"\n",
      "INFO : topic #10 (0.056): 0.006*\"excel\" + 0.006*\"research\" + 0.005*\"spss\" + 0.005*\"r\" + 0.004*\"sas\" + 0.004*\"skills\" + 0.004*\"data\" + 0.004*\"indesign\" + 0.004*\"photoshop\" + 0.004*\"sql\"\n",
      "INFO : topic diff=0.088518, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.751 per-word bound, 430.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.056): 0.007*\"hive\" + 0.007*\"python\" + 0.007*\"excel\" + 0.006*\"pig\" + 0.006*\"hdfs\" + 0.006*\"tableau\" + 0.006*\"hbase\" + 0.006*\"sql\" + 0.006*\"technical\" + 0.006*\"visio\"\n",
      "INFO : topic #8 (0.056): 0.016*\"r\" + 0.015*\"sql\" + 0.015*\"python\" + 0.011*\"hive\" + 0.010*\"hadoop\" + 0.010*\"oracle\" + 0.009*\"technical\" + 0.009*\"pig\" + 0.008*\"java\" + 0.008*\"tableau\"\n",
      "INFO : topic #7 (0.056): 0.010*\"linux\" + 0.007*\"python\" + 0.006*\"sql\" + 0.006*\"c++\" + 0.005*\"core\" + 0.004*\"hadoop\" + 0.004*\"xp\" + 0.004*\"windows\" + 0.004*\"c\" + 0.003*\"mapreduce\"\n",
      "INFO : topic #17 (0.056): 0.006*\"python\" + 0.006*\"project\" + 0.006*\"excel\" + 0.005*\"r\" + 0.005*\"skills\" + 0.004*\"c\" + 0.004*\"technical\" + 0.004*\"perl\" + 0.004*\"c++\" + 0.003*\"core\"\n",
      "INFO : topic #2 (0.056): 0.006*\"linux\" + 0.004*\"r\" + 0.004*\"sql\" + 0.004*\"c++\" + 0.003*\"windows\" + 0.003*\"data\" + 0.003*\"unix\" + 0.003*\"project\" + 0.003*\"pl\" + 0.003*\"computer\"\n",
      "INFO : topic diff=0.073545, rho=0.265989\n",
      "DEBUG : bound: at document #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : -8.741 per-word bound, 428.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.056): 0.006*\"linux\" + 0.003*\"r\" + 0.003*\"sql\" + 0.003*\"windows\" + 0.003*\"c++\" + 0.003*\"data\" + 0.003*\"unix\" + 0.003*\"project\" + 0.003*\"pl\" + 0.003*\"development\"\n",
      "INFO : topic #4 (0.056): 0.010*\"sql\" + 0.008*\"r\" + 0.007*\"technical\" + 0.006*\"data\" + 0.006*\"python\" + 0.005*\"windows\" + 0.005*\"excel\" + 0.004*\"oracle\" + 0.004*\"tableau\" + 0.003*\"skills\"\n",
      "INFO : topic #11 (0.056): 0.051*\"r\" + 0.044*\"sql\" + 0.042*\"python\" + 0.038*\"sas\" + 0.029*\"excel\" + 0.025*\"matlab\" + 0.024*\"tableau\" + 0.020*\"spss\" + 0.017*\"c++\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #0 (0.056): 0.011*\"sql\" + 0.008*\"oracle\" + 0.008*\"technical\" + 0.008*\"pl\" + 0.007*\"ssrs\" + 0.006*\"html\" + 0.006*\"agile\" + 0.006*\"sharepoint\" + 0.006*\"ssis\" + 0.005*\"access\"\n",
      "INFO : topic #3 (0.056): 0.010*\"technical\" + 0.006*\"unix\" + 0.005*\"sql\" + 0.004*\"powershell\" + 0.003*\"testing\" + 0.003*\"linux\" + 0.002*\"t\" + 0.002*\"oracle\" + 0.002*\"bigdata\" + 0.002*\"b.\"\n",
      "INFO : topic diff=0.061851, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.733 per-word bound, 425.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #17 (0.056): 0.006*\"project\" + 0.005*\"excel\" + 0.005*\"python\" + 0.005*\"skills\" + 0.004*\"r\" + 0.004*\"c\" + 0.003*\"core\" + 0.003*\"perl\" + 0.003*\"technical\" + 0.003*\"data\"\n",
      "INFO : topic #8 (0.056): 0.014*\"sql\" + 0.014*\"r\" + 0.013*\"python\" + 0.011*\"hive\" + 0.010*\"oracle\" + 0.010*\"hadoop\" + 0.009*\"technical\" + 0.009*\"pig\" + 0.008*\"java\" + 0.007*\"tableau\"\n",
      "INFO : topic #14 (0.056): 0.013*\"english\" + 0.008*\"r\" + 0.008*\"sql\" + 0.007*\"data\" + 0.007*\"python\" + 0.006*\"c++\" + 0.006*\"technical\" + 0.005*\"c\" + 0.004*\"french\" + 0.004*\"mandarin\"\n",
      "INFO : topic #12 (0.056): 0.007*\"hive\" + 0.007*\"excel\" + 0.006*\"hdfs\" + 0.006*\"tableau\" + 0.006*\"python\" + 0.006*\"pig\" + 0.006*\"databases\" + 0.006*\"visio\" + 0.006*\"hbase\" + 0.005*\"word\"\n",
      "INFO : topic #10 (0.056): 0.006*\"research\" + 0.005*\"indesign\" + 0.005*\"photoshop\" + 0.005*\"excel\" + 0.004*\"spss\" + 0.004*\"skills\" + 0.004*\"data\" + 0.004*\"relevant\" + 0.004*\"illustrator\" + 0.004*\"spanish\"\n",
      "INFO : topic diff=0.052591, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.725 per-word bound, 423.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.056): 0.014*\"sql\" + 0.014*\"r\" + 0.013*\"python\" + 0.011*\"hive\" + 0.010*\"oracle\" + 0.010*\"hadoop\" + 0.009*\"technical\" + 0.009*\"pig\" + 0.008*\"java\" + 0.007*\"tableau\"\n",
      "INFO : topic #2 (0.056): 0.005*\"linux\" + 0.003*\"data\" + 0.003*\"windows\" + 0.003*\"sql\" + 0.003*\"c++\" + 0.003*\"andexcel\" + 0.003*\"r\" + 0.003*\"project\" + 0.003*\"development\" + 0.002*\"microsoft\"\n",
      "INFO : topic #4 (0.056): 0.009*\"sql\" + 0.007*\"r\" + 0.006*\"technical\" + 0.006*\"data\" + 0.005*\"windows\" + 0.005*\"python\" + 0.004*\"excel\" + 0.004*\"oracle\" + 0.003*\"skills\" + 0.003*\"tableau\"\n",
      "INFO : topic #16 (0.056): 0.008*\"sql\" + 0.007*\"technical\" + 0.005*\"r\" + 0.005*\"java\" + 0.004*\"db2\" + 0.004*\"c\" + 0.004*\"oracle\" + 0.004*\"python\" + 0.004*\"stat\" + 0.004*\"databases\"\n",
      "INFO : topic #12 (0.056): 0.007*\"hive\" + 0.007*\"excel\" + 0.006*\"tableau\" + 0.006*\"hdfs\" + 0.006*\"pig\" + 0.006*\"databases\" + 0.006*\"python\" + 0.006*\"visio\" + 0.006*\"unix\" + 0.006*\"word\"\n",
      "INFO : topic diff=0.045219, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.720 per-word bound, 421.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.056): 0.008*\"sql\" + 0.006*\"r\" + 0.006*\"technical\" + 0.006*\"data\" + 0.005*\"windows\" + 0.004*\"python\" + 0.004*\"excel\" + 0.004*\"oracle\" + 0.003*\"skills\" + 0.003*\"ms_excel\"\n",
      "INFO : topic #10 (0.056): 0.006*\"research\" + 0.006*\"indesign\" + 0.005*\"photoshop\" + 0.004*\"excel\" + 0.004*\"spss\" + 0.004*\"illustrator\" + 0.004*\"skills\" + 0.004*\"relevant\" + 0.004*\"data\" + 0.004*\"spanish\"\n",
      "INFO : topic #8 (0.056): 0.014*\"sql\" + 0.013*\"r\" + 0.012*\"python\" + 0.011*\"hive\" + 0.010*\"oracle\" + 0.009*\"hadoop\" + 0.009*\"pig\" + 0.008*\"technical\" + 0.007*\"java\" + 0.007*\"sqoop\"\n",
      "INFO : topic #3 (0.056): 0.010*\"technical\" + 0.006*\"unix\" + 0.005*\"sql\" + 0.004*\"powershell\" + 0.003*\"testing\" + 0.002*\"linux\" + 0.002*\"t\" + 0.002*\"data\" + 0.002*\"bigdata\" + 0.002*\"b.\"\n",
      "INFO : topic #16 (0.056): 0.007*\"sql\" + 0.006*\"technical\" + 0.005*\"r\" + 0.005*\"java\" + 0.004*\"db2\" + 0.004*\"c\" + 0.004*\"oracle\" + 0.004*\"databases\" + 0.004*\"stat\" + 0.004*\"python\"\n",
      "INFO : topic diff=0.039388, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.714 per-word bound, 420.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.056): 0.010*\"technical\" + 0.008*\"java\" + 0.008*\"sql\" + 0.007*\"python\" + 0.006*\"ms\" + 0.005*\"c\" + 0.005*\"r\" + 0.005*\"html\" + 0.005*\"javascript\" + 0.004*\"oracle\"\n",
      "INFO : topic #8 (0.056): 0.013*\"sql\" + 0.012*\"r\" + 0.011*\"python\" + 0.011*\"hive\" + 0.010*\"oracle\" + 0.009*\"hadoop\" + 0.009*\"pig\" + 0.008*\"technical\" + 0.007*\"java\" + 0.007*\"sqoop\"\n",
      "INFO : topic #11 (0.056): 0.052*\"r\" + 0.045*\"sql\" + 0.043*\"python\" + 0.039*\"sas\" + 0.030*\"excel\" + 0.025*\"matlab\" + 0.024*\"tableau\" + 0.020*\"spss\" + 0.018*\"powerpoint\" + 0.018*\"c++\"\n",
      "INFO : topic #5 (0.056): 0.008*\"taleo\" + 0.006*\"technical\" + 0.005*\"jobvite\" + 0.004*\"key\" + 0.004*\"icims\" + 0.003*\"greenhouse\" + 0.003*\"brassring\" + 0.003*\"workday\" + 0.003*\"dice\" + 0.003*\"salesforce\"\n",
      "INFO : topic #10 (0.056): 0.006*\"research\" + 0.006*\"indesign\" + 0.005*\"photoshop\" + 0.004*\"illustrator\" + 0.004*\"skills\" + 0.004*\"excel\" + 0.004*\"spss\" + 0.004*\"relevant\" + 0.004*\"data\" + 0.004*\"spanish\"\n",
      "INFO : topic diff=0.034589, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.708 per-word bound, 418.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #13 (0.056): 0.011*\"technical\" + 0.009*\"sql\" + 0.008*\"sas\" + 0.008*\"c++\" + 0.008*\"html\" + 0.007*\"tableau\" + 0.007*\"python\" + 0.006*\"c\" + 0.006*\"linux\" + 0.006*\"unix\"\n",
      "INFO : topic #6 (0.056): 0.032*\"python\" + 0.027*\"r\" + 0.026*\"pandas\" + 0.024*\"sql\" + 0.021*\"numpy\" + 0.018*\"scikit\" + 0.015*\"technical\" + 0.013*\"scipy\" + 0.013*\"tableau\" + 0.012*\"tensorflow\"\n",
      "INFO : topic #1 (0.056): 0.009*\"technical\" + 0.007*\"java\" + 0.007*\"sql\" + 0.007*\"python\" + 0.006*\"ms\" + 0.005*\"c\" + 0.004*\"r\" + 0.004*\"oracle\" + 0.004*\"html\" + 0.004*\"jira\"\n",
      "INFO : topic #10 (0.056): 0.006*\"indesign\" + 0.006*\"research\" + 0.006*\"photoshop\" + 0.004*\"illustrator\" + 0.004*\"skills\" + 0.004*\"relevant\" + 0.004*\"data\" + 0.004*\"spss\" + 0.004*\"excel\" + 0.004*\"spanish\"\n",
      "INFO : topic #5 (0.056): 0.008*\"taleo\" + 0.006*\"technical\" + 0.005*\"jobvite\" + 0.004*\"key\" + 0.004*\"icims\" + 0.003*\"greenhouse\" + 0.003*\"brassring\" + 0.003*\"workday\" + 0.003*\"salesforce\" + 0.003*\"dice\"\n",
      "INFO : topic diff=0.030702, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.704 per-word bound, 417.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #15 (0.056): 0.032*\"python\" + 0.030*\"r\" + 0.028*\"sql\" + 0.028*\"hadoop\" + 0.027*\"hive\" + 0.021*\"spark\" + 0.020*\"java\" + 0.018*\"pig\" + 0.017*\"tableau\" + 0.015*\"technical\"\n",
      "INFO : topic #2 (0.056): 0.003*\"andexcel\" + 0.003*\"linux\" + 0.003*\"data\" + 0.003*\"development\" + 0.003*\"project\" + 0.002*\"analysis\" + 0.002*\"microsoft\" + 0.002*\"software\" + 0.002*\"team\" + 0.002*\"core\"\n",
      "INFO : topic #8 (0.056): 0.013*\"sql\" + 0.011*\"r\" + 0.010*\"python\" + 0.010*\"hive\" + 0.010*\"oracle\" + 0.009*\"hadoop\" + 0.008*\"pig\" + 0.008*\"technical\" + 0.007*\"sqoop\" + 0.007*\"hbase\"\n",
      "INFO : topic #9 (0.056): 0.034*\"javascript\" + 0.033*\"java\" + 0.032*\"html\" + 0.030*\"c\" + 0.029*\"python\" + 0.026*\"c++\" + 0.025*\"css\" + 0.020*\"mysql\" + 0.019*\"sql\" + 0.016*\"php\"\n",
      "INFO : topic #3 (0.056): 0.009*\"technical\" + 0.006*\"unix\" + 0.004*\"sql\" + 0.004*\"powershell\" + 0.003*\"testing\" + 0.002*\"data\" + 0.002*\"t\" + 0.002*\"linux\" + 0.002*\"bigdata\" + 0.002*\"datamining\"\n",
      "INFO : topic diff=0.027549, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.699 per-word bound, 415.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.056): 0.052*\"r\" + 0.046*\"sql\" + 0.043*\"python\" + 0.039*\"sas\" + 0.031*\"excel\" + 0.025*\"matlab\" + 0.025*\"tableau\" + 0.020*\"spss\" + 0.018*\"powerpoint\" + 0.018*\"c++\"\n",
      "INFO : topic #0 (0.056): 0.010*\"sql\" + 0.010*\"pl\" + 0.009*\"oracle\" + 0.009*\"ssrs\" + 0.009*\"ssis\" + 0.008*\"technical\" + 0.007*\"agile\" + 0.007*\"sharepoint\" + 0.007*\"t\" + 0.006*\"visio\"\n",
      "INFO : topic #14 (0.056): 0.017*\"english\" + 0.007*\"data\" + 0.006*\"french\" + 0.006*\"mandarin\" + 0.005*\"sql\" + 0.005*\"r\" + 0.004*\"c++\" + 0.004*\"technical\" + 0.004*\"native\" + 0.004*\"analytics\"\n",
      "INFO : topic #17 (0.056): 0.006*\"project\" + 0.005*\"skills\" + 0.004*\"excel\" + 0.004*\"core\" + 0.003*\"professional\" + 0.003*\"perl\" + 0.003*\"data\" + 0.003*\"python\" + 0.003*\"ms\" + 0.002*\"microsoft\"\n",
      "INFO : topic #13 (0.056): 0.011*\"technical\" + 0.008*\"sql\" + 0.008*\"sas\" + 0.007*\"c++\" + 0.007*\"html\" + 0.006*\"tableau\" + 0.006*\"c\" + 0.006*\"python\" + 0.006*\"unix\" + 0.006*\"linux\"\n",
      "INFO : topic diff=0.024918, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.695 per-word bound, 414.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.056): 0.003*\"andexcel\" + 0.003*\"data\" + 0.003*\"development\" + 0.003*\"project\" + 0.003*\"linux\" + 0.002*\"analysis\" + 0.002*\"may\" + 0.002*\"core\" + 0.002*\"microsoft\" + 0.002*\"team\"\n",
      "INFO : topic #11 (0.056): 0.053*\"r\" + 0.046*\"sql\" + 0.044*\"python\" + 0.039*\"sas\" + 0.031*\"excel\" + 0.026*\"matlab\" + 0.025*\"tableau\" + 0.020*\"spss\" + 0.018*\"powerpoint\" + 0.018*\"c++\"\n",
      "INFO : topic #13 (0.056): 0.010*\"technical\" + 0.008*\"sql\" + 0.008*\"sas\" + 0.007*\"c++\" + 0.007*\"html\" + 0.006*\"tableau\" + 0.006*\"c\" + 0.006*\"unix\" + 0.005*\"python\" + 0.005*\"linux\"\n",
      "INFO : topic #6 (0.056): 0.032*\"python\" + 0.028*\"r\" + 0.026*\"pandas\" + 0.024*\"sql\" + 0.021*\"numpy\" + 0.018*\"scikit\" + 0.015*\"technical\" + 0.013*\"scipy\" + 0.013*\"tableau\" + 0.012*\"tensorflow\"\n",
      "INFO : topic #3 (0.056): 0.009*\"technical\" + 0.005*\"unix\" + 0.004*\"powershell\" + 0.004*\"sql\" + 0.003*\"testing\" + 0.002*\"data\" + 0.002*\"datamining\" + 0.002*\"bigdata\" + 0.002*\"t\" + 0.002*\"ibm_aix\"\n",
      "INFO : topic diff=0.022696, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.692 per-word bound, 413.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=18, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=18, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (451 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (321 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (456 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (388 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (536 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (592 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (629 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (572 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (542 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (565 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (437 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (478 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (588 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (577 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (586 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (654 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (636 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (693 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (693 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (730 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (730 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 512 documents processed (529 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (384 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 8; 576 documents processed (640 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (529 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (448 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (640 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (656 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (656 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 6; 448 documents processed (590 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (641 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (590 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (641 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (542 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 448 documents processed (542 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (650 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (636 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 512 documents processed (650 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 576 documents processed (731 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (710 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (731 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 9; 639 documents processed (826 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 639 documents processed (826 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 448 documents processed (710 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9406 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12421/12537 documents converged within 50 iterations\n",
      " 70%|██████▉   | 16/23 [06:55<03:01, 25.95s/it]INFO : using symmetric alpha at 0.05263157894736842\n",
      "INFO : using symmetric eta at 0.05263157894736842\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 19 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 437/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3270/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3398/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3189/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #18 (0.053): 0.018*\"python\" + 0.013*\"r\" + 0.013*\"sql\" + 0.012*\"java\" + 0.011*\"hadoop\" + 0.011*\"javascript\" + 0.010*\"html\" + 0.010*\"mysql\" + 0.009*\"c++\" + 0.006*\"sas\"\n",
      "INFO : topic #2 (0.053): 0.011*\"r\" + 0.011*\"sql\" + 0.010*\"python\" + 0.009*\"c++\" + 0.009*\"linux\" + 0.008*\"java\" + 0.007*\"c\" + 0.007*\"windows\" + 0.007*\"sas\" + 0.006*\"programming\"\n",
      "INFO : topic #0 (0.053): 0.018*\"sql\" + 0.014*\"python\" + 0.014*\"r\" + 0.009*\"technical\" + 0.008*\"javascript\" + 0.008*\"html\" + 0.008*\"java\" + 0.008*\"hive\" + 0.008*\"oracle\" + 0.007*\"excel\"\n",
      "INFO : topic #1 (0.053): 0.023*\"python\" + 0.018*\"r\" + 0.017*\"java\" + 0.017*\"technical\" + 0.017*\"sql\" + 0.012*\"c\" + 0.012*\"c++\" + 0.010*\"html\" + 0.010*\"mysql\" + 0.009*\"javascript\"\n",
      "INFO : topic #12 (0.053): 0.020*\"python\" + 0.016*\"r\" + 0.014*\"sql\" + 0.013*\"java\" + 0.011*\"hive\" + 0.011*\"tableau\" + 0.011*\"mysql\" + 0.010*\"hadoop\" + 0.010*\"c\" + 0.010*\"spark\"\n",
      "INFO : topic diff=14.368179, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.342 per-word bound, 649.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3777/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3785/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3842/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.053): 0.027*\"r\" + 0.025*\"python\" + 0.023*\"sql\" + 0.014*\"tableau\" + 0.012*\"hadoop\" + 0.011*\"hive\" + 0.010*\"java\" + 0.010*\"c++\" + 0.010*\"technical\" + 0.009*\"oracle\"\n",
      "INFO : topic #15 (0.053): 0.030*\"python\" + 0.030*\"sql\" + 0.029*\"r\" + 0.017*\"java\" + 0.017*\"matlab\" + 0.017*\"hadoop\" + 0.016*\"c\" + 0.016*\"tableau\" + 0.015*\"c++\" + 0.013*\"hive\"\n",
      "INFO : topic #6 (0.053): 0.025*\"python\" + 0.024*\"r\" + 0.020*\"sql\" + 0.013*\"sas\" + 0.013*\"technical\" + 0.011*\"tableau\" + 0.010*\"pandas\" + 0.010*\"mysql\" + 0.009*\"matlab\" + 0.009*\"statistical\"\n",
      "INFO : topic #3 (0.053): 0.014*\"technical\" + 0.012*\"sql\" + 0.009*\"python\" + 0.008*\"unix\" + 0.008*\"r\" + 0.007*\"tableau\" + 0.006*\"linux\" + 0.006*\"java\" + 0.005*\"html\" + 0.005*\"c++\"\n",
      "INFO : topic #0 (0.053): 0.016*\"sql\" + 0.012*\"python\" + 0.011*\"r\" + 0.008*\"technical\" + 0.008*\"java\" + 0.008*\"html\" + 0.008*\"javascript\" + 0.008*\"oracle\" + 0.007*\"hive\" + 0.006*\"mysql\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.357617, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.115 per-word bound, 554.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3838/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3873/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.053): 0.014*\"sql\" + 0.011*\"technical\" + 0.008*\"r\" + 0.007*\"oracle\" + 0.007*\"access\" + 0.007*\"excel\" + 0.006*\"python\" + 0.006*\"linux\" + 0.006*\"powerpoint\" + 0.005*\"sas\"\n",
      "INFO : topic #10 (0.053): 0.013*\"r\" + 0.011*\"sas\" + 0.010*\"excel\" + 0.009*\"sql\" + 0.009*\"spss\" + 0.008*\"word\" + 0.008*\"powerpoint\" + 0.007*\"access\" + 0.006*\"mysql\" + 0.006*\"python\"\n",
      "INFO : topic #8 (0.053): 0.025*\"r\" + 0.024*\"python\" + 0.022*\"sql\" + 0.013*\"tableau\" + 0.012*\"hadoop\" + 0.011*\"hive\" + 0.010*\"java\" + 0.010*\"technical\" + 0.010*\"c++\" + 0.009*\"oracle\"\n",
      "INFO : topic #11 (0.053): 0.039*\"r\" + 0.036*\"python\" + 0.033*\"sql\" + 0.028*\"sas\" + 0.021*\"matlab\" + 0.018*\"tableau\" + 0.017*\"c++\" + 0.015*\"technical\" + 0.014*\"excel\" + 0.013*\"java\"\n",
      "INFO : topic #18 (0.053): 0.014*\"python\" + 0.012*\"java\" + 0.011*\"javascript\" + 0.011*\"sql\" + 0.010*\"html\" + 0.010*\"mysql\" + 0.010*\"hadoop\" + 0.009*\"r\" + 0.008*\"c++\" + 0.007*\"xml\"\n",
      "INFO : topic diff=0.320866, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.999 per-word bound, 511.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3890/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3884/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.053): 0.011*\"r\" + 0.011*\"excel\" + 0.010*\"sas\" + 0.009*\"word\" + 0.009*\"powerpoint\" + 0.008*\"sql\" + 0.008*\"spss\" + 0.008*\"access\" + 0.005*\"mysql\" + 0.005*\"english\"\n",
      "INFO : topic #16 (0.053): 0.016*\"sql\" + 0.013*\"r\" + 0.013*\"python\" + 0.010*\"java\" + 0.008*\"technical\" + 0.006*\"sas\" + 0.006*\"c\" + 0.006*\"javascript\" + 0.004*\"pandas\" + 0.004*\"mysql\"\n",
      "INFO : topic #18 (0.053): 0.013*\"python\" + 0.012*\"java\" + 0.011*\"javascript\" + 0.010*\"mysql\" + 0.010*\"html\" + 0.010*\"sql\" + 0.010*\"hadoop\" + 0.008*\"c++\" + 0.008*\"xml\" + 0.008*\"r\"\n",
      "INFO : topic #9 (0.053): 0.026*\"python\" + 0.024*\"c\" + 0.024*\"html\" + 0.022*\"java\" + 0.021*\"sql\" + 0.019*\"javascript\" + 0.018*\"c++\" + 0.017*\"css\" + 0.017*\"r\" + 0.014*\"technical\"\n",
      "INFO : topic #11 (0.053): 0.042*\"r\" + 0.039*\"python\" + 0.036*\"sql\" + 0.031*\"sas\" + 0.023*\"matlab\" + 0.019*\"tableau\" + 0.018*\"c++\" + 0.016*\"excel\" + 0.015*\"technical\" + 0.014*\"spss\"\n",
      "INFO : topic diff=0.281089, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.924 per-word bound, 485.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3895/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3916/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.053): 0.013*\"sql\" + 0.008*\"python\" + 0.008*\"technical\" + 0.007*\"r\" + 0.007*\"oracle\" + 0.007*\"java\" + 0.007*\"html\" + 0.007*\"javascript\" + 0.006*\"c\" + 0.005*\"hive\"\n",
      "INFO : topic #9 (0.053): 0.026*\"python\" + 0.026*\"html\" + 0.025*\"c\" + 0.023*\"java\" + 0.022*\"javascript\" + 0.020*\"sql\" + 0.019*\"css\" + 0.019*\"c++\" + 0.017*\"r\" + 0.014*\"technical\"\n",
      "INFO : topic #6 (0.053): 0.029*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.017*\"pandas\" + 0.015*\"technical\" + 0.013*\"numpy\" + 0.013*\"tableau\" + 0.012*\"scikit\" + 0.012*\"sas\" + 0.010*\"hadoop\"\n",
      "INFO : topic #2 (0.053): 0.007*\"r\" + 0.007*\"c++\" + 0.006*\"linux\" + 0.006*\"sql\" + 0.006*\"python\" + 0.005*\"c\" + 0.005*\"computer\" + 0.005*\"windows\" + 0.004*\"java\" + 0.004*\"programming\"\n",
      "INFO : topic #1 (0.053): 0.018*\"python\" + 0.016*\"java\" + 0.015*\"technical\" + 0.013*\"r\" + 0.013*\"sql\" + 0.011*\"c\" + 0.009*\"html\" + 0.009*\"c++\" + 0.009*\"mysql\" + 0.008*\"javascript\"\n",
      "INFO : topic diff=0.239543, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.871 per-word bound, 468.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3917/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.053): 0.011*\"technical\" + 0.008*\"unix\" + 0.007*\"sql\" + 0.006*\"linux\" + 0.004*\"tableau\" + 0.004*\"r\" + 0.004*\"python\" + 0.004*\"html\" + 0.003*\"oracle\" + 0.003*\"windows\"\n",
      "INFO : topic #15 (0.053): 0.033*\"python\" + 0.031*\"r\" + 0.030*\"sql\" + 0.021*\"hadoop\" + 0.021*\"java\" + 0.018*\"c\" + 0.018*\"hive\" + 0.017*\"c++\" + 0.016*\"tableau\" + 0.016*\"matlab\"\n",
      "INFO : topic #18 (0.053): 0.012*\"java\" + 0.011*\"javascript\" + 0.011*\"python\" + 0.010*\"mysql\" + 0.010*\"html\" + 0.009*\"hadoop\" + 0.009*\"sql\" + 0.009*\"jsp\" + 0.009*\"xml\" + 0.008*\"spring\"\n",
      "INFO : topic #11 (0.053): 0.048*\"r\" + 0.042*\"python\" + 0.040*\"sql\" + 0.035*\"sas\" + 0.025*\"matlab\" + 0.021*\"tableau\" + 0.021*\"excel\" + 0.019*\"c++\" + 0.017*\"spss\" + 0.015*\"technical\"\n",
      "INFO : topic #12 (0.053): 0.012*\"python\" + 0.010*\"tableau\" + 0.010*\"r\" + 0.010*\"sql\" + 0.010*\"hive\" + 0.007*\"java\" + 0.007*\"excel\" + 0.007*\"mysql\" + 0.007*\"hadoop\" + 0.007*\"pig\"\n",
      "INFO : topic diff=0.200114, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.833 per-word bound, 456.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3915/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.053): 0.016*\"python\" + 0.014*\"java\" + 0.014*\"technical\" + 0.011*\"r\" + 0.011*\"sql\" + 0.010*\"c\" + 0.008*\"html\" + 0.008*\"mysql\" + 0.008*\"c++\" + 0.007*\"javascript\"\n",
      "INFO : topic #6 (0.053): 0.030*\"python\" + 0.028*\"r\" + 0.024*\"sql\" + 0.020*\"pandas\" + 0.016*\"technical\" + 0.016*\"numpy\" + 0.014*\"scikit\" + 0.014*\"tableau\" + 0.012*\"hadoop\" + 0.011*\"sas\"\n",
      "INFO : topic #17 (0.053): 0.012*\"python\" + 0.008*\"r\" + 0.006*\"skills\" + 0.006*\"sql\" + 0.006*\"excel\" + 0.005*\"tableau\" + 0.005*\"c++\" + 0.005*\"c\" + 0.005*\"technical\" + 0.005*\"data\"\n",
      "INFO : topic #0 (0.053): 0.012*\"sql\" + 0.008*\"technical\" + 0.007*\"oracle\" + 0.007*\"python\" + 0.006*\"html\" + 0.006*\"java\" + 0.006*\"r\" + 0.006*\"javascript\" + 0.005*\"c\" + 0.005*\"pl\"\n",
      "INFO : topic #7 (0.053): 0.016*\"linux\" + 0.011*\"sql\" + 0.009*\"python\" + 0.007*\"c++\" + 0.006*\"windows\" + 0.006*\"excel\" + 0.006*\"matlab\" + 0.006*\"hive\" + 0.006*\"hadoop\" + 0.005*\"core\"\n",
      "INFO : topic diff=0.165126, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.804 per-word bound, 447.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.053): 0.011*\"sql\" + 0.008*\"technical\" + 0.007*\"oracle\" + 0.006*\"html\" + 0.006*\"python\" + 0.006*\"java\" + 0.006*\"pl\" + 0.005*\"javascript\" + 0.005*\"c\" + 0.005*\"r\"\n",
      "INFO : topic #7 (0.053): 0.015*\"linux\" + 0.010*\"sql\" + 0.008*\"python\" + 0.007*\"c++\" + 0.006*\"windows\" + 0.006*\"excel\" + 0.005*\"core\" + 0.005*\"matlab\" + 0.005*\"hive\" + 0.005*\"hadoop\"\n",
      "INFO : topic #6 (0.053): 0.031*\"python\" + 0.028*\"r\" + 0.024*\"sql\" + 0.020*\"pandas\" + 0.016*\"numpy\" + 0.016*\"technical\" + 0.015*\"scikit\" + 0.014*\"tableau\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #18 (0.053): 0.012*\"java\" + 0.011*\"javascript\" + 0.010*\"jsp\" + 0.010*\"mysql\" + 0.009*\"html\" + 0.009*\"xml\" + 0.009*\"spring\" + 0.009*\"python\" + 0.009*\"hadoop\" + 0.008*\"eclipse\"\n",
      "INFO : topic #12 (0.053): 0.010*\"tableau\" + 0.010*\"python\" + 0.009*\"hive\" + 0.009*\"sql\" + 0.008*\"r\" + 0.007*\"excel\" + 0.007*\"pig\" + 0.006*\"java\" + 0.006*\"mysql\" + 0.006*\"hdfs\"\n",
      "INFO : topic diff=0.136035, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.783 per-word bound, 440.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.053): 0.013*\"python\" + 0.013*\"technical\" + 0.013*\"java\" + 0.010*\"sql\" + 0.010*\"r\" + 0.008*\"c\" + 0.007*\"html\" + 0.007*\"mysql\" + 0.007*\"c++\" + 0.006*\"jira\"\n",
      "INFO : topic #0 (0.053): 0.011*\"sql\" + 0.008*\"technical\" + 0.007*\"oracle\" + 0.006*\"html\" + 0.006*\"pl\" + 0.005*\"java\" + 0.005*\"ssrs\" + 0.005*\"t\" + 0.005*\"c\" + 0.005*\"python\"\n",
      "INFO : topic #8 (0.053): 0.016*\"r\" + 0.016*\"python\" + 0.015*\"sql\" + 0.010*\"hive\" + 0.010*\"oracle\" + 0.009*\"tableau\" + 0.009*\"hadoop\" + 0.009*\"technical\" + 0.008*\"java\" + 0.007*\"spark\"\n",
      "INFO : topic #5 (0.053): 0.009*\"technical\" + 0.009*\"sql\" + 0.007*\"oracle\" + 0.005*\"access\" + 0.005*\"linux\" + 0.005*\"teradata\" + 0.005*\"excel\" + 0.004*\"powerpoint\" + 0.004*\"key\" + 0.004*\"ms\"\n",
      "INFO : topic #15 (0.053): 0.033*\"python\" + 0.031*\"r\" + 0.029*\"sql\" + 0.023*\"hadoop\" + 0.022*\"java\" + 0.020*\"hive\" + 0.018*\"c\" + 0.018*\"c++\" + 0.017*\"tableau\" + 0.016*\"spark\"\n",
      "INFO : topic diff=0.112007, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.767 per-word bound, 435.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.053): 0.031*\"html\" + 0.031*\"javascript\" + 0.029*\"python\" + 0.028*\"c\" + 0.028*\"java\" + 0.025*\"css\" + 0.022*\"c++\" + 0.020*\"sql\" + 0.017*\"mysql\" + 0.017*\"php\"\n",
      "INFO : topic #8 (0.053): 0.015*\"r\" + 0.015*\"sql\" + 0.015*\"python\" + 0.010*\"hive\" + 0.010*\"oracle\" + 0.009*\"tableau\" + 0.009*\"hadoop\" + 0.009*\"technical\" + 0.008*\"java\" + 0.007*\"spark\"\n",
      "INFO : topic #13 (0.053): 0.015*\"technical\" + 0.014*\"sql\" + 0.013*\"html\" + 0.011*\"sas\" + 0.011*\"python\" + 0.011*\"tableau\" + 0.010*\"r\" + 0.008*\"c++\" + 0.008*\"c\" + 0.008*\"java\"\n",
      "INFO : topic #5 (0.053): 0.009*\"technical\" + 0.008*\"sql\" + 0.007*\"oracle\" + 0.005*\"teradata\" + 0.005*\"linux\" + 0.005*\"access\" + 0.004*\"excel\" + 0.004*\"powerpoint\" + 0.004*\"key\" + 0.004*\"ms\"\n",
      "INFO : topic #3 (0.053): 0.009*\"technical\" + 0.009*\"unix\" + 0.006*\"linux\" + 0.005*\"sql\" + 0.003*\"tableau\" + 0.003*\"powershell\" + 0.003*\"html\" + 0.003*\"windows\" + 0.002*\"testing\" + 0.002*\"oracle\"\n",
      "INFO : topic diff=0.092642, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.753 per-word bound, 431.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #16 (0.053): 0.009*\"sql\" + 0.007*\"r\" + 0.006*\"java\" + 0.006*\"technical\" + 0.006*\"python\" + 0.005*\"stat\" + 0.004*\"databases\" + 0.004*\"sas\" + 0.004*\"base\" + 0.004*\"c\"\n",
      "INFO : topic #15 (0.053): 0.033*\"python\" + 0.031*\"r\" + 0.029*\"sql\" + 0.024*\"hadoop\" + 0.022*\"java\" + 0.021*\"hive\" + 0.019*\"c\" + 0.018*\"c++\" + 0.017*\"tableau\" + 0.016*\"spark\"\n",
      "INFO : topic #14 (0.053): 0.014*\"sql\" + 0.012*\"r\" + 0.011*\"python\" + 0.008*\"java\" + 0.008*\"c++\" + 0.007*\"technical\" + 0.006*\"tableau\" + 0.006*\"data\" + 0.006*\"c\" + 0.006*\"spark\"\n",
      "INFO : topic #12 (0.053): 0.010*\"tableau\" + 0.008*\"hive\" + 0.008*\"python\" + 0.007*\"excel\" + 0.007*\"sql\" + 0.007*\"pig\" + 0.006*\"databases\" + 0.006*\"windows\" + 0.006*\"visio\" + 0.006*\"hdfs\"\n",
      "INFO : topic #13 (0.053): 0.014*\"technical\" + 0.014*\"sql\" + 0.012*\"html\" + 0.011*\"sas\" + 0.010*\"tableau\" + 0.010*\"python\" + 0.009*\"r\" + 0.008*\"c++\" + 0.008*\"c\" + 0.007*\"java\"\n",
      "INFO : topic diff=0.077134, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.741 per-word bound, 428.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.053): 0.033*\"javascript\" + 0.032*\"html\" + 0.029*\"python\" + 0.029*\"java\" + 0.029*\"c\" + 0.027*\"css\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.018*\"mysql\" + 0.018*\"php\"\n",
      "INFO : topic #2 (0.053): 0.005*\"c++\" + 0.005*\"computer\" + 0.004*\"linux\" + 0.004*\"r\" + 0.004*\"data\" + 0.004*\"c\" + 0.003*\"windows\" + 0.003*\"sql\" + 0.003*\"team\" + 0.003*\"python\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #15 (0.053): 0.033*\"python\" + 0.031*\"r\" + 0.029*\"sql\" + 0.024*\"hadoop\" + 0.022*\"java\" + 0.021*\"hive\" + 0.019*\"c\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.016*\"spark\"\n",
      "INFO : topic #4 (0.053): 0.011*\"sql\" + 0.010*\"r\" + 0.008*\"data\" + 0.008*\"python\" + 0.008*\"matlab\" + 0.007*\"technical\" + 0.006*\"excel\" + 0.004*\"c++\" + 0.004*\"c\" + 0.004*\"oracle\"\n",
      "INFO : topic #13 (0.053): 0.014*\"technical\" + 0.014*\"sql\" + 0.012*\"html\" + 0.011*\"sas\" + 0.010*\"tableau\" + 0.009*\"python\" + 0.009*\"r\" + 0.008*\"c++\" + 0.008*\"c\" + 0.007*\"java\"\n",
      "INFO : topic diff=0.064932, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.732 per-word bound, 425.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.053): 0.014*\"linux\" + 0.007*\"sql\" + 0.006*\"core\" + 0.006*\"taleo\" + 0.006*\"windows\" + 0.005*\"project\" + 0.005*\"excel\" + 0.005*\"jobvite\" + 0.005*\"linkedin\" + 0.005*\"python\"\n",
      "INFO : topic #10 (0.053): 0.014*\"english\" + 0.010*\"excel\" + 0.009*\"powerpoint\" + 0.009*\"word\" + 0.007*\"outlook\" + 0.006*\"access\" + 0.006*\"french\" + 0.005*\"spanish\" + 0.004*\"data\" + 0.004*\"research\"\n",
      "INFO : topic #16 (0.053): 0.008*\"sql\" + 0.006*\"r\" + 0.006*\"technical\" + 0.005*\"java\" + 0.005*\"stat\" + 0.005*\"python\" + 0.004*\"base\" + 0.004*\"databases\" + 0.004*\"ets\" + 0.004*\"graph\"\n",
      "INFO : topic #14 (0.053): 0.013*\"sql\" + 0.010*\"r\" + 0.010*\"python\" + 0.007*\"java\" + 0.007*\"c++\" + 0.006*\"data\" + 0.006*\"technical\" + 0.006*\"tableau\" + 0.005*\"c\" + 0.005*\"spark\"\n",
      "INFO : topic #13 (0.053): 0.013*\"technical\" + 0.013*\"sql\" + 0.012*\"html\" + 0.010*\"sas\" + 0.010*\"tableau\" + 0.008*\"python\" + 0.008*\"r\" + 0.008*\"c++\" + 0.007*\"c\" + 0.007*\"linux\"\n",
      "INFO : topic diff=0.055387, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.723 per-word bound, 422.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.053): 0.012*\"sql\" + 0.011*\"python\" + 0.011*\"r\" + 0.010*\"oracle\" + 0.009*\"hive\" + 0.008*\"technical\" + 0.007*\"s3\" + 0.007*\"hadoop\" + 0.007*\"tableau\" + 0.007*\"sqoop\"\n",
      "INFO : topic #12 (0.053): 0.009*\"tableau\" + 0.007*\"excel\" + 0.007*\"hive\" + 0.007*\"python\" + 0.007*\"unix\" + 0.007*\"windows\" + 0.007*\"databases\" + 0.006*\"pig\" + 0.006*\"sql\" + 0.006*\"visio\"\n",
      "INFO : topic #11 (0.053): 0.055*\"r\" + 0.046*\"python\" + 0.046*\"sql\" + 0.040*\"sas\" + 0.028*\"excel\" + 0.028*\"matlab\" + 0.024*\"tableau\" + 0.021*\"c++\" + 0.021*\"spss\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #15 (0.053): 0.032*\"python\" + 0.030*\"r\" + 0.029*\"sql\" + 0.025*\"hadoop\" + 0.022*\"java\" + 0.022*\"hive\" + 0.019*\"c\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.017*\"spark\"\n",
      "INFO : topic #13 (0.053): 0.013*\"technical\" + 0.013*\"sql\" + 0.012*\"html\" + 0.010*\"sas\" + 0.009*\"tableau\" + 0.008*\"python\" + 0.008*\"c++\" + 0.007*\"r\" + 0.007*\"c\" + 0.006*\"linux\"\n",
      "INFO : topic diff=0.047625, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.715 per-word bound, 420.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.053): 0.012*\"sql\" + 0.011*\"python\" + 0.010*\"r\" + 0.010*\"oracle\" + 0.009*\"hive\" + 0.008*\"technical\" + 0.007*\"s3\" + 0.007*\"sqoop\" + 0.007*\"hadoop\" + 0.007*\"tableau\"\n",
      "INFO : topic #6 (0.053): 0.033*\"python\" + 0.030*\"r\" + 0.026*\"sql\" + 0.023*\"pandas\" + 0.019*\"numpy\" + 0.017*\"technical\" + 0.016*\"scikit\" + 0.015*\"tableau\" + 0.014*\"hadoop\" + 0.013*\"spark\"\n",
      "INFO : topic #10 (0.053): 0.016*\"english\" + 0.009*\"excel\" + 0.009*\"powerpoint\" + 0.008*\"word\" + 0.006*\"outlook\" + 0.006*\"french\" + 0.005*\"access\" + 0.005*\"spanish\" + 0.004*\"research\" + 0.004*\"data\"\n",
      "INFO : topic #16 (0.053): 0.007*\"sql\" + 0.005*\"stat\" + 0.005*\"technical\" + 0.005*\"java\" + 0.005*\"r\" + 0.004*\"base\" + 0.004*\"python\" + 0.004*\"databases\" + 0.004*\"ets\" + 0.004*\"graph\"\n",
      "INFO : topic #2 (0.053): 0.004*\"c++\" + 0.004*\"computer\" + 0.004*\"data\" + 0.003*\"linux\" + 0.003*\"windows\" + 0.003*\"c\" + 0.003*\"team\" + 0.003*\"r\" + 0.003*\"project\" + 0.002*\"oracle\"\n",
      "INFO : topic diff=0.041531, rho=0.234828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : bound: at document #0\n",
      "INFO : -8.709 per-word bound, 418.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.053): 0.011*\"sql\" + 0.010*\"python\" + 0.010*\"r\" + 0.010*\"oracle\" + 0.009*\"hive\" + 0.008*\"s3\" + 0.007*\"technical\" + 0.007*\"sqoop\" + 0.006*\"hadoop\" + 0.006*\"tableau\"\n",
      "INFO : topic #11 (0.053): 0.055*\"r\" + 0.046*\"python\" + 0.046*\"sql\" + 0.040*\"sas\" + 0.029*\"excel\" + 0.028*\"matlab\" + 0.024*\"tableau\" + 0.021*\"c++\" + 0.021*\"spss\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #16 (0.053): 0.006*\"sql\" + 0.006*\"stat\" + 0.005*\"technical\" + 0.005*\"java\" + 0.005*\"base\" + 0.005*\"r\" + 0.004*\"ets\" + 0.004*\"databases\" + 0.004*\"graph\" + 0.004*\"python\"\n",
      "INFO : topic #12 (0.053): 0.009*\"tableau\" + 0.007*\"excel\" + 0.007*\"hive\" + 0.007*\"unix\" + 0.007*\"windows\" + 0.007*\"databases\" + 0.006*\"linux\" + 0.006*\"pig\" + 0.006*\"jad\" + 0.006*\"rad\"\n",
      "INFO : topic #5 (0.053): 0.008*\"technical\" + 0.007*\"oracle\" + 0.006*\"sql\" + 0.005*\"teradata\" + 0.004*\"key\" + 0.004*\"linux\" + 0.003*\"ms\" + 0.003*\"access\" + 0.003*\"sql_server\" + 0.003*\"sharepoint\"\n",
      "INFO : topic diff=0.036622, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.703 per-word bound, 416.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.053): 0.033*\"python\" + 0.030*\"r\" + 0.026*\"sql\" + 0.023*\"pandas\" + 0.019*\"numpy\" + 0.017*\"technical\" + 0.016*\"scikit\" + 0.015*\"tableau\" + 0.014*\"hadoop\" + 0.013*\"spark\"\n",
      "INFO : topic #2 (0.053): 0.004*\"c++\" + 0.004*\"computer\" + 0.004*\"data\" + 0.003*\"linux\" + 0.003*\"team\" + 0.003*\"windows\" + 0.003*\"c\" + 0.003*\"project\" + 0.002*\"r\" + 0.002*\"database\"\n",
      "INFO : topic #5 (0.053): 0.008*\"technical\" + 0.007*\"oracle\" + 0.006*\"sql\" + 0.005*\"teradata\" + 0.004*\"key\" + 0.004*\"linux\" + 0.003*\"ms\" + 0.003*\"sql_server\" + 0.003*\"sharepoint\" + 0.003*\"access\"\n",
      "INFO : topic #11 (0.053): 0.055*\"r\" + 0.046*\"sql\" + 0.046*\"python\" + 0.040*\"sas\" + 0.030*\"excel\" + 0.028*\"matlab\" + 0.024*\"tableau\" + 0.021*\"c++\" + 0.021*\"spss\" + 0.018*\"powerpoint\"\n",
      "INFO : topic #3 (0.053): 0.007*\"unix\" + 0.007*\"technical\" + 0.003*\"sql\" + 0.003*\"linux\" + 0.003*\"powershell\" + 0.003*\"highlightsof\" + 0.002*\"testing\" + 0.002*\"may\" + 0.002*\"oracle\" + 0.002*\"data\"\n",
      "INFO : topic diff=0.032511, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.697 per-word bound, 415.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.053): 0.004*\"computer\" + 0.004*\"c++\" + 0.004*\"data\" + 0.003*\"linux\" + 0.003*\"team\" + 0.003*\"windows\" + 0.003*\"project\" + 0.002*\"c\" + 0.002*\"database\" + 0.002*\"oracle\"\n",
      "INFO : topic #6 (0.053): 0.033*\"python\" + 0.030*\"r\" + 0.026*\"sql\" + 0.023*\"pandas\" + 0.019*\"numpy\" + 0.017*\"technical\" + 0.016*\"scikit\" + 0.015*\"tableau\" + 0.014*\"hadoop\" + 0.013*\"spark\"\n",
      "INFO : topic #18 (0.053): 0.013*\"jsp\" + 0.011*\"spring\" + 0.011*\"xml\" + 0.011*\"java\" + 0.010*\"javascript\" + 0.010*\"hibernate\" + 0.009*\"eclipse\" + 0.009*\"j2ee\" + 0.009*\"maven\" + 0.009*\"mysql\"\n",
      "INFO : topic #9 (0.053): 0.036*\"javascript\" + 0.034*\"html\" + 0.031*\"java\" + 0.030*\"python\" + 0.030*\"c\" + 0.029*\"css\" + 0.025*\"c++\" + 0.020*\"sql\" + 0.020*\"mysql\" + 0.019*\"php\"\n",
      "INFO : topic #16 (0.053): 0.006*\"sql\" + 0.006*\"stat\" + 0.005*\"base\" + 0.005*\"technical\" + 0.004*\"java\" + 0.004*\"ets\" + 0.004*\"databases\" + 0.004*\"iml\" + 0.004*\"graph\" + 0.004*\"r\"\n",
      "INFO : topic diff=0.029167, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.693 per-word bound, 413.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #18 (0.053): 0.013*\"jsp\" + 0.011*\"spring\" + 0.011*\"xml\" + 0.011*\"java\" + 0.010*\"javascript\" + 0.010*\"hibernate\" + 0.010*\"j2ee\" + 0.010*\"maven\" + 0.010*\"eclipse\" + 0.009*\"mysql\"\n",
      "INFO : topic #8 (0.053): 0.010*\"sql\" + 0.009*\"oracle\" + 0.009*\"python\" + 0.008*\"s3\" + 0.008*\"r\" + 0.008*\"hive\" + 0.007*\"technical\" + 0.006*\"redshift\" + 0.006*\"ec2\" + 0.006*\"sqoop\"\n",
      "INFO : topic #5 (0.053): 0.008*\"technical\" + 0.007*\"oracle\" + 0.005*\"sql\" + 0.005*\"teradata\" + 0.004*\"key\" + 0.003*\"linux\" + 0.003*\"ms\" + 0.003*\"sql_server\" + 0.003*\"sharepoint\" + 0.003*\"etl\"\n",
      "INFO : topic #10 (0.053): 0.019*\"english\" + 0.007*\"french\" + 0.007*\"excel\" + 0.006*\"powerpoint\" + 0.006*\"spanish\" + 0.006*\"mandarin\" + 0.006*\"word\" + 0.005*\"outlook\" + 0.005*\"native\" + 0.005*\"chinese\"\n",
      "INFO : topic #1 (0.053): 0.010*\"technical\" + 0.008*\"java\" + 0.006*\"python\" + 0.006*\"jira\" + 0.005*\"sql\" + 0.005*\"r\" + 0.005*\"ms\" + 0.004*\"c\" + 0.004*\"mysql\" + 0.004*\"html\"\n",
      "INFO : topic diff=0.026461, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.688 per-word bound, 412.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.053): 0.004*\"computer\" + 0.004*\"c++\" + 0.004*\"data\" + 0.003*\"team\" + 0.003*\"linux\" + 0.003*\"windows\" + 0.003*\"project\" + 0.002*\"c\" + 0.002*\"database\" + 0.002*\"spoken\"\n",
      "INFO : topic #11 (0.053): 0.056*\"r\" + 0.047*\"sql\" + 0.047*\"python\" + 0.040*\"sas\" + 0.031*\"excel\" + 0.028*\"matlab\" + 0.024*\"tableau\" + 0.021*\"spss\" + 0.021*\"c++\" + 0.018*\"powerpoint\"\n",
      "INFO : topic #7 (0.053): 0.012*\"linux\" + 0.007*\"taleo\" + 0.007*\"core\" + 0.006*\"project\" + 0.006*\"linkedin\" + 0.005*\"jobvite\" + 0.005*\"windows\" + 0.004*\"dice\" + 0.004*\"google\" + 0.004*\"ats\"\n",
      "INFO : topic #0 (0.053): 0.011*\"sql\" + 0.011*\"ssrs\" + 0.011*\"ssis\" + 0.009*\"oracle\" + 0.009*\"t\" + 0.009*\"pl\" + 0.009*\"technical\" + 0.008*\"ssas\" + 0.007*\"ms\" + 0.006*\"agile\"\n",
      "INFO : topic #10 (0.053): 0.020*\"english\" + 0.008*\"french\" + 0.007*\"spanish\" + 0.006*\"mandarin\" + 0.006*\"excel\" + 0.006*\"powerpoint\" + 0.005*\"word\" + 0.005*\"native\" + 0.005*\"outlook\" + 0.005*\"chinese\"\n",
      "INFO : topic diff=0.024035, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.684 per-word bound, 411.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=19, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=19, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (451 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (520 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (321 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (421 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (503 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (404 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (430 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (730 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (595 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (611 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (515 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (629 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (396 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (461 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (592 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (566 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (567 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (401 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (468 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (659 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (401 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (468 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (659 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (686 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (686 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (918 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (918 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (460 virtual)\n",
      "DEBUG : completed batch 8; 532 documents processed (657 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (582 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 532 documents processed (657 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (582 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 9; 640 documents processed (823 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 640 documents processed (823 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (636 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (636 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (525 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (525 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (658 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 512 documents processed (656 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (658 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 512 documents processed (656 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (486 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 448 documents processed (486 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 448 documents processed (460 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 576 documents processed (748 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (748 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9363 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12411/12537 documents converged within 50 iterations\n",
      " 74%|███████▍  | 17/23 [07:24<02:36, 26.13s/it]INFO : using symmetric alpha at 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : using symmetric eta at 0.05\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 20 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 434/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3282/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3415/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3233/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #18 (0.050): 0.020*\"python\" + 0.016*\"sql\" + 0.014*\"r\" + 0.012*\"java\" + 0.012*\"hadoop\" + 0.011*\"javascript\" + 0.010*\"c++\" + 0.010*\"html\" + 0.010*\"mysql\" + 0.007*\"sas\"\n",
      "INFO : topic #16 (0.050): 0.023*\"sql\" + 0.022*\"r\" + 0.016*\"python\" + 0.013*\"java\" + 0.011*\"technical\" + 0.008*\"javascript\" + 0.007*\"c\" + 0.006*\"tableau\" + 0.006*\"mysql\" + 0.006*\"sas\"\n",
      "INFO : topic #5 (0.050): 0.015*\"sql\" + 0.010*\"technical\" + 0.010*\"r\" + 0.008*\"python\" + 0.007*\"access\" + 0.007*\"excel\" + 0.007*\"sas\" + 0.006*\"java\" + 0.006*\"powerpoint\" + 0.006*\"linux\"\n",
      "INFO : topic #6 (0.050): 0.024*\"python\" + 0.024*\"r\" + 0.018*\"sql\" + 0.013*\"sas\" + 0.011*\"mysql\" + 0.010*\"technical\" + 0.010*\"matlab\" + 0.009*\"tableau\" + 0.009*\"pandas\" + 0.008*\"c++\"\n",
      "INFO : topic #12 (0.050): 0.019*\"python\" + 0.017*\"r\" + 0.015*\"java\" + 0.015*\"sql\" + 0.011*\"mysql\" + 0.011*\"hive\" + 0.010*\"tableau\" + 0.009*\"hadoop\" + 0.009*\"c\" + 0.009*\"c++\"\n",
      "INFO : topic diff=15.274213, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.420 per-word bound, 684.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3773/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3853/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3820/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #17 (0.050): 0.022*\"python\" + 0.019*\"r\" + 0.011*\"sql\" + 0.010*\"technical\" + 0.010*\"c++\" + 0.009*\"c\" + 0.009*\"sas\" + 0.008*\"excel\" + 0.008*\"tableau\" + 0.007*\"javascript\"\n",
      "INFO : topic #19 (0.050): 0.019*\"sql\" + 0.017*\"technical\" + 0.015*\"r\" + 0.015*\"python\" + 0.013*\"tableau\" + 0.013*\"excel\" + 0.010*\"oracle\" + 0.009*\"c\" + 0.008*\"sas\" + 0.008*\"c++\"\n",
      "INFO : topic #6 (0.050): 0.025*\"python\" + 0.024*\"r\" + 0.019*\"sql\" + 0.012*\"sas\" + 0.012*\"technical\" + 0.011*\"pandas\" + 0.010*\"mysql\" + 0.010*\"matlab\" + 0.010*\"tableau\" + 0.009*\"statistical\"\n",
      "INFO : topic #4 (0.050): 0.023*\"sql\" + 0.021*\"python\" + 0.020*\"r\" + 0.012*\"technical\" + 0.011*\"matlab\" + 0.010*\"tableau\" + 0.010*\"data\" + 0.009*\"java\" + 0.009*\"linux\" + 0.009*\"c++\"\n",
      "INFO : topic #13 (0.050): 0.022*\"python\" + 0.020*\"sql\" + 0.019*\"technical\" + 0.019*\"r\" + 0.018*\"tableau\" + 0.017*\"sas\" + 0.013*\"html\" + 0.013*\"java\" + 0.011*\"c\" + 0.010*\"c++\"\n",
      "INFO : topic diff=0.357710, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.154 per-word bound, 569.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3913/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3850/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #14 (0.050): 0.021*\"r\" + 0.019*\"sql\" + 0.018*\"python\" + 0.014*\"c++\" + 0.012*\"java\" + 0.011*\"matlab\" + 0.011*\"tableau\" + 0.010*\"c\" + 0.010*\"mysql\" + 0.010*\"technical\"\n",
      "INFO : topic #13 (0.050): 0.021*\"python\" + 0.020*\"sql\" + 0.019*\"technical\" + 0.019*\"tableau\" + 0.018*\"r\" + 0.017*\"sas\" + 0.013*\"html\" + 0.012*\"java\" + 0.011*\"c\" + 0.010*\"c++\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #17 (0.050): 0.020*\"python\" + 0.017*\"r\" + 0.010*\"sql\" + 0.009*\"technical\" + 0.009*\"c++\" + 0.009*\"c\" + 0.008*\"excel\" + 0.008*\"sas\" + 0.007*\"tableau\" + 0.006*\"javascript\"\n",
      "INFO : topic #2 (0.050): 0.010*\"r\" + 0.009*\"python\" + 0.008*\"sql\" + 0.008*\"linux\" + 0.008*\"c++\" + 0.006*\"windows\" + 0.005*\"programming\" + 0.005*\"sas\" + 0.005*\"c\" + 0.005*\"computer\"\n",
      "INFO : topic #12 (0.050): 0.016*\"python\" + 0.015*\"r\" + 0.013*\"java\" + 0.013*\"sql\" + 0.010*\"hive\" + 0.010*\"mysql\" + 0.009*\"spark\" + 0.009*\"tableau\" + 0.009*\"hadoop\" + 0.009*\"programming\"\n",
      "INFO : topic diff=0.322434, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.024 per-word bound, 520.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3868/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.050): 0.012*\"linux\" + 0.011*\"sql\" + 0.009*\"python\" + 0.007*\"excel\" + 0.007*\"hadoop\" + 0.006*\"c++\" + 0.006*\"hive\" + 0.006*\"r\" + 0.005*\"matlab\" + 0.005*\"java\"\n",
      "INFO : topic #19 (0.050): 0.018*\"sql\" + 0.017*\"technical\" + 0.013*\"tableau\" + 0.012*\"r\" + 0.012*\"python\" + 0.012*\"excel\" + 0.011*\"oracle\" + 0.009*\"windows\" + 0.008*\"c\" + 0.008*\"hadoop\"\n",
      "INFO : topic #5 (0.050): 0.011*\"sql\" + 0.008*\"technical\" + 0.007*\"excel\" + 0.006*\"access\" + 0.006*\"powerpoint\" + 0.005*\"key\" + 0.004*\"sas\" + 0.004*\"word\" + 0.004*\"r\" + 0.004*\"taleo\"\n",
      "INFO : topic #2 (0.050): 0.009*\"r\" + 0.008*\"python\" + 0.007*\"sql\" + 0.007*\"linux\" + 0.007*\"c++\" + 0.005*\"windows\" + 0.005*\"programming\" + 0.005*\"computer\" + 0.004*\"sas\" + 0.004*\"html\"\n",
      "INFO : topic #14 (0.050): 0.020*\"r\" + 0.017*\"sql\" + 0.017*\"python\" + 0.014*\"c++\" + 0.011*\"java\" + 0.011*\"matlab\" + 0.010*\"tableau\" + 0.010*\"mysql\" + 0.010*\"c\" + 0.010*\"technical\"\n",
      "INFO : topic diff=0.283370, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.941 per-word bound, 491.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3895/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3915/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.050): 0.027*\"r\" + 0.026*\"python\" + 0.022*\"sql\" + 0.015*\"hadoop\" + 0.013*\"hive\" + 0.012*\"tableau\" + 0.012*\"java\" + 0.011*\"spark\" + 0.010*\"mongodb\" + 0.009*\"c++\"\n",
      "INFO : topic #14 (0.050): 0.019*\"r\" + 0.016*\"sql\" + 0.016*\"python\" + 0.013*\"c++\" + 0.011*\"java\" + 0.010*\"matlab\" + 0.009*\"tableau\" + 0.009*\"technical\" + 0.009*\"mysql\" + 0.009*\"c\"\n",
      "INFO : topic #10 (0.050): 0.012*\"r\" + 0.010*\"excel\" + 0.009*\"sas\" + 0.008*\"powerpoint\" + 0.007*\"word\" + 0.007*\"mysql\" + 0.006*\"sql\" + 0.005*\"spss\" + 0.005*\"linux\" + 0.004*\"access\"\n",
      "INFO : topic #17 (0.050): 0.017*\"python\" + 0.014*\"r\" + 0.009*\"sql\" + 0.008*\"technical\" + 0.008*\"c\" + 0.007*\"c++\" + 0.007*\"excel\" + 0.006*\"sas\" + 0.006*\"tableau\" + 0.006*\"project\"\n",
      "INFO : topic #4 (0.050): 0.018*\"sql\" + 0.016*\"python\" + 0.015*\"r\" + 0.011*\"data\" + 0.009*\"matlab\" + 0.009*\"technical\" + 0.009*\"tableau\" + 0.008*\"linux\" + 0.007*\"c++\" + 0.006*\"java\"\n",
      "INFO : topic diff=0.243200, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.887 per-word bound, 473.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3916/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.050): 0.030*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.020*\"pandas\" + 0.016*\"numpy\" + 0.014*\"technical\" + 0.014*\"scikit\" + 0.012*\"tableau\" + 0.011*\"sas\" + 0.011*\"matplotlib\"\n",
      "INFO : topic #19 (0.050): 0.018*\"sql\" + 0.017*\"technical\" + 0.013*\"tableau\" + 0.012*\"oracle\" + 0.011*\"excel\" + 0.010*\"r\" + 0.010*\"python\" + 0.010*\"ssis\" + 0.009*\"windows\" + 0.009*\"ssrs\"\n",
      "INFO : topic #2 (0.050): 0.007*\"r\" + 0.006*\"python\" + 0.006*\"linux\" + 0.006*\"sql\" + 0.005*\"c++\" + 0.005*\"windows\" + 0.004*\"computer\" + 0.004*\"data\" + 0.004*\"programming\" + 0.004*\"html\"\n",
      "INFO : topic #5 (0.050): 0.009*\"sql\" + 0.007*\"technical\" + 0.007*\"excel\" + 0.006*\"powerpoint\" + 0.006*\"taleo\" + 0.005*\"access\" + 0.005*\"key\" + 0.004*\"word\" + 0.004*\"sql_server\" + 0.004*\"jobvite\"\n",
      "INFO : topic #16 (0.050): 0.015*\"sql\" + 0.014*\"r\" + 0.009*\"python\" + 0.008*\"technical\" + 0.008*\"java\" + 0.006*\"c\" + 0.005*\"sas\" + 0.005*\"javascript\" + 0.004*\"aws\" + 0.004*\"tableau\"\n",
      "INFO : topic diff=0.204809, rho=0.330875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : bound: at document #0\n",
      "INFO : -8.847 per-word bound, 460.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.050): 0.016*\"python\" + 0.013*\"java\" + 0.012*\"sql\" + 0.012*\"technical\" + 0.011*\"r\" + 0.010*\"c\" + 0.007*\"c++\" + 0.007*\"mysql\" + 0.007*\"html\" + 0.006*\"ms\"\n",
      "INFO : topic #10 (0.050): 0.009*\"excel\" + 0.009*\"r\" + 0.008*\"powerpoint\" + 0.007*\"sas\" + 0.007*\"word\" + 0.005*\"mysql\" + 0.005*\"photoshop\" + 0.004*\"sql\" + 0.004*\"relevant\" + 0.004*\"indesign\"\n",
      "INFO : topic #12 (0.050): 0.012*\"python\" + 0.010*\"r\" + 0.009*\"java\" + 0.009*\"sql\" + 0.007*\"spark\" + 0.007*\"hive\" + 0.007*\"programming\" + 0.007*\"mysql\" + 0.007*\"tableau\" + 0.006*\"technical\"\n",
      "INFO : topic #3 (0.050): 0.010*\"unix\" + 0.008*\"technical\" + 0.008*\"linux\" + 0.005*\"sql\" + 0.004*\"python\" + 0.003*\"java\" + 0.003*\"powerpoint\" + 0.003*\"skills\" + 0.003*\"sunsolaris\" + 0.003*\"data\"\n",
      "INFO : topic #15 (0.050): 0.033*\"python\" + 0.032*\"r\" + 0.031*\"sql\" + 0.022*\"hadoop\" + 0.020*\"java\" + 0.018*\"matlab\" + 0.018*\"hive\" + 0.018*\"c++\" + 0.018*\"c\" + 0.017*\"tableau\"\n",
      "INFO : topic diff=0.170299, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.821 per-word bound, 452.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3928/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.050): 0.010*\"sql\" + 0.007*\"html\" + 0.006*\"oracle\" + 0.006*\"project\" + 0.006*\"python\" + 0.006*\"r\" + 0.005*\"technical\" + 0.005*\"linux\" + 0.005*\"ms\" + 0.005*\"javascript\"\n",
      "INFO : topic #8 (0.050): 0.025*\"r\" + 0.024*\"python\" + 0.020*\"sql\" + 0.015*\"hadoop\" + 0.013*\"hive\" + 0.013*\"spark\" + 0.011*\"tableau\" + 0.011*\"java\" + 0.011*\"mongodb\" + 0.009*\"oracle\"\n",
      "INFO : topic #17 (0.050): 0.013*\"python\" + 0.011*\"r\" + 0.007*\"sql\" + 0.007*\"technical\" + 0.007*\"project\" + 0.006*\"c\" + 0.006*\"excel\" + 0.005*\"c++\" + 0.005*\"sas\" + 0.004*\"data\"\n",
      "INFO : topic #16 (0.050): 0.013*\"sql\" + 0.012*\"r\" + 0.008*\"technical\" + 0.007*\"java\" + 0.007*\"python\" + 0.005*\"c\" + 0.004*\"sas\" + 0.004*\"javascript\" + 0.004*\"aws\" + 0.004*\"stat\"\n",
      "INFO : topic #15 (0.050): 0.033*\"python\" + 0.032*\"r\" + 0.031*\"sql\" + 0.023*\"hadoop\" + 0.020*\"java\" + 0.019*\"hive\" + 0.018*\"matlab\" + 0.018*\"c++\" + 0.018*\"c\" + 0.017*\"tableau\"\n",
      "INFO : topic diff=0.140566, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.797 per-word bound, 444.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.050): 0.009*\"excel\" + 0.007*\"powerpoint\" + 0.007*\"r\" + 0.006*\"sas\" + 0.006*\"word\" + 0.006*\"photoshop\" + 0.005*\"indesign\" + 0.005*\"illustrator\" + 0.004*\"relevant\" + 0.004*\"project\"\n",
      "INFO : topic #13 (0.050): 0.017*\"tableau\" + 0.017*\"technical\" + 0.015*\"sql\" + 0.015*\"sas\" + 0.015*\"python\" + 0.013*\"r\" + 0.012*\"html\" + 0.009*\"java\" + 0.008*\"c\" + 0.008*\"spss\"\n",
      "INFO : topic #3 (0.050): 0.011*\"unix\" + 0.007*\"linux\" + 0.007*\"technical\" + 0.003*\"sql\" + 0.003*\"skills\" + 0.003*\"february\" + 0.003*\"sunsolaris\" + 0.003*\"powershell\" + 0.003*\"powerpoint\" + 0.003*\"python\"\n",
      "INFO : topic #6 (0.050): 0.032*\"python\" + 0.028*\"r\" + 0.024*\"sql\" + 0.023*\"pandas\" + 0.019*\"numpy\" + 0.016*\"scikit\" + 0.016*\"technical\" + 0.013*\"tableau\" + 0.012*\"scipy\" + 0.012*\"matplotlib\"\n",
      "INFO : topic #8 (0.050): 0.024*\"r\" + 0.023*\"python\" + 0.019*\"sql\" + 0.015*\"hadoop\" + 0.014*\"spark\" + 0.013*\"hive\" + 0.011*\"java\" + 0.011*\"tableau\" + 0.011*\"mongodb\" + 0.009*\"scala\"\n",
      "INFO : topic diff=0.115933, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.779 per-word bound, 439.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #14 (0.050): 0.014*\"r\" + 0.011*\"python\" + 0.011*\"sql\" + 0.010*\"c++\" + 0.009*\"english\" + 0.008*\"matlab\" + 0.007*\"technical\" + 0.007*\"java\" + 0.007*\"c\" + 0.007*\"mysql\"\n",
      "INFO : topic #6 (0.050): 0.032*\"python\" + 0.028*\"r\" + 0.025*\"sql\" + 0.023*\"pandas\" + 0.019*\"numpy\" + 0.016*\"scikit\" + 0.016*\"technical\" + 0.013*\"tableau\" + 0.012*\"scipy\" + 0.012*\"matplotlib\"\n",
      "INFO : topic #17 (0.050): 0.011*\"python\" + 0.009*\"r\" + 0.007*\"project\" + 0.006*\"technical\" + 0.006*\"c\" + 0.006*\"sql\" + 0.005*\"excel\" + 0.005*\"c++\" + 0.004*\"data\" + 0.004*\"skills\"\n",
      "INFO : topic #3 (0.050): 0.011*\"unix\" + 0.007*\"linux\" + 0.006*\"technical\" + 0.003*\"february\" + 0.003*\"skills\" + 0.003*\"sunsolaris\" + 0.003*\"sql\" + 0.003*\"powershell\" + 0.003*\"macintosh_hd\" + 0.003*\"ux\"\n",
      "INFO : topic #10 (0.050): 0.009*\"excel\" + 0.007*\"powerpoint\" + 0.006*\"photoshop\" + 0.006*\"r\" + 0.006*\"word\" + 0.006*\"sas\" + 0.006*\"indesign\" + 0.005*\"illustrator\" + 0.004*\"relevant\" + 0.004*\"project\"\n",
      "INFO : topic diff=0.096092, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.763 per-word bound, 434.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.050): 0.005*\"r\" + 0.004*\"linux\" + 0.004*\"data\" + 0.004*\"windows\" + 0.004*\"python\" + 0.004*\"sql\" + 0.003*\"c++\" + 0.003*\"computer\" + 0.003*\"core\" + 0.003*\"technical\"\n",
      "INFO : topic #0 (0.050): 0.009*\"sql\" + 0.006*\"html\" + 0.006*\"project\" + 0.006*\"oracle\" + 0.005*\"ms\" + 0.005*\"technical\" + 0.004*\"python\" + 0.004*\"r\" + 0.004*\"linux\" + 0.004*\"agile\"\n",
      "INFO : topic #1 (0.050): 0.012*\"python\" + 0.010*\"java\" + 0.010*\"technical\" + 0.009*\"sql\" + 0.009*\"c\" + 0.008*\"r\" + 0.006*\"ms\" + 0.006*\"c++\" + 0.005*\"html\" + 0.005*\"jira\"\n",
      "INFO : topic #11 (0.050): 0.053*\"r\" + 0.046*\"sql\" + 0.045*\"python\" + 0.041*\"sas\" + 0.028*\"excel\" + 0.026*\"matlab\" + 0.022*\"tableau\" + 0.020*\"spss\" + 0.019*\"c++\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #18 (0.050): 0.012*\"jsp\" + 0.011*\"java\" + 0.010*\"xml\" + 0.010*\"spring\" + 0.009*\"javascript\" + 0.009*\"hibernate\" + 0.009*\"mysql\" + 0.008*\"hadoop\" + 0.008*\"oracle\" + 0.008*\"eclipse\"\n",
      "INFO : topic diff=0.080161, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.751 per-word bound, 430.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3941/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.050): 0.004*\"r\" + 0.004*\"data\" + 0.004*\"linux\" + 0.004*\"windows\" + 0.004*\"python\" + 0.003*\"sql\" + 0.003*\"c++\" + 0.003*\"core\" + 0.003*\"computer\" + 0.003*\"spoken\"\n",
      "INFO : topic #3 (0.050): 0.011*\"unix\" + 0.007*\"linux\" + 0.006*\"technical\" + 0.003*\"february\" + 0.003*\"sunsolaris\" + 0.003*\"skills\" + 0.003*\"powershell\" + 0.003*\"august\" + 0.003*\"macintosh_hd\" + 0.003*\"ux\"\n",
      "INFO : topic #11 (0.050): 0.054*\"r\" + 0.046*\"sql\" + 0.045*\"python\" + 0.041*\"sas\" + 0.029*\"excel\" + 0.027*\"matlab\" + 0.023*\"tableau\" + 0.020*\"spss\" + 0.019*\"c++\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #8 (0.050): 0.022*\"r\" + 0.022*\"python\" + 0.017*\"sql\" + 0.015*\"hadoop\" + 0.015*\"spark\" + 0.014*\"hive\" + 0.012*\"mongodb\" + 0.011*\"java\" + 0.010*\"tableau\" + 0.010*\"scala\"\n",
      "INFO : topic #5 (0.050): 0.007*\"taleo\" + 0.006*\"sql\" + 0.006*\"key\" + 0.005*\"excel\" + 0.005*\"technical\" + 0.005*\"jobvite\" + 0.005*\"powerpoint\" + 0.004*\"sql_server\" + 0.004*\"leadership\" + 0.003*\"access\"\n",
      "INFO : topic diff=0.067529, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.740 per-word bound, 427.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.050): 0.022*\"r\" + 0.022*\"python\" + 0.017*\"sql\" + 0.015*\"hadoop\" + 0.015*\"spark\" + 0.014*\"hive\" + 0.012*\"mongodb\" + 0.010*\"java\" + 0.010*\"scala\" + 0.010*\"tableau\"\n",
      "INFO : topic #13 (0.050): 0.016*\"tableau\" + 0.015*\"technical\" + 0.013*\"sas\" + 0.012*\"sql\" + 0.012*\"python\" + 0.011*\"html\" + 0.010*\"r\" + 0.008*\"spss\" + 0.008*\"java\" + 0.007*\"c\"\n",
      "INFO : topic #16 (0.050): 0.009*\"sql\" + 0.008*\"r\" + 0.006*\"technical\" + 0.006*\"java\" + 0.004*\"c\" + 0.004*\"python\" + 0.004*\"stat\" + 0.003*\"aws\" + 0.003*\"sas\" + 0.003*\"databases\"\n",
      "INFO : topic #0 (0.050): 0.008*\"sql\" + 0.006*\"project\" + 0.006*\"html\" + 0.006*\"oracle\" + 0.005*\"ms\" + 0.004*\"agile\" + 0.004*\"technical\" + 0.004*\"linux\" + 0.004*\"xml\" + 0.004*\"python\"\n",
      "INFO : topic #2 (0.050): 0.004*\"data\" + 0.004*\"r\" + 0.004*\"linux\" + 0.004*\"windows\" + 0.003*\"python\" + 0.003*\"sql\" + 0.003*\"c++\" + 0.003*\"core\" + 0.003*\"spoken\" + 0.003*\"computer\"\n",
      "INFO : topic diff=0.057235, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.731 per-word bound, 424.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.050): 0.010*\"data\" + 0.008*\"sql\" + 0.007*\"linux\" + 0.006*\"windows\" + 0.006*\"python\" + 0.005*\"r\" + 0.005*\"matlab\" + 0.004*\"tableau\" + 0.004*\"technical\" + 0.004*\"c++\"\n",
      "INFO : topic #11 (0.050): 0.055*\"r\" + 0.047*\"sql\" + 0.046*\"python\" + 0.042*\"sas\" + 0.030*\"excel\" + 0.027*\"matlab\" + 0.023*\"tableau\" + 0.021*\"spss\" + 0.019*\"c++\" + 0.018*\"powerpoint\"\n",
      "INFO : topic #3 (0.050): 0.011*\"unix\" + 0.007*\"linux\" + 0.006*\"technical\" + 0.004*\"february\" + 0.003*\"august\" + 0.003*\"sunsolaris\" + 0.003*\"powershell\" + 0.003*\"skills\" + 0.003*\"january\" + 0.003*\"macintosh_hd\"\n",
      "INFO : topic #16 (0.050): 0.009*\"sql\" + 0.008*\"r\" + 0.006*\"technical\" + 0.006*\"java\" + 0.004*\"c\" + 0.004*\"python\" + 0.004*\"stat\" + 0.003*\"aws\" + 0.003*\"sas\" + 0.003*\"databases\"\n",
      "INFO : topic #7 (0.050): 0.006*\"linux\" + 0.004*\"sql\" + 0.004*\"core\" + 0.004*\"data\" + 0.004*\"excel\" + 0.003*\"spanish\" + 0.003*\"project\" + 0.003*\"english\" + 0.003*\"technology\" + 0.002*\"c++\"\n",
      "INFO : topic diff=0.049159, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.724 per-word bound, 422.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.050): 0.021*\"r\" + 0.021*\"python\" + 0.016*\"sql\" + 0.015*\"spark\" + 0.015*\"hadoop\" + 0.014*\"hive\" + 0.012*\"mongodb\" + 0.011*\"scala\" + 0.010*\"java\" + 0.010*\"tableau\"\n",
      "INFO : topic #4 (0.050): 0.010*\"data\" + 0.008*\"sql\" + 0.007*\"linux\" + 0.006*\"windows\" + 0.006*\"python\" + 0.005*\"r\" + 0.004*\"matlab\" + 0.004*\"tableau\" + 0.004*\"technical\" + 0.004*\"xp\"\n",
      "INFO : topic #7 (0.050): 0.005*\"linux\" + 0.004*\"core\" + 0.004*\"sql\" + 0.004*\"data\" + 0.003*\"excel\" + 0.003*\"spanish\" + 0.003*\"technology\" + 0.003*\"j.\" + 0.003*\"english\" + 0.003*\"project\"\n",
      "INFO : topic #2 (0.050): 0.004*\"data\" + 0.004*\"windows\" + 0.004*\"linux\" + 0.003*\"r\" + 0.003*\"core\" + 0.003*\"python\" + 0.003*\"sql\" + 0.003*\"c++\" + 0.003*\"spoken\" + 0.002*\"technical\"\n",
      "INFO : topic #12 (0.050): 0.006*\"python\" + 0.005*\"programming\" + 0.004*\"java\" + 0.004*\"spark\" + 0.004*\"r\" + 0.004*\"tableau\" + 0.004*\"hive\" + 0.004*\"mysql\" + 0.004*\"scala\" + 0.003*\"visio\"\n",
      "INFO : topic diff=0.042553, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.716 per-word bound, 420.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3968/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.050): 0.038*\"javascript\" + 0.037*\"html\" + 0.036*\"java\" + 0.036*\"python\" + 0.032*\"c\" + 0.030*\"css\" + 0.029*\"c++\" + 0.023*\"mysql\" + 0.022*\"sql\" + 0.020*\"r\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #6 (0.050): 0.034*\"python\" + 0.029*\"r\" + 0.026*\"sql\" + 0.025*\"pandas\" + 0.021*\"numpy\" + 0.017*\"scikit\" + 0.016*\"technical\" + 0.014*\"tableau\" + 0.013*\"scipy\" + 0.012*\"hadoop\"\n",
      "INFO : topic #0 (0.050): 0.007*\"sql\" + 0.006*\"project\" + 0.005*\"html\" + 0.005*\"oracle\" + 0.005*\"ms\" + 0.004*\"agile\" + 0.003*\"xml\" + 0.003*\"development\" + 0.003*\"linux\" + 0.003*\"technical\"\n",
      "INFO : topic #4 (0.050): 0.010*\"data\" + 0.007*\"sql\" + 0.007*\"linux\" + 0.006*\"windows\" + 0.005*\"python\" + 0.004*\"matlab\" + 0.004*\"r\" + 0.004*\"tableau\" + 0.004*\"xp\" + 0.004*\"vista\"\n",
      "INFO : topic #3 (0.050): 0.011*\"unix\" + 0.007*\"linux\" + 0.005*\"technical\" + 0.004*\"february\" + 0.004*\"august\" + 0.003*\"sunsolaris\" + 0.003*\"powershell\" + 0.003*\"january\" + 0.003*\"highlightsof\" + 0.003*\"skills\"\n",
      "INFO : topic diff=0.037239, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.710 per-word bound, 418.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.050): 0.006*\"project\" + 0.006*\"sql\" + 0.005*\"html\" + 0.005*\"oracle\" + 0.005*\"ms\" + 0.004*\"agile\" + 0.003*\"development\" + 0.003*\"xml\" + 0.003*\"access\" + 0.003*\"linux\"\n",
      "INFO : topic #12 (0.050): 0.005*\"python\" + 0.004*\"programming\" + 0.004*\"java\" + 0.004*\"tableau\" + 0.004*\"spark\" + 0.004*\"hive\" + 0.004*\"scala\" + 0.004*\"mysql\" + 0.003*\"visio\" + 0.003*\"r\"\n",
      "INFO : topic #7 (0.050): 0.005*\"linux\" + 0.004*\"core\" + 0.004*\"data\" + 0.004*\"sql\" + 0.003*\"spanish\" + 0.003*\"j.\" + 0.003*\"excel\" + 0.003*\"e.\" + 0.003*\"technology\" + 0.003*\"english\"\n",
      "INFO : topic #9 (0.050): 0.038*\"javascript\" + 0.037*\"html\" + 0.037*\"java\" + 0.036*\"python\" + 0.032*\"c\" + 0.030*\"css\" + 0.030*\"c++\" + 0.023*\"mysql\" + 0.022*\"sql\" + 0.021*\"r\"\n",
      "INFO : topic #8 (0.050): 0.020*\"r\" + 0.020*\"python\" + 0.015*\"sql\" + 0.015*\"spark\" + 0.015*\"hadoop\" + 0.014*\"hive\" + 0.012*\"mongodb\" + 0.011*\"scala\" + 0.010*\"aws\" + 0.010*\"java\"\n",
      "INFO : topic diff=0.032901, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.704 per-word bound, 417.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #16 (0.050): 0.007*\"sql\" + 0.006*\"r\" + 0.005*\"java\" + 0.005*\"technical\" + 0.004*\"c\" + 0.004*\"stat\" + 0.003*\"datascience\" + 0.003*\"aws\" + 0.003*\"databases\" + 0.003*\"python\"\n",
      "INFO : topic #13 (0.050): 0.014*\"tableau\" + 0.014*\"technical\" + 0.012*\"sas\" + 0.010*\"sql\" + 0.010*\"html\" + 0.009*\"python\" + 0.008*\"r\" + 0.007*\"spss\" + 0.006*\"c\" + 0.006*\"java\"\n",
      "INFO : topic #18 (0.050): 0.013*\"jsp\" + 0.011*\"xml\" + 0.010*\"spring\" + 0.010*\"java\" + 0.009*\"hibernate\" + 0.009*\"eclipse\" + 0.009*\"j2ee\" + 0.009*\"javascript\" + 0.008*\"oracle\" + 0.008*\"hive\"\n",
      "INFO : topic #15 (0.050): 0.033*\"python\" + 0.032*\"r\" + 0.030*\"sql\" + 0.027*\"hadoop\" + 0.024*\"hive\" + 0.021*\"java\" + 0.020*\"spark\" + 0.018*\"c++\" + 0.018*\"matlab\" + 0.018*\"c\"\n",
      "INFO : topic #1 (0.050): 0.008*\"technical\" + 0.008*\"java\" + 0.007*\"python\" + 0.007*\"c\" + 0.006*\"ms\" + 0.006*\"sql\" + 0.005*\"jira\" + 0.004*\"r\" + 0.004*\"oracle\" + 0.004*\"c++\"\n",
      "INFO : topic diff=0.029265, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.699 per-word bound, 415.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.050): 0.010*\"unix\" + 0.006*\"linux\" + 0.005*\"technical\" + 0.004*\"february\" + 0.004*\"august\" + 0.003*\"highlightsof\" + 0.003*\"january\" + 0.003*\"sunsolaris\" + 0.003*\"powershell\" + 0.003*\"skills\"\n",
      "INFO : topic #17 (0.050): 0.010*\"project\" + 0.006*\"python\" + 0.005*\"core\" + 0.004*\"technical\" + 0.004*\"skills\" + 0.004*\"r\" + 0.004*\"data\" + 0.004*\"c\" + 0.004*\"ms\" + 0.004*\"team\"\n",
      "INFO : topic #12 (0.050): 0.004*\"python\" + 0.004*\"programming\" + 0.004*\"tableau\" + 0.004*\"java\" + 0.003*\"spark\" + 0.003*\"scala\" + 0.003*\"hive\" + 0.003*\"mysql\" + 0.003*\"visio\" + 0.003*\"self\"\n",
      "INFO : topic #18 (0.050): 0.013*\"jsp\" + 0.011*\"xml\" + 0.010*\"spring\" + 0.010*\"java\" + 0.009*\"hibernate\" + 0.009*\"eclipse\" + 0.009*\"j2ee\" + 0.009*\"javascript\" + 0.008*\"oracle\" + 0.008*\"hive\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #19 (0.050): 0.018*\"technical\" + 0.017*\"sql\" + 0.016*\"oracle\" + 0.015*\"ssis\" + 0.014*\"ssrs\" + 0.013*\"pl\" + 0.013*\"tableau\" + 0.011*\"windows\" + 0.010*\"unix\" + 0.010*\"teradata\"\n",
      "INFO : topic diff=0.026337, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.694 per-word bound, 414.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.050): 0.006*\"project\" + 0.005*\"sql\" + 0.004*\"oracle\" + 0.004*\"ms\" + 0.004*\"html\" + 0.004*\"agile\" + 0.004*\"development\" + 0.003*\"waterfall\" + 0.003*\"scrum\" + 0.003*\"uml\"\n",
      "INFO : topic #13 (0.050): 0.014*\"tableau\" + 0.013*\"technical\" + 0.012*\"sas\" + 0.009*\"html\" + 0.009*\"sql\" + 0.008*\"python\" + 0.007*\"spss\" + 0.007*\"r\" + 0.006*\"c\" + 0.006*\"java\"\n",
      "INFO : topic #19 (0.050): 0.018*\"technical\" + 0.017*\"sql\" + 0.017*\"oracle\" + 0.015*\"ssis\" + 0.015*\"ssrs\" + 0.013*\"pl\" + 0.013*\"tableau\" + 0.012*\"windows\" + 0.010*\"unix\" + 0.010*\"teradata\"\n",
      "INFO : topic #10 (0.050): 0.009*\"illustrator\" + 0.009*\"photoshop\" + 0.008*\"indesign\" + 0.007*\"excel\" + 0.005*\"powerpoint\" + 0.005*\"word\" + 0.005*\"relevant\" + 0.004*\"research\" + 0.004*\"project\" + 0.004*\"sharepoint\"\n",
      "INFO : topic #18 (0.050): 0.013*\"jsp\" + 0.011*\"xml\" + 0.010*\"spring\" + 0.010*\"java\" + 0.009*\"hibernate\" + 0.009*\"eclipse\" + 0.009*\"j2ee\" + 0.008*\"javascript\" + 0.008*\"oracle\" + 0.008*\"hive\"\n",
      "INFO : topic diff=0.023833, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.690 per-word bound, 413.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=20, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=20, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (250 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (314 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (378 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (451 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (321 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (456 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (442 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (375 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (757 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (414 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (445 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (453 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (430 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (640 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (532 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (641 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (716 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (821 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (567 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (493 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (493 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 5; 384 documents processed (439 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (576 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (439 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (576 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (596 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (596 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 387 documents processed (640 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (505 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 8; 576 documents processed (630 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (505 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (630 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 6; 448 documents processed (526 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (703 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (703 virtual)\n",
      "DEBUG : finished all batches; 387 documents processed (640 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (705 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (780 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (526 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (384 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (705 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (780 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (913 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (913 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 6; 448 documents processed (530 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (990 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (530 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (990 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9410 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12418/12537 documents converged within 50 iterations\n",
      " 78%|███████▊  | 18/23 [07:53<02:11, 26.33s/it]INFO : using symmetric alpha at 0.047619047619047616\n",
      "INFO : using symmetric eta at 0.047619047619047616\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 21 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 442/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : 3423/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3281/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3223/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.048): 0.019*\"python\" + 0.016*\"r\" + 0.015*\"sql\" + 0.015*\"java\" + 0.011*\"hive\" + 0.011*\"tableau\" + 0.010*\"c++\" + 0.010*\"mysql\" + 0.009*\"hadoop\" + 0.009*\"c\"\n",
      "INFO : topic #0 (0.048): 0.018*\"sql\" + 0.016*\"r\" + 0.015*\"python\" + 0.009*\"hive\" + 0.008*\"java\" + 0.008*\"javascript\" + 0.008*\"html\" + 0.008*\"technical\" + 0.008*\"oracle\" + 0.007*\"excel\"\n",
      "INFO : topic #8 (0.048): 0.030*\"r\" + 0.028*\"python\" + 0.024*\"sql\" + 0.013*\"hadoop\" + 0.012*\"tableau\" + 0.011*\"c++\" + 0.011*\"java\" + 0.011*\"hive\" + 0.010*\"c\" + 0.009*\"linux\"\n",
      "INFO : topic #20 (0.048): 0.020*\"r\" + 0.018*\"python\" + 0.017*\"sql\" + 0.012*\"mysql\" + 0.012*\"matlab\" + 0.011*\"java\" + 0.011*\"technical\" + 0.009*\"tableau\" + 0.009*\"data\" + 0.008*\"c\"\n",
      "INFO : topic #2 (0.048): 0.014*\"r\" + 0.013*\"sql\" + 0.013*\"python\" + 0.009*\"c++\" + 0.009*\"linux\" + 0.008*\"programming\" + 0.007*\"java\" + 0.007*\"sas\" + 0.006*\"windows\" + 0.006*\"tableau\"\n",
      "INFO : topic diff=16.113760, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.421 per-word bound, 685.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 525/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3793/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3824/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3847/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.048): 0.011*\"technical\" + 0.009*\"python\" + 0.009*\"sql\" + 0.007*\"unix\" + 0.007*\"linux\" + 0.007*\"r\" + 0.006*\"powerpoint\" + 0.006*\"tableau\" + 0.006*\"java\" + 0.004*\"skills\"\n",
      "INFO : topic #1 (0.048): 0.023*\"python\" + 0.018*\"java\" + 0.018*\"r\" + 0.018*\"sql\" + 0.017*\"technical\" + 0.012*\"c++\" + 0.012*\"c\" + 0.010*\"mysql\" + 0.009*\"html\" + 0.008*\"javascript\"\n",
      "INFO : topic #14 (0.048): 0.019*\"r\" + 0.017*\"sql\" + 0.017*\"python\" + 0.012*\"c++\" + 0.012*\"java\" + 0.010*\"matlab\" + 0.010*\"c\" + 0.009*\"tableau\" + 0.009*\"technical\" + 0.008*\"mysql\"\n",
      "INFO : topic #4 (0.048): 0.022*\"sql\" + 0.022*\"r\" + 0.022*\"python\" + 0.011*\"matlab\" + 0.011*\"technical\" + 0.010*\"tableau\" + 0.009*\"java\" + 0.009*\"c++\" + 0.009*\"hadoop\" + 0.009*\"data\"\n",
      "INFO : topic #10 (0.048): 0.014*\"r\" + 0.010*\"excel\" + 0.009*\"sas\" + 0.009*\"mysql\" + 0.009*\"sql\" + 0.007*\"word\" + 0.007*\"spss\" + 0.007*\"powerpoint\" + 0.006*\"access\" + 0.006*\"python\"\n",
      "INFO : topic diff=0.373862, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.155 per-word bound, 570.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3878/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3883/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.048): 0.026*\"python\" + 0.025*\"html\" + 0.024*\"c\" + 0.023*\"java\" + 0.021*\"sql\" + 0.019*\"javascript\" + 0.019*\"r\" + 0.017*\"c++\" + 0.017*\"css\" + 0.014*\"technical\"\n",
      "INFO : topic #14 (0.048): 0.017*\"r\" + 0.016*\"sql\" + 0.016*\"python\" + 0.012*\"c++\" + 0.011*\"java\" + 0.009*\"matlab\" + 0.009*\"c\" + 0.008*\"tableau\" + 0.008*\"technical\" + 0.008*\"mysql\"\n",
      "INFO : topic #8 (0.048): 0.029*\"r\" + 0.028*\"python\" + 0.022*\"sql\" + 0.014*\"hadoop\" + 0.013*\"java\" + 0.012*\"tableau\" + 0.011*\"hive\" + 0.011*\"c++\" + 0.010*\"spark\" + 0.010*\"linux\"\n",
      "INFO : topic #13 (0.048): 0.019*\"python\" + 0.016*\"r\" + 0.016*\"technical\" + 0.015*\"sql\" + 0.014*\"tableau\" + 0.014*\"sas\" + 0.011*\"html\" + 0.010*\"java\" + 0.010*\"c++\" + 0.009*\"c\"\n",
      "INFO : topic #12 (0.048): 0.018*\"python\" + 0.014*\"r\" + 0.014*\"sql\" + 0.013*\"java\" + 0.010*\"hive\" + 0.010*\"tableau\" + 0.010*\"mysql\" + 0.009*\"spark\" + 0.009*\"c++\" + 0.009*\"hadoop\"\n",
      "INFO : topic diff=0.339225, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.009 per-word bound, 515.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3925/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : 3892/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.048): 0.013*\"sql\" + 0.010*\"technical\" + 0.007*\"r\" + 0.006*\"python\" + 0.006*\"sas\" + 0.006*\"tableau\" + 0.005*\"oracle\" + 0.005*\"linux\" + 0.005*\"agile\" + 0.005*\"teradata\"\n",
      "INFO : topic #3 (0.048): 0.010*\"technical\" + 0.008*\"unix\" + 0.006*\"sql\" + 0.006*\"linux\" + 0.006*\"powerpoint\" + 0.006*\"python\" + 0.005*\"skills\" + 0.004*\"java\" + 0.004*\"excel\" + 0.004*\"word\"\n",
      "INFO : topic #11 (0.048): 0.044*\"r\" + 0.042*\"python\" + 0.039*\"sql\" + 0.032*\"sas\" + 0.025*\"matlab\" + 0.019*\"c++\" + 0.018*\"tableau\" + 0.018*\"excel\" + 0.016*\"technical\" + 0.015*\"spss\"\n",
      "INFO : topic #6 (0.048): 0.028*\"python\" + 0.025*\"r\" + 0.022*\"sql\" + 0.018*\"pandas\" + 0.014*\"numpy\" + 0.013*\"scikit\" + 0.013*\"technical\" + 0.012*\"tableau\" + 0.012*\"sas\" + 0.011*\"matplotlib\"\n",
      "INFO : topic #9 (0.048): 0.027*\"python\" + 0.027*\"html\" + 0.026*\"java\" + 0.025*\"c\" + 0.023*\"javascript\" + 0.021*\"sql\" + 0.019*\"css\" + 0.019*\"c++\" + 0.018*\"r\" + 0.015*\"technical\"\n",
      "INFO : topic diff=0.298833, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.924 per-word bound, 485.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3907/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3903/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #14 (0.048): 0.014*\"r\" + 0.013*\"sql\" + 0.013*\"python\" + 0.010*\"c++\" + 0.009*\"java\" + 0.008*\"matlab\" + 0.007*\"c\" + 0.007*\"technical\" + 0.006*\"tableau\" + 0.006*\"mysql\"\n",
      "INFO : topic #2 (0.048): 0.009*\"r\" + 0.008*\"linux\" + 0.008*\"sql\" + 0.007*\"windows\" + 0.007*\"python\" + 0.006*\"c++\" + 0.005*\"programming\" + 0.005*\"data\" + 0.004*\"computer\" + 0.004*\"java\"\n",
      "INFO : topic #8 (0.048): 0.026*\"r\" + 0.026*\"python\" + 0.020*\"sql\" + 0.014*\"hadoop\" + 0.013*\"java\" + 0.011*\"spark\" + 0.011*\"hive\" + 0.011*\"tableau\" + 0.010*\"c++\" + 0.010*\"linux\"\n",
      "INFO : topic #15 (0.048): 0.034*\"python\" + 0.033*\"r\" + 0.032*\"sql\" + 0.021*\"hadoop\" + 0.019*\"tableau\" + 0.018*\"hive\" + 0.018*\"java\" + 0.016*\"matlab\" + 0.016*\"spark\" + 0.015*\"c\"\n",
      "INFO : topic #16 (0.048): 0.014*\"sql\" + 0.011*\"r\" + 0.010*\"python\" + 0.009*\"java\" + 0.008*\"technical\" + 0.006*\"c\" + 0.005*\"javascript\" + 0.005*\"sas\" + 0.004*\"databases\" + 0.004*\"mysql\"\n",
      "INFO : topic diff=0.257087, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.867 per-word bound, 466.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.048): 0.018*\"python\" + 0.015*\"java\" + 0.015*\"technical\" + 0.014*\"sql\" + 0.013*\"r\" + 0.010*\"c\" + 0.009*\"c++\" + 0.008*\"mysql\" + 0.007*\"html\" + 0.006*\"javascript\"\n",
      "INFO : topic #2 (0.048): 0.008*\"linux\" + 0.008*\"r\" + 0.007*\"windows\" + 0.007*\"sql\" + 0.006*\"python\" + 0.005*\"c++\" + 0.005*\"data\" + 0.004*\"programming\" + 0.004*\"computer\" + 0.003*\"xp\"\n",
      "INFO : topic #4 (0.048): 0.017*\"r\" + 0.017*\"sql\" + 0.016*\"python\" + 0.009*\"matlab\" + 0.008*\"data\" + 0.008*\"technical\" + 0.007*\"spss\" + 0.007*\"c++\" + 0.007*\"tableau\" + 0.006*\"java\"\n",
      "INFO : topic #11 (0.048): 0.050*\"r\" + 0.046*\"python\" + 0.043*\"sql\" + 0.036*\"sas\" + 0.027*\"matlab\" + 0.022*\"excel\" + 0.021*\"c++\" + 0.020*\"tableau\" + 0.018*\"spss\" + 0.016*\"technical\"\n",
      "INFO : topic #8 (0.048): 0.025*\"r\" + 0.025*\"python\" + 0.019*\"sql\" + 0.014*\"hadoop\" + 0.013*\"java\" + 0.011*\"spark\" + 0.010*\"hive\" + 0.010*\"tableau\" + 0.010*\"c++\" + 0.010*\"linux\"\n",
      "INFO : topic diff=0.217018, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.825 per-word bound, 453.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.048): 0.013*\"python\" + 0.010*\"sql\" + 0.010*\"r\" + 0.009*\"java\" + 0.008*\"hive\" + 0.008*\"tableau\" + 0.007*\"mysql\" + 0.007*\"spark\" + 0.006*\"programming\" + 0.006*\"hdfs\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #17 (0.048): 0.010*\"python\" + 0.009*\"r\" + 0.007*\"c\" + 0.007*\"excel\" + 0.007*\"c++\" + 0.005*\"technical\" + 0.005*\"sql\" + 0.005*\"javascript\" + 0.005*\"skills\" + 0.004*\"project\"\n",
      "INFO : topic #0 (0.048): 0.010*\"sql\" + 0.007*\"r\" + 0.007*\"python\" + 0.007*\"oracle\" + 0.006*\"html\" + 0.006*\"technical\" + 0.006*\"javascript\" + 0.006*\"linux\" + 0.006*\"excel\" + 0.005*\"hive\"\n",
      "INFO : topic #8 (0.048): 0.025*\"r\" + 0.024*\"python\" + 0.018*\"sql\" + 0.014*\"hadoop\" + 0.013*\"java\" + 0.011*\"spark\" + 0.010*\"hive\" + 0.010*\"linux\" + 0.010*\"tableau\" + 0.009*\"c++\"\n",
      "INFO : topic #3 (0.048): 0.008*\"technical\" + 0.007*\"unix\" + 0.006*\"linux\" + 0.006*\"skills\" + 0.005*\"powerpoint\" + 0.004*\"sql\" + 0.004*\"salesforce\" + 0.004*\"excel\" + 0.003*\"project\" + 0.003*\"bullhorn\"\n",
      "INFO : topic diff=0.180789, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.793 per-word bound, 443.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3924/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #17 (0.048): 0.009*\"python\" + 0.008*\"r\" + 0.007*\"c\" + 0.007*\"excel\" + 0.006*\"c++\" + 0.005*\"technical\" + 0.005*\"sql\" + 0.005*\"skills\" + 0.004*\"project\" + 0.004*\"javascript\"\n",
      "INFO : topic #16 (0.048): 0.010*\"sql\" + 0.008*\"r\" + 0.007*\"java\" + 0.007*\"technical\" + 0.007*\"python\" + 0.005*\"c\" + 0.004*\"databases\" + 0.004*\"javascript\" + 0.003*\"sas\" + 0.003*\"oracle\"\n",
      "INFO : topic #7 (0.048): 0.011*\"linux\" + 0.009*\"sql\" + 0.009*\"python\" + 0.006*\"r\" + 0.005*\"c++\" + 0.005*\"hadoop\" + 0.005*\"hive\" + 0.004*\"matlab\" + 0.004*\"skill\" + 0.004*\"mapreduce\"\n",
      "INFO : topic #19 (0.048): 0.018*\"technical\" + 0.017*\"sql\" + 0.014*\"oracle\" + 0.013*\"tableau\" + 0.011*\"ssis\" + 0.011*\"windows\" + 0.010*\"ssrs\" + 0.010*\"excel\" + 0.010*\"pl\" + 0.010*\"unix\"\n",
      "INFO : topic #2 (0.048): 0.008*\"linux\" + 0.008*\"windows\" + 0.007*\"r\" + 0.005*\"sql\" + 0.005*\"python\" + 0.004*\"data\" + 0.004*\"c++\" + 0.004*\"xp\" + 0.004*\"vista\" + 0.003*\"programming\"\n",
      "INFO : topic diff=0.149870, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.768 per-word bound, 436.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3935/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3926/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.048): 0.008*\"excel\" + 0.006*\"photoshop\" + 0.006*\"indesign\" + 0.006*\"powerpoint\" + 0.006*\"word\" + 0.006*\"r\" + 0.006*\"access\" + 0.005*\"relevant\" + 0.005*\"illustrator\" + 0.004*\"sql\"\n",
      "INFO : topic #1 (0.048): 0.014*\"python\" + 0.013*\"java\" + 0.012*\"technical\" + 0.011*\"sql\" + 0.011*\"r\" + 0.008*\"c\" + 0.007*\"c++\" + 0.006*\"mysql\" + 0.006*\"ms\" + 0.005*\"html\"\n",
      "INFO : topic #18 (0.048): 0.009*\"hadoop\" + 0.009*\"java\" + 0.008*\"spring\" + 0.008*\"sql\" + 0.008*\"javascript\" + 0.008*\"jsp\" + 0.008*\"mysql\" + 0.008*\"hbase\" + 0.007*\"hibernate\" + 0.007*\"jdbc\"\n",
      "INFO : topic #15 (0.048): 0.035*\"python\" + 0.033*\"r\" + 0.031*\"sql\" + 0.025*\"hadoop\" + 0.023*\"hive\" + 0.019*\"tableau\" + 0.019*\"java\" + 0.019*\"spark\" + 0.015*\"matlab\" + 0.015*\"pig\"\n",
      "INFO : topic #5 (0.048): 0.008*\"technical\" + 0.008*\"sql\" + 0.006*\"agile\" + 0.005*\"scrum\" + 0.005*\"teradata\" + 0.005*\"key\" + 0.004*\"oracle\" + 0.004*\"etl\" + 0.004*\"tableau\" + 0.004*\"waterfall\"\n",
      "INFO : topic diff=0.123990, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.747 per-word bound, 429.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.048): 0.010*\"python\" + 0.008*\"sql\" + 0.007*\"r\" + 0.007*\"java\" + 0.007*\"hive\" + 0.006*\"tableau\" + 0.006*\"hdfs\" + 0.006*\"programming\" + 0.006*\"spark\" + 0.005*\"mysql\"\n",
      "INFO : topic #2 (0.048): 0.008*\"windows\" + 0.008*\"linux\" + 0.006*\"r\" + 0.004*\"data\" + 0.004*\"sql\" + 0.004*\"xp\" + 0.004*\"vista\" + 0.004*\"python\" + 0.003*\"c++\" + 0.003*\"project\"\n",
      "INFO : topic #10 (0.048): 0.008*\"excel\" + 0.007*\"photoshop\" + 0.007*\"indesign\" + 0.006*\"powerpoint\" + 0.006*\"illustrator\" + 0.006*\"word\" + 0.005*\"access\" + 0.005*\"relevant\" + 0.005*\"r\" + 0.004*\"sql\"\n",
      "INFO : topic #14 (0.048): 0.008*\"sql\" + 0.008*\"r\" + 0.008*\"c++\" + 0.007*\"python\" + 0.006*\"java\" + 0.005*\"matlab\" + 0.005*\"c\" + 0.005*\"project\" + 0.005*\"data\" + 0.004*\"technical\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #6 (0.048): 0.032*\"python\" + 0.027*\"r\" + 0.026*\"pandas\" + 0.024*\"sql\" + 0.021*\"numpy\" + 0.019*\"scikit\" + 0.015*\"technical\" + 0.014*\"scipy\" + 0.014*\"tableau\" + 0.013*\"matplotlib\"\n",
      "INFO : topic diff=0.102845, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.731 per-word bound, 424.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.048): 0.008*\"technical\" + 0.007*\"sql\" + 0.006*\"agile\" + 0.006*\"scrum\" + 0.005*\"key\" + 0.004*\"teradata\" + 0.004*\"etl\" + 0.004*\"oracle\" + 0.004*\"waterfall\" + 0.004*\"tableau\"\n",
      "INFO : topic #2 (0.048): 0.008*\"windows\" + 0.008*\"linux\" + 0.005*\"r\" + 0.004*\"data\" + 0.004*\"xp\" + 0.004*\"sql\" + 0.004*\"vista\" + 0.003*\"python\" + 0.003*\"c++\" + 0.003*\"project\"\n",
      "INFO : topic #20 (0.048): 0.009*\"data\" + 0.009*\"english\" + 0.008*\"r\" + 0.007*\"sql\" + 0.007*\"python\" + 0.006*\"technical\" + 0.006*\"project\" + 0.006*\"mysql\" + 0.005*\"business\" + 0.005*\"french\"\n",
      "INFO : topic #12 (0.048): 0.009*\"python\" + 0.007*\"sql\" + 0.006*\"java\" + 0.006*\"r\" + 0.006*\"hive\" + 0.006*\"tableau\" + 0.005*\"hdfs\" + 0.005*\"programming\" + 0.005*\"spark\" + 0.005*\"mysql\"\n",
      "INFO : topic #9 (0.048): 0.033*\"javascript\" + 0.033*\"java\" + 0.033*\"html\" + 0.029*\"python\" + 0.029*\"c\" + 0.026*\"css\" + 0.025*\"c++\" + 0.021*\"sql\" + 0.020*\"mysql\" + 0.017*\"php\"\n",
      "INFO : topic diff=0.085907, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.718 per-word bound, 421.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.048): 0.007*\"photoshop\" + 0.007*\"indesign\" + 0.007*\"excel\" + 0.007*\"illustrator\" + 0.005*\"relevant\" + 0.005*\"powerpoint\" + 0.005*\"word\" + 0.005*\"access\" + 0.004*\"r\" + 0.004*\"andexcel\"\n",
      "INFO : topic #9 (0.048): 0.034*\"javascript\" + 0.034*\"java\" + 0.034*\"html\" + 0.030*\"c\" + 0.030*\"python\" + 0.026*\"css\" + 0.025*\"c++\" + 0.021*\"sql\" + 0.020*\"mysql\" + 0.018*\"php\"\n",
      "INFO : topic #2 (0.048): 0.008*\"windows\" + 0.008*\"linux\" + 0.005*\"r\" + 0.004*\"data\" + 0.004*\"xp\" + 0.004*\"vista\" + 0.004*\"sql\" + 0.003*\"python\" + 0.003*\"project\" + 0.003*\"c++\"\n",
      "INFO : topic #15 (0.048): 0.034*\"python\" + 0.033*\"r\" + 0.030*\"sql\" + 0.026*\"hadoop\" + 0.025*\"hive\" + 0.020*\"spark\" + 0.019*\"tableau\" + 0.019*\"java\" + 0.017*\"pig\" + 0.015*\"matlab\"\n",
      "INFO : topic #14 (0.048): 0.007*\"sql\" + 0.007*\"c++\" + 0.007*\"r\" + 0.006*\"python\" + 0.005*\"java\" + 0.005*\"project\" + 0.005*\"data\" + 0.004*\"matlab\" + 0.004*\"c\" + 0.004*\"analytics\"\n",
      "INFO : topic diff=0.072241, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.707 per-word bound, 417.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 537/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.048): 0.035*\"javascript\" + 0.034*\"java\" + 0.034*\"html\" + 0.030*\"c\" + 0.030*\"python\" + 0.027*\"css\" + 0.025*\"c++\" + 0.021*\"sql\" + 0.020*\"mysql\" + 0.018*\"php\"\n",
      "INFO : topic #3 (0.048): 0.007*\"unix\" + 0.007*\"technical\" + 0.006*\"skills\" + 0.005*\"linux\" + 0.004*\"salesforce\" + 0.004*\"bullhorn\" + 0.004*\"powerpoint\" + 0.004*\"taleo\" + 0.003*\"project\" + 0.003*\"icims\"\n",
      "INFO : topic #5 (0.048): 0.007*\"technical\" + 0.006*\"agile\" + 0.006*\"sql\" + 0.006*\"scrum\" + 0.005*\"key\" + 0.004*\"teradata\" + 0.004*\"etl\" + 0.004*\"waterfall\" + 0.004*\"means\" + 0.003*\"sql_server\"\n",
      "INFO : topic #18 (0.048): 0.010*\"jsp\" + 0.009*\"spring\" + 0.008*\"hibernate\" + 0.008*\"hbase\" + 0.008*\"hadoop\" + 0.008*\"jdbc\" + 0.008*\"java\" + 0.008*\"servlets\" + 0.007*\"sql\" + 0.007*\"javascript\"\n",
      "INFO : topic #10 (0.048): 0.008*\"photoshop\" + 0.008*\"indesign\" + 0.007*\"illustrator\" + 0.007*\"excel\" + 0.006*\"relevant\" + 0.005*\"word\" + 0.005*\"powerpoint\" + 0.005*\"access\" + 0.004*\"andexcel\" + 0.004*\"academic\"\n",
      "INFO : topic diff=0.061232, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.697 per-word bound, 414.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 537/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.048): 0.007*\"technical\" + 0.006*\"agile\" + 0.006*\"scrum\" + 0.005*\"sql\" + 0.005*\"key\" + 0.004*\"teradata\" + 0.004*\"etl\" + 0.004*\"waterfall\" + 0.004*\"means\" + 0.004*\"highlightsof\"\n",
      "INFO : topic #15 (0.048): 0.034*\"python\" + 0.033*\"r\" + 0.030*\"sql\" + 0.027*\"hadoop\" + 0.027*\"hive\" + 0.021*\"spark\" + 0.019*\"java\" + 0.019*\"tableau\" + 0.018*\"pig\" + 0.015*\"c\"\n",
      "INFO : topic #11 (0.048): 0.058*\"r\" + 0.050*\"python\" + 0.048*\"sql\" + 0.041*\"sas\" + 0.030*\"matlab\" + 0.028*\"excel\" + 0.023*\"c++\" + 0.023*\"tableau\" + 0.021*\"spss\" + 0.017*\"technical\"\n",
      "INFO : topic #1 (0.048): 0.010*\"technical\" + 0.010*\"python\" + 0.009*\"java\" + 0.008*\"sql\" + 0.007*\"r\" + 0.006*\"c\" + 0.005*\"ms\" + 0.005*\"c++\" + 0.004*\"oracle\" + 0.004*\"mysql\"\n",
      "INFO : topic #2 (0.048): 0.008*\"windows\" + 0.007*\"linux\" + 0.005*\"r\" + 0.004*\"xp\" + 0.004*\"data\" + 0.004*\"vista\" + 0.003*\"sql\" + 0.003*\"project\" + 0.003*\"skills/\" + 0.003*\"python\"\n",
      "INFO : topic diff=0.052508, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.690 per-word bound, 412.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #19 (0.048): 0.020*\"technical\" + 0.018*\"sql\" + 0.018*\"oracle\" + 0.014*\"ssis\" + 0.014*\"tableau\" + 0.013*\"ssrs\" + 0.013*\"pl\" + 0.012*\"windows\" + 0.012*\"teradata\" + 0.011*\"unix\"\n",
      "INFO : topic #1 (0.048): 0.010*\"technical\" + 0.009*\"python\" + 0.009*\"java\" + 0.008*\"sql\" + 0.007*\"r\" + 0.006*\"c\" + 0.005*\"ms\" + 0.005*\"c++\" + 0.004*\"oracle\" + 0.004*\"mysql\"\n",
      "INFO : topic #4 (0.048): 0.009*\"r\" + 0.009*\"sql\" + 0.007*\"python\" + 0.007*\"data\" + 0.005*\"technical\" + 0.005*\"spss\" + 0.005*\"matlab\" + 0.004*\"windows\" + 0.004*\"computer\" + 0.004*\"oracle\"\n",
      "INFO : topic #6 (0.048): 0.033*\"python\" + 0.028*\"r\" + 0.028*\"pandas\" + 0.025*\"sql\" + 0.023*\"numpy\" + 0.019*\"scikit\" + 0.016*\"technical\" + 0.015*\"scipy\" + 0.014*\"tableau\" + 0.013*\"matplotlib\"\n",
      "INFO : topic #18 (0.048): 0.010*\"jsp\" + 0.009*\"spring\" + 0.009*\"hibernate\" + 0.008*\"hbase\" + 0.008*\"jdbc\" + 0.008*\"servlets\" + 0.008*\"hadoop\" + 0.007*\"java\" + 0.007*\"sql\" + 0.007*\"javascript\"\n",
      "INFO : topic diff=0.045540, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.683 per-word bound, 410.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.048): 0.008*\"windows\" + 0.007*\"linux\" + 0.005*\"xp\" + 0.004*\"vista\" + 0.004*\"data\" + 0.004*\"r\" + 0.003*\"project\" + 0.003*\"skills/\" + 0.003*\"sql\" + 0.003*\"analytics\"\n",
      "INFO : topic #20 (0.048): 0.012*\"english\" + 0.010*\"data\" + 0.007*\"project\" + 0.007*\"business\" + 0.006*\"french\" + 0.006*\"areasof\" + 0.005*\"r\" + 0.005*\"language\" + 0.005*\"sql\" + 0.005*\"team\"\n",
      "INFO : topic #19 (0.048): 0.020*\"technical\" + 0.018*\"oracle\" + 0.018*\"sql\" + 0.014*\"ssis\" + 0.014*\"ssrs\" + 0.014*\"tableau\" + 0.013*\"pl\" + 0.012*\"windows\" + 0.012*\"teradata\" + 0.011*\"unix\"\n",
      "INFO : topic #7 (0.048): 0.008*\"linux\" + 0.005*\"skill\" + 0.005*\"sql\" + 0.004*\"core\" + 0.004*\"python\" + 0.004*\"probability\" + 0.003*\"software\" + 0.003*\"taleo\" + 0.003*\"c++\" + 0.003*\"computer\"\n",
      "INFO : topic #5 (0.048): 0.007*\"technical\" + 0.006*\"agile\" + 0.006*\"scrum\" + 0.005*\"key\" + 0.005*\"sql\" + 0.004*\"teradata\" + 0.004*\"etl\" + 0.004*\"highlightsof\" + 0.004*\"means\" + 0.004*\"waterfall\"\n",
      "INFO : topic diff=0.039830, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.676 per-word bound, 409.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3967/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #14 (0.048): 0.005*\"c++\" + 0.005*\"project\" + 0.005*\"sql\" + 0.004*\"r\" + 0.004*\"data\" + 0.004*\"analytics\" + 0.004*\"java\" + 0.004*\"python\" + 0.003*\"c\" + 0.003*\"matlab\"\n",
      "INFO : topic #18 (0.048): 0.011*\"jsp\" + 0.010*\"spring\" + 0.009*\"hibernate\" + 0.008*\"hbase\" + 0.008*\"jdbc\" + 0.008*\"servlets\" + 0.007*\"hadoop\" + 0.007*\"java\" + 0.007*\"xml\" + 0.007*\"tcp\"\n",
      "INFO : topic #3 (0.048): 0.007*\"unix\" + 0.006*\"technical\" + 0.006*\"skills\" + 0.005*\"salesforce\" + 0.005*\"taleo\" + 0.005*\"linux\" + 0.004*\"bullhorn\" + 0.004*\"icims\" + 0.004*\"powerpoint\" + 0.003*\"project\"\n",
      "INFO : topic #16 (0.048): 0.005*\"s.\" + 0.004*\"sql\" + 0.004*\"technical\" + 0.004*\"databases\" + 0.004*\"java\" + 0.004*\"d.\" + 0.004*\"j.\" + 0.004*\"m.\" + 0.004*\"r\" + 0.003*\"p.\"\n",
      "INFO : topic #9 (0.048): 0.036*\"javascript\" + 0.035*\"java\" + 0.035*\"html\" + 0.031*\"c\" + 0.030*\"python\" + 0.028*\"css\" + 0.027*\"c++\" + 0.021*\"sql\" + 0.021*\"mysql\" + 0.018*\"php\"\n",
      "INFO : topic diff=0.035241, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.671 per-word bound, 407.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3967/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #20 (0.048): 0.013*\"english\" + 0.010*\"data\" + 0.007*\"project\" + 0.007*\"business\" + 0.006*\"french\" + 0.006*\"areasof\" + 0.005*\"language\" + 0.005*\"team\" + 0.005*\"spanish\" + 0.005*\"core\"\n",
      "INFO : topic #9 (0.048): 0.037*\"javascript\" + 0.036*\"java\" + 0.035*\"html\" + 0.031*\"c\" + 0.030*\"python\" + 0.028*\"css\" + 0.027*\"c++\" + 0.021*\"sql\" + 0.021*\"mysql\" + 0.018*\"php\"\n",
      "INFO : topic #18 (0.048): 0.011*\"jsp\" + 0.010*\"spring\" + 0.009*\"hibernate\" + 0.008*\"jdbc\" + 0.008*\"servlets\" + 0.008*\"hbase\" + 0.007*\"hadoop\" + 0.007*\"tcp\" + 0.007*\"xml\" + 0.007*\"java\"\n",
      "INFO : topic #15 (0.048): 0.034*\"python\" + 0.033*\"r\" + 0.029*\"sql\" + 0.029*\"hive\" + 0.029*\"hadoop\" + 0.023*\"spark\" + 0.020*\"java\" + 0.019*\"pig\" + 0.019*\"tableau\" + 0.014*\"c\"\n",
      "INFO : topic #10 (0.048): 0.009*\"illustrator\" + 0.009*\"photoshop\" + 0.008*\"indesign\" + 0.006*\"relevant\" + 0.005*\"excel\" + 0.004*\"word\" + 0.004*\"academic\" + 0.004*\"powerpoint\" + 0.004*\"andexcel\" + 0.004*\"access\"\n",
      "INFO : topic diff=0.031400, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.666 per-word bound, 406.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 536/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.048): 0.033*\"python\" + 0.029*\"r\" + 0.028*\"pandas\" + 0.025*\"sql\" + 0.023*\"numpy\" + 0.019*\"scikit\" + 0.016*\"technical\" + 0.015*\"scipy\" + 0.014*\"tableau\" + 0.013*\"tensorflow\"\n",
      "INFO : topic #9 (0.048): 0.037*\"javascript\" + 0.036*\"java\" + 0.036*\"html\" + 0.031*\"c\" + 0.031*\"python\" + 0.028*\"css\" + 0.027*\"c++\" + 0.021*\"mysql\" + 0.021*\"sql\" + 0.018*\"php\"\n",
      "INFO : topic #18 (0.048): 0.011*\"jsp\" + 0.010*\"spring\" + 0.009*\"hibernate\" + 0.008*\"jdbc\" + 0.008*\"servlets\" + 0.008*\"hbase\" + 0.007*\"tcp\" + 0.007*\"hadoop\" + 0.007*\"xml\" + 0.007*\"j2ee\"\n",
      "INFO : topic #11 (0.048): 0.059*\"r\" + 0.051*\"python\" + 0.048*\"sql\" + 0.042*\"sas\" + 0.031*\"matlab\" + 0.030*\"excel\" + 0.023*\"tableau\" + 0.023*\"c++\" + 0.021*\"spss\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #0 (0.048): 0.006*\"sql\" + 0.005*\"oracle\" + 0.004*\"excel\" + 0.004*\"project\" + 0.003*\"html\" + 0.003*\"javascript\" + 0.003*\"technical\" + 0.003*\"linux\" + 0.003*\"r\" + 0.003*\"access\"\n",
      "INFO : topic diff=0.028213, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.662 per-word bound, 405.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.048): 0.006*\"sql\" + 0.005*\"oracle\" + 0.004*\"excel\" + 0.004*\"project\" + 0.003*\"html\" + 0.003*\"technical\" + 0.003*\"javascript\" + 0.003*\"linux\" + 0.003*\"development\" + 0.003*\"access\"\n",
      "INFO : topic #13 (0.048): 0.008*\"technical\" + 0.008*\"data\" + 0.008*\"spss\" + 0.008*\"sas\" + 0.007*\"tableau\" + 0.006*\"sql\" + 0.006*\"html\" + 0.005*\"python\" + 0.005*\"statistical\" + 0.004*\"r\"\n",
      "INFO : topic #4 (0.048): 0.007*\"r\" + 0.007*\"sql\" + 0.006*\"data\" + 0.005*\"technical\" + 0.004*\"python\" + 0.004*\"spss\" + 0.004*\"windows\" + 0.004*\"oracle\" + 0.004*\"matlab\" + 0.003*\"computer\"\n",
      "INFO : topic #9 (0.048): 0.037*\"javascript\" + 0.036*\"java\" + 0.036*\"html\" + 0.031*\"c\" + 0.031*\"python\" + 0.028*\"css\" + 0.027*\"c++\" + 0.022*\"mysql\" + 0.021*\"sql\" + 0.019*\"php\"\n",
      "INFO : topic #8 (0.048): 0.016*\"r\" + 0.015*\"python\" + 0.011*\"sql\" + 0.010*\"spark\" + 0.009*\"hadoop\" + 0.008*\"java\" + 0.007*\"postgresql\" + 0.006*\"linux\" + 0.006*\"hive\" + 0.006*\"s3\"\n",
      "INFO : topic diff=0.025584, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.658 per-word bound, 403.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=21, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=21, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (481 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (400 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (371 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (452 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (456 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (375 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (891 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (404 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (568 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 4; 320 documents processed (435 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (453 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (460 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (641 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (494 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (654 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (449 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (756 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (502 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (512 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 5; 384 documents processed (439 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (517 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (439 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (592 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (517 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (592 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (705 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 465 documents processed (589 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 465 documents processed (589 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (966 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (518 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 448 documents processed (705 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (518 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (718 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (513 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (513 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (718 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (610 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (610 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (558 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (558 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (966 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 5; 384 documents processed (516 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 384 documents processed (516 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (733 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (733 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 9; 640 documents processed (938 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (938 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9424 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12432/12537 documents converged within 50 iterations\n",
      " 83%|████████▎ | 19/23 [08:22<01:45, 26.47s/it]INFO : using symmetric alpha at 0.045454545454545456\n",
      "INFO : using symmetric eta at 0.045454545454545456\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 22 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 441/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 3426/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3310/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3213/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #20 (0.045): 0.019*\"r\" + 0.018*\"python\" + 0.017*\"sql\" + 0.011*\"technical\" + 0.011*\"mysql\" + 0.010*\"java\" + 0.010*\"matlab\" + 0.008*\"c++\" + 0.008*\"c\" + 0.008*\"tableau\"\n",
      "INFO : topic #7 (0.045): 0.017*\"python\" + 0.017*\"sql\" + 0.014*\"linux\" + 0.012*\"r\" + 0.010*\"hadoop\" + 0.010*\"c++\" + 0.008*\"excel\" + 0.008*\"matlab\" + 0.008*\"c\" + 0.007*\"hive\"\n",
      "INFO : topic #1 (0.045): 0.024*\"python\" + 0.018*\"sql\" + 0.018*\"java\" + 0.018*\"r\" + 0.016*\"technical\" + 0.012*\"c\" + 0.012*\"c++\" + 0.011*\"mysql\" + 0.009*\"html\" + 0.009*\"tableau\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #16 (0.045): 0.024*\"sql\" + 0.022*\"r\" + 0.017*\"python\" + 0.012*\"java\" + 0.012*\"technical\" + 0.009*\"sas\" + 0.009*\"javascript\" + 0.007*\"c\" + 0.007*\"tableau\" + 0.007*\"hadoop\"\n",
      "INFO : topic #12 (0.045): 0.021*\"python\" + 0.015*\"r\" + 0.014*\"sql\" + 0.014*\"java\" + 0.013*\"hive\" + 0.012*\"mysql\" + 0.010*\"tableau\" + 0.010*\"hadoop\" + 0.009*\"spark\" + 0.009*\"c\"\n",
      "INFO : topic diff=17.042198, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.392 per-word bound, 672.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 523/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3812/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3769/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3838/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.045): 0.016*\"sql\" + 0.015*\"python\" + 0.013*\"linux\" + 0.011*\"r\" + 0.009*\"c++\" + 0.009*\"hadoop\" + 0.008*\"excel\" + 0.008*\"matlab\" + 0.007*\"c\" + 0.006*\"java\"\n",
      "INFO : topic #2 (0.045): 0.013*\"r\" + 0.010*\"python\" + 0.009*\"sql\" + 0.008*\"linux\" + 0.008*\"c++\" + 0.007*\"sas\" + 0.006*\"html\" + 0.006*\"windows\" + 0.005*\"computer\" + 0.005*\"java\"\n",
      "INFO : topic #19 (0.045): 0.020*\"sql\" + 0.016*\"technical\" + 0.014*\"python\" + 0.014*\"r\" + 0.014*\"tableau\" + 0.013*\"excel\" + 0.010*\"oracle\" + 0.009*\"sas\" + 0.008*\"c\" + 0.008*\"hadoop\"\n",
      "INFO : topic #20 (0.045): 0.017*\"r\" + 0.017*\"python\" + 0.016*\"sql\" + 0.011*\"technical\" + 0.010*\"mysql\" + 0.010*\"java\" + 0.010*\"matlab\" + 0.008*\"c++\" + 0.008*\"programming\" + 0.008*\"c\"\n",
      "INFO : topic #15 (0.045): 0.033*\"python\" + 0.031*\"r\" + 0.031*\"sql\" + 0.019*\"matlab\" + 0.018*\"java\" + 0.017*\"hadoop\" + 0.016*\"c\" + 0.015*\"tableau\" + 0.015*\"c++\" + 0.014*\"hive\"\n",
      "INFO : topic diff=0.366197, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.158 per-word bound, 571.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 520/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3848/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3923/4000 documents converged within 50 iterations\n",
      "DEBUG : 3865/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #17 (0.045): 0.019*\"python\" + 0.016*\"r\" + 0.010*\"sql\" + 0.009*\"c\" + 0.009*\"excel\" + 0.008*\"technical\" + 0.008*\"c++\" + 0.008*\"tableau\" + 0.007*\"matlab\" + 0.007*\"hadoop\"\n",
      "INFO : topic #13 (0.045): 0.021*\"python\" + 0.020*\"sql\" + 0.018*\"r\" + 0.016*\"technical\" + 0.016*\"sas\" + 0.015*\"tableau\" + 0.012*\"html\" + 0.011*\"c\" + 0.011*\"java\" + 0.011*\"c++\"\n",
      "INFO : topic #6 (0.045): 0.026*\"python\" + 0.025*\"r\" + 0.020*\"sql\" + 0.014*\"pandas\" + 0.013*\"technical\" + 0.012*\"tableau\" + 0.011*\"sas\" + 0.010*\"numpy\" + 0.010*\"matlab\" + 0.010*\"statistical\"\n",
      "INFO : topic #9 (0.045): 0.026*\"python\" + 0.025*\"c\" + 0.024*\"html\" + 0.023*\"java\" + 0.021*\"sql\" + 0.020*\"javascript\" + 0.019*\"r\" + 0.019*\"c++\" + 0.016*\"css\" + 0.015*\"technical\"\n",
      "INFO : topic #3 (0.045): 0.010*\"technical\" + 0.010*\"unix\" + 0.009*\"linux\" + 0.009*\"sql\" + 0.007*\"python\" + 0.007*\"r\" + 0.005*\"tableau\" + 0.005*\"java\" + 0.004*\"c\" + 0.004*\"word\"\n",
      "INFO : topic diff=0.334214, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.026 per-word bound, 521.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 526/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3878/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.045): 0.011*\"r\" + 0.009*\"excel\" + 0.009*\"sas\" + 0.009*\"powerpoint\" + 0.008*\"access\" + 0.007*\"sql\" + 0.007*\"mysql\" + 0.006*\"spss\" + 0.006*\"data\" + 0.006*\"linux\"\n",
      "INFO : topic #12 (0.045): 0.017*\"python\" + 0.012*\"hive\" + 0.012*\"r\" + 0.011*\"java\" + 0.011*\"mysql\" + 0.011*\"sql\" + 0.009*\"spark\" + 0.009*\"tableau\" + 0.009*\"hadoop\" + 0.008*\"mapreduce\"\n",
      "INFO : topic #9 (0.045): 0.026*\"python\" + 0.026*\"html\" + 0.026*\"c\" + 0.024*\"java\" + 0.023*\"javascript\" + 0.021*\"sql\" + 0.020*\"c++\" + 0.019*\"css\" + 0.018*\"r\" + 0.015*\"technical\"\n",
      "INFO : topic #8 (0.045): 0.028*\"python\" + 0.027*\"r\" + 0.022*\"sql\" + 0.015*\"tableau\" + 0.014*\"hadoop\" + 0.013*\"hive\" + 0.011*\"java\" + 0.010*\"technical\" + 0.010*\"linux\" + 0.010*\"spark\"\n",
      "INFO : topic #18 (0.045): 0.014*\"javascript\" + 0.014*\"python\" + 0.014*\"java\" + 0.012*\"sql\" + 0.011*\"mysql\" + 0.011*\"html\" + 0.010*\"hadoop\" + 0.010*\"c++\" + 0.009*\"xml\" + 0.008*\"r\"\n",
      "INFO : topic diff=0.295302, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.942 per-word bound, 491.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #17 (0.045): 0.015*\"python\" + 0.012*\"r\" + 0.008*\"sql\" + 0.008*\"excel\" + 0.007*\"c\" + 0.007*\"c++\" + 0.007*\"tableau\" + 0.007*\"technical\" + 0.005*\"matlab\" + 0.005*\"javascript\"\n",
      "INFO : topic #1 (0.045): 0.019*\"python\" + 0.016*\"sql\" + 0.015*\"java\" + 0.013*\"technical\" + 0.012*\"r\" + 0.011*\"c\" + 0.010*\"mysql\" + 0.009*\"c++\" + 0.009*\"linux\" + 0.008*\"html\"\n",
      "INFO : topic #15 (0.045): 0.036*\"python\" + 0.035*\"r\" + 0.033*\"sql\" + 0.021*\"hadoop\" + 0.020*\"java\" + 0.019*\"matlab\" + 0.018*\"hive\" + 0.017*\"tableau\" + 0.017*\"c\" + 0.017*\"c++\"\n",
      "INFO : topic #18 (0.045): 0.014*\"javascript\" + 0.014*\"java\" + 0.012*\"python\" + 0.011*\"sql\" + 0.011*\"mysql\" + 0.011*\"html\" + 0.010*\"hadoop\" + 0.009*\"xml\" + 0.009*\"c++\" + 0.009*\"jsp\"\n",
      "INFO : topic #4 (0.045): 0.018*\"sql\" + 0.017*\"python\" + 0.017*\"r\" + 0.009*\"matlab\" + 0.008*\"data\" + 0.007*\"java\" + 0.007*\"sas\" + 0.007*\"technical\" + 0.007*\"tableau\" + 0.007*\"spss\"\n",
      "INFO : topic diff=0.253088, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.884 per-word bound, 472.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3895/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #19 (0.045): 0.018*\"sql\" + 0.017*\"technical\" + 0.013*\"tableau\" + 0.013*\"excel\" + 0.012*\"oracle\" + 0.010*\"python\" + 0.009*\"word\" + 0.009*\"r\" + 0.009*\"windows\" + 0.009*\"hive\"\n",
      "INFO : topic #0 (0.045): 0.011*\"sql\" + 0.008*\"r\" + 0.007*\"python\" + 0.007*\"technical\" + 0.006*\"linux\" + 0.006*\"oracle\" + 0.006*\"hive\" + 0.006*\"html\" + 0.005*\"javascript\" + 0.005*\"java\"\n",
      "INFO : topic #18 (0.045): 0.014*\"java\" + 0.013*\"javascript\" + 0.011*\"python\" + 0.011*\"mysql\" + 0.011*\"sql\" + 0.010*\"html\" + 0.010*\"xml\" + 0.010*\"jsp\" + 0.010*\"hadoop\" + 0.009*\"oracle\"\n",
      "INFO : topic #15 (0.045): 0.037*\"python\" + 0.035*\"r\" + 0.032*\"sql\" + 0.022*\"hadoop\" + 0.021*\"java\" + 0.019*\"matlab\" + 0.019*\"hive\" + 0.018*\"tableau\" + 0.017*\"c++\" + 0.017*\"c\"\n",
      "INFO : topic #21 (0.045): 0.006*\"taleo\" + 0.005*\"python\" + 0.004*\"jobvite\" + 0.004*\"technical\" + 0.003*\"cross\" + 0.003*\"management\" + 0.003*\"greenhouse\" + 0.003*\"excel\" + 0.002*\"brassring\" + 0.002*\"datascientist\"\n",
      "INFO : topic diff=0.213316, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.847 per-word bound, 460.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3917/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3923/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.045): 0.009*\"sql\" + 0.009*\"linux\" + 0.007*\"python\" + 0.006*\"c++\" + 0.006*\"excel\" + 0.005*\"matlab\" + 0.005*\"r\" + 0.005*\"c\" + 0.005*\"hadoop\" + 0.004*\"core\"\n",
      "INFO : topic #16 (0.045): 0.013*\"sql\" + 0.011*\"r\" + 0.008*\"technical\" + 0.007*\"python\" + 0.006*\"java\" + 0.006*\"sas\" + 0.005*\"javascript\" + 0.005*\"stat\" + 0.004*\"c\" + 0.004*\"graph\"\n",
      "INFO : topic #9 (0.045): 0.030*\"html\" + 0.029*\"javascript\" + 0.029*\"c\" + 0.029*\"java\" + 0.028*\"python\" + 0.024*\"c++\" + 0.023*\"css\" + 0.020*\"sql\" + 0.018*\"r\" + 0.017*\"mysql\"\n",
      "INFO : topic #3 (0.045): 0.011*\"unix\" + 0.009*\"linux\" + 0.007*\"technical\" + 0.005*\"sql\" + 0.003*\"python\" + 0.003*\"r\" + 0.003*\"skills\" + 0.003*\"powershell\" + 0.003*\"sunsolaris\" + 0.003*\"powerpoint\"\n",
      "INFO : topic #19 (0.045): 0.018*\"sql\" + 0.017*\"technical\" + 0.014*\"tableau\" + 0.013*\"oracle\" + 0.012*\"excel\" + 0.009*\"python\" + 0.009*\"word\" + 0.009*\"windows\" + 0.009*\"ssis\" + 0.009*\"ssrs\"\n",
      "INFO : topic diff=0.178530, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.818 per-word bound, 451.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.045): 0.010*\"sql\" + 0.007*\"r\" + 0.006*\"technical\" + 0.006*\"linux\" + 0.006*\"python\" + 0.006*\"html\" + 0.006*\"oracle\" + 0.005*\"hive\" + 0.005*\"javascript\" + 0.005*\"excel\"\n",
      "INFO : topic #3 (0.045): 0.011*\"unix\" + 0.009*\"linux\" + 0.007*\"technical\" + 0.005*\"sql\" + 0.003*\"powershell\" + 0.003*\"skills\" + 0.003*\"sunsolaris\" + 0.003*\"macintosh_hd\" + 0.003*\"r\" + 0.003*\"python\"\n",
      "INFO : topic #14 (0.045): 0.014*\"r\" + 0.013*\"python\" + 0.013*\"sql\" + 0.009*\"java\" + 0.008*\"c++\" + 0.008*\"english\" + 0.007*\"technical\" + 0.007*\"c\" + 0.007*\"tableau\" + 0.006*\"spark\"\n",
      "INFO : topic #12 (0.045): 0.013*\"python\" + 0.010*\"hive\" + 0.009*\"mysql\" + 0.009*\"r\" + 0.008*\"java\" + 0.008*\"spark\" + 0.008*\"sql\" + 0.007*\"mapreduce\" + 0.007*\"tableau\" + 0.006*\"pig\"\n",
      "INFO : topic #16 (0.045): 0.012*\"sql\" + 0.010*\"r\" + 0.008*\"technical\" + 0.006*\"python\" + 0.006*\"java\" + 0.006*\"sas\" + 0.005*\"stat\" + 0.004*\"javascript\" + 0.004*\"c\" + 0.004*\"graph\"\n",
      "INFO : topic diff=0.148312, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.795 per-word bound, 444.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.045): 0.011*\"unix\" + 0.009*\"linux\" + 0.007*\"technical\" + 0.004*\"sql\" + 0.003*\"powershell\" + 0.003*\"sunsolaris\" + 0.003*\"skills\" + 0.003*\"macintosh_hd\" + 0.003*\"powerpoint\" + 0.003*\"r\"\n",
      "INFO : topic #11 (0.045): 0.056*\"r\" + 0.048*\"python\" + 0.048*\"sql\" + 0.041*\"sas\" + 0.028*\"matlab\" + 0.024*\"excel\" + 0.023*\"tableau\" + 0.021*\"c++\" + 0.020*\"spss\" + 0.017*\"technical\"\n",
      "INFO : topic #1 (0.045): 0.015*\"python\" + 0.013*\"sql\" + 0.012*\"java\" + 0.011*\"technical\" + 0.009*\"c\" + 0.009*\"ms\" + 0.009*\"mysql\" + 0.009*\"r\" + 0.009*\"linux\" + 0.008*\"windows\"\n",
      "INFO : topic #0 (0.045): 0.009*\"sql\" + 0.007*\"r\" + 0.006*\"linux\" + 0.006*\"technical\" + 0.005*\"html\" + 0.005*\"python\" + 0.005*\"oracle\" + 0.005*\"hive\" + 0.005*\"javascript\" + 0.005*\"ms\"\n",
      "INFO : topic #14 (0.045): 0.013*\"r\" + 0.013*\"sql\" + 0.013*\"python\" + 0.008*\"english\" + 0.008*\"java\" + 0.008*\"c++\" + 0.007*\"technical\" + 0.006*\"c\" + 0.006*\"spark\" + 0.006*\"data\"\n",
      "INFO : topic diff=0.122897, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.778 per-word bound, 438.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.045): 0.008*\"sql\" + 0.007*\"r\" + 0.006*\"linux\" + 0.005*\"technical\" + 0.005*\"html\" + 0.005*\"oracle\" + 0.005*\"python\" + 0.005*\"hive\" + 0.005*\"project\" + 0.004*\"ms\"\n",
      "INFO : topic #1 (0.045): 0.014*\"python\" + 0.013*\"sql\" + 0.012*\"java\" + 0.011*\"technical\" + 0.009*\"ms\" + 0.009*\"c\" + 0.008*\"linux\" + 0.008*\"mysql\" + 0.008*\"windows\" + 0.008*\"r\"\n",
      "INFO : topic #20 (0.045): 0.010*\"sql\" + 0.009*\"r\" + 0.009*\"data\" + 0.009*\"python\" + 0.008*\"project\" + 0.008*\"technical\" + 0.007*\"team\" + 0.006*\"business\" + 0.006*\"programming\" + 0.006*\"areasof\"\n",
      "INFO : topic #4 (0.045): 0.012*\"sql\" + 0.011*\"r\" + 0.011*\"python\" + 0.007*\"data\" + 0.006*\"matlab\" + 0.005*\"technical\" + 0.005*\"oracle\" + 0.005*\"spss\" + 0.005*\"sas\" + 0.005*\"excel\"\n",
      "INFO : topic #8 (0.045): 0.024*\"python\" + 0.023*\"r\" + 0.018*\"sql\" + 0.016*\"hadoop\" + 0.015*\"hive\" + 0.014*\"spark\" + 0.013*\"tableau\" + 0.012*\"java\" + 0.012*\"pig\" + 0.011*\"technical\"\n",
      "INFO : topic diff=0.102296, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.763 per-word bound, 434.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.045): 0.033*\"javascript\" + 0.033*\"html\" + 0.032*\"java\" + 0.031*\"c\" + 0.030*\"python\" + 0.026*\"c++\" + 0.026*\"css\" + 0.021*\"sql\" + 0.019*\"mysql\" + 0.018*\"r\"\n",
      "INFO : topic #4 (0.045): 0.012*\"sql\" + 0.010*\"r\" + 0.010*\"python\" + 0.007*\"data\" + 0.005*\"matlab\" + 0.005*\"technical\" + 0.005*\"oracle\" + 0.005*\"spss\" + 0.004*\"excel\" + 0.004*\"sas\"\n",
      "INFO : topic #18 (0.045): 0.013*\"java\" + 0.013*\"jsp\" + 0.012*\"javascript\" + 0.011*\"xml\" + 0.010*\"mysql\" + 0.010*\"spring\" + 0.010*\"eclipse\" + 0.009*\"oracle\" + 0.009*\"html\" + 0.009*\"hibernate\"\n",
      "INFO : topic #20 (0.045): 0.009*\"data\" + 0.009*\"sql\" + 0.008*\"r\" + 0.008*\"project\" + 0.008*\"python\" + 0.008*\"technical\" + 0.007*\"team\" + 0.007*\"business\" + 0.006*\"areasof\" + 0.005*\"programming\"\n",
      "INFO : topic #10 (0.045): 0.009*\"powerpoint\" + 0.009*\"excel\" + 0.007*\"access\" + 0.006*\"word\" + 0.006*\"data\" + 0.005*\"skills\" + 0.004*\"project\" + 0.004*\"spanish\" + 0.004*\"r\" + 0.004*\"sas\"\n",
      "INFO : topic diff=0.085606, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.751 per-word bound, 430.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #21 (0.045): 0.010*\"taleo\" + 0.007*\"jobvite\" + 0.004*\"brassring\" + 0.004*\"greenhouse\" + 0.003*\"cross\" + 0.003*\"dice\" + 0.003*\"management\" + 0.003*\"salesforce\" + 0.003*\"workday\" + 0.003*\"datascientist\"\n",
      "INFO : topic #18 (0.045): 0.013*\"jsp\" + 0.013*\"java\" + 0.012*\"javascript\" + 0.012*\"xml\" + 0.010*\"spring\" + 0.010*\"eclipse\" + 0.010*\"mysql\" + 0.009*\"hibernate\" + 0.009*\"oracle\" + 0.009*\"html\"\n",
      "INFO : topic #8 (0.045): 0.023*\"python\" + 0.022*\"r\" + 0.017*\"sql\" + 0.016*\"hadoop\" + 0.016*\"hive\" + 0.014*\"spark\" + 0.013*\"tableau\" + 0.012*\"pig\" + 0.012*\"java\" + 0.011*\"technical\"\n",
      "INFO : topic #7 (0.045): 0.006*\"linux\" + 0.005*\"sql\" + 0.004*\"core\" + 0.004*\"c++\" + 0.004*\"excel\" + 0.004*\"python\" + 0.004*\"data\" + 0.003*\"matlab\" + 0.003*\"c\" + 0.003*\"skill\"\n",
      "INFO : topic #17 (0.045): 0.007*\"python\" + 0.006*\"r\" + 0.005*\"excel\" + 0.005*\"project\" + 0.005*\"data\" + 0.005*\"c\" + 0.004*\"sql\" + 0.004*\"microsoft\" + 0.004*\"c++\" + 0.004*\"skills\"\n",
      "INFO : topic diff=0.072140, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.740 per-word bound, 427.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.045): 0.059*\"r\" + 0.050*\"sql\" + 0.050*\"python\" + 0.044*\"sas\" + 0.030*\"matlab\" + 0.028*\"excel\" + 0.024*\"tableau\" + 0.021*\"spss\" + 0.021*\"c++\" + 0.017*\"technical\"\n",
      "INFO : topic #20 (0.045): 0.010*\"data\" + 0.009*\"project\" + 0.008*\"sql\" + 0.008*\"team\" + 0.007*\"business\" + 0.007*\"r\" + 0.007*\"technical\" + 0.007*\"python\" + 0.006*\"areasof\" + 0.005*\"programming\"\n",
      "INFO : topic #15 (0.045): 0.038*\"python\" + 0.035*\"r\" + 0.031*\"sql\" + 0.026*\"hadoop\" + 0.024*\"hive\" + 0.022*\"java\" + 0.020*\"spark\" + 0.019*\"matlab\" + 0.018*\"c++\" + 0.018*\"tableau\"\n",
      "INFO : topic #10 (0.045): 0.009*\"powerpoint\" + 0.008*\"excel\" + 0.007*\"access\" + 0.006*\"data\" + 0.006*\"word\" + 0.005*\"skills\" + 0.005*\"project\" + 0.004*\"spanish\" + 0.004*\"illustrator\" + 0.004*\"quickbooks\"\n",
      "INFO : topic #1 (0.045): 0.011*\"python\" + 0.011*\"sql\" + 0.010*\"java\" + 0.010*\"ms\" + 0.009*\"technical\" + 0.008*\"linux\" + 0.008*\"windows\" + 0.008*\"c\" + 0.007*\"mysql\" + 0.007*\"jira\"\n",
      "INFO : topic diff=0.061373, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.731 per-word bound, 425.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #18 (0.045): 0.014*\"jsp\" + 0.012*\"java\" + 0.012*\"javascript\" + 0.012*\"xml\" + 0.010*\"spring\" + 0.010*\"eclipse\" + 0.010*\"hibernate\" + 0.009*\"oracle\" + 0.009*\"mysql\" + 0.009*\"html\"\n",
      "INFO : topic #15 (0.045): 0.038*\"python\" + 0.035*\"r\" + 0.031*\"sql\" + 0.027*\"hadoop\" + 0.024*\"hive\" + 0.022*\"java\" + 0.021*\"spark\" + 0.019*\"matlab\" + 0.018*\"c++\" + 0.018*\"tableau\"\n",
      "INFO : topic #4 (0.045): 0.009*\"sql\" + 0.008*\"r\" + 0.007*\"python\" + 0.006*\"data\" + 0.005*\"oracle\" + 0.005*\"technical\" + 0.004*\"matlab\" + 0.004*\"excel\" + 0.004*\"spss\" + 0.003*\"sas\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #7 (0.045): 0.005*\"linux\" + 0.004*\"core\" + 0.004*\"sql\" + 0.004*\"c++\" + 0.004*\"excel\" + 0.003*\"data\" + 0.003*\"skill\" + 0.003*\"python\" + 0.003*\"c\" + 0.003*\"matlab\"\n",
      "INFO : topic #17 (0.045): 0.006*\"python\" + 0.005*\"project\" + 0.005*\"data\" + 0.005*\"r\" + 0.005*\"excel\" + 0.004*\"c\" + 0.004*\"microsoft\" + 0.004*\"skills\" + 0.004*\"sql\" + 0.003*\"c++\"\n",
      "INFO : topic diff=0.052627, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.724 per-word bound, 422.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.045): 0.004*\"data\" + 0.004*\"python\" + 0.004*\"r\" + 0.004*\"project\" + 0.003*\"relevant\" + 0.003*\"c++\" + 0.003*\"may\" + 0.003*\"december\" + 0.003*\"linux\" + 0.003*\"march\"\n",
      "INFO : topic #13 (0.045): 0.011*\"technical\" + 0.010*\"sql\" + 0.009*\"sas\" + 0.008*\"tableau\" + 0.008*\"html\" + 0.007*\"c\" + 0.007*\"python\" + 0.007*\"r\" + 0.006*\"c++\" + 0.005*\"java\"\n",
      "INFO : topic #9 (0.045): 0.035*\"javascript\" + 0.035*\"html\" + 0.033*\"java\" + 0.032*\"c\" + 0.031*\"python\" + 0.028*\"c++\" + 0.028*\"css\" + 0.021*\"sql\" + 0.020*\"mysql\" + 0.018*\"r\"\n",
      "INFO : topic #6 (0.045): 0.031*\"python\" + 0.028*\"r\" + 0.026*\"pandas\" + 0.024*\"sql\" + 0.021*\"numpy\" + 0.018*\"scikit\" + 0.016*\"technical\" + 0.014*\"tableau\" + 0.014*\"scipy\" + 0.013*\"matplotlib\"\n",
      "INFO : topic #18 (0.045): 0.014*\"jsp\" + 0.012*\"java\" + 0.012*\"javascript\" + 0.012*\"xml\" + 0.010*\"spring\" + 0.010*\"eclipse\" + 0.010*\"hibernate\" + 0.009*\"oracle\" + 0.009*\"mysql\" + 0.009*\"maven\"\n",
      "INFO : topic diff=0.045593, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.717 per-word bound, 420.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3968/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.045): 0.060*\"r\" + 0.051*\"sql\" + 0.050*\"python\" + 0.045*\"sas\" + 0.030*\"matlab\" + 0.030*\"excel\" + 0.024*\"tableau\" + 0.022*\"spss\" + 0.022*\"c++\" + 0.018*\"powerpoint\"\n",
      "INFO : topic #12 (0.045): 0.008*\"python\" + 0.007*\"hive\" + 0.007*\"mysql\" + 0.006*\"mapreduce\" + 0.005*\"java\" + 0.005*\"spark\" + 0.005*\"scala\" + 0.005*\"tableau\" + 0.005*\"sql\" + 0.005*\"skills\"\n",
      "INFO : topic #0 (0.045): 0.006*\"sql\" + 0.005*\"r\" + 0.005*\"project\" + 0.004*\"linux\" + 0.004*\"technical\" + 0.004*\"oracle\" + 0.004*\"ms\" + 0.004*\"html\" + 0.003*\"javascript\" + 0.003*\"hive\"\n",
      "INFO : topic #3 (0.045): 0.011*\"unix\" + 0.009*\"linux\" + 0.005*\"technical\" + 0.004*\"sunsolaris\" + 0.004*\"powershell\" + 0.004*\"skills\" + 0.003*\"macintosh_hd\" + 0.003*\"ux\" + 0.002*\"hp\" + 0.002*\"sql\"\n",
      "INFO : topic #18 (0.045): 0.014*\"jsp\" + 0.012*\"java\" + 0.012*\"xml\" + 0.012*\"javascript\" + 0.010*\"spring\" + 0.010*\"eclipse\" + 0.010*\"hibernate\" + 0.009*\"oracle\" + 0.009*\"maven\" + 0.009*\"mysql\"\n",
      "INFO : topic diff=0.039923, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.712 per-word bound, 419.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3967/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.045): 0.031*\"python\" + 0.028*\"r\" + 0.026*\"pandas\" + 0.024*\"sql\" + 0.022*\"numpy\" + 0.018*\"scikit\" + 0.016*\"technical\" + 0.014*\"scipy\" + 0.014*\"tableau\" + 0.013*\"matplotlib\"\n",
      "INFO : topic #5 (0.045): 0.005*\"scrum\" + 0.004*\"technical\" + 0.004*\"agile\" + 0.003*\"waterfall\" + 0.003*\"sql\" + 0.003*\"key\" + 0.003*\"business\" + 0.002*\"skills\" + 0.002*\"sas9.3\" + 0.002*\"g\"\n",
      "INFO : topic #16 (0.045): 0.006*\"sql\" + 0.005*\"stat\" + 0.005*\"technical\" + 0.005*\"graph\" + 0.004*\"r\" + 0.004*\"j.\" + 0.004*\"base\" + 0.004*\"d.\" + 0.003*\"s.\" + 0.003*\"languages\"\n",
      "INFO : topic #13 (0.045): 0.010*\"technical\" + 0.010*\"sql\" + 0.008*\"sas\" + 0.008*\"tableau\" + 0.007*\"html\" + 0.007*\"c\" + 0.006*\"r\" + 0.006*\"python\" + 0.005*\"c++\" + 0.005*\"data\"\n",
      "INFO : topic #19 (0.045): 0.019*\"sql\" + 0.018*\"technical\" + 0.017*\"oracle\" + 0.014*\"tableau\" + 0.014*\"ssis\" + 0.014*\"ssrs\" + 0.012*\"pl\" + 0.011*\"teradata\" + 0.010*\"windows\" + 0.009*\"visio\"\n",
      "INFO : topic diff=0.035256, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.706 per-word bound, 417.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.045): 0.007*\"sql\" + 0.006*\"r\" + 0.006*\"data\" + 0.005*\"python\" + 0.004*\"oracle\" + 0.004*\"technical\" + 0.003*\"excel\" + 0.003*\"postgres\" + 0.003*\"spss\" + 0.003*\"matlab\"\n",
      "INFO : topic #1 (0.045): 0.010*\"ms\" + 0.008*\"sql\" + 0.008*\"windows\" + 0.008*\"linux\" + 0.008*\"java\" + 0.008*\"python\" + 0.007*\"technical\" + 0.007*\"jira\" + 0.006*\"c\" + 0.006*\"mysql\"\n",
      "INFO : topic #5 (0.045): 0.005*\"scrum\" + 0.004*\"technical\" + 0.004*\"agile\" + 0.004*\"waterfall\" + 0.003*\"sql\" + 0.003*\"key\" + 0.003*\"business\" + 0.002*\"sas9.3\" + 0.002*\"skills\" + 0.002*\"g\"\n",
      "INFO : topic #6 (0.045): 0.032*\"python\" + 0.028*\"r\" + 0.027*\"pandas\" + 0.024*\"sql\" + 0.022*\"numpy\" + 0.018*\"scikit\" + 0.016*\"technical\" + 0.014*\"scipy\" + 0.014*\"tableau\" + 0.013*\"matplotlib\"\n",
      "INFO : topic #18 (0.045): 0.014*\"jsp\" + 0.012*\"xml\" + 0.012*\"java\" + 0.012*\"javascript\" + 0.010*\"spring\" + 0.010*\"eclipse\" + 0.010*\"hibernate\" + 0.009*\"oracle\" + 0.009*\"maven\" + 0.009*\"j2ee\"\n",
      "INFO : topic diff=0.031330, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.703 per-word bound, 416.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #18 (0.045): 0.014*\"jsp\" + 0.012*\"xml\" + 0.012*\"java\" + 0.011*\"javascript\" + 0.010*\"spring\" + 0.010*\"eclipse\" + 0.010*\"hibernate\" + 0.009*\"oracle\" + 0.009*\"maven\" + 0.009*\"j2ee\"\n",
      "INFO : topic #14 (0.045): 0.013*\"english\" + 0.008*\"r\" + 0.007*\"sql\" + 0.006*\"python\" + 0.006*\"language\" + 0.006*\"data\" + 0.005*\"mandarin\" + 0.005*\"java\" + 0.005*\"c++\" + 0.005*\"analytics\"\n",
      "INFO : topic #7 (0.045): 0.004*\"core\" + 0.004*\"linux\" + 0.003*\"skill\" + 0.003*\"data\" + 0.003*\"technology\" + 0.003*\"c++\" + 0.003*\"excel\" + 0.003*\"sql\" + 0.002*\"project\" + 0.002*\"m.\"\n",
      "INFO : topic #6 (0.045): 0.032*\"python\" + 0.028*\"r\" + 0.027*\"pandas\" + 0.024*\"sql\" + 0.022*\"numpy\" + 0.018*\"scikit\" + 0.016*\"technical\" + 0.014*\"scipy\" + 0.014*\"tableau\" + 0.013*\"matplotlib\"\n",
      "INFO : topic #4 (0.045): 0.007*\"sql\" + 0.006*\"r\" + 0.005*\"data\" + 0.004*\"python\" + 0.004*\"oracle\" + 0.004*\"technical\" + 0.003*\"postgres\" + 0.003*\"excel\" + 0.003*\"spss\" + 0.003*\"matlab\"\n",
      "INFO : topic diff=0.028185, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.699 per-word bound, 415.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #15 (0.045): 0.038*\"python\" + 0.035*\"r\" + 0.031*\"sql\" + 0.029*\"hadoop\" + 0.026*\"hive\" + 0.023*\"java\" + 0.022*\"spark\" + 0.019*\"matlab\" + 0.018*\"c++\" + 0.018*\"c\"\n",
      "INFO : topic #11 (0.045): 0.061*\"r\" + 0.051*\"sql\" + 0.051*\"python\" + 0.045*\"sas\" + 0.032*\"excel\" + 0.031*\"matlab\" + 0.025*\"tableau\" + 0.023*\"spss\" + 0.022*\"c++\" + 0.019*\"powerpoint\"\n",
      "INFO : topic #9 (0.045): 0.037*\"javascript\" + 0.036*\"html\" + 0.034*\"java\" + 0.033*\"c\" + 0.032*\"python\" + 0.029*\"css\" + 0.029*\"c++\" + 0.021*\"sql\" + 0.021*\"mysql\" + 0.019*\"r\"\n",
      "INFO : topic #4 (0.045): 0.007*\"sql\" + 0.005*\"r\" + 0.005*\"data\" + 0.004*\"oracle\" + 0.004*\"python\" + 0.004*\"technical\" + 0.003*\"postgres\" + 0.003*\"excel\" + 0.003*\"spss\" + 0.003*\"agile\"\n",
      "INFO : topic #10 (0.045): 0.008*\"excel\" + 0.007*\"powerpoint\" + 0.006*\"illustrator\" + 0.006*\"indesign\" + 0.006*\"skills\" + 0.006*\"access\" + 0.006*\"data\" + 0.005*\"spanish\" + 0.005*\"quickbooks\" + 0.005*\"project\"\n",
      "INFO : topic diff=0.025462, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.695 per-word bound, 414.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=22, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=22, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (153 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (400 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (417 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (460 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (439 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (485 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (505 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (404 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (464 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (392 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (666 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (584 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (550 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (494 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (514 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (566 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (703 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (547 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (592 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (576 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (576 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (528 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (528 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (636 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (665 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (468 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (665 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (636 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (468 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (456 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (625 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : finished all batches; 448 documents processed (456 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (630 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (637 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (872 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (872 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (630 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 512 documents processed (637 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 576 documents processed (625 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (448 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (767 virtual)\n",
      "DEBUG : completed batch 7; 480 documents processed (782 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 512 documents processed (708 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 480 documents processed (782 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (767 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (708 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (641 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (641 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9439 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12434/12537 documents converged within 50 iterations\n",
      " 87%|████████▋ | 20/23 [08:52<01:19, 26.64s/it]INFO : using symmetric alpha at 0.043478260869565216\n",
      "INFO : using symmetric eta at 0.043478260869565216\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 23 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 438/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 3303/4000 documents converged within 50 iterations\n",
      "DEBUG : 3424/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3231/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #20 (0.043): 0.019*\"r\" + 0.018*\"python\" + 0.017*\"sql\" + 0.013*\"matlab\" + 0.012*\"mysql\" + 0.011*\"technical\" + 0.009*\"java\" + 0.009*\"c++\" + 0.009*\"c\" + 0.009*\"sas\"\n",
      "INFO : topic #10 (0.043): 0.020*\"r\" + 0.016*\"sql\" + 0.011*\"sas\" + 0.010*\"excel\" + 0.009*\"python\" + 0.008*\"linux\" + 0.008*\"mysql\" + 0.008*\"powerpoint\" + 0.008*\"java\" + 0.007*\"c++\"\n",
      "INFO : topic #12 (0.043): 0.018*\"python\" + 0.015*\"r\" + 0.015*\"sql\" + 0.015*\"java\" + 0.012*\"hive\" + 0.011*\"hadoop\" + 0.010*\"mysql\" + 0.010*\"spark\" + 0.010*\"tableau\" + 0.009*\"c++\"\n",
      "INFO : topic #15 (0.043): 0.029*\"python\" + 0.028*\"sql\" + 0.026*\"r\" + 0.017*\"matlab\" + 0.016*\"java\" + 0.016*\"c\" + 0.015*\"tableau\" + 0.015*\"hadoop\" + 0.014*\"c++\" + 0.012*\"technical\"\n",
      "INFO : topic #16 (0.043): 0.025*\"sql\" + 0.020*\"r\" + 0.018*\"python\" + 0.014*\"java\" + 0.011*\"technical\" + 0.009*\"c\" + 0.009*\"javascript\" + 0.007*\"hadoop\" + 0.007*\"sas\" + 0.006*\"mysql\"\n",
      "INFO : topic diff=17.942616, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.458 per-word bound, 703.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 521/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3846/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3808/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3850/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.043): 0.030*\"r\" + 0.026*\"python\" + 0.025*\"sql\" + 0.014*\"tableau\" + 0.013*\"hadoop\" + 0.011*\"technical\" + 0.011*\"java\" + 0.011*\"hive\" + 0.011*\"spark\" + 0.010*\"c++\"\n",
      "INFO : topic #3 (0.043): 0.012*\"technical\" + 0.012*\"sql\" + 0.010*\"python\" + 0.009*\"unix\" + 0.008*\"linux\" + 0.008*\"r\" + 0.007*\"java\" + 0.005*\"c++\" + 0.004*\"tableau\" + 0.004*\"word\"\n",
      "INFO : topic #1 (0.043): 0.022*\"python\" + 0.018*\"r\" + 0.017*\"java\" + 0.017*\"sql\" + 0.015*\"technical\" + 0.010*\"c++\" + 0.010*\"html\" + 0.009*\"mysql\" + 0.009*\"c\" + 0.008*\"matlab\"\n",
      "INFO : topic #2 (0.043): 0.013*\"r\" + 0.011*\"python\" + 0.010*\"sql\" + 0.009*\"c++\" + 0.007*\"computer\" + 0.006*\"sas\" + 0.006*\"linux\" + 0.006*\"java\" + 0.006*\"c\" + 0.005*\"html\"\n",
      "INFO : topic #6 (0.043): 0.025*\"python\" + 0.023*\"r\" + 0.021*\"sql\" + 0.012*\"sas\" + 0.011*\"pandas\" + 0.011*\"technical\" + 0.010*\"matlab\" + 0.010*\"tableau\" + 0.010*\"mysql\" + 0.009*\"statistical\"\n",
      "INFO : topic diff=0.365525, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.184 per-word bound, 581.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3900/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3902/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3865/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.043): 0.011*\"technical\" + 0.010*\"sql\" + 0.010*\"unix\" + 0.008*\"linux\" + 0.008*\"python\" + 0.006*\"r\" + 0.006*\"java\" + 0.004*\"word\" + 0.004*\"c++\" + 0.004*\"tableau\"\n",
      "INFO : topic #9 (0.043): 0.029*\"python\" + 0.026*\"c\" + 0.025*\"html\" + 0.024*\"java\" + 0.020*\"c++\" + 0.020*\"sql\" + 0.020*\"javascript\" + 0.019*\"r\" + 0.017*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #18 (0.043): 0.016*\"python\" + 0.012*\"sql\" + 0.012*\"javascript\" + 0.012*\"r\" + 0.012*\"java\" + 0.010*\"c++\" + 0.010*\"html\" + 0.010*\"hadoop\" + 0.009*\"mysql\" + 0.006*\"css\"\n",
      "INFO : topic #21 (0.043): 0.008*\"python\" + 0.006*\"sql\" + 0.006*\"technical\" + 0.005*\"excel\" + 0.004*\"data\" + 0.003*\"powerpoint\" + 0.003*\"mysql\" + 0.003*\"r\" + 0.003*\"postgresql\" + 0.003*\"academic\"\n",
      "INFO : topic #6 (0.043): 0.026*\"python\" + 0.024*\"r\" + 0.022*\"sql\" + 0.015*\"pandas\" + 0.012*\"technical\" + 0.011*\"sas\" + 0.011*\"tableau\" + 0.011*\"numpy\" + 0.011*\"matlab\" + 0.010*\"scikit\"\n",
      "INFO : topic diff=0.335365, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.041 per-word bound, 526.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.043): 0.010*\"r\" + 0.008*\"python\" + 0.008*\"sql\" + 0.008*\"c++\" + 0.007*\"computer\" + 0.005*\"linux\" + 0.005*\"java\" + 0.005*\"sas\" + 0.005*\"windows\" + 0.004*\"html\"\n",
      "INFO : topic #15 (0.043): 0.034*\"python\" + 0.031*\"r\" + 0.031*\"sql\" + 0.020*\"hadoop\" + 0.020*\"java\" + 0.018*\"c\" + 0.018*\"matlab\" + 0.017*\"c++\" + 0.017*\"tableau\" + 0.017*\"hive\"\n",
      "INFO : topic #7 (0.043): 0.016*\"linux\" + 0.012*\"sql\" + 0.011*\"python\" + 0.008*\"r\" + 0.007*\"hadoop\" + 0.007*\"c++\" + 0.007*\"hive\" + 0.006*\"matlab\" + 0.006*\"c\" + 0.006*\"excel\"\n",
      "INFO : topic #6 (0.043): 0.027*\"python\" + 0.025*\"r\" + 0.023*\"sql\" + 0.017*\"pandas\" + 0.013*\"numpy\" + 0.013*\"technical\" + 0.012*\"scikit\" + 0.011*\"tableau\" + 0.011*\"sas\" + 0.011*\"matlab\"\n",
      "INFO : topic #9 (0.043): 0.030*\"python\" + 0.027*\"c\" + 0.027*\"html\" + 0.027*\"java\" + 0.024*\"javascript\" + 0.022*\"c++\" + 0.020*\"sql\" + 0.019*\"css\" + 0.019*\"r\" + 0.015*\"mysql\"\n",
      "INFO : topic diff=0.298214, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.951 per-word bound, 495.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #21 (0.043): 0.005*\"python\" + 0.005*\"technical\" + 0.004*\"sql\" + 0.004*\"excel\" + 0.004*\"data\" + 0.003*\"academic\" + 0.003*\"powerpoint\" + 0.003*\"outlook\" + 0.003*\"postgresql\" + 0.002*\"development\"\n",
      "INFO : topic #14 (0.043): 0.019*\"r\" + 0.017*\"sql\" + 0.016*\"python\" + 0.012*\"c++\" + 0.011*\"java\" + 0.010*\"technical\" + 0.010*\"matlab\" + 0.009*\"c\" + 0.009*\"mysql\" + 0.009*\"hadoop\"\n",
      "INFO : topic #12 (0.043): 0.016*\"python\" + 0.014*\"r\" + 0.014*\"sql\" + 0.013*\"java\" + 0.012*\"hive\" + 0.010*\"spark\" + 0.009*\"mysql\" + 0.009*\"hadoop\" + 0.009*\"tableau\" + 0.008*\"c++\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #17 (0.043): 0.014*\"python\" + 0.013*\"r\" + 0.009*\"excel\" + 0.007*\"sql\" + 0.007*\"technical\" + 0.005*\"project\" + 0.005*\"c\" + 0.005*\"c++\" + 0.005*\"sas\" + 0.005*\"java\"\n",
      "INFO : topic #19 (0.043): 0.019*\"technical\" + 0.017*\"sql\" + 0.014*\"tableau\" + 0.014*\"oracle\" + 0.012*\"python\" + 0.011*\"r\" + 0.010*\"ssis\" + 0.009*\"ssrs\" + 0.009*\"excel\" + 0.009*\"windows\"\n",
      "INFO : topic diff=0.257971, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.891 per-word bound, 474.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.043): 0.014*\"sql\" + 0.009*\"technical\" + 0.008*\"oracle\" + 0.007*\"python\" + 0.007*\"r\" + 0.007*\"linux\" + 0.006*\"javascript\" + 0.006*\"java\" + 0.006*\"html\" + 0.005*\"hive\"\n",
      "INFO : topic #10 (0.043): 0.018*\"excel\" + 0.016*\"powerpoint\" + 0.015*\"access\" + 0.015*\"word\" + 0.013*\"r\" + 0.011*\"sql\" + 0.010*\"sas\" + 0.008*\"spss\" + 0.006*\"outlook\" + 0.006*\"linux\"\n",
      "INFO : topic #9 (0.043): 0.032*\"python\" + 0.030*\"java\" + 0.030*\"html\" + 0.029*\"c\" + 0.029*\"javascript\" + 0.025*\"c++\" + 0.023*\"css\" + 0.020*\"sql\" + 0.019*\"r\" + 0.018*\"mysql\"\n",
      "INFO : topic #13 (0.043): 0.017*\"python\" + 0.016*\"sql\" + 0.015*\"technical\" + 0.014*\"r\" + 0.012*\"tableau\" + 0.012*\"sas\" + 0.010*\"java\" + 0.010*\"c\" + 0.009*\"html\" + 0.008*\"c++\"\n",
      "INFO : topic #7 (0.043): 0.014*\"linux\" + 0.010*\"sql\" + 0.008*\"python\" + 0.006*\"hadoop\" + 0.006*\"hive\" + 0.006*\"r\" + 0.005*\"c++\" + 0.005*\"excel\" + 0.005*\"c\" + 0.005*\"matlab\"\n",
      "INFO : topic diff=0.218613, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.846 per-word bound, 460.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3937/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.043): 0.014*\"r\" + 0.013*\"sql\" + 0.012*\"python\" + 0.008*\"linux\" + 0.007*\"windows\" + 0.007*\"matlab\" + 0.007*\"data\" + 0.007*\"technical\" + 0.006*\"c++\" + 0.006*\"tableau\"\n",
      "INFO : topic #22 (0.043): 0.017*\"python\" + 0.016*\"r\" + 0.014*\"tableau\" + 0.013*\"sql\" + 0.010*\"sas\" + 0.006*\"html\" + 0.006*\"technical\" + 0.006*\"mysql\" + 0.005*\"c\" + 0.005*\"spss\"\n",
      "INFO : topic #2 (0.043): 0.008*\"r\" + 0.007*\"c++\" + 0.006*\"computer\" + 0.006*\"sql\" + 0.006*\"python\" + 0.004*\"windows\" + 0.004*\"java\" + 0.004*\"linux\" + 0.004*\"ms\" + 0.003*\"html\"\n",
      "INFO : topic #20 (0.043): 0.010*\"sql\" + 0.010*\"data\" + 0.009*\"r\" + 0.009*\"python\" + 0.007*\"mysql\" + 0.006*\"project\" + 0.006*\"matlab\" + 0.006*\"technical\" + 0.006*\"java\" + 0.005*\"programming\"\n",
      "INFO : topic #12 (0.043): 0.014*\"python\" + 0.013*\"r\" + 0.013*\"sql\" + 0.012*\"hive\" + 0.011*\"java\" + 0.009*\"spark\" + 0.008*\"mysql\" + 0.008*\"tableau\" + 0.007*\"hadoop\" + 0.007*\"c++\"\n",
      "INFO : topic diff=0.182523, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.812 per-word bound, 449.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.043): 0.008*\"taleo\" + 0.007*\"excel\" + 0.006*\"sql\" + 0.005*\"jobvite\" + 0.005*\"agile\" + 0.005*\"technical\" + 0.004*\"icims\" + 0.004*\"twitter\" + 0.004*\"skills\" + 0.004*\"scrum\"\n",
      "INFO : topic #22 (0.043): 0.016*\"python\" + 0.015*\"r\" + 0.013*\"tableau\" + 0.012*\"sql\" + 0.009*\"sas\" + 0.006*\"html\" + 0.005*\"technical\" + 0.005*\"a\" + 0.005*\"mysql\" + 0.005*\"spss\"\n",
      "INFO : topic #4 (0.043): 0.013*\"r\" + 0.012*\"sql\" + 0.011*\"python\" + 0.007*\"windows\" + 0.007*\"linux\" + 0.007*\"data\" + 0.007*\"matlab\" + 0.006*\"technical\" + 0.006*\"c++\" + 0.006*\"tableau\"\n",
      "INFO : topic #18 (0.043): 0.011*\"javascript\" + 0.010*\"java\" + 0.010*\"jsp\" + 0.009*\"python\" + 0.009*\"spring\" + 0.009*\"html\" + 0.008*\"sql\" + 0.008*\"servlets\" + 0.008*\"hadoop\" + 0.008*\"jdbc\"\n",
      "INFO : topic #20 (0.043): 0.010*\"data\" + 0.010*\"sql\" + 0.008*\"r\" + 0.008*\"python\" + 0.007*\"project\" + 0.006*\"mysql\" + 0.005*\"matlab\" + 0.005*\"technical\" + 0.005*\"team\" + 0.005*\"java\"\n",
      "INFO : topic diff=0.151626, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.789 per-word bound, 442.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.043): 0.020*\"excel\" + 0.018*\"powerpoint\" + 0.018*\"word\" + 0.016*\"access\" + 0.010*\"r\" + 0.008*\"sql\" + 0.008*\"outlook\" + 0.007*\"sas\" + 0.007*\"photoshop\" + 0.007*\"illustrator\"\n",
      "INFO : topic #20 (0.043): 0.010*\"data\" + 0.009*\"sql\" + 0.007*\"r\" + 0.007*\"project\" + 0.007*\"python\" + 0.006*\"team\" + 0.005*\"mysql\" + 0.005*\"english\" + 0.005*\"technical\" + 0.005*\"java\"\n",
      "INFO : topic #22 (0.043): 0.015*\"python\" + 0.014*\"r\" + 0.012*\"tableau\" + 0.011*\"sql\" + 0.008*\"sas\" + 0.005*\"html\" + 0.005*\"a\" + 0.005*\"technical\" + 0.005*\"mysql\" + 0.004*\"spss\"\n",
      "INFO : topic #21 (0.043): 0.003*\"excel\" + 0.003*\"academic\" + 0.003*\"technical\" + 0.003*\"data\" + 0.003*\"sql\" + 0.003*\"healthcare\" + 0.003*\"linkedin\" + 0.002*\"python\" + 0.002*\"sharepoint\" + 0.002*\"outlook\"\n",
      "INFO : topic #13 (0.043): 0.014*\"technical\" + 0.013*\"python\" + 0.013*\"sql\" + 0.011*\"r\" + 0.011*\"tableau\" + 0.011*\"sas\" + 0.009*\"java\" + 0.009*\"c\" + 0.008*\"html\" + 0.008*\"data\"\n",
      "INFO : topic diff=0.125631, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.768 per-word bound, 436.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #15 (0.043): 0.035*\"python\" + 0.031*\"r\" + 0.029*\"sql\" + 0.025*\"hadoop\" + 0.022*\"hive\" + 0.022*\"java\" + 0.020*\"spark\" + 0.019*\"c\" + 0.019*\"c++\" + 0.018*\"matlab\"\n",
      "INFO : topic #17 (0.043): 0.007*\"r\" + 0.007*\"python\" + 0.006*\"project\" + 0.006*\"excel\" + 0.005*\"data\" + 0.004*\"sql\" + 0.004*\"technical\" + 0.003*\"ms\" + 0.003*\"c\" + 0.003*\"skills\"\n",
      "INFO : topic #12 (0.043): 0.011*\"sql\" + 0.011*\"r\" + 0.011*\"python\" + 0.011*\"hive\" + 0.009*\"java\" + 0.008*\"spark\" + 0.007*\"tableau\" + 0.007*\"mysql\" + 0.007*\"excel\" + 0.006*\"programming\"\n",
      "INFO : topic #22 (0.043): 0.014*\"python\" + 0.013*\"r\" + 0.012*\"tableau\" + 0.011*\"sql\" + 0.008*\"sas\" + 0.006*\"a\" + 0.005*\"html\" + 0.005*\"technical\" + 0.004*\"mysql\" + 0.004*\"ms\"\n",
      "INFO : topic #7 (0.043): 0.011*\"linux\" + 0.006*\"sql\" + 0.005*\"python\" + 0.005*\"hive\" + 0.004*\"hadoop\" + 0.004*\"mapreduce\" + 0.004*\"d.\" + 0.004*\"excel\" + 0.004*\"operating\" + 0.003*\"c++\"\n",
      "INFO : topic diff=0.104292, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.751 per-word bound, 430.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #16 (0.043): 0.013*\"sql\" + 0.008*\"r\" + 0.008*\"java\" + 0.007*\"technical\" + 0.007*\"python\" + 0.006*\"stat\" + 0.005*\"languages\" + 0.005*\"c\" + 0.005*\"base\" + 0.005*\"unix\"\n",
      "INFO : topic #11 (0.043): 0.058*\"r\" + 0.050*\"python\" + 0.049*\"sql\" + 0.044*\"sas\" + 0.030*\"matlab\" + 0.029*\"excel\" + 0.024*\"tableau\" + 0.022*\"c++\" + 0.021*\"spss\" + 0.017*\"technical\"\n",
      "INFO : topic #15 (0.043): 0.035*\"python\" + 0.031*\"r\" + 0.029*\"sql\" + 0.026*\"hadoop\" + 0.023*\"hive\" + 0.022*\"java\" + 0.020*\"spark\" + 0.019*\"c\" + 0.019*\"c++\" + 0.018*\"matlab\"\n",
      "INFO : topic #6 (0.043): 0.032*\"python\" + 0.028*\"r\" + 0.026*\"sql\" + 0.025*\"pandas\" + 0.020*\"numpy\" + 0.017*\"scikit\" + 0.015*\"technical\" + 0.014*\"tableau\" + 0.013*\"scipy\" + 0.012*\"matplotlib\"\n",
      "INFO : topic #22 (0.043): 0.013*\"python\" + 0.012*\"r\" + 0.011*\"tableau\" + 0.010*\"sql\" + 0.007*\"sas\" + 0.006*\"a\" + 0.005*\"html\" + 0.004*\"technical\" + 0.004*\"ms\" + 0.004*\"spss\"\n",
      "INFO : topic diff=0.087083, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.735 per-word bound, 426.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processing chunk #1 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.043): 0.032*\"python\" + 0.029*\"r\" + 0.026*\"sql\" + 0.025*\"pandas\" + 0.020*\"numpy\" + 0.018*\"scikit\" + 0.016*\"technical\" + 0.014*\"tableau\" + 0.013*\"scipy\" + 0.012*\"hadoop\"\n",
      "INFO : topic #2 (0.043): 0.006*\"computer\" + 0.006*\"r\" + 0.005*\"c++\" + 0.004*\"sql\" + 0.004*\"python\" + 0.004*\"core\" + 0.004*\"windows\" + 0.003*\"key\" + 0.003*\"java\" + 0.003*\"ms\"\n",
      "INFO : topic #8 (0.043): 0.023*\"r\" + 0.021*\"python\" + 0.018*\"sql\" + 0.015*\"spark\" + 0.014*\"hadoop\" + 0.012*\"hive\" + 0.011*\"tableau\" + 0.011*\"oracle\" + 0.010*\"java\" + 0.010*\"technical\"\n",
      "INFO : topic #7 (0.043): 0.010*\"linux\" + 0.005*\"sql\" + 0.004*\"d.\" + 0.004*\"python\" + 0.004*\"hive\" + 0.004*\"mapreduce\" + 0.004*\"hadoop\" + 0.003*\"excel\" + 0.003*\"operating\" + 0.003*\"n.\"\n",
      "INFO : topic #1 (0.043): 0.010*\"python\" + 0.009*\"java\" + 0.009*\"sql\" + 0.009*\"technical\" + 0.007*\"r\" + 0.005*\"html\" + 0.005*\"mysql\" + 0.005*\"oracle\" + 0.004*\"ms\" + 0.004*\"c\"\n",
      "INFO : topic diff=0.073370, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.721 per-word bound, 422.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.043): 0.059*\"r\" + 0.051*\"python\" + 0.050*\"sql\" + 0.044*\"sas\" + 0.030*\"matlab\" + 0.030*\"excel\" + 0.024*\"tableau\" + 0.022*\"c++\" + 0.021*\"spss\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #6 (0.043): 0.032*\"python\" + 0.029*\"r\" + 0.026*\"sql\" + 0.025*\"pandas\" + 0.021*\"numpy\" + 0.018*\"scikit\" + 0.016*\"technical\" + 0.014*\"tableau\" + 0.013*\"scipy\" + 0.012*\"hadoop\"\n",
      "INFO : topic #16 (0.043): 0.012*\"sql\" + 0.007*\"r\" + 0.007*\"technical\" + 0.007*\"java\" + 0.006*\"stat\" + 0.006*\"python\" + 0.006*\"base\" + 0.005*\"languages\" + 0.005*\"unix\" + 0.005*\"databases\"\n",
      "INFO : topic #18 (0.043): 0.013*\"jsp\" + 0.010*\"spring\" + 0.010*\"servlets\" + 0.009*\"javascript\" + 0.009*\"jdbc\" + 0.009*\"hibernate\" + 0.009*\"java\" + 0.008*\"xml\" + 0.008*\"hadoop\" + 0.007*\"hbase\"\n",
      "INFO : topic #20 (0.043): 0.010*\"data\" + 0.008*\"project\" + 0.008*\"english\" + 0.007*\"team\" + 0.007*\"sql\" + 0.005*\"areasof\" + 0.005*\"r\" + 0.004*\"leadership\" + 0.004*\"python\" + 0.004*\"research\"\n",
      "INFO : topic diff=0.062411, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.712 per-word bound, 419.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3953/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #18 (0.043): 0.013*\"jsp\" + 0.010*\"spring\" + 0.010*\"servlets\" + 0.009*\"hibernate\" + 0.009*\"jdbc\" + 0.009*\"javascript\" + 0.009*\"java\" + 0.008*\"xml\" + 0.008*\"j2ee\" + 0.007*\"hbase\"\n",
      "INFO : topic #11 (0.043): 0.059*\"r\" + 0.051*\"python\" + 0.050*\"sql\" + 0.044*\"sas\" + 0.030*\"matlab\" + 0.030*\"excel\" + 0.025*\"tableau\" + 0.022*\"c++\" + 0.022*\"spss\" + 0.017*\"powerpoint\"\n",
      "INFO : topic #6 (0.043): 0.032*\"python\" + 0.029*\"r\" + 0.026*\"sql\" + 0.026*\"pandas\" + 0.021*\"numpy\" + 0.018*\"scikit\" + 0.016*\"technical\" + 0.014*\"tableau\" + 0.013*\"scipy\" + 0.013*\"hadoop\"\n",
      "INFO : topic #0 (0.043): 0.010*\"sql\" + 0.007*\"technical\" + 0.007*\"oracle\" + 0.006*\"linux\" + 0.005*\"xml\" + 0.005*\"windows\" + 0.004*\"javascript\" + 0.004*\"eclipse\" + 0.004*\"ms\" + 0.004*\"java\"\n",
      "INFO : topic #15 (0.043): 0.035*\"python\" + 0.031*\"r\" + 0.029*\"sql\" + 0.027*\"hadoop\" + 0.024*\"hive\" + 0.022*\"java\" + 0.022*\"spark\" + 0.018*\"c\" + 0.018*\"c++\" + 0.017*\"matlab\"\n",
      "INFO : topic diff=0.053600, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.702 per-word bound, 416.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.043): 0.006*\"computer\" + 0.005*\"r\" + 0.005*\"c++\" + 0.004*\"core\" + 0.004*\"sql\" + 0.003*\"python\" + 0.003*\"windows\" + 0.003*\"qgis\" + 0.003*\"development\" + 0.003*\"key\"\n",
      "INFO : topic #21 (0.043): 0.003*\"academic\" + 0.003*\"healthcare\" + 0.003*\"linkedin\" + 0.003*\"retail\" + 0.002*\"relationship\" + 0.002*\"data\" + 0.002*\"rf\" + 0.002*\"sharepoint\" + 0.002*\"development\" + 0.002*\"oncology\"\n",
      "INFO : topic #12 (0.043): 0.009*\"hive\" + 0.008*\"sql\" + 0.008*\"r\" + 0.008*\"python\" + 0.007*\"java\" + 0.007*\"spark\" + 0.006*\"excel\" + 0.006*\"tableau\" + 0.006*\"programming\" + 0.005*\"mysql\"\n",
      "INFO : topic #20 (0.043): 0.010*\"data\" + 0.009*\"english\" + 0.009*\"project\" + 0.008*\"team\" + 0.006*\"sql\" + 0.005*\"areasof\" + 0.005*\"leadership\" + 0.004*\"business\" + 0.004*\"research\" + 0.004*\"strategic\"\n",
      "INFO : topic #17 (0.043): 0.006*\"project\" + 0.004*\"data\" + 0.004*\"r\" + 0.004*\"python\" + 0.004*\"excel\" + 0.003*\"ms\" + 0.003*\"skills\" + 0.002*\"c\" + 0.002*\"oracle\" + 0.002*\"core\"\n",
      "INFO : topic diff=0.046488, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.695 per-word bound, 414.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.043): 0.010*\"taleo\" + 0.008*\"jobvite\" + 0.006*\"salesforce\" + 0.006*\"agile\" + 0.005*\"excel\" + 0.005*\"facebook\" + 0.005*\"twitter\" + 0.005*\"linkedin\" + 0.004*\"ats\" + 0.004*\"icims\"\n",
      "INFO : topic #11 (0.043): 0.060*\"r\" + 0.051*\"python\" + 0.051*\"sql\" + 0.045*\"sas\" + 0.031*\"excel\" + 0.031*\"matlab\" + 0.025*\"tableau\" + 0.022*\"spss\" + 0.022*\"c++\" + 0.018*\"powerpoint\"\n",
      "INFO : topic #17 (0.043): 0.006*\"project\" + 0.004*\"data\" + 0.003*\"r\" + 0.003*\"excel\" + 0.003*\"python\" + 0.003*\"ms\" + 0.003*\"skills\" + 0.002*\"oracle\" + 0.002*\"core\" + 0.002*\"c\"\n",
      "INFO : topic #22 (0.043): 0.009*\"python\" + 0.008*\"tableau\" + 0.008*\"r\" + 0.007*\"sql\" + 0.006*\"a\" + 0.005*\"sas\" + 0.004*\"html\" + 0.004*\"ms\" + 0.003*\"computer\" + 0.003*\"spss\"\n",
      "INFO : topic #8 (0.043): 0.021*\"r\" + 0.019*\"python\" + 0.016*\"sql\" + 0.015*\"spark\" + 0.014*\"hadoop\" + 0.012*\"hive\" + 0.010*\"oracle\" + 0.010*\"s3\" + 0.010*\"tableau\" + 0.010*\"java\"\n",
      "INFO : topic diff=0.040701, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.687 per-word bound, 412.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #18 (0.043): 0.014*\"jsp\" + 0.011*\"spring\" + 0.010*\"servlets\" + 0.010*\"hibernate\" + 0.010*\"jdbc\" + 0.008*\"javascript\" + 0.008*\"xml\" + 0.008*\"java\" + 0.008*\"j2ee\" + 0.008*\"hbase\"\n",
      "INFO : topic #11 (0.043): 0.060*\"r\" + 0.051*\"python\" + 0.051*\"sql\" + 0.045*\"sas\" + 0.031*\"excel\" + 0.031*\"matlab\" + 0.025*\"tableau\" + 0.022*\"spss\" + 0.022*\"c++\" + 0.018*\"powerpoint\"\n",
      "INFO : topic #22 (0.043): 0.008*\"python\" + 0.007*\"tableau\" + 0.007*\"r\" + 0.006*\"sql\" + 0.006*\"a\" + 0.005*\"sas\" + 0.004*\"ms\" + 0.003*\"html\" + 0.003*\"computer\" + 0.003*\"areasof\"\n",
      "INFO : topic #0 (0.043): 0.009*\"sql\" + 0.007*\"oracle\" + 0.007*\"technical\" + 0.005*\"linux\" + 0.004*\"xml\" + 0.004*\"windows\" + 0.004*\"javascript\" + 0.004*\"eclipse\" + 0.004*\"uml\" + 0.004*\"access\"\n",
      "INFO : topic #7 (0.043): 0.009*\"linux\" + 0.005*\"d.\" + 0.004*\"mandarin\" + 0.003*\"n.\" + 0.003*\"sql\" + 0.003*\"mapreduce\" + 0.003*\"hive\" + 0.003*\"chinese\" + 0.003*\"s.\" + 0.003*\"m.\"\n",
      "INFO : topic diff=0.035987, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.681 per-word bound, 410.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #18 (0.043): 0.014*\"jsp\" + 0.011*\"spring\" + 0.010*\"servlets\" + 0.010*\"hibernate\" + 0.010*\"jdbc\" + 0.008*\"xml\" + 0.008*\"j2ee\" + 0.008*\"javascript\" + 0.008*\"java\" + 0.008*\"hbase\"\n",
      "INFO : topic #10 (0.043): 0.027*\"excel\" + 0.025*\"word\" + 0.025*\"powerpoint\" + 0.019*\"access\" + 0.013*\"photoshop\" + 0.011*\"illustrator\" + 0.011*\"outlook\" + 0.009*\"project\" + 0.008*\"indesign\" + 0.006*\"computer\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #13 (0.043): 0.011*\"technical\" + 0.009*\"sql\" + 0.008*\"data\" + 0.008*\"sas\" + 0.007*\"tableau\" + 0.007*\"python\" + 0.006*\"r\" + 0.006*\"spss\" + 0.006*\"c\" + 0.005*\"html\"\n",
      "INFO : topic #8 (0.043): 0.020*\"r\" + 0.019*\"python\" + 0.015*\"sql\" + 0.015*\"spark\" + 0.013*\"hadoop\" + 0.012*\"hive\" + 0.011*\"s3\" + 0.010*\"oracle\" + 0.010*\"ec2\" + 0.010*\"java\"\n",
      "INFO : topic #5 (0.043): 0.010*\"taleo\" + 0.008*\"jobvite\" + 0.006*\"salesforce\" + 0.006*\"agile\" + 0.006*\"facebook\" + 0.005*\"twitter\" + 0.005*\"linkedin\" + 0.005*\"excel\" + 0.005*\"ats\" + 0.005*\"waterfall\"\n",
      "INFO : topic diff=0.031992, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.677 per-word bound, 409.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3967/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #19 (0.043): 0.020*\"technical\" + 0.019*\"oracle\" + 0.018*\"sql\" + 0.015*\"ssis\" + 0.015*\"tableau\" + 0.014*\"ssrs\" + 0.014*\"pl\" + 0.011*\"teradata\" + 0.011*\"unix\" + 0.011*\"ms\"\n",
      "INFO : topic #6 (0.043): 0.033*\"python\" + 0.029*\"r\" + 0.026*\"pandas\" + 0.026*\"sql\" + 0.022*\"numpy\" + 0.018*\"scikit\" + 0.016*\"technical\" + 0.014*\"tableau\" + 0.014*\"scipy\" + 0.013*\"hadoop\"\n",
      "INFO : topic #20 (0.043): 0.012*\"english\" + 0.011*\"data\" + 0.009*\"project\" + 0.009*\"team\" + 0.006*\"leadership\" + 0.006*\"areasof\" + 0.005*\"business\" + 0.005*\"core\" + 0.005*\"strategic\" + 0.005*\"sql\"\n",
      "INFO : topic #12 (0.043): 0.008*\"hive\" + 0.007*\"sql\" + 0.007*\"r\" + 0.006*\"python\" + 0.006*\"excel\" + 0.006*\"spark\" + 0.006*\"java\" + 0.005*\"tableau\" + 0.005*\"mapreduce\" + 0.005*\"programming\"\n",
      "INFO : topic #15 (0.043): 0.035*\"python\" + 0.032*\"r\" + 0.029*\"hadoop\" + 0.029*\"sql\" + 0.026*\"hive\" + 0.023*\"spark\" + 0.022*\"java\" + 0.018*\"c\" + 0.018*\"c++\" + 0.017*\"pig\"\n",
      "INFO : topic diff=0.028765, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.671 per-word bound, 407.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3971/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3972/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #16 (0.043): 0.009*\"sql\" + 0.007*\"stat\" + 0.007*\"base\" + 0.006*\"technical\" + 0.006*\"java\" + 0.005*\"r\" + 0.005*\"languages\" + 0.005*\"graph\" + 0.005*\"databases\" + 0.005*\"iml\"\n",
      "INFO : topic #19 (0.043): 0.020*\"technical\" + 0.019*\"oracle\" + 0.018*\"sql\" + 0.015*\"ssis\" + 0.015*\"tableau\" + 0.014*\"ssrs\" + 0.014*\"pl\" + 0.012*\"teradata\" + 0.011*\"unix\" + 0.011*\"ms\"\n",
      "INFO : topic #2 (0.043): 0.005*\"computer\" + 0.004*\"c++\" + 0.004*\"core\" + 0.004*\"r\" + 0.004*\"qgis\" + 0.003*\"development\" + 0.003*\"windows\" + 0.003*\"industry\" + 0.003*\"sql\" + 0.003*\"key\"\n",
      "INFO : topic #11 (0.043): 0.061*\"r\" + 0.051*\"python\" + 0.051*\"sql\" + 0.045*\"sas\" + 0.032*\"excel\" + 0.031*\"matlab\" + 0.026*\"tableau\" + 0.023*\"spss\" + 0.022*\"c++\" + 0.018*\"powerpoint\"\n",
      "INFO : topic #17 (0.043): 0.006*\"project\" + 0.004*\"data\" + 0.003*\"ms\" + 0.003*\"excel\" + 0.002*\"skills\" + 0.002*\"r\" + 0.002*\"python\" + 0.002*\"core\" + 0.002*\"oracle\" + 0.002*\"professional\"\n",
      "INFO : topic diff=0.025959, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.667 per-word bound, 406.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=23, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=23, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (336 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (563 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (388 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (392 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (420 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (592 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (794 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (528 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (350 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (696 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (469 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (497 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (641 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (566 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (618 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (460 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (457 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (656 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (384 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (771 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (656 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (448 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (771 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (716 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (705 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (431 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (705 virtual)\n",
      "DEBUG : finished all batches; 384 documents processed (431 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (512 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (612 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (1000 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (1000 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (612 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (691 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (691 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 576 documents processed (630 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 576 documents processed (630 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (524 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 512 documents processed (524 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (716 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 484 documents processed (651 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 484 documents processed (651 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (712 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (712 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9443 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12435/12537 documents converged within 50 iterations\n",
      " 91%|█████████▏| 21/23 [09:24<00:53, 26.88s/it]INFO : using symmetric alpha at 0.041666666666666664\n",
      "INFO : using symmetric eta at 0.041666666666666664\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 24 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 431/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3442/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3299/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3238/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #21 (0.042): 0.012*\"python\" + 0.009*\"sql\" + 0.008*\"r\" + 0.006*\"technical\" + 0.005*\"html\" + 0.005*\"excel\" + 0.005*\"pandas\" + 0.004*\"mysql\" + 0.004*\"powerpoint\" + 0.003*\"c++\"\n",
      "INFO : topic #23 (0.042): 0.014*\"r\" + 0.014*\"python\" + 0.013*\"sql\" + 0.009*\"linux\" + 0.006*\"matlab\" + 0.005*\"technical\" + 0.005*\"pandas\" + 0.005*\"excel\" + 0.005*\"java\" + 0.005*\"git\"\n",
      "INFO : topic #16 (0.042): 0.023*\"sql\" + 0.021*\"r\" + 0.017*\"python\" + 0.011*\"java\" + 0.011*\"technical\" + 0.009*\"sas\" + 0.008*\"javascript\" + 0.008*\"c\" + 0.007*\"hadoop\" + 0.007*\"pandas\"\n",
      "INFO : topic #0 (0.042): 0.018*\"sql\" + 0.015*\"python\" + 0.014*\"r\" + 0.010*\"hive\" + 0.009*\"java\" + 0.009*\"technical\" + 0.008*\"javascript\" + 0.008*\"html\" + 0.008*\"oracle\" + 0.008*\"c++\"\n",
      "INFO : topic #12 (0.042): 0.017*\"python\" + 0.015*\"java\" + 0.014*\"sql\" + 0.014*\"r\" + 0.012*\"hive\" + 0.010*\"tableau\" + 0.010*\"c\" + 0.010*\"hadoop\" + 0.009*\"c++\" + 0.009*\"spark\"\n",
      "INFO : topic diff=18.850269, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.451 per-word bound, 700.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3812/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3863/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3822/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #19 (0.042): 0.021*\"sql\" + 0.019*\"technical\" + 0.017*\"python\" + 0.016*\"r\" + 0.016*\"excel\" + 0.015*\"tableau\" + 0.010*\"oracle\" + 0.009*\"c\" + 0.009*\"hive\" + 0.008*\"sas\"\n",
      "INFO : topic #21 (0.042): 0.009*\"python\" + 0.007*\"sql\" + 0.005*\"r\" + 0.005*\"technical\" + 0.004*\"html\" + 0.004*\"excel\" + 0.004*\"pandas\" + 0.003*\"academic\" + 0.003*\"mysql\" + 0.003*\"powerpoint\"\n",
      "INFO : topic #17 (0.042): 0.022*\"python\" + 0.019*\"r\" + 0.011*\"c\" + 0.011*\"sql\" + 0.010*\"c++\" + 0.010*\"technical\" + 0.009*\"javascript\" + 0.008*\"excel\" + 0.008*\"mysql\" + 0.008*\"java\"\n",
      "INFO : topic #11 (0.042): 0.035*\"python\" + 0.032*\"r\" + 0.030*\"sql\" + 0.024*\"sas\" + 0.020*\"matlab\" + 0.018*\"c++\" + 0.015*\"technical\" + 0.015*\"java\" + 0.014*\"tableau\" + 0.012*\"excel\"\n",
      "INFO : topic #0 (0.042): 0.016*\"sql\" + 0.013*\"python\" + 0.012*\"r\" + 0.009*\"java\" + 0.009*\"technical\" + 0.009*\"hive\" + 0.008*\"oracle\" + 0.008*\"javascript\" + 0.008*\"html\" + 0.007*\"c++\"\n",
      "INFO : topic diff=0.364194, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.184 per-word bound, 581.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3886/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3896/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #21 (0.042): 0.007*\"python\" + 0.006*\"sql\" + 0.004*\"technical\" + 0.004*\"html\" + 0.004*\"excel\" + 0.004*\"r\" + 0.004*\"academic\" + 0.003*\"pandas\" + 0.003*\"linkedin\" + 0.003*\"powerpoint\"\n",
      "INFO : topic #10 (0.042): 0.015*\"r\" + 0.010*\"sas\" + 0.010*\"sql\" + 0.010*\"mysql\" + 0.009*\"excel\" + 0.007*\"html\" + 0.007*\"spss\" + 0.006*\"powerpoint\" + 0.006*\"linux\" + 0.006*\"access\"\n",
      "INFO : topic #5 (0.042): 0.014*\"sql\" + 0.013*\"technical\" + 0.009*\"r\" + 0.009*\"python\" + 0.009*\"excel\" + 0.007*\"access\" + 0.006*\"linux\" + 0.006*\"powerpoint\" + 0.006*\"tableau\" + 0.005*\"sas\"\n",
      "INFO : topic #4 (0.042): 0.021*\"sql\" + 0.020*\"python\" + 0.019*\"r\" + 0.013*\"technical\" + 0.010*\"data\" + 0.009*\"java\" + 0.009*\"matlab\" + 0.009*\"tableau\" + 0.008*\"c++\" + 0.008*\"hadoop\"\n",
      "INFO : topic #15 (0.042): 0.033*\"python\" + 0.032*\"sql\" + 0.031*\"r\" + 0.019*\"hadoop\" + 0.018*\"matlab\" + 0.018*\"java\" + 0.017*\"c\" + 0.016*\"tableau\" + 0.015*\"c++\" + 0.015*\"hive\"\n",
      "INFO : topic diff=0.335938, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.046 per-word bound, 528.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3905/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3923/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #13 (0.042): 0.020*\"python\" + 0.018*\"sql\" + 0.016*\"technical\" + 0.016*\"r\" + 0.013*\"tableau\" + 0.013*\"sas\" + 0.012*\"java\" + 0.012*\"html\" + 0.010*\"c\" + 0.009*\"c++\"\n",
      "INFO : topic #1 (0.042): 0.019*\"python\" + 0.016*\"java\" + 0.016*\"technical\" + 0.015*\"sql\" + 0.013*\"r\" + 0.011*\"c\" + 0.011*\"mysql\" + 0.010*\"c++\" + 0.008*\"tableau\" + 0.007*\"html\"\n",
      "INFO : topic #0 (0.042): 0.015*\"sql\" + 0.010*\"python\" + 0.010*\"r\" + 0.009*\"technical\" + 0.008*\"java\" + 0.008*\"oracle\" + 0.008*\"html\" + 0.007*\"javascript\" + 0.007*\"hive\" + 0.007*\"c\"\n",
      "INFO : topic #16 (0.042): 0.018*\"sql\" + 0.017*\"r\" + 0.013*\"python\" + 0.009*\"technical\" + 0.009*\"java\" + 0.008*\"sas\" + 0.006*\"stat\" + 0.006*\"c\" + 0.005*\"javascript\" + 0.005*\"matlab\"\n",
      "INFO : topic #7 (0.042): 0.012*\"sql\" + 0.011*\"linux\" + 0.010*\"python\" + 0.008*\"r\" + 0.007*\"hadoop\" + 0.007*\"matlab\" + 0.007*\"c++\" + 0.007*\"hive\" + 0.005*\"excel\" + 0.005*\"data\"\n",
      "INFO : topic diff=0.300053, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.958 per-word bound, 497.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3919/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.042): 0.045*\"r\" + 0.042*\"python\" + 0.039*\"sql\" + 0.034*\"sas\" + 0.026*\"matlab\" + 0.021*\"excel\" + 0.020*\"c++\" + 0.018*\"tableau\" + 0.016*\"spss\" + 0.015*\"technical\"\n",
      "INFO : topic #16 (0.042): 0.017*\"sql\" + 0.015*\"r\" + 0.011*\"python\" + 0.009*\"technical\" + 0.008*\"sas\" + 0.008*\"java\" + 0.007*\"stat\" + 0.006*\"c\" + 0.005*\"base\" + 0.005*\"javascript\"\n",
      "INFO : topic #4 (0.042): 0.017*\"sql\" + 0.017*\"python\" + 0.016*\"r\" + 0.011*\"technical\" + 0.010*\"data\" + 0.008*\"matlab\" + 0.008*\"java\" + 0.008*\"tableau\" + 0.007*\"c++\" + 0.007*\"excel\"\n",
      "INFO : topic #20 (0.042): 0.013*\"sql\" + 0.012*\"r\" + 0.010*\"python\" + 0.009*\"technical\" + 0.007*\"mysql\" + 0.007*\"data\" + 0.006*\"c++\" + 0.006*\"programming\" + 0.006*\"oracle\" + 0.006*\"sas\"\n",
      "INFO : topic #19 (0.042): 0.020*\"sql\" + 0.020*\"technical\" + 0.015*\"excel\" + 0.015*\"tableau\" + 0.013*\"python\" + 0.013*\"r\" + 0.012*\"oracle\" + 0.010*\"hive\" + 0.010*\"word\" + 0.008*\"hadoop\"\n",
      "INFO : topic diff=0.259955, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.896 per-word bound, 476.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3928/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3942/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.042): 0.013*\"unix\" + 0.011*\"linux\" + 0.008*\"technical\" + 0.006*\"sql\" + 0.006*\"python\" + 0.004*\"r\" + 0.004*\"java\" + 0.003*\"powershell\" + 0.003*\"tableau\" + 0.003*\"sunsolaris\"\n",
      "INFO : topic #1 (0.042): 0.016*\"python\" + 0.015*\"java\" + 0.015*\"technical\" + 0.013*\"sql\" + 0.011*\"r\" + 0.011*\"c\" + 0.010*\"mysql\" + 0.009*\"c++\" + 0.007*\"tableau\" + 0.006*\"html\"\n",
      "INFO : topic #13 (0.042): 0.017*\"python\" + 0.017*\"sql\" + 0.015*\"technical\" + 0.014*\"r\" + 0.012*\"tableau\" + 0.012*\"sas\" + 0.011*\"java\" + 0.011*\"html\" + 0.009*\"c\" + 0.009*\"linux\"\n",
      "INFO : topic #22 (0.042): 0.016*\"tableau\" + 0.016*\"r\" + 0.015*\"python\" + 0.015*\"sql\" + 0.011*\"sas\" + 0.008*\"c\" + 0.008*\"technical\" + 0.008*\"html\" + 0.007*\"mysql\" + 0.007*\"spss\"\n",
      "INFO : topic #14 (0.042): 0.015*\"sql\" + 0.015*\"r\" + 0.014*\"python\" + 0.011*\"c++\" + 0.010*\"java\" + 0.009*\"tableau\" + 0.009*\"c\" + 0.008*\"technical\" + 0.008*\"matlab\" + 0.007*\"hadoop\"\n",
      "INFO : topic diff=0.221328, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.856 per-word bound, 463.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 528/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.042): 0.008*\"r\" + 0.006*\"c++\" + 0.006*\"python\" + 0.006*\"windows\" + 0.005*\"computer\" + 0.005*\"linux\" + 0.004*\"matlab\" + 0.004*\"sql\" + 0.004*\"data\" + 0.004*\"microsoft\"\n",
      "INFO : topic #17 (0.042): 0.013*\"python\" + 0.012*\"r\" + 0.009*\"project\" + 0.008*\"skills\" + 0.007*\"c\" + 0.007*\"c++\" + 0.007*\"sql\" + 0.007*\"technical\" + 0.006*\"excel\" + 0.006*\"data\"\n",
      "INFO : topic #4 (0.042): 0.014*\"sql\" + 0.014*\"python\" + 0.013*\"r\" + 0.010*\"data\" + 0.010*\"technical\" + 0.006*\"matlab\" + 0.006*\"tableau\" + 0.006*\"java\" + 0.006*\"excel\" + 0.006*\"c++\"\n",
      "INFO : topic #20 (0.042): 0.011*\"sql\" + 0.010*\"r\" + 0.008*\"technical\" + 0.008*\"python\" + 0.006*\"data\" + 0.006*\"oracle\" + 0.005*\"mysql\" + 0.005*\"team\" + 0.005*\"c++\" + 0.005*\"sas\"\n",
      "INFO : topic #23 (0.042): 0.006*\"m.\" + 0.005*\"j.\" + 0.004*\"sql\" + 0.004*\"s.\" + 0.004*\"y.\" + 0.004*\"python\" + 0.004*\"l.\" + 0.004*\"r\" + 0.004*\"c.\" + 0.003*\"d.\"\n",
      "INFO : topic diff=0.186145, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.823 per-word bound, 452.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3932/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #15 (0.042): 0.035*\"python\" + 0.032*\"r\" + 0.031*\"sql\" + 0.024*\"hadoop\" + 0.021*\"java\" + 0.020*\"hive\" + 0.018*\"matlab\" + 0.018*\"spark\" + 0.017*\"c\" + 0.017*\"tableau\"\n",
      "INFO : topic #19 (0.042): 0.021*\"technical\" + 0.020*\"sql\" + 0.015*\"tableau\" + 0.013*\"oracle\" + 0.013*\"excel\" + 0.011*\"python\" + 0.010*\"r\" + 0.010*\"hive\" + 0.010*\"ssis\" + 0.010*\"teradata\"\n",
      "INFO : topic #3 (0.042): 0.013*\"unix\" + 0.011*\"linux\" + 0.007*\"technical\" + 0.005*\"sql\" + 0.004*\"python\" + 0.004*\"powershell\" + 0.004*\"sunsolaris\" + 0.003*\"macintosh_hd\" + 0.003*\"java\" + 0.002*\"hp\"\n",
      "INFO : topic #7 (0.042): 0.009*\"linux\" + 0.008*\"sql\" + 0.006*\"python\" + 0.005*\"core\" + 0.005*\"c++\" + 0.005*\"matlab\" + 0.005*\"relevant\" + 0.005*\"r\" + 0.004*\"data\" + 0.004*\"hadoop\"\n",
      "INFO : topic #0 (0.042): 0.012*\"sql\" + 0.008*\"oracle\" + 0.007*\"technical\" + 0.007*\"python\" + 0.007*\"java\" + 0.006*\"html\" + 0.006*\"r\" + 0.006*\"linux\" + 0.006*\"c\" + 0.005*\"javascript\"\n",
      "INFO : topic diff=0.155151, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.797 per-word bound, 444.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #21 (0.042): 0.006*\"linkedin\" + 0.005*\"academic\" + 0.004*\"additional\" + 0.003*\"peoplesoft\" + 0.003*\"dice\" + 0.003*\"careerbuilder\" + 0.003*\"ms_office\" + 0.003*\"salesforce\" + 0.003*\"taleo\" + 0.003*\"google\"\n",
      "INFO : topic #17 (0.042): 0.011*\"python\" + 0.010*\"project\" + 0.009*\"r\" + 0.008*\"skills\" + 0.006*\"c\" + 0.006*\"technical\" + 0.006*\"data\" + 0.006*\"c++\" + 0.005*\"sql\" + 0.005*\"microsoft\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #11 (0.042): 0.053*\"r\" + 0.046*\"python\" + 0.045*\"sql\" + 0.040*\"sas\" + 0.029*\"matlab\" + 0.028*\"excel\" + 0.021*\"tableau\" + 0.021*\"c++\" + 0.019*\"spss\" + 0.018*\"powerpoint\"\n",
      "INFO : topic #1 (0.042): 0.013*\"technical\" + 0.013*\"java\" + 0.012*\"python\" + 0.010*\"sql\" + 0.009*\"c\" + 0.009*\"mysql\" + 0.008*\"r\" + 0.007*\"c++\" + 0.005*\"tableau\" + 0.005*\"ms\"\n",
      "INFO : topic #3 (0.042): 0.013*\"unix\" + 0.010*\"linux\" + 0.007*\"technical\" + 0.005*\"sql\" + 0.004*\"powershell\" + 0.004*\"sunsolaris\" + 0.004*\"python\" + 0.003*\"macintosh_hd\" + 0.003*\"hp\" + 0.002*\"java\"\n",
      "INFO : topic diff=0.128907, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.778 per-word bound, 439.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #20 (0.042): 0.009*\"sql\" + 0.007*\"r\" + 0.007*\"technical\" + 0.006*\"data\" + 0.006*\"team\" + 0.006*\"python\" + 0.005*\"oracle\" + 0.005*\"project\" + 0.005*\"business\" + 0.005*\"db2\"\n",
      "INFO : topic #16 (0.042): 0.013*\"sql\" + 0.012*\"stat\" + 0.011*\"r\" + 0.008*\"base\" + 0.008*\"technical\" + 0.007*\"python\" + 0.007*\"graph\" + 0.007*\"sas\" + 0.006*\"macro\" + 0.006*\"java\"\n",
      "INFO : topic #11 (0.042): 0.053*\"r\" + 0.046*\"python\" + 0.046*\"sql\" + 0.040*\"sas\" + 0.030*\"matlab\" + 0.030*\"excel\" + 0.022*\"tableau\" + 0.021*\"c++\" + 0.020*\"spss\" + 0.019*\"powerpoint\"\n",
      "INFO : topic #14 (0.042): 0.012*\"sql\" + 0.011*\"r\" + 0.010*\"python\" + 0.010*\"c++\" + 0.008*\"java\" + 0.007*\"tableau\" + 0.007*\"c\" + 0.007*\"technical\" + 0.005*\"analytics\" + 0.005*\"hadoop\"\n",
      "INFO : topic #15 (0.042): 0.036*\"python\" + 0.032*\"r\" + 0.031*\"sql\" + 0.025*\"hadoop\" + 0.021*\"hive\" + 0.021*\"java\" + 0.018*\"spark\" + 0.018*\"matlab\" + 0.017*\"c\" + 0.017*\"c++\"\n",
      "INFO : topic diff=0.107403, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.764 per-word bound, 434.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.042): 0.034*\"python\" + 0.031*\"r\" + 0.027*\"sql\" + 0.024*\"pandas\" + 0.019*\"numpy\" + 0.017*\"scikit\" + 0.017*\"technical\" + 0.015*\"tableau\" + 0.013*\"spark\" + 0.013*\"scipy\"\n",
      "INFO : topic #21 (0.042): 0.007*\"linkedin\" + 0.005*\"academic\" + 0.005*\"additional\" + 0.004*\"dice\" + 0.004*\"peoplesoft\" + 0.003*\"careerbuilder\" + 0.003*\"ms_office\" + 0.003*\"salesforce\" + 0.003*\"google\" + 0.003*\"taleo\"\n",
      "INFO : topic #19 (0.042): 0.021*\"technical\" + 0.020*\"sql\" + 0.015*\"tableau\" + 0.015*\"oracle\" + 0.012*\"ssis\" + 0.012*\"excel\" + 0.011*\"teradata\" + 0.011*\"ssrs\" + 0.010*\"hive\" + 0.010*\"python\"\n",
      "INFO : topic #20 (0.042): 0.009*\"sql\" + 0.007*\"r\" + 0.006*\"technical\" + 0.006*\"data\" + 0.006*\"team\" + 0.005*\"oracle\" + 0.005*\"python\" + 0.005*\"project\" + 0.005*\"business\" + 0.005*\"db2\"\n",
      "INFO : topic #13 (0.042): 0.014*\"sql\" + 0.013*\"technical\" + 0.012*\"python\" + 0.010*\"r\" + 0.009*\"sas\" + 0.009*\"data\" + 0.009*\"tableau\" + 0.009*\"html\" + 0.008*\"java\" + 0.007*\"c\"\n",
      "INFO : topic diff=0.090070, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.750 per-word bound, 430.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #1 (0.042): 0.011*\"technical\" + 0.011*\"java\" + 0.009*\"python\" + 0.008*\"sql\" + 0.008*\"mysql\" + 0.008*\"c\" + 0.006*\"r\" + 0.006*\"c++\" + 0.005*\"ms\" + 0.004*\"tableau\"\n",
      "INFO : topic #2 (0.042): 0.006*\"r\" + 0.005*\"c++\" + 0.005*\"windows\" + 0.004*\"computer\" + 0.004*\"python\" + 0.004*\"data\" + 0.003*\"microsoft\" + 0.003*\"linux\" + 0.003*\"december\" + 0.003*\"software\"\n",
      "INFO : topic #10 (0.042): 0.005*\"excel\" + 0.005*\"sas\" + 0.005*\"html\" + 0.004*\"sql\" + 0.004*\"r\" + 0.004*\"research\" + 0.004*\"mysql\" + 0.003*\"linux\" + 0.003*\"dataanalysis\" + 0.003*\"outlook\"\n",
      "INFO : topic #17 (0.042): 0.011*\"project\" + 0.009*\"skills\" + 0.008*\"python\" + 0.007*\"r\" + 0.006*\"data\" + 0.005*\"microsoft\" + 0.005*\"c\" + 0.005*\"core\" + 0.005*\"technical\" + 0.004*\"business\"\n",
      "INFO : topic #3 (0.042): 0.013*\"unix\" + 0.010*\"linux\" + 0.006*\"technical\" + 0.004*\"sunsolaris\" + 0.004*\"powershell\" + 0.003*\"macintosh_hd\" + 0.003*\"sql\" + 0.003*\"hp\" + 0.002*\"python\" + 0.002*\"development\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.075982, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.738 per-word bound, 427.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3968/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #18 (0.042): 0.014*\"jsp\" + 0.011*\"javascript\" + 0.009*\"java\" + 0.009*\"hibernate\" + 0.009*\"xml\" + 0.009*\"spring\" + 0.009*\"servlets\" + 0.008*\"j2ee\" + 0.008*\"jdbc\" + 0.008*\"oracle\"\n",
      "INFO : topic #11 (0.042): 0.055*\"r\" + 0.047*\"sql\" + 0.047*\"python\" + 0.041*\"sas\" + 0.032*\"excel\" + 0.030*\"matlab\" + 0.023*\"tableau\" + 0.021*\"c++\" + 0.021*\"spss\" + 0.020*\"powerpoint\"\n",
      "INFO : topic #2 (0.042): 0.006*\"r\" + 0.005*\"c++\" + 0.004*\"windows\" + 0.004*\"computer\" + 0.004*\"data\" + 0.004*\"python\" + 0.003*\"december\" + 0.003*\"microsoft\" + 0.003*\"linux\" + 0.003*\"software\"\n",
      "INFO : topic #14 (0.042): 0.010*\"sql\" + 0.009*\"c++\" + 0.008*\"r\" + 0.008*\"python\" + 0.007*\"java\" + 0.006*\"c\" + 0.006*\"tableau\" + 0.006*\"analytics\" + 0.006*\"technical\" + 0.005*\"data\"\n",
      "INFO : topic #10 (0.042): 0.005*\"excel\" + 0.004*\"html\" + 0.004*\"sas\" + 0.004*\"sql\" + 0.004*\"research\" + 0.003*\"r\" + 0.003*\"linux\" + 0.003*\"mysql\" + 0.003*\"dataanalysis\" + 0.003*\"outlook\"\n",
      "INFO : topic diff=0.064632, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.729 per-word bound, 424.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.042): 0.013*\"unix\" + 0.010*\"linux\" + 0.005*\"technical\" + 0.004*\"sunsolaris\" + 0.004*\"powershell\" + 0.004*\"macintosh_hd\" + 0.003*\"sql\" + 0.003*\"hp\" + 0.002*\"development\" + 0.002*\"aix\"\n",
      "INFO : topic #18 (0.042): 0.014*\"jsp\" + 0.011*\"javascript\" + 0.010*\"hibernate\" + 0.009*\"xml\" + 0.009*\"java\" + 0.009*\"spring\" + 0.009*\"servlets\" + 0.009*\"j2ee\" + 0.008*\"jdbc\" + 0.008*\"oracle\"\n",
      "INFO : topic #0 (0.042): 0.009*\"sql\" + 0.007*\"oracle\" + 0.006*\"technical\" + 0.005*\"html\" + 0.005*\"java\" + 0.004*\"linux\" + 0.004*\"eclipse\" + 0.004*\"project\" + 0.004*\"python\" + 0.004*\"xml\"\n",
      "INFO : topic #9 (0.042): 0.037*\"javascript\" + 0.037*\"html\" + 0.036*\"java\" + 0.033*\"python\" + 0.032*\"c\" + 0.030*\"css\" + 0.029*\"c++\" + 0.022*\"mysql\" + 0.021*\"sql\" + 0.019*\"r\"\n",
      "INFO : topic #12 (0.042): 0.009*\"hive\" + 0.007*\"java\" + 0.007*\"hdfs\" + 0.007*\"python\" + 0.006*\"pig\" + 0.006*\"tableau\" + 0.006*\"hbase\" + 0.006*\"r\" + 0.005*\"programming\" + 0.005*\"technical\"\n",
      "INFO : topic diff=0.055599, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.721 per-word bound, 422.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #19 (0.042): 0.022*\"technical\" + 0.020*\"sql\" + 0.016*\"oracle\" + 0.015*\"tableau\" + 0.013*\"ssis\" + 0.013*\"ssrs\" + 0.012*\"teradata\" + 0.012*\"pl\" + 0.011*\"windows\" + 0.010*\"unix\"\n",
      "INFO : topic #11 (0.042): 0.056*\"r\" + 0.048*\"sql\" + 0.048*\"python\" + 0.042*\"sas\" + 0.033*\"excel\" + 0.030*\"matlab\" + 0.023*\"tableau\" + 0.021*\"spss\" + 0.021*\"c++\" + 0.021*\"powerpoint\"\n",
      "INFO : topic #20 (0.042): 0.007*\"sql\" + 0.007*\"team\" + 0.006*\"data\" + 0.005*\"technical\" + 0.005*\"project\" + 0.005*\"db2\" + 0.005*\"business\" + 0.005*\"cobol\" + 0.005*\"skills\" + 0.005*\"r\"\n",
      "INFO : topic #9 (0.042): 0.037*\"javascript\" + 0.037*\"html\" + 0.036*\"java\" + 0.033*\"python\" + 0.032*\"c\" + 0.030*\"css\" + 0.029*\"c++\" + 0.022*\"mysql\" + 0.021*\"sql\" + 0.019*\"r\"\n",
      "INFO : topic #15 (0.042): 0.035*\"python\" + 0.032*\"r\" + 0.031*\"sql\" + 0.027*\"hadoop\" + 0.024*\"hive\" + 0.021*\"java\" + 0.020*\"spark\" + 0.018*\"matlab\" + 0.017*\"c\" + 0.016*\"c++\"\n",
      "INFO : topic diff=0.048217, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.714 per-word bound, 420.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #17 (0.042): 0.012*\"project\" + 0.011*\"skills\" + 0.007*\"data\" + 0.006*\"core\" + 0.005*\"microsoft\" + 0.005*\"business\" + 0.005*\"python\" + 0.005*\"r\" + 0.004*\"key\" + 0.004*\"technical\"\n",
      "INFO : topic #6 (0.042): 0.035*\"python\" + 0.032*\"r\" + 0.027*\"sql\" + 0.025*\"pandas\" + 0.021*\"numpy\" + 0.018*\"scikit\" + 0.017*\"technical\" + 0.016*\"tableau\" + 0.013*\"spark\" + 0.013*\"hadoop\"\n",
      "INFO : topic #4 (0.042): 0.008*\"data\" + 0.006*\"technical\" + 0.006*\"sql\" + 0.005*\"r\" + 0.005*\"python\" + 0.004*\"oracle\" + 0.003*\"spss\" + 0.003*\"operations\" + 0.003*\"windows\" + 0.003*\"excel\"\n",
      "INFO : topic #23 (0.042): 0.009*\"j.\" + 0.008*\"m.\" + 0.007*\"d.\" + 0.007*\"s.\" + 0.006*\"c.\" + 0.005*\"b.\" + 0.005*\"p.\" + 0.005*\"y.\" + 0.005*\"l.\" + 0.004*\"ca\"\n",
      "INFO : topic #19 (0.042): 0.022*\"technical\" + 0.020*\"sql\" + 0.017*\"oracle\" + 0.015*\"tableau\" + 0.014*\"ssis\" + 0.013*\"ssrs\" + 0.013*\"teradata\" + 0.013*\"pl\" + 0.011*\"windows\" + 0.011*\"unix\"\n",
      "INFO : topic diff=0.042199, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.707 per-word bound, 418.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.042): 0.008*\"hive\" + 0.007*\"hdfs\" + 0.006*\"java\" + 0.006*\"pig\" + 0.006*\"python\" + 0.005*\"hbase\" + 0.005*\"tableau\" + 0.005*\"programming\" + 0.005*\"r\" + 0.005*\"mapreduce\"\n",
      "INFO : topic #17 (0.042): 0.012*\"project\" + 0.012*\"skills\" + 0.007*\"data\" + 0.006*\"core\" + 0.005*\"business\" + 0.005*\"microsoft\" + 0.005*\"python\" + 0.005*\"key\" + 0.004*\"r\" + 0.004*\"technical\"\n",
      "INFO : topic #16 (0.042): 0.018*\"stat\" + 0.012*\"base\" + 0.010*\"sql\" + 0.010*\"graph\" + 0.008*\"macro\" + 0.007*\"r\" + 0.007*\"technical\" + 0.006*\"iml\" + 0.006*\"sas\" + 0.005*\"macros\"\n",
      "INFO : topic #23 (0.042): 0.009*\"j.\" + 0.008*\"m.\" + 0.007*\"d.\" + 0.007*\"s.\" + 0.006*\"c.\" + 0.005*\"b.\" + 0.005*\"p.\" + 0.005*\"y.\" + 0.005*\"l.\" + 0.004*\"ca\"\n",
      "INFO : topic #2 (0.042): 0.005*\"r\" + 0.004*\"c++\" + 0.004*\"december\" + 0.004*\"computer\" + 0.004*\"windows\" + 0.004*\"data\" + 0.003*\"march\" + 0.003*\"detail\" + 0.003*\"may\" + 0.003*\"microsoft\"\n",
      "INFO : topic diff=0.037232, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.701 per-word bound, 416.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3965/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.042): 0.008*\"sql\" + 0.006*\"oracle\" + 0.005*\"technical\" + 0.004*\"project\" + 0.004*\"html\" + 0.004*\"eclipse\" + 0.004*\"linux\" + 0.004*\"uml\" + 0.004*\"access\" + 0.004*\"sdlc\"\n",
      "INFO : topic #12 (0.042): 0.008*\"hive\" + 0.007*\"hdfs\" + 0.006*\"java\" + 0.006*\"pig\" + 0.006*\"python\" + 0.005*\"hbase\" + 0.005*\"tableau\" + 0.005*\"programming\" + 0.004*\"mapreduce\" + 0.004*\"mysql\"\n",
      "INFO : topic #21 (0.042): 0.008*\"linkedin\" + 0.006*\"additional\" + 0.005*\"academic\" + 0.005*\"dice\" + 0.004*\"careerbuilder\" + 0.004*\"google\" + 0.004*\"peoplesoft\" + 0.004*\"twitter\" + 0.004*\"salesforce\" + 0.003*\"ms_office\"\n",
      "INFO : topic #10 (0.042): 0.004*\"research\" + 0.004*\"excel\" + 0.003*\"html\" + 0.003*\"dataanalysis\" + 0.003*\"sas\" + 0.003*\"sql\" + 0.003*\"linux\" + 0.002*\"dec2015\" + 0.002*\"apr\" + 0.002*\"relevant\"\n",
      "INFO : topic #14 (0.042): 0.008*\"c++\" + 0.008*\"sql\" + 0.006*\"analytics\" + 0.006*\"r\" + 0.005*\"python\" + 0.005*\"java\" + 0.005*\"c\" + 0.005*\"data\" + 0.005*\"tableau\" + 0.004*\"technical\"\n",
      "INFO : topic diff=0.033141, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.697 per-word bound, 414.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.042): 0.036*\"python\" + 0.032*\"r\" + 0.027*\"sql\" + 0.025*\"pandas\" + 0.021*\"numpy\" + 0.018*\"scikit\" + 0.017*\"technical\" + 0.016*\"tableau\" + 0.014*\"hadoop\" + 0.013*\"spark\"\n",
      "INFO : topic #4 (0.042): 0.007*\"data\" + 0.006*\"technical\" + 0.004*\"sql\" + 0.004*\"oracle\" + 0.004*\"r\" + 0.003*\"operations\" + 0.003*\"python\" + 0.003*\"spss\" + 0.003*\"windows\" + 0.003*\"excel\"\n",
      "INFO : topic #22 (0.042): 0.010*\"tableau\" + 0.007*\"sql\" + 0.006*\"sas\" + 0.006*\"c\" + 0.006*\"r\" + 0.005*\"html\" + 0.005*\"python\" + 0.005*\"spss\" + 0.005*\"ms\" + 0.005*\"oracle\"\n",
      "INFO : topic #9 (0.042): 0.038*\"javascript\" + 0.038*\"html\" + 0.037*\"java\" + 0.034*\"python\" + 0.033*\"c\" + 0.031*\"css\" + 0.030*\"c++\" + 0.023*\"mysql\" + 0.021*\"sql\" + 0.019*\"r\"\n",
      "INFO : topic #5 (0.042): 0.010*\"taleo\" + 0.006*\"technical\" + 0.005*\"jobvite\" + 0.005*\"icims\" + 0.005*\"greenhouse\" + 0.005*\"brassring\" + 0.004*\"scrum\" + 0.004*\"qgis\" + 0.004*\"agile\" + 0.004*\"excel\"\n",
      "INFO : topic diff=0.029688, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.692 per-word bound, 413.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3977/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3963/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.042): 0.010*\"taleo\" + 0.006*\"technical\" + 0.005*\"jobvite\" + 0.005*\"icims\" + 0.005*\"greenhouse\" + 0.005*\"brassring\" + 0.004*\"scrum\" + 0.004*\"qgis\" + 0.004*\"agile\" + 0.004*\"excel\"\n",
      "INFO : topic #21 (0.042): 0.009*\"linkedin\" + 0.006*\"additional\" + 0.005*\"dice\" + 0.005*\"academic\" + 0.004*\"google\" + 0.004*\"careerbuilder\" + 0.004*\"twitter\" + 0.004*\"peoplesoft\" + 0.004*\"salesforce\" + 0.003*\"ms_office\"\n",
      "INFO : topic #12 (0.042): 0.007*\"hive\" + 0.007*\"hdfs\" + 0.006*\"pig\" + 0.006*\"java\" + 0.005*\"hbase\" + 0.005*\"python\" + 0.005*\"programming\" + 0.005*\"tableau\" + 0.004*\"mapreduce\" + 0.004*\"mysql\"\n",
      "INFO : topic #0 (0.042): 0.007*\"sql\" + 0.005*\"oracle\" + 0.004*\"project\" + 0.004*\"technical\" + 0.004*\"uml\" + 0.004*\"eclipse\" + 0.004*\"html\" + 0.004*\"access\" + 0.004*\"sdlc\" + 0.003*\"linux\"\n",
      "INFO : topic #22 (0.042): 0.010*\"tableau\" + 0.007*\"sql\" + 0.006*\"sas\" + 0.006*\"c\" + 0.006*\"r\" + 0.005*\"html\" + 0.005*\"spss\" + 0.005*\"ms\" + 0.005*\"python\" + 0.005*\"oracle\"\n",
      "INFO : topic diff=0.026746, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.689 per-word bound, 412.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=24, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=24, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (153 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (336 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (513 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (439 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (569 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (404 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (452 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (396 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (456 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (746 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (548 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (419 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (629 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (644 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (520 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (617 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (810 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (517 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (602 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (502 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (617 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (502 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (460 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 320 documents processed (460 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (448 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 5; 384 documents processed (494 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 6; 448 documents processed (716 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 9; 640 documents processed (838 virtual)\n",
      "DEBUG : finished all batches; 448 documents processed (716 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (838 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (584 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 512 documents processed (654 virtual)\n",
      "DEBUG : finished all batches; 576 documents processed (584 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 9; 640 documents processed (772 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (654 virtual)\n",
      "DEBUG : finished all batches; 384 documents processed (494 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (612 virtual)\n",
      "DEBUG : finished all batches; 640 documents processed (772 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 6; 448 documents processed (465 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (465 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 479 documents processed (791 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 479 documents processed (791 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 512 documents processed (874 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (612 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 512 documents processed (874 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 8; 576 documents processed (611 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 576 documents processed (611 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9438 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12440/12537 documents converged within 50 iterations\n",
      " 96%|█████████▌| 22/23 [09:54<00:27, 27.02s/it]INFO : using symmetric alpha at 0.04\n",
      "INFO : using symmetric eta at 0.04\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 25 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 438/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3403/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3309/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3258/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #13 (0.040): 0.022*\"python\" + 0.021*\"sql\" + 0.019*\"r\" + 0.017*\"technical\" + 0.016*\"sas\" + 0.015*\"tableau\" + 0.013*\"java\" + 0.012*\"c++\" + 0.011*\"html\" + 0.011*\"c\"\n",
      "INFO : topic #3 (0.040): 0.015*\"technical\" + 0.012*\"python\" + 0.012*\"sql\" + 0.010*\"r\" + 0.010*\"unix\" + 0.008*\"java\" + 0.008*\"tableau\" + 0.008*\"linux\" + 0.006*\"powerpoint\" + 0.006*\"c++\"\n",
      "INFO : topic #18 (0.040): 0.021*\"python\" + 0.016*\"r\" + 0.015*\"sql\" + 0.013*\"javascript\" + 0.012*\"java\" + 0.012*\"hadoop\" + 0.011*\"html\" + 0.011*\"c++\" + 0.010*\"mysql\" + 0.007*\"c\"\n",
      "INFO : topic #15 (0.040): 0.029*\"python\" + 0.028*\"sql\" + 0.026*\"r\" + 0.017*\"matlab\" + 0.016*\"c\" + 0.016*\"java\" + 0.014*\"c++\" + 0.014*\"hadoop\" + 0.014*\"tableau\" + 0.012*\"sas\"\n",
      "INFO : topic #0 (0.040): 0.019*\"sql\" + 0.016*\"r\" + 0.016*\"python\" + 0.010*\"technical\" + 0.009*\"java\" + 0.008*\"html\" + 0.008*\"hive\" + 0.008*\"oracle\" + 0.008*\"javascript\" + 0.008*\"hadoop\"\n",
      "INFO : topic diff=19.779774, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.452 per-word bound, 700.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3821/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3868/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3805/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #23 (0.040): 0.011*\"r\" + 0.010*\"python\" + 0.010*\"sql\" + 0.008*\"linux\" + 0.004*\"excel\" + 0.004*\"powerpoint\" + 0.004*\"matlab\" + 0.004*\"technical\" + 0.004*\"aws\" + 0.004*\"access\"\n",
      "INFO : topic #15 (0.040): 0.031*\"python\" + 0.030*\"sql\" + 0.029*\"r\" + 0.018*\"matlab\" + 0.017*\"java\" + 0.017*\"c\" + 0.017*\"hadoop\" + 0.016*\"c++\" + 0.015*\"tableau\" + 0.013*\"hive\"\n",
      "INFO : topic #8 (0.040): 0.032*\"r\" + 0.030*\"python\" + 0.028*\"sql\" + 0.015*\"tableau\" + 0.015*\"hadoop\" + 0.013*\"c++\" + 0.013*\"hive\" + 0.012*\"technical\" + 0.011*\"java\" + 0.011*\"c\"\n",
      "INFO : topic #20 (0.040): 0.017*\"sql\" + 0.016*\"python\" + 0.015*\"r\" + 0.011*\"technical\" + 0.011*\"mysql\" + 0.009*\"java\" + 0.009*\"matlab\" + 0.008*\"tableau\" + 0.008*\"c\" + 0.008*\"sas\"\n",
      "INFO : topic #10 (0.040): 0.016*\"r\" + 0.012*\"sql\" + 0.010*\"excel\" + 0.010*\"sas\" + 0.008*\"powerpoint\" + 0.008*\"word\" + 0.007*\"c++\" + 0.007*\"mysql\" + 0.006*\"python\" + 0.005*\"spss\"\n",
      "INFO : topic diff=0.361061, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.173 per-word bound, 577.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3873/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3930/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.040): 0.012*\"technical\" + 0.011*\"unix\" + 0.008*\"python\" + 0.008*\"sql\" + 0.008*\"linux\" + 0.006*\"r\" + 0.006*\"java\" + 0.005*\"powerpoint\" + 0.005*\"tableau\" + 0.005*\"word\"\n",
      "INFO : topic #13 (0.040): 0.020*\"python\" + 0.020*\"sql\" + 0.018*\"r\" + 0.017*\"technical\" + 0.015*\"sas\" + 0.014*\"tableau\" + 0.012*\"java\" + 0.012*\"c++\" + 0.011*\"html\" + 0.011*\"c\"\n",
      "INFO : topic #20 (0.040): 0.016*\"sql\" + 0.014*\"python\" + 0.014*\"r\" + 0.010*\"technical\" + 0.010*\"mysql\" + 0.008*\"java\" + 0.008*\"data\" + 0.008*\"matlab\" + 0.007*\"tableau\" + 0.007*\"c\"\n",
      "INFO : topic #14 (0.040): 0.024*\"r\" + 0.022*\"sql\" + 0.021*\"python\" + 0.015*\"c++\" + 0.014*\"java\" + 0.013*\"matlab\" + 0.011*\"c\" + 0.011*\"spark\" + 0.011*\"technical\" + 0.010*\"tableau\"\n",
      "INFO : topic #22 (0.040): 0.020*\"python\" + 0.019*\"r\" + 0.015*\"tableau\" + 0.015*\"sql\" + 0.013*\"sas\" + 0.009*\"mysql\" + 0.009*\"technical\" + 0.008*\"html\" + 0.008*\"c\" + 0.008*\"java\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.333770, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.035 per-word bound, 524.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3889/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3940/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.040): 0.016*\"sql\" + 0.012*\"r\" + 0.011*\"python\" + 0.008*\"technical\" + 0.008*\"oracle\" + 0.007*\"html\" + 0.007*\"java\" + 0.007*\"javascript\" + 0.006*\"linux\" + 0.006*\"excel\"\n",
      "INFO : topic #22 (0.040): 0.019*\"python\" + 0.018*\"r\" + 0.015*\"tableau\" + 0.014*\"sql\" + 0.012*\"sas\" + 0.009*\"mysql\" + 0.008*\"technical\" + 0.008*\"html\" + 0.008*\"c\" + 0.007*\"java\"\n",
      "INFO : topic #3 (0.040): 0.011*\"unix\" + 0.010*\"technical\" + 0.008*\"linux\" + 0.007*\"python\" + 0.006*\"sql\" + 0.005*\"powerpoint\" + 0.005*\"java\" + 0.005*\"r\" + 0.005*\"word\" + 0.004*\"excel\"\n",
      "INFO : topic #8 (0.040): 0.030*\"r\" + 0.029*\"python\" + 0.026*\"sql\" + 0.016*\"hadoop\" + 0.016*\"tableau\" + 0.015*\"hive\" + 0.012*\"technical\" + 0.012*\"c++\" + 0.012*\"java\" + 0.012*\"spark\"\n",
      "INFO : topic #12 (0.040): 0.018*\"python\" + 0.014*\"r\" + 0.014*\"java\" + 0.014*\"hive\" + 0.013*\"sql\" + 0.011*\"mysql\" + 0.010*\"spark\" + 0.010*\"hadoop\" + 0.010*\"pig\" + 0.010*\"c\"\n",
      "INFO : topic diff=0.299030, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.948 per-word bound, 494.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 531/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3910/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.040): 0.011*\"sql\" + 0.009*\"technical\" + 0.006*\"r\" + 0.005*\"linux\" + 0.005*\"k\" + 0.005*\"python\" + 0.005*\"java\" + 0.004*\"spss\" + 0.004*\"excel\" + 0.004*\"teradata\"\n",
      "INFO : topic #16 (0.040): 0.016*\"sql\" + 0.016*\"r\" + 0.011*\"python\" + 0.008*\"technical\" + 0.007*\"java\" + 0.007*\"sas\" + 0.006*\"c\" + 0.006*\"javascript\" + 0.005*\"stat\" + 0.004*\"tableau\"\n",
      "INFO : topic #9 (0.040): 0.030*\"html\" + 0.029*\"python\" + 0.028*\"java\" + 0.028*\"c\" + 0.028*\"javascript\" + 0.023*\"css\" + 0.023*\"c++\" + 0.020*\"sql\" + 0.017*\"r\" + 0.016*\"php\"\n",
      "INFO : topic #21 (0.040): 0.006*\"python\" + 0.006*\"taleo\" + 0.004*\"academic\" + 0.004*\"jobvite\" + 0.004*\"sql\" + 0.004*\"excel\" + 0.003*\"technical\" + 0.003*\"html\" + 0.003*\"r\" + 0.003*\"datascience\"\n",
      "INFO : topic #0 (0.040): 0.015*\"sql\" + 0.010*\"r\" + 0.010*\"python\" + 0.008*\"oracle\" + 0.008*\"technical\" + 0.007*\"java\" + 0.007*\"html\" + 0.006*\"javascript\" + 0.006*\"linux\" + 0.005*\"excel\"\n",
      "INFO : topic diff=0.260493, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.890 per-word bound, 474.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3912/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3947/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.040): 0.030*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.023*\"pandas\" + 0.018*\"numpy\" + 0.016*\"scikit\" + 0.014*\"technical\" + 0.013*\"tableau\" + 0.012*\"scipy\" + 0.012*\"matplotlib\"\n",
      "INFO : topic #10 (0.040): 0.011*\"r\" + 0.011*\"excel\" + 0.010*\"english\" + 0.008*\"powerpoint\" + 0.007*\"project\" + 0.007*\"sas\" + 0.007*\"sql\" + 0.007*\"word\" + 0.005*\"illustrator\" + 0.005*\"c++\"\n",
      "INFO : topic #2 (0.040): 0.007*\"sql\" + 0.007*\"c++\" + 0.006*\"linux\" + 0.006*\"r\" + 0.005*\"data\" + 0.005*\"python\" + 0.005*\"computer\" + 0.004*\"programming\" + 0.004*\"excel\" + 0.004*\"core\"\n",
      "INFO : topic #24 (0.040): 0.010*\"sql\" + 0.010*\"r\" + 0.007*\"python\" + 0.007*\"excel\" + 0.007*\"technical\" + 0.006*\"linux\" + 0.005*\"access\" + 0.005*\"powerpoint\" + 0.004*\"html\" + 0.004*\"unix\"\n",
      "INFO : topic #11 (0.040): 0.047*\"r\" + 0.042*\"python\" + 0.042*\"sql\" + 0.036*\"sas\" + 0.026*\"matlab\" + 0.025*\"excel\" + 0.021*\"tableau\" + 0.018*\"c++\" + 0.018*\"spss\" + 0.017*\"technical\"\n",
      "INFO : topic diff=0.222342, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.846 per-word bound, 460.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3909/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3944/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #14 (0.040): 0.020*\"r\" + 0.018*\"sql\" + 0.017*\"python\" + 0.013*\"c++\" + 0.011*\"java\" + 0.011*\"matlab\" + 0.009*\"spark\" + 0.009*\"c\" + 0.008*\"technical\" + 0.007*\"tableau\"\n",
      "INFO : topic #16 (0.040): 0.014*\"sql\" + 0.013*\"r\" + 0.009*\"python\" + 0.007*\"technical\" + 0.006*\"sas\" + 0.006*\"java\" + 0.006*\"stat\" + 0.005*\"c\" + 0.005*\"javascript\" + 0.004*\"base\"\n",
      "INFO : topic #10 (0.040): 0.011*\"english\" + 0.010*\"excel\" + 0.010*\"r\" + 0.008*\"powerpoint\" + 0.007*\"project\" + 0.006*\"word\" + 0.006*\"sas\" + 0.006*\"illustrator\" + 0.006*\"sql\" + 0.005*\"indesign\"\n",
      "INFO : topic #21 (0.040): 0.008*\"taleo\" + 0.005*\"jobvite\" + 0.005*\"academic\" + 0.004*\"python\" + 0.004*\"greenhouse\" + 0.003*\"linkedin\" + 0.003*\"google\" + 0.003*\"datascience\" + 0.003*\"brassring\" + 0.003*\"careerbuilder\"\n",
      "INFO : topic #9 (0.040): 0.032*\"html\" + 0.032*\"javascript\" + 0.031*\"java\" + 0.031*\"python\" + 0.030*\"c\" + 0.026*\"css\" + 0.025*\"c++\" + 0.020*\"sql\" + 0.018*\"php\" + 0.018*\"r\"\n",
      "INFO : topic diff=0.187364, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.813 per-word bound, 449.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3914/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #22 (0.040): 0.014*\"python\" + 0.013*\"r\" + 0.013*\"tableau\" + 0.011*\"sql\" + 0.010*\"sas\" + 0.007*\"mysql\" + 0.006*\"c\" + 0.006*\"html\" + 0.006*\"technical\" + 0.005*\"java\"\n",
      "INFO : topic #6 (0.040): 0.031*\"python\" + 0.028*\"r\" + 0.025*\"pandas\" + 0.024*\"sql\" + 0.020*\"numpy\" + 0.017*\"scikit\" + 0.014*\"technical\" + 0.013*\"tableau\" + 0.013*\"scipy\" + 0.012*\"matplotlib\"\n",
      "INFO : topic #20 (0.040): 0.011*\"sql\" + 0.007*\"python\" + 0.007*\"data\" + 0.007*\"r\" + 0.007*\"technical\" + 0.006*\"mysql\" + 0.005*\"project\" + 0.005*\"oracle\" + 0.005*\"sas\" + 0.004*\"tableau\"\n",
      "INFO : topic #14 (0.040): 0.018*\"r\" + 0.017*\"sql\" + 0.016*\"python\" + 0.012*\"c++\" + 0.010*\"java\" + 0.010*\"matlab\" + 0.008*\"c\" + 0.008*\"spark\" + 0.008*\"technical\" + 0.007*\"tableau\"\n",
      "INFO : topic #21 (0.040): 0.009*\"taleo\" + 0.006*\"jobvite\" + 0.005*\"academic\" + 0.004*\"python\" + 0.004*\"greenhouse\" + 0.004*\"linkedin\" + 0.003*\"google\" + 0.003*\"careerbuilder\" + 0.003*\"brassring\" + 0.003*\"datascience\"\n",
      "INFO : topic diff=0.156694, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.789 per-word bound, 442.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.040): 0.052*\"r\" + 0.045*\"sql\" + 0.044*\"python\" + 0.040*\"sas\" + 0.030*\"excel\" + 0.027*\"matlab\" + 0.022*\"tableau\" + 0.020*\"spss\" + 0.018*\"powerpoint\" + 0.018*\"c++\"\n",
      "INFO : topic #19 (0.040): 0.019*\"technical\" + 0.018*\"sql\" + 0.016*\"oracle\" + 0.014*\"tableau\" + 0.012*\"windows\" + 0.012*\"ssis\" + 0.011*\"ssrs\" + 0.011*\"pl\" + 0.010*\"hive\" + 0.010*\"unix\"\n",
      "INFO : topic #14 (0.040): 0.017*\"r\" + 0.016*\"sql\" + 0.015*\"python\" + 0.012*\"c++\" + 0.010*\"matlab\" + 0.010*\"java\" + 0.008*\"c\" + 0.008*\"spark\" + 0.008*\"technical\" + 0.006*\"tableau\"\n",
      "INFO : topic #8 (0.040): 0.027*\"python\" + 0.026*\"r\" + 0.022*\"sql\" + 0.018*\"hadoop\" + 0.017*\"hive\" + 0.015*\"spark\" + 0.014*\"tableau\" + 0.012*\"java\" + 0.012*\"technical\" + 0.011*\"pig\"\n",
      "INFO : topic #17 (0.040): 0.012*\"python\" + 0.011*\"r\" + 0.007*\"sql\" + 0.007*\"c++\" + 0.006*\"c\" + 0.006*\"project\" + 0.006*\"technical\" + 0.005*\"excel\" + 0.005*\"skills\" + 0.005*\"perl\"\n",
      "INFO : topic diff=0.130557, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.768 per-word bound, 435.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #15 (0.040): 0.039*\"python\" + 0.037*\"r\" + 0.033*\"sql\" + 0.027*\"hadoop\" + 0.022*\"hive\" + 0.022*\"java\" + 0.021*\"matlab\" + 0.020*\"spark\" + 0.019*\"c++\" + 0.019*\"tableau\"\n",
      "INFO : topic #22 (0.040): 0.012*\"python\" + 0.012*\"r\" + 0.012*\"tableau\" + 0.009*\"sas\" + 0.009*\"sql\" + 0.006*\"mysql\" + 0.005*\"c\" + 0.005*\"html\" + 0.005*\"technical\" + 0.005*\"spss\"\n",
      "INFO : topic #23 (0.040): 0.004*\"may\" + 0.003*\"ca\" + 0.003*\"skills\" + 0.003*\"j.\" + 0.003*\"r\" + 0.003*\"linux\" + 0.003*\"nov\" + 0.002*\"business\" + 0.002*\"sql\" + 0.002*\"python\"\n",
      "INFO : topic #20 (0.040): 0.010*\"sql\" + 0.007*\"data\" + 0.006*\"technical\" + 0.006*\"python\" + 0.006*\"project\" + 0.006*\"r\" + 0.005*\"business\" + 0.005*\"mysql\" + 0.005*\"oracle\" + 0.004*\"research\"\n",
      "INFO : topic #11 (0.040): 0.052*\"r\" + 0.046*\"sql\" + 0.045*\"python\" + 0.041*\"sas\" + 0.031*\"excel\" + 0.027*\"matlab\" + 0.023*\"tableau\" + 0.020*\"spss\" + 0.019*\"powerpoint\" + 0.018*\"c++\"\n",
      "INFO : topic diff=0.108993, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.750 per-word bound, 430.5 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 529/537 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3958/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.040): 0.032*\"python\" + 0.029*\"r\" + 0.027*\"pandas\" + 0.025*\"sql\" + 0.022*\"numpy\" + 0.018*\"scikit\" + 0.015*\"technical\" + 0.014*\"tableau\" + 0.014*\"scipy\" + 0.013*\"matplotlib\"\n",
      "INFO : topic #21 (0.040): 0.010*\"taleo\" + 0.007*\"jobvite\" + 0.005*\"linkedin\" + 0.005*\"academic\" + 0.004*\"greenhouse\" + 0.004*\"brassring\" + 0.004*\"careerbuilder\" + 0.004*\"google\" + 0.004*\"bullhorn\" + 0.004*\"salesforce\"\n",
      "INFO : topic #11 (0.040): 0.053*\"r\" + 0.047*\"sql\" + 0.045*\"python\" + 0.042*\"sas\" + 0.032*\"excel\" + 0.027*\"matlab\" + 0.023*\"tableau\" + 0.021*\"spss\" + 0.019*\"powerpoint\" + 0.018*\"c++\"\n",
      "INFO : topic #18 (0.040): 0.012*\"java\" + 0.011*\"spring\" + 0.011*\"javascript\" + 0.011*\"jsp\" + 0.010*\"hibernate\" + 0.010*\"html\" + 0.009*\"mysql\" + 0.009*\"oracle\" + 0.008*\"eclipse\" + 0.008*\"python\"\n",
      "INFO : topic #0 (0.040): 0.010*\"sql\" + 0.007*\"oracle\" + 0.006*\"r\" + 0.006*\"technical\" + 0.005*\"python\" + 0.005*\"javascript\" + 0.004*\"java\" + 0.004*\"linux\" + 0.004*\"html\" + 0.004*\"data\"\n",
      "INFO : topic diff=0.091327, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.735 per-word bound, 426.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3961/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.040): 0.005*\"data\" + 0.005*\"c++\" + 0.005*\"core\" + 0.005*\"linux\" + 0.005*\"sql\" + 0.004*\"computer\" + 0.003*\"development\" + 0.003*\"r\" + 0.003*\"programming\" + 0.003*\"python\"\n",
      "INFO : topic #21 (0.040): 0.011*\"taleo\" + 0.007*\"jobvite\" + 0.005*\"linkedin\" + 0.005*\"academic\" + 0.004*\"greenhouse\" + 0.004*\"brassring\" + 0.004*\"careerbuilder\" + 0.004*\"salesforce\" + 0.004*\"bullhorn\" + 0.004*\"google\"\n",
      "INFO : topic #7 (0.040): 0.009*\"linux\" + 0.008*\"core\" + 0.007*\"python\" + 0.005*\"sql\" + 0.005*\"hadoop\" + 0.005*\"c++\" + 0.005*\"hive\" + 0.005*\"technology\" + 0.004*\"data\" + 0.004*\"matlab\"\n",
      "INFO : topic #20 (0.040): 0.008*\"sql\" + 0.007*\"data\" + 0.006*\"project\" + 0.005*\"technical\" + 0.005*\"business\" + 0.005*\"python\" + 0.005*\"team\" + 0.004*\"leadership\" + 0.004*\"r\" + 0.004*\"oracle\"\n",
      "INFO : topic #24 (0.040): 0.006*\"sql\" + 0.005*\"dataanalysis\" + 0.005*\"linux\" + 0.004*\"r\" + 0.004*\"technical\" + 0.004*\"excel\" + 0.004*\"core\" + 0.004*\"jira\" + 0.003*\"areasof\" + 0.003*\"access\"\n",
      "INFO : topic diff=0.077238, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.722 per-word bound, 422.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3971/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3955/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3973/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.040): 0.054*\"r\" + 0.047*\"sql\" + 0.045*\"python\" + 0.042*\"sas\" + 0.033*\"excel\" + 0.028*\"matlab\" + 0.023*\"tableau\" + 0.021*\"spss\" + 0.020*\"powerpoint\" + 0.018*\"c++\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #4 (0.040): 0.012*\"sql\" + 0.010*\"r\" + 0.009*\"python\" + 0.008*\"technical\" + 0.006*\"spss\" + 0.006*\"tableau\" + 0.005*\"data\" + 0.005*\"matlab\" + 0.005*\"excel\" + 0.004*\"c++\"\n",
      "INFO : topic #12 (0.040): 0.013*\"python\" + 0.012*\"hive\" + 0.010*\"sql\" + 0.009*\"r\" + 0.009*\"pig\" + 0.009*\"java\" + 0.009*\"spark\" + 0.008*\"hdfs\" + 0.007*\"c\" + 0.007*\"mysql\"\n",
      "INFO : topic #20 (0.040): 0.008*\"sql\" + 0.007*\"data\" + 0.006*\"project\" + 0.005*\"business\" + 0.005*\"technical\" + 0.005*\"team\" + 0.005*\"leadership\" + 0.004*\"research\" + 0.004*\"python\" + 0.004*\"oracle\"\n",
      "INFO : topic #23 (0.040): 0.004*\"may\" + 0.004*\"ca\" + 0.003*\"j.\" + 0.003*\"nov\" + 0.003*\"skills\" + 0.002*\"business\" + 0.002*\"il\" + 0.002*\"dec\" + 0.002*\"pp\" + 0.002*\"linux\"\n",
      "INFO : topic diff=0.065720, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.711 per-word bound, 419.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3971/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #12 (0.040): 0.012*\"python\" + 0.012*\"hive\" + 0.010*\"sql\" + 0.009*\"pig\" + 0.009*\"r\" + 0.008*\"java\" + 0.008*\"spark\" + 0.008*\"hdfs\" + 0.007*\"c\" + 0.007*\"mysql\"\n",
      "INFO : topic #17 (0.040): 0.008*\"python\" + 0.007*\"r\" + 0.007*\"project\" + 0.005*\"c++\" + 0.005*\"c\" + 0.005*\"skills\" + 0.005*\"sql\" + 0.004*\"perl\" + 0.004*\"technical\" + 0.004*\"excel\"\n",
      "INFO : topic #3 (0.040): 0.012*\"unix\" + 0.006*\"linux\" + 0.005*\"technical\" + 0.004*\"sunsolaris\" + 0.004*\"powershell\" + 0.003*\"macintosh_hd\" + 0.003*\"customer\" + 0.003*\"data\" + 0.003*\"project\" + 0.002*\"key\"\n",
      "INFO : topic #21 (0.040): 0.011*\"taleo\" + 0.008*\"jobvite\" + 0.006*\"linkedin\" + 0.005*\"academic\" + 0.005*\"salesforce\" + 0.005*\"brassring\" + 0.005*\"bullhorn\" + 0.005*\"dice\" + 0.004*\"greenhouse\" + 0.004*\"careerbuilder\"\n",
      "INFO : topic #20 (0.040): 0.007*\"sql\" + 0.007*\"data\" + 0.006*\"project\" + 0.005*\"business\" + 0.005*\"team\" + 0.005*\"leadership\" + 0.005*\"technical\" + 0.004*\"research\" + 0.004*\"areasof\" + 0.004*\"oracle\"\n",
      "INFO : topic diff=0.056520, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.703 per-word bound, 416.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 536/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3966/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.040): 0.055*\"r\" + 0.048*\"sql\" + 0.046*\"python\" + 0.043*\"sas\" + 0.034*\"excel\" + 0.028*\"matlab\" + 0.023*\"tableau\" + 0.022*\"spss\" + 0.021*\"powerpoint\" + 0.018*\"c++\"\n",
      "INFO : topic #1 (0.040): 0.011*\"java\" + 0.010*\"technical\" + 0.009*\"python\" + 0.008*\"sql\" + 0.007*\"mysql\" + 0.006*\"c\" + 0.006*\"git\" + 0.006*\"r\" + 0.005*\"ms\" + 0.005*\"c++\"\n",
      "INFO : topic #10 (0.040): 0.020*\"english\" + 0.010*\"illustrator\" + 0.009*\"mandarin\" + 0.008*\"excel\" + 0.008*\"indesign\" + 0.008*\"project\" + 0.007*\"photoshop\" + 0.006*\"chinese\" + 0.006*\"native\" + 0.005*\"powerpoint\"\n",
      "INFO : topic #16 (0.040): 0.008*\"sql\" + 0.008*\"r\" + 0.008*\"stat\" + 0.006*\"base\" + 0.005*\"technical\" + 0.005*\"macro\" + 0.005*\"graph\" + 0.005*\"iml\" + 0.005*\"ets\" + 0.004*\"c\"\n",
      "INFO : topic #14 (0.040): 0.012*\"r\" + 0.012*\"sql\" + 0.009*\"python\" + 0.009*\"c++\" + 0.007*\"matlab\" + 0.006*\"data\" + 0.006*\"java\" + 0.006*\"c\" + 0.006*\"technical\" + 0.006*\"microsoft\"\n",
      "INFO : topic diff=0.049005, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.694 per-word bound, 414.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3972/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3971/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.040): 0.012*\"unix\" + 0.006*\"linux\" + 0.005*\"technical\" + 0.004*\"sunsolaris\" + 0.004*\"powershell\" + 0.003*\"customer\" + 0.003*\"macintosh_hd\" + 0.003*\"data\" + 0.002*\"project\" + 0.002*\"key\"\n",
      "INFO : topic #4 (0.040): 0.009*\"sql\" + 0.008*\"r\" + 0.008*\"technical\" + 0.007*\"python\" + 0.005*\"spss\" + 0.005*\"data\" + 0.005*\"tableau\" + 0.004*\"matlab\" + 0.004*\"excel\" + 0.004*\"c++\"\n",
      "INFO : topic #23 (0.040): 0.005*\"may\" + 0.004*\"ca\" + 0.004*\"nov\" + 0.003*\"j.\" + 0.003*\"skills\" + 0.003*\"dec\" + 0.003*\"il\" + 0.003*\"business\" + 0.002*\"jun\" + 0.002*\"pp\"\n",
      "INFO : topic #22 (0.040): 0.008*\"tableau\" + 0.008*\"python\" + 0.008*\"r\" + 0.007*\"sas\" + 0.006*\"sql\" + 0.005*\"mysql\" + 0.004*\"spss\" + 0.003*\"clustering\" + 0.003*\"html\" + 0.003*\"database\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #14 (0.040): 0.012*\"r\" + 0.011*\"sql\" + 0.008*\"python\" + 0.008*\"c++\" + 0.006*\"matlab\" + 0.006*\"data\" + 0.006*\"java\" + 0.006*\"c\" + 0.006*\"microsoft\" + 0.006*\"technical\"\n",
      "INFO : topic diff=0.042839, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.688 per-word bound, 412.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 536/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3967/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.040): 0.024*\"python\" + 0.023*\"r\" + 0.019*\"hadoop\" + 0.019*\"sql\" + 0.018*\"hive\" + 0.017*\"spark\" + 0.012*\"pig\" + 0.012*\"tableau\" + 0.012*\"scala\" + 0.011*\"java\"\n",
      "INFO : topic #11 (0.040): 0.055*\"r\" + 0.048*\"sql\" + 0.046*\"python\" + 0.043*\"sas\" + 0.035*\"excel\" + 0.028*\"matlab\" + 0.024*\"tableau\" + 0.022*\"spss\" + 0.021*\"powerpoint\" + 0.018*\"c++\"\n",
      "INFO : topic #4 (0.040): 0.009*\"sql\" + 0.008*\"r\" + 0.007*\"technical\" + 0.006*\"python\" + 0.005*\"spss\" + 0.005*\"data\" + 0.004*\"tableau\" + 0.004*\"matlab\" + 0.004*\"skills\" + 0.004*\"excel\"\n",
      "INFO : topic #15 (0.040): 0.041*\"python\" + 0.039*\"r\" + 0.034*\"sql\" + 0.031*\"hadoop\" + 0.025*\"hive\" + 0.023*\"spark\" + 0.022*\"java\" + 0.021*\"matlab\" + 0.019*\"tableau\" + 0.019*\"c++\"\n",
      "INFO : topic #18 (0.040): 0.014*\"jsp\" + 0.013*\"spring\" + 0.012*\"hibernate\" + 0.012*\"java\" + 0.010*\"javascript\" + 0.010*\"servlets\" + 0.009*\"oracle\" + 0.009*\"eclipse\" + 0.009*\"xml\" + 0.009*\"html\"\n",
      "INFO : topic diff=0.037856, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.682 per-word bound, 410.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3971/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3974/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3962/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.040): 0.008*\"sql\" + 0.007*\"technical\" + 0.007*\"r\" + 0.006*\"python\" + 0.005*\"data\" + 0.005*\"spss\" + 0.004*\"tableau\" + 0.004*\"skills\" + 0.004*\"french\" + 0.004*\"matlab\"\n",
      "INFO : topic #8 (0.040): 0.024*\"python\" + 0.023*\"r\" + 0.019*\"hadoop\" + 0.019*\"sql\" + 0.018*\"hive\" + 0.017*\"spark\" + 0.013*\"pig\" + 0.012*\"scala\" + 0.012*\"tableau\" + 0.011*\"java\"\n",
      "INFO : topic #9 (0.040): 0.039*\"javascript\" + 0.037*\"html\" + 0.036*\"java\" + 0.034*\"python\" + 0.033*\"c\" + 0.031*\"css\" + 0.030*\"c++\" + 0.023*\"mysql\" + 0.021*\"sql\" + 0.020*\"php\"\n",
      "INFO : topic #14 (0.040): 0.011*\"r\" + 0.010*\"sql\" + 0.008*\"c++\" + 0.007*\"python\" + 0.006*\"data\" + 0.006*\"matlab\" + 0.006*\"microsoft\" + 0.005*\"c\" + 0.005*\"technical\" + 0.005*\"java\"\n",
      "INFO : topic #0 (0.040): 0.008*\"sql\" + 0.006*\"oracle\" + 0.004*\"technical\" + 0.004*\"project\" + 0.004*\"javascript\" + 0.004*\"data\" + 0.004*\"linux\" + 0.003*\"r\" + 0.003*\"iis\" + 0.003*\"java\"\n",
      "INFO : topic diff=0.033769, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.676 per-word bound, 409.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 536/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3972/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3973/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #23 (0.040): 0.005*\"may\" + 0.004*\"ca\" + 0.004*\"nov\" + 0.004*\"dec\" + 0.003*\"j.\" + 0.003*\"skills\" + 0.003*\"il\" + 0.002*\"business\" + 0.002*\"jun\" + 0.002*\"feb\"\n",
      "INFO : topic #13 (0.040): 0.010*\"technical\" + 0.008*\"data\" + 0.007*\"sql\" + 0.007*\"c++\" + 0.006*\"sas\" + 0.006*\"python\" + 0.006*\"tableau\" + 0.005*\"c\" + 0.005*\"html\" + 0.005*\"business\"\n",
      "INFO : topic #24 (0.040): 0.005*\"dataanalysis\" + 0.004*\"linux\" + 0.004*\"mm\" + 0.004*\"jira\" + 0.004*\"core\" + 0.004*\"sql\" + 0.004*\"facebook\" + 0.004*\"sd\" + 0.004*\"areasof\" + 0.003*\"crm\"\n",
      "INFO : topic #5 (0.040): 0.005*\"technical\" + 0.005*\"sql\" + 0.004*\"key\" + 0.003*\"linear\" + 0.003*\"adp\" + 0.003*\"time\" + 0.003*\"query\" + 0.003*\"teradata\" + 0.003*\"k\" + 0.003*\"sql_server\"\n",
      "INFO : topic #20 (0.040): 0.007*\"project\" + 0.006*\"leadership\" + 0.006*\"data\" + 0.006*\"business\" + 0.006*\"team\" + 0.006*\"sql\" + 0.005*\"research\" + 0.004*\"areasof\" + 0.004*\"technical\" + 0.004*\"management\"\n",
      "INFO : topic diff=0.030374, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.670 per-word bound, 407.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : 536/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3968/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3970/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.040): 0.034*\"python\" + 0.030*\"r\" + 0.029*\"pandas\" + 0.026*\"sql\" + 0.023*\"numpy\" + 0.019*\"scikit\" + 0.016*\"technical\" + 0.015*\"tableau\" + 0.015*\"scipy\" + 0.013*\"matplotlib\"\n",
      "INFO : topic #8 (0.040): 0.023*\"python\" + 0.022*\"r\" + 0.019*\"hadoop\" + 0.019*\"hive\" + 0.018*\"sql\" + 0.017*\"spark\" + 0.013*\"pig\" + 0.012*\"scala\" + 0.011*\"tableau\" + 0.011*\"sqoop\"\n",
      "INFO : topic #17 (0.040): 0.008*\"project\" + 0.005*\"python\" + 0.005*\"r\" + 0.005*\"skills\" + 0.004*\"c++\" + 0.004*\"c\" + 0.004*\"perl\" + 0.003*\"microsoft\" + 0.003*\"technical\" + 0.003*\"sql\"\n",
      "INFO : topic #15 (0.040): 0.041*\"python\" + 0.040*\"r\" + 0.034*\"sql\" + 0.032*\"hadoop\" + 0.026*\"hive\" + 0.023*\"spark\" + 0.023*\"java\" + 0.021*\"matlab\" + 0.020*\"tableau\" + 0.019*\"c++\"\n",
      "INFO : topic #1 (0.040): 0.008*\"java\" + 0.008*\"technical\" + 0.007*\"python\" + 0.005*\"sql\" + 0.005*\"mysql\" + 0.005*\"git\" + 0.004*\"c\" + 0.004*\"ms\" + 0.004*\"r\" + 0.004*\"confluence\"\n",
      "INFO : topic diff=0.027433, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.665 per-word bound, 406.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=25, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=25, decay=0.5, chunksize=4000)\n",
      "INFO : using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (97 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 0; 64 documents processed (64 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (161 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (128 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 1; 128 documents processed (153 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (225 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (217 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 2; 192 documents processed (192 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (289 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (281 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 3; 256 documents processed (256 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (353 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (512 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : completed batch 4; 320 documents processed (320 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (400 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (345 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (435 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (385 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (388 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (375 virtual)\n",
      "DEBUG : completed batch 4; 320 documents processed (377 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (499 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (392 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (409 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (493 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (437 virtual)\n",
      "DEBUG : completed batch 8; 576 documents processed (922 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (528 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (384 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (648 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (563 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (564 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (563 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (460 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (453 virtual)\n",
      "DEBUG : completed batch 5; 384 documents processed (495 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (456 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (473 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (473 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 6; 448 documents processed (603 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (603 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 9; 640 documents processed (1003 virtual)\n",
      "DEBUG : completed batch 6; 448 documents processed (448 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 640 documents processed (1003 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 448 documents processed (448 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (627 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (627 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (699 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 8; 576 documents processed (628 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 512 documents processed (699 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 5; 384 documents processed (573 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 576 documents processed (628 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 384 documents processed (495 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : finished all batches; 384 documents processed (573 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 6; 448 documents processed (625 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : completed batch 7; 512 documents processed (757 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (791 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 448 documents processed (625 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (757 virtual)\n",
      "DEBUG : finished all batches; 512 documents processed (791 virtual)\n",
      "DEBUG : completed batch 7; 512 documents processed (524 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (524 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "DEBUG : completed batch 7; 485 documents processed (668 virtual)\n",
      "DEBUG : observed sentinel value; terminating\n",
      "DEBUG : finished all batches; 485 documents processed (668 virtual)\n",
      "INFO : accumulator serialized\n",
      "INFO : serializing accumulator to return to master...\n",
      "DEBUG : completed batch 7; 512 documents processed (530 virtual)\n",
      "INFO : accumulator serialized\n",
      "DEBUG : observed sentinel value; terminating\n",
      "INFO : accumulator serialized\n",
      "DEBUG : finished all batches; 512 documents processed (530 virtual)\n",
      "INFO : serializing accumulator to return to master...\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : accumulator serialized\n",
      "INFO : 15 accumulators retrieved from output queue\n",
      "INFO : accumulated word occurrence stats for 9444 virtual documents\n",
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12447/12537 documents converged within 50 iterations\n",
      "100%|██████████| 23/23 [10:25<00:00, 27.20s/it]\n"
     ]
    }
   ],
   "source": [
    "Lda = models.LdaMulticore\n",
    "coherenceList_umass = []\n",
    "coherenceList_cv = []\n",
    "num_topics_list = [3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n",
    "for num_topics in tqdm(num_topics_list):\n",
    "    lda= Lda(doc_term_matrix, num_topics=num_topics,id2word = dictionary, passes=20,chunksize=4000,random_state=43)\n",
    "    cm = CoherenceModel(model=lda, corpus=doc_term_matrix, dictionary=dictionary, coherence='u_mass')\n",
    "    coherenceList_umass.append(cm.get_coherence())\n",
    "    cm_cv = CoherenceModel(model=lda, corpus=doc_term_matrix,texts=skillList, dictionary=dictionary, coherence='c_v')\n",
    "    coherenceList_cv.append(cm_cv.get_coherence())\n",
    "    vis = pyLDAvis.gensim.prepare(lda, doc_term_matrix, dictionary)\n",
    "    pyLDAvis.save_html(vis,f'pyLDAvis_{num_topics}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING : No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f52d4cc0048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(num_topics_list, coherenceList_umass, 'bx-')\n",
    "plt.axhline(y=-4)\n",
    "plt.xlabel('number of topics')\n",
    "plt.ylabel('u_mass')\n",
    "plt.title('Topic coherence')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I get a sense that the ideal number of topics revolves around 11. I searched the best number of clusters around 11 and found that 12 is the ideal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : using symmetric alpha at 0.08333333333333333\n",
      "INFO : using symmetric eta at 0.08333333333333333\n",
      "INFO : using serial LDA version on this node\n",
      "INFO : running online LDA training, 12 topics, 20 passes over the supplied corpus of 12537 documents, updating every 60000 documents, evaluating every ~12537 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO : training LDA model using 15 processes\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : worker process entering E-step loop\n",
      "DEBUG : worker process entering E-step loop\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "DEBUG : getting a new job\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 424/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3189/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3099/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3297/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #3 (0.083): 0.013*\"technical\" + 0.012*\"sql\" + 0.011*\"python\" + 0.009*\"r\" + 0.008*\"unix\" + 0.008*\"java\" + 0.007*\"tableau\" + 0.007*\"linux\" + 0.005*\"powerpoint\" + 0.005*\"c\"\n",
      "INFO : topic #2 (0.083): 0.013*\"r\" + 0.011*\"sql\" + 0.010*\"python\" + 0.010*\"c++\" + 0.007*\"html\" + 0.007*\"c\" + 0.007*\"java\" + 0.006*\"linux\" + 0.006*\"programming\" + 0.006*\"sas\"\n",
      "INFO : topic #11 (0.083): 0.032*\"python\" + 0.028*\"r\" + 0.027*\"sql\" + 0.020*\"sas\" + 0.018*\"matlab\" + 0.017*\"c++\" + 0.015*\"technical\" + 0.015*\"tableau\" + 0.014*\"java\" + 0.013*\"hadoop\"\n",
      "INFO : topic #10 (0.083): 0.014*\"r\" + 0.011*\"sql\" + 0.011*\"sas\" + 0.010*\"mysql\" + 0.008*\"excel\" + 0.007*\"c++\" + 0.007*\"html\" + 0.007*\"python\" + 0.006*\"java\" + 0.006*\"linux\"\n",
      "INFO : topic #7 (0.083): 0.015*\"sql\" + 0.015*\"python\" + 0.012*\"linux\" + 0.011*\"hadoop\" + 0.011*\"c++\" + 0.010*\"hive\" + 0.010*\"r\" + 0.009*\"matlab\" + 0.008*\"c\" + 0.007*\"java\"\n",
      "INFO : topic diff=8.340587, rho=1.000000\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.200 per-word bound, 588.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 515/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3757/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3796/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3761/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.083): 0.013*\"sql\" + 0.013*\"python\" + 0.010*\"linux\" + 0.010*\"hadoop\" + 0.009*\"c++\" + 0.009*\"hive\" + 0.009*\"r\" + 0.008*\"matlab\" + 0.007*\"c\" + 0.007*\"java\"\n",
      "INFO : topic #6 (0.083): 0.025*\"r\" + 0.024*\"python\" + 0.019*\"sql\" + 0.012*\"sas\" + 0.012*\"tableau\" + 0.012*\"technical\" + 0.011*\"mysql\" + 0.009*\"pandas\" + 0.009*\"matlab\" + 0.009*\"hadoop\"\n",
      "INFO : topic #1 (0.083): 0.023*\"python\" + 0.019*\"java\" + 0.017*\"r\" + 0.017*\"sql\" + 0.017*\"technical\" + 0.013*\"c\" + 0.012*\"c++\" + 0.010*\"mysql\" + 0.009*\"tableau\" + 0.009*\"html\"\n",
      "INFO : topic #5 (0.083): 0.014*\"sql\" + 0.009*\"technical\" + 0.008*\"r\" + 0.007*\"excel\" + 0.007*\"python\" + 0.006*\"tableau\" + 0.006*\"sas\" + 0.005*\"access\" + 0.005*\"java\" + 0.004*\"spss\"\n",
      "INFO : topic #0 (0.083): 0.016*\"sql\" + 0.013*\"python\" + 0.013*\"r\" + 0.010*\"hive\" + 0.009*\"technical\" + 0.009*\"java\" + 0.008*\"html\" + 0.008*\"oracle\" + 0.008*\"javascript\" + 0.007*\"c++\"\n",
      "INFO : topic diff=0.350514, rho=0.441328\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -9.014 per-word bound, 516.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 524/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3810/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3878/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3879/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #9 (0.083): 0.024*\"python\" + 0.023*\"html\" + 0.023*\"c\" + 0.021*\"sql\" + 0.021*\"java\" + 0.018*\"javascript\" + 0.017*\"r\" + 0.015*\"c++\" + 0.014*\"css\" + 0.013*\"technical\"\n",
      "INFO : topic #3 (0.083): 0.010*\"technical\" + 0.008*\"sql\" + 0.007*\"unix\" + 0.006*\"python\" + 0.006*\"linux\" + 0.005*\"r\" + 0.005*\"tableau\" + 0.005*\"java\" + 0.005*\"powerpoint\" + 0.004*\"skills\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #8 (0.083): 0.027*\"r\" + 0.026*\"python\" + 0.023*\"sql\" + 0.017*\"hadoop\" + 0.016*\"hive\" + 0.016*\"tableau\" + 0.012*\"java\" + 0.012*\"technical\" + 0.012*\"spark\" + 0.010*\"pig\"\n",
      "INFO : topic #4 (0.083): 0.021*\"sql\" + 0.019*\"r\" + 0.019*\"python\" + 0.011*\"technical\" + 0.010*\"matlab\" + 0.009*\"tableau\" + 0.009*\"data\" + 0.008*\"java\" + 0.008*\"excel\" + 0.008*\"c++\"\n",
      "INFO : topic #6 (0.083): 0.025*\"python\" + 0.025*\"r\" + 0.020*\"sql\" + 0.012*\"tableau\" + 0.012*\"technical\" + 0.012*\"sas\" + 0.011*\"pandas\" + 0.011*\"mysql\" + 0.010*\"hadoop\" + 0.009*\"matlab\"\n",
      "INFO : topic diff=0.291399, rho=0.403756\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.914 per-word bound, 482.4 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3891/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : 3846/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3898/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.083): 0.009*\"r\" + 0.008*\"sas\" + 0.008*\"sql\" + 0.007*\"excel\" + 0.006*\"mysql\" + 0.006*\"powerpoint\" + 0.005*\"word\" + 0.005*\"data\" + 0.005*\"spss\" + 0.005*\"html\"\n",
      "INFO : topic #2 (0.083): 0.009*\"r\" + 0.008*\"sql\" + 0.008*\"c++\" + 0.006*\"python\" + 0.006*\"html\" + 0.005*\"data\" + 0.005*\"c\" + 0.005*\"linux\" + 0.005*\"computer\" + 0.004*\"java\"\n",
      "INFO : topic #11 (0.083): 0.039*\"python\" + 0.039*\"r\" + 0.035*\"sql\" + 0.026*\"sas\" + 0.023*\"matlab\" + 0.020*\"c++\" + 0.018*\"tableau\" + 0.016*\"excel\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #0 (0.083): 0.014*\"sql\" + 0.010*\"python\" + 0.010*\"r\" + 0.009*\"technical\" + 0.008*\"oracle\" + 0.008*\"java\" + 0.008*\"hive\" + 0.008*\"html\" + 0.007*\"javascript\" + 0.006*\"c++\"\n",
      "INFO : topic #8 (0.083): 0.026*\"r\" + 0.026*\"python\" + 0.022*\"sql\" + 0.018*\"hadoop\" + 0.018*\"hive\" + 0.016*\"tableau\" + 0.013*\"java\" + 0.012*\"spark\" + 0.012*\"technical\" + 0.012*\"pig\"\n",
      "INFO : topic diff=0.239468, rho=0.374391\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.856 per-word bound, 463.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3871/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3896/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3918/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.083): 0.010*\"sql\" + 0.007*\"technical\" + 0.006*\"excel\" + 0.005*\"access\" + 0.005*\"r\" + 0.004*\"sas\" + 0.004*\"tableau\" + 0.004*\"k\" + 0.004*\"oracle\" + 0.003*\"spss\"\n",
      "INFO : topic #9 (0.083): 0.025*\"html\" + 0.023*\"python\" + 0.023*\"c\" + 0.022*\"java\" + 0.021*\"javascript\" + 0.020*\"sql\" + 0.017*\"c++\" + 0.017*\"css\" + 0.015*\"r\" + 0.013*\"technical\"\n",
      "INFO : topic #11 (0.083): 0.041*\"r\" + 0.040*\"python\" + 0.037*\"sql\" + 0.027*\"sas\" + 0.024*\"matlab\" + 0.020*\"c++\" + 0.019*\"tableau\" + 0.018*\"excel\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #6 (0.083): 0.026*\"python\" + 0.025*\"r\" + 0.021*\"sql\" + 0.013*\"pandas\" + 0.013*\"technical\" + 0.013*\"tableau\" + 0.011*\"sas\" + 0.011*\"hadoop\" + 0.010*\"numpy\" + 0.010*\"mysql\"\n",
      "INFO : topic #4 (0.083): 0.018*\"sql\" + 0.017*\"r\" + 0.016*\"python\" + 0.009*\"technical\" + 0.009*\"data\" + 0.008*\"matlab\" + 0.008*\"tableau\" + 0.008*\"c++\" + 0.008*\"excel\" + 0.007*\"java\"\n",
      "INFO : topic diff=0.194661, rho=0.350624\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.817 per-word bound, 450.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3897/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3931/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3927/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #11 (0.083): 0.042*\"r\" + 0.041*\"python\" + 0.038*\"sql\" + 0.028*\"sas\" + 0.024*\"matlab\" + 0.020*\"c++\" + 0.019*\"tableau\" + 0.019*\"excel\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #5 (0.083): 0.009*\"sql\" + 0.007*\"technical\" + 0.005*\"excel\" + 0.005*\"access\" + 0.004*\"r\" + 0.004*\"sas\" + 0.004*\"k\" + 0.004*\"tableau\" + 0.004*\"oracle\" + 0.003*\"spss\"\n",
      "INFO : topic #2 (0.083): 0.007*\"r\" + 0.007*\"c++\" + 0.006*\"sql\" + 0.005*\"html\" + 0.005*\"data\" + 0.005*\"python\" + 0.004*\"computer\" + 0.004*\"c\" + 0.004*\"linux\" + 0.004*\"windows\"\n",
      "INFO : topic #8 (0.083): 0.024*\"python\" + 0.024*\"r\" + 0.021*\"sql\" + 0.020*\"hive\" + 0.019*\"hadoop\" + 0.016*\"tableau\" + 0.014*\"spark\" + 0.013*\"java\" + 0.013*\"pig\" + 0.013*\"technical\"\n",
      "INFO : topic #0 (0.083): 0.012*\"sql\" + 0.008*\"oracle\" + 0.008*\"technical\" + 0.008*\"python\" + 0.007*\"r\" + 0.007*\"java\" + 0.007*\"html\" + 0.006*\"hive\" + 0.006*\"javascript\" + 0.006*\"mysql\"\n",
      "INFO : topic diff=0.156680, rho=0.330875\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.790 per-word bound, 442.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3894/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3906/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #10 (0.083): 0.006*\"english\" + 0.006*\"excel\" + 0.006*\"r\" + 0.005*\"sas\" + 0.005*\"sql\" + 0.005*\"powerpoint\" + 0.005*\"data\" + 0.004*\"word\" + 0.004*\"research\" + 0.004*\"mysql\"\n",
      "INFO : topic #7 (0.083): 0.007*\"sql\" + 0.006*\"python\" + 0.006*\"hadoop\" + 0.005*\"linux\" + 0.005*\"c++\" + 0.004*\"c\" + 0.004*\"matlab\" + 0.004*\"excel\" + 0.004*\"hive\" + 0.004*\"core\"\n",
      "INFO : topic #2 (0.083): 0.006*\"c++\" + 0.006*\"r\" + 0.006*\"sql\" + 0.005*\"data\" + 0.005*\"html\" + 0.004*\"python\" + 0.004*\"computer\" + 0.004*\"c\" + 0.004*\"linux\" + 0.003*\"windows\"\n",
      "INFO : topic #11 (0.083): 0.044*\"r\" + 0.042*\"python\" + 0.039*\"sql\" + 0.029*\"sas\" + 0.025*\"matlab\" + 0.021*\"c++\" + 0.020*\"tableau\" + 0.019*\"excel\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #1 (0.083): 0.017*\"python\" + 0.015*\"java\" + 0.014*\"technical\" + 0.013*\"sql\" + 0.012*\"r\" + 0.011*\"c\" + 0.009*\"c++\" + 0.008*\"mysql\" + 0.006*\"html\" + 0.006*\"tableau\"\n",
      "INFO : topic diff=0.125712, rho=0.314126\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.772 per-word bound, 437.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 530/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3911/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.083): 0.011*\"sql\" + 0.008*\"oracle\" + 0.008*\"technical\" + 0.007*\"html\" + 0.007*\"java\" + 0.006*\"python\" + 0.006*\"r\" + 0.005*\"javascript\" + 0.005*\"hive\" + 0.005*\"xml\"\n",
      "INFO : topic #2 (0.083): 0.006*\"c++\" + 0.006*\"r\" + 0.005*\"sql\" + 0.005*\"data\" + 0.004*\"html\" + 0.004*\"computer\" + 0.004*\"python\" + 0.003*\"c\" + 0.003*\"linux\" + 0.003*\"windows\"\n",
      "INFO : topic #9 (0.083): 0.026*\"html\" + 0.024*\"javascript\" + 0.024*\"c\" + 0.024*\"java\" + 0.023*\"python\" + 0.019*\"sql\" + 0.019*\"css\" + 0.018*\"c++\" + 0.014*\"r\" + 0.014*\"mysql\"\n",
      "INFO : topic #1 (0.083): 0.016*\"python\" + 0.014*\"java\" + 0.014*\"technical\" + 0.012*\"sql\" + 0.011*\"r\" + 0.011*\"c\" + 0.008*\"c++\" + 0.007*\"mysql\" + 0.006*\"html\" + 0.006*\"tableau\"\n",
      "INFO : topic #8 (0.083): 0.023*\"python\" + 0.023*\"r\" + 0.021*\"hive\" + 0.021*\"sql\" + 0.020*\"hadoop\" + 0.015*\"tableau\" + 0.015*\"pig\" + 0.014*\"spark\" + 0.014*\"java\" + 0.014*\"technical\"\n",
      "INFO : topic diff=0.101450, rho=0.299688\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.756 per-word bound, 432.2 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3920/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3933/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #3 (0.083): 0.007*\"technical\" + 0.007*\"unix\" + 0.005*\"skills\" + 0.004*\"linux\" + 0.004*\"sql\" + 0.003*\"powerpoint\" + 0.003*\"tableau\" + 0.003*\"software\" + 0.002*\"windows\" + 0.002*\"project\"\n",
      "INFO : topic #4 (0.083): 0.013*\"sql\" + 0.012*\"r\" + 0.011*\"python\" + 0.008*\"data\" + 0.007*\"technical\" + 0.007*\"matlab\" + 0.006*\"c++\" + 0.006*\"excel\" + 0.006*\"computer\" + 0.005*\"spss\"\n",
      "INFO : topic #0 (0.083): 0.010*\"sql\" + 0.008*\"oracle\" + 0.007*\"technical\" + 0.007*\"html\" + 0.007*\"java\" + 0.006*\"python\" + 0.005*\"xml\" + 0.005*\"pl\" + 0.005*\"javascript\" + 0.005*\"r\"\n",
      "INFO : topic #9 (0.083): 0.027*\"html\" + 0.025*\"javascript\" + 0.025*\"java\" + 0.024*\"c\" + 0.023*\"python\" + 0.020*\"css\" + 0.019*\"sql\" + 0.019*\"c++\" + 0.014*\"mysql\" + 0.014*\"r\"\n",
      "INFO : topic #2 (0.083): 0.006*\"c++\" + 0.005*\"r\" + 0.005*\"data\" + 0.005*\"sql\" + 0.004*\"html\" + 0.004*\"computer\" + 0.003*\"python\" + 0.003*\"c\" + 0.003*\"linux\" + 0.003*\"windows\"\n",
      "INFO : topic diff=0.082211, rho=0.287074\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.745 per-word bound, 429.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 527/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3921/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3934/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3936/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.083): 0.012*\"sql\" + 0.011*\"r\" + 0.010*\"python\" + 0.007*\"data\" + 0.006*\"technical\" + 0.006*\"matlab\" + 0.006*\"excel\" + 0.006*\"c++\" + 0.005*\"computer\" + 0.005*\"spss\"\n",
      "INFO : topic #5 (0.083): 0.007*\"sql\" + 0.006*\"technical\" + 0.004*\"excel\" + 0.004*\"access\" + 0.003*\"oracle\" + 0.003*\"k\" + 0.003*\"key\" + 0.003*\"tableau\" + 0.003*\"data\" + 0.003*\"r\"\n",
      "INFO : topic #7 (0.083): 0.005*\"sql\" + 0.004*\"python\" + 0.004*\"linux\" + 0.004*\"hadoop\" + 0.004*\"c++\" + 0.004*\"core\" + 0.003*\"excel\" + 0.003*\"c\" + 0.003*\"matlab\" + 0.003*\"software\"\n",
      "INFO : topic #6 (0.083): 0.028*\"python\" + 0.026*\"r\" + 0.022*\"sql\" + 0.017*\"pandas\" + 0.014*\"technical\" + 0.014*\"numpy\" + 0.013*\"tableau\" + 0.012*\"scikit\" + 0.012*\"hadoop\" + 0.010*\"spark\"\n",
      "INFO : topic #10 (0.083): 0.009*\"english\" + 0.005*\"excel\" + 0.005*\"data\" + 0.004*\"powerpoint\" + 0.004*\"research\" + 0.004*\"sas\" + 0.004*\"sql\" + 0.004*\"r\" + 0.004*\"word\" + 0.004*\"indesign\"\n",
      "INFO : topic diff=0.067430, rho=0.275929\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.735 per-word bound, 426.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3922/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3938/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #5 (0.083): 0.007*\"sql\" + 0.005*\"technical\" + 0.004*\"excel\" + 0.004*\"access\" + 0.003*\"oracle\" + 0.003*\"key\" + 0.003*\"k\" + 0.002*\"tableau\" + 0.002*\"data\" + 0.002*\"sql_server\"\n",
      "INFO : topic #2 (0.083): 0.005*\"c++\" + 0.005*\"r\" + 0.004*\"data\" + 0.004*\"sql\" + 0.003*\"html\" + 0.003*\"computer\" + 0.003*\"project\" + 0.003*\"c\" + 0.003*\"windows\" + 0.003*\"linux\"\n",
      "INFO : topic #7 (0.083): 0.004*\"sql\" + 0.004*\"python\" + 0.004*\"core\" + 0.004*\"linux\" + 0.004*\"c++\" + 0.004*\"hadoop\" + 0.003*\"excel\" + 0.003*\"c\" + 0.003*\"software\" + 0.003*\"matlab\"\n",
      "INFO : topic #4 (0.083): 0.011*\"sql\" + 0.010*\"r\" + 0.009*\"python\" + 0.007*\"data\" + 0.006*\"technical\" + 0.006*\"matlab\" + 0.005*\"excel\" + 0.005*\"c++\" + 0.005*\"computer\" + 0.004*\"spss\"\n",
      "INFO : topic #0 (0.083): 0.009*\"sql\" + 0.009*\"oracle\" + 0.007*\"technical\" + 0.006*\"html\" + 0.006*\"java\" + 0.006*\"xml\" + 0.005*\"pl\" + 0.005*\"javascript\" + 0.005*\"windows\" + 0.005*\"linux\"\n",
      "INFO : topic diff=0.055871, rho=0.265989\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.727 per-word bound, 423.7 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3946/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #6 (0.083): 0.029*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.018*\"pandas\" + 0.014*\"numpy\" + 0.014*\"technical\" + 0.013*\"tableau\" + 0.013*\"scikit\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #5 (0.083): 0.006*\"sql\" + 0.005*\"technical\" + 0.003*\"excel\" + 0.003*\"access\" + 0.003*\"key\" + 0.003*\"oracle\" + 0.003*\"k\" + 0.002*\"sql_server\" + 0.002*\"data\" + 0.002*\"means\"\n",
      "INFO : topic #2 (0.083): 0.005*\"c++\" + 0.004*\"data\" + 0.004*\"r\" + 0.004*\"sql\" + 0.003*\"computer\" + 0.003*\"html\" + 0.003*\"project\" + 0.003*\"analytics\" + 0.003*\"windows\" + 0.003*\"c\"\n",
      "INFO : topic #7 (0.083): 0.004*\"core\" + 0.004*\"sql\" + 0.003*\"python\" + 0.003*\"linux\" + 0.003*\"c++\" + 0.003*\"hadoop\" + 0.003*\"excel\" + 0.003*\"software\" + 0.003*\"skill\" + 0.003*\"c\"\n",
      "INFO : topic #0 (0.083): 0.009*\"sql\" + 0.009*\"oracle\" + 0.007*\"technical\" + 0.006*\"html\" + 0.006*\"java\" + 0.006*\"xml\" + 0.005*\"pl\" + 0.005*\"javascript\" + 0.005*\"windows\" + 0.005*\"linux\"\n",
      "INFO : topic diff=0.046863, rho=0.257051\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.720 per-word bound, 421.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3956/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #3 (0.083): 0.006*\"unix\" + 0.006*\"technical\" + 0.005*\"skills\" + 0.003*\"linux\" + 0.002*\"salesforce\" + 0.002*\"sql\" + 0.002*\"powerpoint\" + 0.002*\"taleo\" + 0.002*\"project\" + 0.002*\"software\"\n",
      "INFO : topic #1 (0.083): 0.012*\"python\" + 0.012*\"technical\" + 0.011*\"java\" + 0.009*\"sql\" + 0.008*\"c\" + 0.008*\"r\" + 0.006*\"c++\" + 0.006*\"ms\" + 0.005*\"windows\" + 0.005*\"mysql\"\n",
      "INFO : topic #0 (0.083): 0.009*\"sql\" + 0.009*\"oracle\" + 0.007*\"technical\" + 0.006*\"html\" + 0.006*\"xml\" + 0.006*\"java\" + 0.005*\"pl\" + 0.005*\"windows\" + 0.005*\"javascript\" + 0.005*\"agile\"\n",
      "INFO : topic #11 (0.083): 0.047*\"r\" + 0.043*\"python\" + 0.042*\"sql\" + 0.032*\"sas\" + 0.026*\"matlab\" + 0.023*\"excel\" + 0.021*\"c++\" + 0.021*\"tableau\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #9 (0.083): 0.028*\"html\" + 0.027*\"javascript\" + 0.026*\"java\" + 0.025*\"c\" + 0.023*\"python\" + 0.021*\"css\" + 0.020*\"c++\" + 0.019*\"sql\" + 0.015*\"mysql\" + 0.013*\"r\"\n",
      "INFO : topic diff=0.039871, rho=0.248958\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.714 per-word bound, 419.8 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 534/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3949/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3959/4000 documents converged within 50 iterations\n",
      "DEBUG : 3929/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #0 (0.083): 0.009*\"oracle\" + 0.008*\"sql\" + 0.007*\"technical\" + 0.006*\"html\" + 0.006*\"xml\" + 0.006*\"java\" + 0.006*\"pl\" + 0.005*\"windows\" + 0.005*\"uml\" + 0.005*\"agile\"\n",
      "INFO : topic #6 (0.083): 0.029*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.018*\"pandas\" + 0.015*\"numpy\" + 0.014*\"technical\" + 0.013*\"tableau\" + 0.013*\"scikit\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #1 (0.083): 0.012*\"technical\" + 0.011*\"python\" + 0.010*\"java\" + 0.009*\"sql\" + 0.008*\"c\" + 0.007*\"r\" + 0.006*\"c++\" + 0.006*\"ms\" + 0.005*\"windows\" + 0.005*\"data\"\n",
      "INFO : topic #3 (0.083): 0.006*\"unix\" + 0.006*\"technical\" + 0.005*\"skills\" + 0.003*\"linux\" + 0.002*\"salesforce\" + 0.002*\"taleo\" + 0.002*\"powerpoint\" + 0.002*\"sql\" + 0.002*\"project\" + 0.002*\"software\"\n",
      "INFO : topic #2 (0.083): 0.005*\"c++\" + 0.004*\"data\" + 0.004*\"r\" + 0.003*\"computer\" + 0.003*\"sql\" + 0.003*\"project\" + 0.003*\"html\" + 0.003*\"analytics\" + 0.003*\"core\" + 0.002*\"analysis\"\n",
      "INFO : topic diff=0.034329, rho=0.241584\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.709 per-word bound, 418.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3950/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #2 (0.083): 0.004*\"c++\" + 0.004*\"data\" + 0.003*\"r\" + 0.003*\"computer\" + 0.003*\"project\" + 0.003*\"sql\" + 0.003*\"html\" + 0.003*\"analytics\" + 0.003*\"core\" + 0.002*\"analysis\"\n",
      "INFO : topic #10 (0.083): 0.011*\"english\" + 0.005*\"data\" + 0.004*\"indesign\" + 0.004*\"research\" + 0.004*\"excel\" + 0.004*\"mandarin\" + 0.004*\"spanish\" + 0.003*\"illustrator\" + 0.003*\"relevant\" + 0.003*\"photoshop\"\n",
      "INFO : topic #5 (0.083): 0.005*\"sql\" + 0.005*\"technical\" + 0.003*\"key\" + 0.003*\"access\" + 0.003*\"excel\" + 0.003*\"k\" + 0.003*\"oracle\" + 0.002*\"means\" + 0.002*\"sql_server\" + 0.002*\"teradata\"\n",
      "INFO : topic #3 (0.083): 0.006*\"unix\" + 0.006*\"technical\" + 0.005*\"skills\" + 0.003*\"linux\" + 0.003*\"salesforce\" + 0.002*\"taleo\" + 0.002*\"powerpoint\" + 0.002*\"project\" + 0.002*\"software\" + 0.002*\"sql\"\n",
      "INFO : topic #8 (0.083): 0.024*\"hive\" + 0.022*\"python\" + 0.021*\"hadoop\" + 0.020*\"r\" + 0.020*\"sql\" + 0.017*\"pig\" + 0.016*\"spark\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"java\"\n",
      "INFO : topic diff=0.029986, rho=0.234828\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.704 per-word bound, 417.1 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 533/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 3943/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #7 (0.083): 0.004*\"core\" + 0.003*\"jobvite\" + 0.003*\"skill\" + 0.003*\"software\" + 0.003*\"d.\" + 0.003*\"s.\" + 0.003*\"m.\" + 0.003*\"j.\" + 0.002*\"sql\" + 0.002*\"linux\"\n",
      "INFO : topic #11 (0.083): 0.048*\"r\" + 0.043*\"python\" + 0.042*\"sql\" + 0.032*\"sas\" + 0.026*\"matlab\" + 0.024*\"excel\" + 0.021*\"tableau\" + 0.021*\"c++\" + 0.016*\"java\" + 0.016*\"technical\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic #1 (0.083): 0.011*\"technical\" + 0.010*\"python\" + 0.009*\"java\" + 0.008*\"sql\" + 0.007*\"c\" + 0.006*\"r\" + 0.006*\"ms\" + 0.005*\"c++\" + 0.005*\"data\" + 0.005*\"windows\"\n",
      "INFO : topic #3 (0.083): 0.006*\"unix\" + 0.006*\"technical\" + 0.005*\"skills\" + 0.003*\"linux\" + 0.003*\"salesforce\" + 0.003*\"taleo\" + 0.002*\"project\" + 0.002*\"powerpoint\" + 0.002*\"powershell\" + 0.002*\"software\"\n",
      "INFO : topic #10 (0.083): 0.011*\"english\" + 0.005*\"data\" + 0.004*\"indesign\" + 0.004*\"research\" + 0.004*\"excel\" + 0.004*\"mandarin\" + 0.004*\"spanish\" + 0.003*\"illustrator\" + 0.003*\"relevant\" + 0.003*\"photoshop\"\n",
      "INFO : topic diff=0.026397, rho=0.228610\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.701 per-word bound, 416.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3951/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.083): 0.007*\"sql\" + 0.006*\"data\" + 0.006*\"r\" + 0.005*\"python\" + 0.005*\"technical\" + 0.004*\"matlab\" + 0.004*\"excel\" + 0.004*\"computer\" + 0.004*\"c++\" + 0.003*\"windows\"\n",
      "INFO : topic #6 (0.083): 0.030*\"python\" + 0.027*\"r\" + 0.023*\"sql\" + 0.019*\"pandas\" + 0.016*\"numpy\" + 0.015*\"technical\" + 0.013*\"scikit\" + 0.013*\"tableau\" + 0.012*\"hadoop\" + 0.011*\"spark\"\n",
      "INFO : topic #5 (0.083): 0.005*\"sql\" + 0.004*\"technical\" + 0.003*\"key\" + 0.003*\"access\" + 0.003*\"k\" + 0.003*\"oracle\" + 0.002*\"excel\" + 0.002*\"means\" + 0.002*\"sql_server\" + 0.002*\"teradata\"\n",
      "INFO : topic #1 (0.083): 0.011*\"technical\" + 0.009*\"python\" + 0.009*\"java\" + 0.008*\"sql\" + 0.007*\"c\" + 0.006*\"r\" + 0.006*\"ms\" + 0.005*\"c++\" + 0.005*\"data\" + 0.004*\"windows\"\n",
      "INFO : topic #0 (0.083): 0.009*\"oracle\" + 0.008*\"sql\" + 0.006*\"technical\" + 0.006*\"xml\" + 0.006*\"html\" + 0.006*\"pl\" + 0.005*\"java\" + 0.005*\"uml\" + 0.005*\"agile\" + 0.005*\"windows\"\n",
      "INFO : topic diff=0.023472, rho=0.222860\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.697 per-word bound, 414.9 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3945/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3957/4000 documents converged within 50 iterations\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : 3960/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #4 (0.083): 0.006*\"sql\" + 0.006*\"data\" + 0.005*\"r\" + 0.004*\"technical\" + 0.004*\"python\" + 0.004*\"excel\" + 0.004*\"computer\" + 0.004*\"matlab\" + 0.003*\"c++\" + 0.003*\"skills\"\n",
      "INFO : topic #11 (0.083): 0.048*\"r\" + 0.043*\"python\" + 0.043*\"sql\" + 0.033*\"sas\" + 0.027*\"matlab\" + 0.024*\"excel\" + 0.022*\"tableau\" + 0.021*\"c++\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #8 (0.083): 0.024*\"hive\" + 0.021*\"python\" + 0.021*\"hadoop\" + 0.020*\"sql\" + 0.019*\"r\" + 0.017*\"pig\" + 0.016*\"spark\" + 0.015*\"tableau\" + 0.014*\"technical\" + 0.014*\"java\"\n",
      "INFO : topic #9 (0.083): 0.029*\"html\" + 0.029*\"javascript\" + 0.027*\"java\" + 0.026*\"c\" + 0.024*\"python\" + 0.022*\"css\" + 0.021*\"c++\" + 0.019*\"sql\" + 0.016*\"mysql\" + 0.014*\"php\"\n",
      "INFO : topic #10 (0.083): 0.012*\"english\" + 0.005*\"data\" + 0.005*\"indesign\" + 0.005*\"research\" + 0.004*\"mandarin\" + 0.004*\"spanish\" + 0.004*\"excel\" + 0.004*\"illustrator\" + 0.003*\"relevant\" + 0.003*\"native\"\n",
      "INFO : topic diff=0.021006, rho=0.217524\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.694 per-word bound, 414.0 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : 535/537 documents converged within 50 iterations\n",
      "DEBUG : 3939/4000 documents converged within 50 iterations\n",
      "DEBUG : 3948/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3967/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : updating topics\n",
      "DEBUG : getting a new job\n",
      "INFO : topic #9 (0.083): 0.029*\"html\" + 0.029*\"javascript\" + 0.027*\"java\" + 0.026*\"c\" + 0.024*\"python\" + 0.023*\"css\" + 0.021*\"c++\" + 0.019*\"sql\" + 0.016*\"mysql\" + 0.014*\"php\"\n",
      "INFO : topic #2 (0.083): 0.004*\"data\" + 0.004*\"c++\" + 0.003*\"project\" + 0.003*\"analytics\" + 0.003*\"computer\" + 0.003*\"core\" + 0.003*\"analysis\" + 0.002*\"areasof\" + 0.002*\"r\" + 0.002*\"team\"\n",
      "INFO : topic #11 (0.083): 0.048*\"r\" + 0.043*\"python\" + 0.043*\"sql\" + 0.033*\"sas\" + 0.027*\"matlab\" + 0.024*\"excel\" + 0.022*\"tableau\" + 0.021*\"c++\" + 0.016*\"java\" + 0.016*\"technical\"\n",
      "INFO : topic #0 (0.083): 0.009*\"oracle\" + 0.007*\"sql\" + 0.006*\"xml\" + 0.006*\"technical\" + 0.006*\"pl\" + 0.006*\"html\" + 0.005*\"uml\" + 0.005*\"agile\" + 0.005*\"java\" + 0.005*\"windows\"\n",
      "INFO : topic #4 (0.083): 0.006*\"data\" + 0.006*\"sql\" + 0.005*\"r\" + 0.004*\"technical\" + 0.004*\"python\" + 0.004*\"excel\" + 0.004*\"computer\" + 0.004*\"matlab\" + 0.003*\"skills\" + 0.003*\"windows\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : topic diff=0.018992, rho=0.212553\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.691 per-word bound, 413.3 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #4000/12537, outstanding queue size 1\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #8000/12537, outstanding queue size 2\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #12000/12537, outstanding queue size 3\n",
      "INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #12537/12537, outstanding queue size 4\n",
      "DEBUG : processing chunk #0 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #1 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #2 of 4000 documents\n",
      "DEBUG : performing inference on a chunk of 4000 documents\n",
      "DEBUG : processing chunk #3 of 537 documents\n",
      "DEBUG : performing inference on a chunk of 537 documents\n",
      "DEBUG : 532/537 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3952/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3954/4000 documents converged within 50 iterations\n",
      "DEBUG : result put\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : getting a new job\n",
      "DEBUG : 3964/4000 documents converged within 50 iterations\n",
      "DEBUG : processed chunk, queuing the result\n",
      "DEBUG : result put\n",
      "DEBUG : getting a new job\n",
      "DEBUG : updating topics\n",
      "INFO : topic #8 (0.083): 0.024*\"hive\" + 0.021*\"hadoop\" + 0.021*\"python\" + 0.020*\"sql\" + 0.019*\"r\" + 0.018*\"pig\" + 0.016*\"spark\" + 0.015*\"tableau\" + 0.015*\"technical\" + 0.014*\"java\"\n",
      "INFO : topic #4 (0.083): 0.006*\"data\" + 0.005*\"sql\" + 0.005*\"r\" + 0.004*\"technical\" + 0.004*\"excel\" + 0.004*\"computer\" + 0.004*\"python\" + 0.004*\"matlab\" + 0.003*\"skills\" + 0.003*\"windows\"\n",
      "INFO : topic #3 (0.083): 0.005*\"technical\" + 0.005*\"unix\" + 0.005*\"skills\" + 0.003*\"taleo\" + 0.003*\"salesforce\" + 0.002*\"powershell\" + 0.002*\"project\" + 0.002*\"linux\" + 0.002*\"bullhorn\" + 0.002*\"linkedin\"\n",
      "INFO : topic #1 (0.083): 0.010*\"technical\" + 0.008*\"java\" + 0.008*\"python\" + 0.007*\"sql\" + 0.006*\"c\" + 0.005*\"ms\" + 0.005*\"r\" + 0.004*\"data\" + 0.004*\"windows\" + 0.004*\"oracle\"\n",
      "INFO : topic #10 (0.083): 0.012*\"english\" + 0.005*\"data\" + 0.005*\"research\" + 0.005*\"indesign\" + 0.005*\"mandarin\" + 0.005*\"spanish\" + 0.004*\"illustrator\" + 0.004*\"native\" + 0.004*\"french\" + 0.003*\"relevant\"\n",
      "INFO : topic diff=0.017327, rho=0.207909\n",
      "DEBUG : bound: at document #0\n",
      "INFO : -8.689 per-word bound, 412.6 perplexity estimate based on a held-out corpus of 537 documents with 6909 words\n"
     ]
    }
   ],
   "source": [
    "lda_final= Lda(doc_term_matrix, num_topics=12,id2word = dictionary, passes=20,chunksize=4000,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model):\n",
    "    data = model.top_topics(doc_term_matrix,dictionary=dictionary,topn=20)\n",
    "    finaltopic_repr = []\n",
    "    for topic in range(len(data)):\n",
    "        wordstr =''\n",
    "        for words in data[topic][0]:\n",
    "            wordstr+='+'+str(words[1])\n",
    "        score = data[topic][1]\n",
    "        wordstr=wordstr.split('+',1)[1]\n",
    "        finaltopic_repr.append((wordstr,score))\n",
    "    finaltopic_repr = sorted(finaltopic_repr,key =lambda x: x[1], reverse=True)\n",
    "    return finaltopic_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : Setting topics to those of the model: LdaModel(num_terms=25488, num_topics=12, decay=0.5, chunksize=4000)\n",
      "INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "INFO : CorpusAccumulator accumulated stats from 12000 documents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic-word Representation</th>\n",
       "      <th>Coherence score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hive+hadoop+python+sql+r+pig+spark+tableau+tec...</td>\n",
       "      <td>-1.473616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>html+javascript+java+c+python+css+c+++sql+mysq...</td>\n",
       "      <td>-1.507970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python+r+sql+pandas+numpy+technical+scikit+tab...</td>\n",
       "      <td>-1.861966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r+python+sql+sas+matlab+excel+tableau+c+++java...</td>\n",
       "      <td>-1.923961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oracle+sql+xml+technical+pl+html+uml+agile+win...</td>\n",
       "      <td>-2.034309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>technical+java+python+sql+c+ms+r+data+windows+...</td>\n",
       "      <td>-2.099782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data+sql+r+technical+excel+computer+python+mat...</td>\n",
       "      <td>-3.137381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data+c+++project+analytics+core+computer+analy...</td>\n",
       "      <td>-3.722686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sql+technical+key+oracle+k+access+means+terada...</td>\n",
       "      <td>-5.933414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>technical+unix+skills+taleo+salesforce+powersh...</td>\n",
       "      <td>-7.028471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>english+data+research+indesign+mandarin+spanis...</td>\n",
       "      <td>-7.162294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>core+jobvite+d.+s.+m.+skill+j.+software+r.+tal...</td>\n",
       "      <td>-7.828040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Topic-word Representation  Coherence score\n",
       "0   hive+hadoop+python+sql+r+pig+spark+tableau+tec...        -1.473616\n",
       "1   html+javascript+java+c+python+css+c+++sql+mysq...        -1.507970\n",
       "2   python+r+sql+pandas+numpy+technical+scikit+tab...        -1.861966\n",
       "3   r+python+sql+sas+matlab+excel+tableau+c+++java...        -1.923961\n",
       "4   oracle+sql+xml+technical+pl+html+uml+agile+win...        -2.034309\n",
       "5   technical+java+python+sql+c+ms+r+data+windows+...        -2.099782\n",
       "6   data+sql+r+technical+excel+computer+python+mat...        -3.137381\n",
       "7   data+c+++project+analytics+core+computer+analy...        -3.722686\n",
       "8   sql+technical+key+oracle+k+access+means+terada...        -5.933414\n",
       "9   technical+unix+skills+taleo+salesforce+powersh...        -7.028471\n",
       "10  english+data+research+indesign+mandarin+spanis...        -7.162294\n",
       "11  core+jobvite+d.+s.+m.+skill+j.+software+r.+tal...        -7.828040"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(print_topics(lda_final),columns=['Topic-word Representation','Coherence score']).sort_values(by='Coherence score',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG : performing inference on a chunk of 12537 documents\n",
      "DEBUG : 12402/12537 documents converged within 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el16481399931787258561910670915\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el16481399931787258561910670915_data = {\"mdsDat\": {\"Freq\": [21.018930435180664, 20.327831268310547, 17.509239196777344, 14.393433570861816, 7.235928058624268, 3.7480130195617676, 3.3688957691192627, 3.0480494499206543, 2.673363447189331, 2.3349006175994873, 2.1916937828063965, 2.149719715118408], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], \"x\": [0.1783857549032864, 0.204531368943192, 0.23071067378094864, 0.17188585225763922, 0.028247556716662167, -0.012752806777677136, -0.07478411868361634, -0.15808910786748395, -0.1511001624308604, -0.12280743145061462, -0.13271054578004068, -0.1615170336114355], \"y\": [-0.09905049077439786, -0.14121497553184817, 0.04340585934249608, 0.10789000591714876, 0.1793002841994226, 0.02756448637244434, -0.05754615455576726, -0.021893192436511125, 0.03761133062925126, -0.011622350422037747, -0.02214508557028802, -0.042299717169913036]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\"], \"Freq\": [1530.0, 701.0, 1020.0, 1058.0, 1114.0, 656.0, 567.0, 458.0, 646.0, 3289.0, 3500.0, 1092.0, 1462.0, 1851.0, 396.0, 357.0, 300.0, 954.0, 515.0, 286.0, 1582.0, 359.0, 684.0, 302.0, 513.0, 337.0, 257.0, 1346.0, 369.0, 357.0, 30.653230667114258, 37.14659881591797, 41.25349044799805, 18.10948371887207, 29.889427185058594, 12.72348690032959, 9.98438549041748, 27.275531768798828, 9.936199188232422, 45.56496047973633, 14.635875701904297, 7.901810169219971, 8.773781776428223, 5.524521350860596, 5.517757415771484, 5.516547679901123, 47.47324752807617, 12.7393217086792, 244.3356170654297, 33.848793029785156, 180.7667694091797, 21.59137725830078, 14.16105842590332, 4.61146354675293, 4.607047080993652, 4.599328517913818, 12.044764518737793, 4.575338363647461, 4.5497918128967285, 5.28167200088501, 435.4529113769531, 110.41980743408203, 142.0616912841797, 65.05493927001953, 370.1397399902344, 54.42942810058594, 277.08538818359375, 23.595121383666992, 779.42578125, 499.03924560546875, 1052.731201171875, 306.9114074707031, 308.0362243652344, 43.2037239074707, 34.15925598144531, 850.3724975585938, 129.16758728027344, 1540.376953125, 95.56644439697266, 1368.2508544921875, 1386.47021484375, 691.6441650390625, 684.7215576171875, 99.83206176757812, 77.3234634399414, 476.12127685546875, 501.963623046875, 505.07440185546875, 177.738525390625, 124.00768280029297, 237.25518798828125, 249.6495819091797, 278.9126892089844, 234.07240295410156, 186.45814514160156, 168.84622192382812, 162.2484588623047, 135.26649475097656, 146.62960815429688, 143.1005859375, 70.43865203857422, 120.1266098022461, 33.99032211303711, 250.54409790039062, 148.90757751464844, 28.374649047851562, 28.267759323120117, 62.03538131713867, 29.106782913208008, 44.915287017822266, 39.53809356689453, 289.4990234375, 15.703837394714355, 17.436552047729492, 20.920387268066406, 26.153112411499023, 75.70298767089844, 13.836283683776855, 46.468101501464844, 129.3924560546875, 12.028773307800293, 24.989892959594727, 212.6578369140625, 27.329612731933594, 11.110419273376465, 17.92889976501465, 11.031570434570312, 10.189621925354004, 221.85183715820312, 17.741979598999023, 423.8507385253906, 276.9980773925781, 28.579904556274414, 303.0569763183594, 287.4048767089844, 65.82405090332031, 58.82844924926758, 491.8665771484375, 601.7286376953125, 222.03134155273438, 322.13751220703125, 312.1083068847656, 307.4092712402344, 248.4167938232422, 66.84762573242188, 67.29283142089844, 56.617855072021484, 300.6131896972656, 74.6821517944336, 112.32324981689453, 275.45526123046875, 168.56468200683594, 322.6091003417969, 930.0496215820312, 859.2409057617188, 130.94607543945312, 354.08050537109375, 725.9365234375, 387.50909423828125, 457.4080810546875, 414.8419494628906, 218.72105407714844, 300.8248596191406, 308.7006530761719, 273.6828308105469, 273.04595947265625, 256.54473876953125, 225.22047424316406, 225.1316680908203, 30.432119369506836, 21.43604278564453, 21.429794311523438, 16.779268264770508, 14.934326171875, 13.035733222961426, 13.89342975616455, 12.137751579284668, 165.8701171875, 11.211641311645508, 22.32724380493164, 11.172247886657715, 15.489304542541504, 10.292716026306152, 26.454126358032227, 13.684884071350098, 265.84576416015625, 21.33808135986328, 10.150980949401855, 8.435243606567383, 78.88600158691406, 9.248148918151855, 20.94664192199707, 7.5103607177734375, 7.504335880279541, 12.5501127243042, 62.217708587646484, 7.477048873901367, 8.314901351928711, 155.158935546875, 119.50293731689453, 35.19828414916992, 310.5998840332031, 109.62468719482422, 31.506446838378906, 18.944007873535156, 190.72238159179688, 471.76507568359375, 33.35131072998047, 66.10690307617188, 66.49408721923828, 652.0856323242188, 265.4238586425781, 50.936431884765625, 40.320865631103516, 34.72406768798828, 247.7947540283203, 98.91061401367188, 96.07052612304688, 59.2419319152832, 72.04531860351562, 58.17805480957031, 255.98483276367188, 154.55064392089844, 563.478515625, 183.00743103027344, 419.5441589355469, 85.7242431640625, 170.89059448242188, 133.2649688720703, 341.39520263671875, 149.04287719726562, 73.24684143066406, 214.3362579345703, 390.4315185546875, 388.4833068847656, 557.3923950195312, 527.6876220703125, 378.3770751953125, 508.25946044921875, 271.9032287597656, 216.9102783203125, 184.08920288085938, 195.35739135742188, 251.9724884033203, 228.29710388183594, 191.33460998535156, 171.71714782714844, 17.213176727294922, 12.002264976501465, 11.971038818359375, 31.533071517944336, 10.138344764709473, 9.262924194335938, 13.374761581420898, 9.201576232910156, 32.59896469116211, 7.423062324523926, 7.422792911529541, 7.410447597503662, 23.92363166809082, 7.382801532745361, 7.383270263671875, 8.171249389648438, 8.113043785095215, 6.483032703399658, 6.480585098266602, 6.459096908569336, 18.6346492767334, 7.196444511413574, 5.582090854644775, 5.5783796310424805, 5.580347537994385, 5.547571182250977, 18.719104766845703, 13.201436996459961, 25.6832332611084, 4.669233798980713, 219.37353515625, 25.48503303527832, 501.65826416015625, 308.14422607421875, 86.26020812988281, 119.49555206298828, 29.79377555847168, 88.38353729248047, 34.25199890136719, 642.6912841796875, 61.57561111450195, 646.231689453125, 58.03986358642578, 18.722129821777344, 237.59654235839844, 130.14419555664062, 57.02806091308594, 54.00511932373047, 268.33270263671875, 38.207584381103516, 101.95357513427734, 574.2333374023438, 70.79241180419922, 78.98592376708984, 596.16552734375, 472.24603271484375, 363.40594482421875, 53.9840202331543, 183.3893585205078, 79.20829010009766, 523.5631103515625, 67.41582489013672, 114.30094146728516, 223.18716430664062, 405.732666015625, 287.60150146484375, 159.09507751464844, 171.19204711914062, 293.3770446777344, 176.3648223876953, 119.60316467285156, 138.02110290527344, 124.30987548828125, 79.93710327148438, 11.021384239196777, 10.845858573913574, 16.919960021972656, 6.799032211303711, 14.395892143249512, 5.983896732330322, 5.961872577667236, 5.947218894958496, 31.654293060302734, 5.9147443771362305, 5.140966892242432, 32.434696197509766, 4.312475204467773, 4.312013149261475, 4.310488224029541, 32.43703079223633, 5.735187530517578, 4.260257720947266, 4.255125522613525, 5.706851959228516, 7.640018939971924, 6.857200622558594, 3.4668211936950684, 3.4665825366973877, 3.466323137283325, 3.466306447982788, 3.465883493423462, 3.46527361869812, 3.461097240447998, 3.460416793823242, 5.595762252807617, 4.88551664352417, 7.455965995788574, 4.1676177978515625, 36.80310821533203, 21.93734359741211, 36.87449264526367, 9.022850036621094, 13.837248802185059, 22.062042236328125, 37.85015106201172, 24.327686309814453, 15.124228477478027, 7.300445079803467, 56.954345703125, 49.113155364990234, 42.4503288269043, 24.070383071899414, 23.34442138671875, 34.02655029296875, 36.15990447998047, 17.36079216003418, 45.22744369506836, 10.812718391418457, 43.66242980957031, 28.137826919555664, 35.05023956298828, 34.72581100463867, 33.68378448486328, 50.12253189086914, 54.96818161010742, 38.6337890625, 99.12245178222656, 26.759164810180664, 62.907901763916016, 49.18927764892578, 52.83012771606445, 67.91143035888672, 49.95168685913086, 54.227210998535156, 59.926700592041016, 78.56475830078125, 65.03877258300781, 45.981964111328125, 53.045345306396484, 43.919002532958984, 43.67202377319336, 38.13401794433594, 38.827571868896484, 35.6002197265625, 6.427215099334717, 6.426909446716309, 6.426394939422607, 2.8883471488952637, 2.8876500129699707, 2.879981517791748, 2.18208646774292, 2.181593179702759, 2.1807587146759033, 2.180233955383301, 2.180327892303467, 5.009204864501953, 2.1706032752990723, 2.169666051864624, 2.1723129749298096, 2.1306817531585693, 2.880000114440918, 1.4746959209442139, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 1.4746958017349243, 6.42680549621582, 6.427546977996826, 3.0715560913085938, 2.8885035514831543, 2.181317090988159, 4.805813789367676, 2.871185302734375, 2.180773973464966, 3.61434268951416, 2.7972300052642822, 13.852611541748047, 2.8886513710021973, 2.438204050064087, 3.3665244579315186, 13.657500267028809, 11.10556411743164, 10.979653358459473, 6.8433122634887695, 31.192716598510742, 21.730545043945312, 57.03644943237305, 4.625948429107666, 45.958229064941406, 13.13903522491455, 5.198416233062744, 6.637155055999756, 4.736074447631836, 25.28569221496582, 24.3800106048584, 7.754991054534912, 34.498905181884766, 45.134300231933594, 24.282711029052734, 8.90318489074707, 37.330230712890625, 13.50493049621582, 14.735305786132812, 20.82695960998535, 23.327960968017578, 25.977046966552734, 11.011661529541016, 11.138197898864746, 17.359643936157227, 16.954238891601562, 16.09495735168457, 13.740906715393066, 11.222466468811035, 9.964022636413574, 10.138999938964844, 12.370668411254883, 11.587054252624512, 9.869706153869629, 2.163259744644165, 2.163245677947998, 2.1630265712738037, 2.1622660160064697, 2.161247968673706, 2.144909381866455, 2.1257965564727783, 2.116370916366577, 2.094142436981201, 3.5426406860351562, 3.5530996322631836, 1.461661696434021, 1.4616607427597046, 1.4616601467132568, 1.4616599082946777, 1.4616590738296509, 1.4616583585739136, 1.4616106748580933, 1.4615384340286255, 1.4615329504013062, 1.4615256786346436, 1.461464524269104, 1.4614702463150024, 1.4614439010620117, 1.4613251686096191, 1.4612951278686523, 1.4612706899642944, 1.4612632989883423, 1.4612030982971191, 6.889654159545898, 4.837409973144531, 3.5564091205596924, 9.319867134094238, 2.8558876514434814, 2.163256883621216, 3.147394895553589, 4.177099704742432, 2.7626535892486572, 2.862877368927002, 2.1522505283355713, 2.83839750289917, 3.7136752605438232, 1.8511292934417725, 4.807389259338379, 4.583338737487793, 2.098534345626831, 2.1607537269592285, 2.8126072883605957, 2.861189603805542, 14.151285171508789, 4.711212158203125, 4.626452445983887, 6.753362655639648, 9.083946228027344, 5.21082878112793, 4.27041482925415, 29.076982498168945, 6.586907386779785, 11.857933044433594, 3.3568053245544434, 9.6172456741333, 13.001435279846191, 4.958065032958984, 18.711929321289062, 16.908384323120117, 8.363988876342773, 18.922409057617188, 27.20014190673828, 15.706779479980469, 21.385190963745117, 18.27733612060547, 23.093547821044922, 12.70853042602539, 13.489583969116211, 11.583224296569824, 9.997963905334473, 18.61575698852539, 15.198768615722656, 8.361181259155273, 10.648054122924805, 7.5605597496032715, 7.712002277374268, 9.475387573242188, 8.011697769165039, 8.260843276977539, 8.244083404541016, 7.992302894592285, 2.8836801052093506, 14.152812957763672, 2.186399459838867, 2.186312198638916, 2.1862435340881348, 2.185857057571411, 2.1293346881866455, 2.675696611404419, 2.1108193397521973, 3.5978212356567383, 8.574105262756348, 1.4780241250991821, 1.4779852628707886, 1.477902889251709, 1.477889060974121, 1.4778763055801392, 1.4778242111206055, 1.4777406454086304, 1.4778199195861816, 1.4776843786239624, 1.4776735305786133, 1.4775645732879639, 1.4774341583251953, 1.477204442024231, 1.4771758317947388, 1.4771580696105957, 1.4771595001220703, 1.477146863937378, 1.4771167039871216, 1.4770668745040894, 9.197372436523438, 4.279295921325684, 7.06866979598999, 4.2594804763793945, 6.248434543609619, 9.100699424743652, 13.885313987731934, 2.791584014892578, 2.7862515449523926, 7.813880443572998, 1.9505146741867065, 14.01685619354248, 8.12555980682373, 5.331969261169434, 13.599600791931152, 13.05137825012207, 2.7861177921295166, 8.56856918334961, 7.041530132293701, 8.119402885437012, 11.14972972869873, 5.5114827156066895, 6.148421764373779, 4.865578651428223, 3.5620367527008057, 11.79527473449707, 7.590537071228027, 5.919280052185059, 5.163461208343506, 7.118130207061768, 19.14087677001953, 13.302407264709473, 12.645978927612305, 8.568259239196777, 6.503974914550781, 6.972365379333496, 8.476207733154297, 9.841919898986816, 8.571173667907715, 8.4234037399292, 8.376047134399414, 7.465128421783447, 7.646348476409912, 7.130981922149658, 4.1282548904418945, 3.4342284202575684, 2.1302967071533203, 2.129723072052002, 2.1294755935668945, 2.1288352012634277, 2.1243896484375, 2.123894214630127, 2.100898027420044, 2.100417375564575, 2.0946338176727295, 3.0568084716796875, 3.508406400680542, 1.9823466539382935, 1.4395320415496826, 1.4389474391937256, 1.4389231204986572, 1.4388643503189087, 1.438833475112915, 1.438815712928772, 1.4388889074325562, 1.4388734102249146, 1.438836693763733, 1.4388275146484375, 1.438753366470337, 1.438785433769226, 1.4387930631637573, 1.4387621879577637, 1.4386686086654663, 1.4384535551071167, 1.4384535551071167, 6.883930206298828, 7.663504600524902, 2.81925630569458, 2.760669469833374, 3.178539514541626, 5.513092994689941, 10.64488410949707, 6.673715114593506, 2.1289916038513184, 4.169814586639404, 2.1292502880096436, 5.440393924713135, 3.5099434852600098, 2.6544227600097656, 2.82033634185791, 6.411434173583984, 4.240303993225098, 3.457698106765747, 7.448647499084473, 5.436502456665039, 8.299678802490234, 4.1715898513793945, 5.775015830993652, 4.036486625671387, 20.413311004638672, 10.575703620910645, 4.077965259552002, 6.590394020080566, 5.454956531524658, 20.953083038330078, 5.80352783203125, 21.19856834411621, 5.890835285186768, 4.538732051849365, 8.27051830291748, 4.661770343780518, 5.112536430358887, 7.425573825836182, 6.767252445220947, 6.438380241394043, 7.892585277557373, 5.992574214935303, 6.65118408203125, 6.8256611824035645, 5.285556316375732, 5.24293327331543, 5.222798824310303, 2.7037227153778076, 2.702518939971924, 2.6986074447631836, 2.0416250228881836, 2.040055274963379, 2.038163661956787, 2.0352513790130615, 2.018249988555908, 3.4714300632476807, 2.531651258468628, 1.993878960609436, 1.3810365200042725, 1.3810365200042725, 1.3810365200042725, 1.3810359239578247, 1.3810356855392456, 1.3810356855392456, 1.3805058002471924, 1.380286455154419, 1.3802906274795532, 1.3802909851074219, 1.3802847862243652, 1.380279302597046, 1.380284070968628, 1.3802521228790283, 1.3802478313446045, 1.3802027702331543, 1.3802481889724731, 1.3802467584609985, 1.3802454471588135, 2.6924946308135986, 2.042245864868164, 2.0394415855407715, 5.998500823974609, 2.656827688217163, 4.991682529449463, 2.0437607765197754, 2.025158405303955, 3.219561815261841, 2.7064027786254883, 1.9321835041046143, 2.0378968715667725, 8.324909210205078, 5.6044206619262695, 2.0215280055999756, 2.354271411895752, 2.0273454189300537, 2.7046661376953125, 2.5406641960144043, 3.7902166843414307, 9.699320793151855, 6.284327983856201, 9.062895774841309, 4.656028747558594, 8.457371711730957, 7.524779319763184, 10.428245544433594, 14.626160621643066, 9.280919075012207, 4.776172161102295, 5.789608001708984, 6.543205738067627, 9.108634948730469, 7.692007541656494, 7.444124698638916, 12.569747924804688, 5.174783229827881, 5.031933784484863, 7.397822856903076, 6.560801029205322, 7.889599800109863, 7.53072452545166, 3.8308355808258057, 5.756981372833252, 4.474874019622803, 5.879286289215088, 5.6925129890441895, 4.512217044830322, 4.692786693572998, 6.473203182220459, 3.9273598194122314, 3.282905101776123, 3.282818555831909, 3.28275728225708, 2.6376194953918457, 2.63761568069458, 5.213957786560059, 1.9915835857391357, 3.923379898071289, 1.9912621974945068, 1.9910415410995483, 1.9904909133911133, 1.9888439178466797, 1.9881415367126465, 1.9883095026016235, 1.9852830171585083, 1.984627366065979, 1.983641505241394, 1.981576919555664, 1.978356122970581, 5.201085090637207, 2.430793285369873, 3.283576488494873, 5.109017848968506, 1.3462152481079102, 1.3462151288986206, 1.3462151288986206, 1.3462151288986206, 1.3462151288986206, 1.3462151288986206, 5.138972759246826, 1.3462151288986206, 5.201907157897949, 2.519059419631958, 2.5889570713043213, 3.777900457382202, 4.4897379875183105, 6.292661666870117, 3.2343087196350098, 3.2614922523498535, 3.2310867309570312, 3.8822991847991943, 2.6366946697235107, 10.936995506286621, 4.053652286529541, 6.088794231414795, 3.909421920776367, 3.102221965789795, 7.13611364364624, 3.8911983966827393, 3.6714327335357666, 3.1529464721679688, 5.650315284729004, 12.631896018981934, 13.8008394241333, 4.731760501861572, 4.989634037017822, 7.370051860809326, 5.138367176055908, 7.165145397186279, 6.673936367034912, 7.722767353057861, 6.594226360321045, 5.067425727844238, 5.669677257537842, 5.4963507652282715, 6.421031951904297, 6.589350700378418, 5.347043514251709, 4.885778903961182, 4.949183940887451, 10.40201473236084, 15.217608451843262, 3.0619313716888428, 1.9871461391448975, 1.9852845668792725, 1.9642820358276367, 11.576006889343262, 1.896756887435913, 5.658726692199707, 1.3427680730819702, 1.3427683115005493, 1.3427683115005493, 1.3427680730819702, 1.3427680730819702, 1.3427635431289673, 1.3423161506652832, 1.3420729637145996, 1.3420615196228027, 1.3420183658599854, 1.3420289754867554, 1.342014193534851, 1.3419839143753052, 1.3419570922851562, 1.3419686555862427, 1.341956615447998, 1.341761827468872, 1.3417611122131348, 1.3415815830230713, 1.3415724039077759, 1.3412450551986694, 14.764854431152344, 15.198044776916504, 40.60867691040039, 11.46694564819336, 1.7445228099822998, 4.321139335632324, 1.985021710395813, 3.1008129119873047, 11.902295112609863, 3.4007673263549805, 3.493783473968506, 3.7264840602874756, 2.6889662742614746, 1.961683988571167, 2.48779559135437, 1.941203236579895, 3.9112141132354736, 15.235597610473633, 2.5561301708221436, 2.5188345909118652, 1.986018419265747, 10.816319465637207, 11.414258003234863, 7.9879655838012695, 5.593968868255615, 10.353340148925781, 5.752874851226807, 15.485638618469238, 5.537333965301514, 4.612993240356445, 5.403157711029053, 10.150372505187988, 4.740997314453125, 4.070770263671875, 11.016294479370117, 7.27790641784668, 7.350163459777832, 6.2212724685668945, 6.523344993591309, 5.955002784729004, 4.922416687011719, 4.765884876251221, 4.964687347412109, 4.994925498962402], \"Term\": [\"sas\", \"pandas\", \"javascript\", \"hive\", \"html\", \"css\", \"numpy\", \"scikit\", \"pig\", \"r\", \"python\", \"excel\", \"matlab\", \"java\", \"php\", \"hbase\", \"matplotlib\", \"spark\", \"powerpoint\", \"sqoop\", \"c\", \"scipy\", \"spss\", \"learn\", \"xml\", \"regression\", \"jquery\", \"hadoop\", \"svm\", \"clustering\", \"ampl\", \"eviews\", \"proficientin_r\", \"gurobi\", \"arena\", \"lingo\", \"@risk\", \"gams\", \"gauss\", \"bloomberg\", \"winbugs\", \"simio\", \"pspice\", \"vensim\", \"probit\", \"cfa\", \"cplex\", \"lindo\", \"stata\", \"microsoft_word\", \"minitab\", \"iml\", \"solver\", \"lessthan1year\", \"anylogic\", \"emblem\", \"andexcel\", \"nvivo\", \"structured\", \"candc++\", \"powerpoint\", \"outlook\", \"jmp\", \"stat\", \"word\", \"base\", \"vba\", \"plus\", \"excel\", \"spss\", \"sas\", \"access\", \"computer\", \"maple\", \"spss_modeler\", \"matlab\", \"latex\", \"r\", \"mathematica\", \"sql\", \"python\", \"tableau\", \"c++\", \"msoffice\", \"sap\", \"c\", \"technical\", \"java\", \"skills\", \"visio\", \"programming\", \"linux\", \"hadoop\", \"mysql\", \"unix\", \"windows\", \"data\", \"ms\", \"html\", \"spark\", \"boosting\", \"na\\u00efve_bayes\", \"statsmodels\", \"classification\", \"knn\", \"scrapy\", \"pytorch\", \"cnn\", \"scikit-\", \"rnn\", \"bagging\", \"matplotlib\", \"python2.x/3.x\", \"tree\", \"networkx\", \"neural_network\", \"lda\", \"ggplot\", \"nn\", \"seaborn\", \"spark2.x\", \"svd\", \"nltk\", \"hierarchical\", \"tableau8.0\", \"word2vec\", \"matplotib\", \"mongodb3.x\", \"pca\", \"hypothesis\", \"scikit\", \"learn\", \"adaboost\", \"regression\", \"k\", \"random_forest\", \"decision_tree\", \"numpy\", \"pandas\", \"keras\", \"svm\", \"scipy\", \"clustering\", \"machine\", \"logistic\", \"naive_bayes\", \"xgboost\", \"tensorflow\", \"theano\", \"linear\", \"statistical\", \"nlp\", \"data\", \"python\", \"r\", \"a\", \"spark\", \"sql\", \"hadoop\", \"technical\", \"tableau\", \"aws\", \"mysql\", \"matlab\", \"hive\", \"sas\", \"java\", \"programming\", \"c++\", \"ambari\", \"orazuredata\", \"erwinr9.6\", \"cognos7.0/6.0\", \"6.x\", \"parquet\", \"rcurl\", \"reshape2\", \"flume\", \"databasessql\", \"powerpoint/\", \"rpy2\", \"vpc\", \"presto\", \"macintosh_hd\", \"nifi\", \"sqoop\", \"spark_sql\", \"tez\", \"no_sql\", \"zookeeper\", \"bigdata_tools\", \"apache_kafka\", \"cloudera_cdh\", \"cognosbi_10\", \"kinesis\", \"yarn\", \"mesos\", \"scala_nlp\", \"kafka\", \"oozie\", \"hue\", \"hbase\", \"impala\", \"etl_tools\", \"mapr\", \"cassandra\", \"pig\", \"dynamodb\", \"obiee\", \"mahout\", \"hive\", \"hdfs\", \"map_reduce\", \"er\", \"jad\", \"scala\", \"s3\", \"ec2\", \"cloudera\", \"redshift\", \"emr\", \"mapreduce\", \"ssis\", \"hadoop\", \"bigdata\", \"spark\", \"ssas\", \"nosql\", \"ssrs\", \"oracle\", \"etl\", \"erwin\", \"mongodb\", \"tableau\", \"technical\", \"python\", \"sql\", \"java\", \"r\", \"linux\", \"unix\", \"aws\", \"windows\", \"c\", \"mysql\", \"c++\", \"programming\", \"lamp\", \"rails\", \"notepad++\", \"swift\", \"react.js\", \"web_api\", \"sass\", \"infragistics\", \"react\", \"net_2015\", \"teleriktoolkit\", \"jaspersoft\", \"android_studio\", \"firebase\", \"actionscript\", \"nunit\", \"rspec\", \"express.js\", \"databasetools\", \"redux\", \"angular_js\", \"singleton\", \"agile(scrum\", \"gulp\", \"flex\", \"oauth\", \"wpf\", \"coldfusion\", \"wcf\", \"intellijidea\", \"jquery\", \"linq\", \"css\", \"php\", \"django\", \"ajax\", \"objective\", \"bootstrap\", \"angularjs\", \"javascript\", \"android\", \"html\", \"node.js\", \"rubyon_rails\", \"eclipse\", \"html5\", \"css3\", \"rest\", \"xml\", \"vb.net\", \"json\", \"c\", \"ruby\", \"visual_studio\", \"java\", \"c++\", \"mysql\", \"netbeans\", \"git\", \"jsp\", \"python\", \"svn\", \"perl\", \"linux\", \"sql\", \"technical\", \"windows\", \"programming\", \"r\", \"matlab\", \"mongodb\", \"oracle\", \"unix\", \"hadoop\", \"jaxb\", \"awt\", \"rmi\", \"build_tools\", \"jndi\", \"jbuilder\", \"applets\", \"ibatis\", \"jms\", \"portal\", \"ibm_mq\", \"jboss\", \"log4j\", \"be\", \"msmq\", \"weblogic\", \"dataflux\", \"sax\", \"eclipse3.x\", \"udb\", \"bpmn\", \"jstl\", \"sas_bi\", \"onlinecourses\", \"scripting_r\", \"adjustedr\", \"web_servers\", \"initiative\", \"debugging\", \"ttest\", \"rootcause\", \"brd\", \"java_beans\", \"jni\", \"struts\", \"jsf\", \"ant\", \"middleware\", \"tso\", \"websphere\", \"cvs\", \"ejb\", \"dns\", \"soap_ui\", \"uml\", \"soap\", \"hibernate\", \"http\", \"wsdl\", \"waterfall\", \"servlets\", \"methodologies\", \"j2ee\", \"dhcp\", \"spring\", \"application\", \"sybase\", \"jdbc\", \"maven\", \"jsp\", \"agile\", \"scrum\", \"oracle\", \"tcp\", \"pl\", \"db2\", \"project\", \"xml\", \"ms\", \"windows\", \"html\", \"sql\", \"technical\", \"unix\", \"java\", \"javascript\", \"linux\", \"eclipse\", \"c\", \"c++\", \"python2.7/3.3\", \"mssuite2012\", \"spark2.0\", \"tableau_8\", \"hive2.8\", \"tmux\", \"scala2.10\", \"my\", \"-9.2\", \"keel\", \"softmax\", \"databaseand\", \"movingaverages\", \"autoregression\", \"jama\", \"\\u2663\", \"electronic\", \"vbasic\", \"nativemandarin\", \"clintrial4.0\", \"grt\", \"medra\", \"whodra\", \"phosco\", \"servlet2.0\", \"cucumber_api\", \"gatling_tool\", \"spring4.0\", \"testingtool\", \"jsp2.0\", \"hadoop2\", \"windows7/8/10\", \"c#.\", \"sas9\", \"tealeaf\", \"javaand\", \"July\", \"dell\", \"arm\", \"riskmanagement\", \"vista\", \"hpquality\", \"meditech\", \"data_cleaning\", \"xp\", \"confluence\", \"co\", \"trello\", \"ms\", \"jira\", \"technical\", \"epic\", \"java\", \"areasof\", \"slack\", \"dec\", \"vi\", \"data\", \"windows\", \"academic\", \"c\", \"python\", \"oracle\", \"modeling\", \"sql\", \"ssrs\", \"pl\", \"linux\", \"c++\", \"r\", \"business\", \"t\", \"html\", \"javascript\", \"mysql\", \"css\", \"ssis\", \"cloud\", \"project\", \"tableau\", \"matlab\", \"hplc\", \"excelandword\", \"tika\", \"ontology\", \"pune\", \"teradata_12\", \"dde\", \"appliedmachine\", \"organizations\", \"msoffice2013\", \"linearandnon\", \"mexico\", \"modflow\", \"e.g.\", \"cm_synergy\", \"sqlandexcel\", \"learnetc\", \"softwarer\", \"trimble\", \"sigmastat\", \"yii2\", \"googleanalytic\", \"geocoding\", \"stylus\", \"erwin9.x\", \"automatic\", \"liwc\", \"esr\", \"tumblr\", \"photovoltaics\", \"community\", \"gc\", \"writing\", \"volunteer\", \"hadoopmap\", \"top1\", \"userexperience\", \"survey\", \"ensembles\", \"lm\", \"undergraduate\", \"message\", \"nmr\", \"ncss\", \"certificate\", \"December\", \"retention\", \"eit\", \"vice\", \"graphic\", \"management\", \"international\", \"ms_outlook\", \"june\", \"self\", \"tx\", \"seattle\", \"data\", \"other\", \"professional\", \"analyst\", \"analytical\", \"ms_excel\", \"montecarlo\", \"computer\", \"skills\", \"english\", \"excel\", \"sql\", \"windows\", \"technical\", \"matlab\", \"r\", \"powerpoint\", \"spss\", \"ms\", \"project\", \"python\", \"c++\", \"agile\", \"programming\", \"areasof\", \"core\", \"c\", \"perl\", \"linux\", \"tableau\", \"sas\", \"toolkit\", \"jobvite\", \"virtual_edge\", \"istqb\", \"basesas9.2\", \"pentaho_kettle\", \"jobdiva\", \"social_media\", \"theoretical\", \"liu\", \"g.\", \"competencies\", \"superputty\", \"taubetapi\", \"ibmutilities\", \"ndm\", \"vsamand\", \"hu\", \"pgadminiii\", \"emf\", \"filehandling\", \"transfer\", \"multimedia\", \"scrum_masters\", \"connectivity\", \"sfdcadmin\", \"sapfico\", \"redmatch\", \"pega_csa\", \"data_engineer\", \"n.\", \"la\", \"l.\", \"z.\", \"greenhouse\", \"p.\", \"s.\", \"may2017\", \"sdet\", \"y.\", \"hardworking\", \"d.\", \"dice\", \"aug2016\", \"m.\", \"j.\", \"hospitality\", \"b.\", \"e.\", \"ats\", \"taleo\", \"w.\", \"a.\", \"k.\", \"x.\", \"r.\", \"c.\", \"qualifications\", \"h.\", \"facebook\", \"core\", \"skill\", \"software\", \"key\", \"engineering\", \"may\", \"professional\", \"project\", \"computer\", \"linux\", \"c++\", \"excel\", \"sql\", \"c\", \"scorecards\", \"dataquality\", \"google_earth\", \"ssis_2008\", \"negotiation\", \"sarkar\", \"bottom\", \"sccp\", \"inclusion\", \"pdw\", \"python_2\", \"erecruit\", \"d.c.\", \"september2015\", \"rollout\", \"jobviteand\", \"itrecruitment\", \"sustainingedge\", \"linuxserver\", \"recruit\", \"ssmsexport\", \"bo6\", \"ssrs_2008\", \"ssis_2012\", \"isup\", \"andunix\", \"otherused\", \"ssis_2005\", \"huecloudera\", \"dataprofiling\", \"3.1.15\", \"icims\", \"bullhorn\", \"csh\", \"python_3\", \"diversity\", \"brassring\", \"taleo\", \"october\", \"pic\", \"washington\", \"honorsand\", \"adp\", \"executive\", \"resumix\", \"cyber\", \"november\", \"workday\", \"kerberos\", \"linkedin\", \"highlightsof\", \"powershell\", \"bo\", \"mobile\", \"kpi\", \"skills\", \"salesforce\", \"us\", \"peoplesoft\", \"c.\", \"unix\", \"program\", \"technical\", \"hp\", \"april\", \"project\", \"j.\", \"ux\", \"software\", \"business\", \"core\", \"linux\", \"sharepoint\", \"powerpoint\", \"data\", \"google\", \"development\", \"sql\", \"ubuntuand\", \"magento\", \"oracle_rdbms\", \"public_health\", \"spatialdata\", \"hebrew\", \"lucid\", \"copy\", \"campaign\", \"linearalgebra\", \"transaction\", \"initiates\", \"factor_models\", \"greeks\", \"decisionspace\", \"swahili\", \"hfds\", \"netezzaand\", \"human_services\", \"nurses\", \"snome\", \"obe\", \"icd10\", \"clinical_and\", \"healthcare_it\", \"hl7message\", \"seg\", \"databaseadmin\", \"icd9toicd10\", \"bigdataskill\", \"advertising\", \"swot_analysis\", \"sas_enterprise\", \"envi\", \"idrisi\", \"spoken\", \"rxnorm\", \"b2c\", \"\\u25c6\", \"loinc\", \"ithaca\", \"ppc\", \"team\", \"qa\", \"scholes\", \"consumer\", \"ebay\", \"fast\", \"cybersecurity\", \"president\", \"analytics\", \"advanced\", \"analysis\", \"hands\", \"areasof\", \"key\", \"project\", \"data\", \"core\", \"qgis\", \"e\", \"research\", \"computer\", \"software\", \"microsoft\", \"c++\", \"arcgis\", \"professional\", \"html\", \"windows\", \"r\", \"sql\", \"selected\", \"linux\", \"sharepoint\", \"technical\", \"c\", \"t\", \"oracle\", \"ddl\", \"ggplot2and\", \"modeltuning/\", \"filter_methods\", \"gridsearchand\", \"subqueries\", \"edain\", \"pigand\", \"thingworx\", \"hiv\", \"proc_print\", \"rheumatology\", \"greenbeltsix\", \"unix_script\", \"teradataand\", \"eeo\", \"therapeutic\", \"neurology\", \"depression\", \"erwindata\", \"inv\", \"dml\", \"po\", \"ctms\", \"stepwise\", \"h&r\", \"cfra\", \"hrtools\", \"hr_operations\", \"googlesuite\", \"boarding\", \"oncology\", \"i-9_compliance\", \"univariate\", \"respiratory\", \"prototyping\", \"rave\", \"aic\", \"inform\", \"square_tests\", \"scraping\", \"t_test\", \"interpersonal\", \"korn\", \"key\", \"logit\", \"ridge\", \"tf\", \"ap\", \"means\", \"idf\", \"documentum\", \"statistics/\", \"multi\", \"technical\", \"sql\", \"datascientist\", \"macros\", \"k\", \"g\", \"access\", \"teradata\", \"oracle\", \"sql_server\", \"management\", \"core\", \"a\", \"data\", \"excel\", \"ms\", \"linear\", \"databases\", \"chinese\", \"indesign\", \"hootsuite\", \"testing/\", \"mcsa\", \"russian\", \"native\", \"green\", \"cantonese\", \"columbia\", \"rollout/\", \"migrations\", \"pyramid\", \"istrategy\", \"arc\", \"andreal\", \"exceldata\", \"zohooffice\", \"knowledgeloinc\", \"icpc\", \"irdb(in\", \"atlassiancloud\", \"businesslaw\", \"memory.net\", \"useraccess\", \"persuasive\", \"processdesign\", \"taq\", \"etltool\", \"hodes_iq\", \"spanish\", \"mandarin\", \"english\", \"french\", \"side\", \"human\", \"tibcospotfire\", \"interests\", \"illustrator\", \"arabic\", \"organizational\", \"computerskills\", \"interviewing\", \"leansixsigma\", \"pythonandr\", \"googledocs\", \"teambuilding\", \"research\", \"japanese\", \"andspss\", \"educational\", \"photoshop\", \"relevant\", \"leadership\", \"strategic\", \"business\", \"academic\", \"data\", \"crm\", \"functional\", \"cross\", \"skills\", \"intermediate\", \"quickbooks\", \"excel\", \"project\", \"powerpoint\", \"microsoft\", \"word\", \"software\", \"dataanalysis\", \"ibm\", \"visio\", \"access\"], \"Total\": [1530.0, 701.0, 1020.0, 1058.0, 1114.0, 656.0, 567.0, 458.0, 646.0, 3289.0, 3500.0, 1092.0, 1462.0, 1851.0, 396.0, 357.0, 300.0, 954.0, 515.0, 286.0, 1582.0, 359.0, 684.0, 302.0, 513.0, 337.0, 257.0, 1346.0, 369.0, 357.0, 31.5947265625, 38.694828033447266, 43.13845443725586, 18.94306182861328, 31.455963134765625, 13.475885391235352, 10.757574081420898, 29.46673011779785, 10.762781143188477, 49.81864929199219, 16.026777267456055, 8.865362167358398, 9.860384941101074, 6.224575519561768, 6.224318504333496, 6.223812103271484, 53.595252990722656, 14.39263916015625, 277.3182678222656, 38.590721130371094, 206.1513671875, 24.627676010131836, 16.221582412719727, 5.31574010848999, 5.315119743347168, 5.31164026260376, 13.924320220947266, 5.307395935058594, 5.301214694976807, 6.18171501159668, 515.41943359375, 130.87225341796875, 169.3251495361328, 78.13619232177734, 477.40118408203125, 66.23220825195312, 360.3643493652344, 28.19959831237793, 1092.3843994140625, 684.115234375, 1530.01220703125, 418.7623291015625, 438.4506530761719, 53.730140686035156, 42.26238250732422, 1462.3885498046875, 185.2094268798828, 3289.197021484375, 136.33811950683594, 3209.36865234375, 3500.403076171875, 1596.42236328125, 1672.2535400390625, 152.98040771484375, 113.14678955078125, 1582.216064453125, 1821.3455810546875, 1851.887939453125, 410.2186584472656, 258.1858825683594, 844.4890747070312, 1056.8343505859375, 1346.6116943359375, 1187.620361328125, 744.1380004882812, 685.0565795898438, 742.0325317382812, 415.4355163574219, 1114.404296875, 954.747802734375, 71.52459716796875, 122.82825469970703, 34.80636978149414, 258.2970886230469, 153.69326782226562, 29.28945541381836, 29.244239807128906, 64.19774627685547, 30.14676856994629, 46.565773010253906, 41.029300689697266, 300.6264343261719, 16.41646385192871, 18.254371643066406, 21.92099952697754, 27.420671463012695, 79.42274475097656, 14.575638771057129, 49.03819274902344, 136.79595947265625, 12.735865592956543, 26.525251388549805, 225.73712158203125, 29.031047821044922, 11.814921379089355, 19.115678787231445, 11.793904304504395, 10.895647048950195, 237.81085205078125, 19.058555603027344, 458.1841735839844, 302.69732666015625, 30.738290786743164, 337.1165466308594, 320.5987548828125, 71.4568099975586, 63.743927001953125, 567.1653442382812, 701.197998046875, 251.25645446777344, 369.97662353515625, 359.6163330078125, 357.3338623046875, 289.1019592285156, 74.42462921142578, 75.02316284179688, 62.321128845214844, 392.8952331542969, 85.50006866455078, 141.1452178955078, 456.1147766113281, 246.59222412109375, 742.0325317382812, 3500.403076171875, 3289.197021484375, 202.5591583251953, 954.747802734375, 3209.36865234375, 1346.6116943359375, 1821.3455810546875, 1596.42236328125, 559.1994018554688, 1187.620361328125, 1462.3885498046875, 1058.2452392578125, 1530.01220703125, 1851.887939453125, 844.4890747070312, 1672.2535400390625, 31.426603317260742, 22.1575927734375, 22.15825843811035, 17.50868034362793, 15.649336814880371, 13.785856246948242, 14.717570304870605, 12.860424041748047, 175.9814910888672, 11.930980682373047, 23.79535484313965, 11.921928405761719, 16.548730850219727, 11.00023078918457, 28.28261375427246, 14.697673797607422, 286.2447204589844, 23.000246047973633, 10.991207122802734, 9.141538619995117, 85.73163604736328, 10.05465316772461, 22.856687545776367, 8.211867332458496, 8.211590766906738, 13.743274688720703, 68.30510711669922, 8.209101676940918, 9.140604972839355, 170.74136352539062, 132.72279357910156, 39.179019927978516, 357.4888916015625, 124.10582733154297, 35.577335357666016, 21.116531372070312, 234.1744384765625, 646.433837890625, 38.615970611572266, 82.3162612915039, 83.54448699951172, 1058.2452392578125, 390.2633056640625, 62.82905960083008, 48.47065734863281, 41.7299919128418, 407.5452880859375, 140.09107971191406, 135.80384826660156, 77.58102416992188, 99.03956604003906, 78.13423919677734, 478.6766357421875, 261.20977783203125, 1346.6116943359375, 331.9485168457031, 954.747802734375, 129.7483367919922, 324.5588684082031, 234.52099609375, 826.1654663085938, 289.39215087890625, 107.4315185546875, 538.1947631835938, 1596.42236328125, 1821.3455810546875, 3500.403076171875, 3209.36865234375, 1851.887939453125, 3289.197021484375, 1056.8343505859375, 744.1380004882812, 559.1994018554688, 685.0565795898438, 1582.216064453125, 1187.620361328125, 1672.2535400390625, 844.4890747070312, 18.227115631103516, 12.722156524658203, 12.714709281921387, 33.60314178466797, 10.87608528137207, 9.965282440185547, 14.455013275146484, 9.947827339172363, 35.4543342590332, 8.126932144165039, 8.126872062683105, 8.12503719329834, 26.230876922607422, 8.122971534729004, 8.124625205993652, 9.046747207641602, 8.992566108703613, 7.2036848068237305, 7.201605796813965, 7.199774742126465, 20.870460510253906, 8.07464599609375, 6.2886505126953125, 6.286814212799072, 6.289228439331055, 6.280802249908447, 21.299699783325195, 15.087514877319336, 29.510759353637695, 5.370070934295654, 257.4154357910156, 29.49658203125, 656.7999877929688, 396.09967041015625, 107.36923217773438, 153.83462524414062, 35.7332649230957, 112.27288055419922, 42.52467727661133, 1020.90771484375, 80.90615844726562, 1114.404296875, 79.45745086669922, 22.723674774169922, 383.0337219238281, 197.2415771484375, 78.46573638916016, 77.37333679199219, 513.5374755859375, 53.161346435546875, 178.42788696289062, 1582.216064453125, 118.41458892822266, 137.0260009765625, 1851.887939453125, 1672.2535400390625, 1187.620361328125, 90.79267883300781, 604.0803833007812, 169.7722930908203, 3500.403076171875, 134.1363983154297, 324.7256774902344, 1056.8343505859375, 3209.36865234375, 1821.3455810546875, 685.0565795898438, 844.4890747070312, 3289.197021484375, 1462.3885498046875, 538.1947631835938, 826.1654663085938, 744.1380004882812, 1346.6116943359375, 11.81847095489502, 11.827493667602539, 18.464954376220703, 7.5724639892578125, 16.136959075927734, 6.720961570739746, 6.718011856079102, 6.724082946777344, 35.8724479675293, 6.725854396820068, 5.869205474853516, 37.62958908081055, 5.020439624786377, 5.0203633308410645, 5.020137786865234, 37.800331115722656, 6.741494178771973, 5.01158332824707, 5.010654926300049, 6.733394622802734, 9.11504077911377, 8.230809211730957, 4.171448230743408, 4.171453475952148, 4.171517372131348, 4.171518802642822, 4.171198844909668, 4.171236991882324, 4.171926021575928, 4.171937942504883, 6.757180213928223, 5.89286994934082, 9.086491584777832, 5.032155990600586, 47.36756134033203, 28.378311157226562, 49.74369430541992, 11.701964378356934, 18.7633056640625, 31.379789352416992, 58.0802116394043, 35.59130859375, 21.714200973510742, 9.385090827941895, 110.47737884521484, 92.70796966552734, 78.82988739013672, 39.700836181640625, 38.383358001708984, 65.37655639648438, 71.30307006835938, 27.668926239013672, 108.611328125, 15.33154010772705, 107.5580825805664, 62.07744598388672, 85.70667266845703, 92.47727966308594, 90.11470031738281, 169.7722930908203, 216.1090850830078, 118.79214477539062, 826.1654663085938, 66.37284088134766, 365.40191650390625, 231.86737060546875, 277.8829650878906, 513.5374755859375, 415.4355163574219, 685.0565795898438, 1114.404296875, 3209.36865234375, 1821.3455810546875, 744.1380004882812, 1851.887939453125, 1020.90771484375, 1056.8343505859375, 383.0337219238281, 1582.216064453125, 1672.2535400390625, 7.1456217765808105, 7.1457109451293945, 7.145859241485596, 3.6060268878936768, 3.6059181690216064, 3.606248140335083, 2.8978114128112793, 2.8978841304779053, 2.897801637649536, 2.898221254348755, 2.898376941680908, 6.659233570098877, 2.8970611095428467, 2.8969192504882812, 2.9007983207702637, 2.9073281288146973, 4.2498297691345215, 2.189920425415039, 2.189920663833618, 2.189920425415039, 2.189920425415039, 2.189920425415039, 2.189920425415039, 2.189920425415039, 2.1899209022521973, 2.1899209022521973, 2.1899209022521973, 2.1899209022521973, 2.1899209022521973, 2.1899209022521973, 9.870797157287598, 11.794167518615723, 5.327782154083252, 4.952193737030029, 3.542631149291992, 9.490925788879395, 5.1050705909729, 3.5999441146850586, 7.0953168869018555, 5.200495719909668, 50.954734802246094, 5.644831657409668, 4.450994491577148, 7.1623148918151855, 68.83570098876953, 52.17832565307617, 53.081703186035156, 24.57263946533203, 415.4355163574219, 252.75729370117188, 1821.3455810546875, 13.974261283874512, 1851.887939453125, 138.45314025878906, 18.648893356323242, 32.3663444519043, 15.708040237426758, 742.0325317382812, 685.0565795898438, 48.906429290771484, 1582.216064453125, 3500.403076171875, 826.1654663085938, 74.39781951904297, 3209.36865234375, 234.52099609375, 365.40191650390625, 1056.8343505859375, 1672.2535400390625, 3289.197021484375, 181.07815551757812, 189.1283416748047, 1114.404296875, 1020.90771484375, 1187.620361328125, 656.7999877929688, 261.20977783203125, 139.0106658935547, 277.8829650878906, 1596.42236328125, 1462.3885498046875, 12.014966011047363, 2.879004955291748, 2.87900972366333, 2.879077911376953, 2.879021406173706, 2.8794264793395996, 2.884215831756592, 2.8875362873077393, 2.893383502960205, 2.900301694869995, 4.998049259185791, 5.205816745758057, 2.1774072647094727, 2.17740797996521, 2.177407741546631, 2.17740797996521, 2.177408456802368, 2.1774086952209473, 2.177407741546631, 2.1773972511291504, 2.1773970127105713, 2.177448034286499, 2.177391529083252, 2.177466869354248, 2.1774754524230957, 2.17741060256958, 2.1775217056274414, 2.177522897720337, 2.1775245666503906, 2.1775424480438232, 11.38525676727295, 8.455806732177734, 6.362804889678955, 21.682626724243164, 4.9992499351501465, 3.5699808597564697, 5.768241882324219, 8.318045616149902, 4.920231342315674, 5.163205146789551, 3.5903072357177734, 5.1467766761779785, 7.409637451171875, 2.9669902324676514, 10.492362976074219, 9.849830627441406, 3.5614254474639893, 3.728327989578247, 5.421478748321533, 5.767642974853516, 73.89734649658203, 12.870959281921387, 13.136377334594727, 25.221771240234375, 45.201778411865234, 16.918045043945312, 11.894004821777344, 742.0325317382812, 32.227054595947266, 125.44258117675781, 7.733672618865967, 89.68624114990234, 183.28965759277344, 19.521137237548828, 438.4506530761719, 410.2186584472656, 79.75303649902344, 1092.3843994140625, 3209.36865234375, 685.0565795898438, 1821.3455810546875, 1462.3885498046875, 3289.197021484375, 515.41943359375, 684.115234375, 415.4355163574219, 277.8829650878906, 3500.403076171875, 1672.2535400390625, 216.1090850830078, 844.4890747070312, 138.45314025878906, 220.93666076660156, 1582.216064453125, 324.7256774902344, 1056.8343505859375, 1596.42236328125, 1530.01220703125, 3.6161389350891113, 18.264001846313477, 2.902897834777832, 2.9030258655548096, 2.9031567573547363, 2.90311861038208, 2.914247512817383, 3.680274486541748, 2.924163341522217, 5.015333652496338, 12.39601993560791, 2.193347692489624, 2.1933627128601074, 2.1933817863464355, 2.1933915615081787, 2.1933963298797607, 2.193410634994507, 2.1932923793792725, 2.193413496017456, 2.19326114654541, 2.19331955909729, 2.1933817863464355, 2.193380832672119, 2.193392753601074, 2.193411111831665, 2.1934142112731934, 2.1934216022491455, 2.1934149265289307, 2.1934118270874023, 2.1934092044830322, 13.66380500793457, 6.387441635131836, 10.637706756591797, 6.4241790771484375, 9.796239852905273, 14.74683666229248, 23.63367462158203, 4.319441795349121, 4.337619781494141, 13.334793090820312, 2.961508274078369, 25.84025001525879, 14.85071086883545, 9.40186882019043, 27.25214385986328, 26.031017303466797, 4.565873146057129, 16.918283462524414, 14.209213256835938, 17.037105560302734, 25.841510772705078, 10.726441383361816, 13.305097579956055, 10.54345989227295, 6.408194541931152, 46.93086242675781, 24.71192169189453, 16.391332626342773, 12.948009490966797, 25.345619201660156, 220.93666076660156, 155.4918670654297, 275.9976806640625, 111.91879272460938, 35.76685333251953, 49.74595260620117, 125.44258117675781, 277.8829650878906, 438.4506530761719, 1056.8343505859375, 1672.2535400390625, 1092.3843994140625, 3209.36865234375, 1582.216064453125, 4.925065517425537, 4.254802703857422, 2.8472042083740234, 2.8473708629608154, 2.8473076820373535, 2.847417116165161, 2.847663402557373, 2.8491125106811523, 2.855158805847168, 2.8572347164154053, 2.8554494380950928, 4.204362392425537, 4.939348220825195, 2.896186351776123, 2.1561620235443115, 2.1561710834503174, 2.1561715602874756, 2.156172513961792, 2.156179904937744, 2.1561553478240967, 2.1563525199890137, 2.1563613414764404, 2.1563689708709717, 2.15637469291687, 2.1562650203704834, 2.156315803527832, 2.1563825607299805, 2.156393527984619, 2.156426191329956, 2.1561789512634277, 2.1561789512634277, 10.509739875793457, 11.876957893371582, 4.458677291870117, 4.4016523361206055, 5.178924083709717, 10.56342887878418, 25.841510772705078, 14.539094924926758, 3.5105180740356445, 8.348712921142578, 3.5567102432250977, 11.881033897399902, 7.054225921630859, 4.97300910949707, 5.536821365356445, 17.66326904296875, 10.886634826660156, 7.900994300842285, 31.402076721191406, 18.066650390625, 39.780494689941406, 11.53381633758545, 23.952838897705078, 11.435397148132324, 410.2186584472656, 101.46537017822266, 12.452723503112793, 37.73429870605469, 24.71192169189453, 744.1380004882812, 35.52102279663086, 1821.3455810546875, 56.16212844848633, 22.554363250732422, 277.8829650878906, 26.031017303466797, 40.42670822143555, 275.9976806640625, 181.07815551757812, 220.93666076660156, 1056.8343505859375, 152.15484619140625, 515.41943359375, 742.0325317382812, 93.05941772460938, 117.35105895996094, 3209.36865234375, 3.4270052909851074, 3.42620587348938, 3.4284274578094482, 2.763157844543457, 2.7633473873138428, 2.763608694076538, 2.7649521827697754, 2.764906167984009, 4.787045001983643, 3.4924700260162354, 2.7654852867126465, 2.100006341934204, 2.100006580352783, 2.100006580352783, 2.1000068187713623, 2.1000070571899414, 2.1000070571899414, 2.1000375747680664, 2.100149631500244, 2.100156545639038, 2.1001570224761963, 2.1001474857330322, 2.1001429557800293, 2.100170850753784, 2.100132703781128, 2.100146770477295, 2.100088357925415, 2.1001670360565186, 2.100168228149414, 2.1001787185668945, 4.773122787475586, 3.4648003578186035, 3.472384452819824, 14.388785362243652, 5.018938064575195, 13.269964218139648, 3.692674398422241, 3.678131341934204, 7.747130393981934, 6.507162094116211, 3.722487449645996, 4.181573390960693, 54.19255065917969, 29.679096221923828, 4.336343765258789, 5.819177627563477, 4.406174182891846, 8.056282997131348, 7.141763687133789, 16.328838348388672, 129.40773010253906, 53.70193862915039, 152.78140258789062, 30.2525691986084, 138.45314025878906, 111.91879272460938, 277.8829650878906, 742.0325317382812, 220.93666076660156, 40.66326141357422, 72.7369155883789, 110.80926513671875, 438.4506530761719, 275.9976806640625, 249.8988800048828, 1672.2535400390625, 71.51079559326172, 125.44258117675781, 1114.404296875, 685.0565795898438, 3289.197021484375, 3209.36865234375, 41.52927017211914, 1056.8343505859375, 152.15484619140625, 1821.3455810546875, 1582.216064453125, 189.1283416748047, 826.1654663085938, 7.248222351074219, 4.651893138885498, 4.005570888519287, 4.005559921264648, 4.005552291870117, 3.3590617179870605, 3.359065532684326, 6.794921875, 2.713047742843628, 5.344941139221191, 2.712853193283081, 2.712963104248047, 2.7135698795318604, 2.7132341861724854, 2.7132937908172607, 2.714493989944458, 2.7156484127044678, 2.715414524078369, 2.7161433696746826, 2.715378999710083, 2.71828293800354, 7.328693866729736, 3.4494988918304443, 4.713486671447754, 7.638789176940918, 2.066577911376953, 2.066577911376953, 2.066577911376953, 2.066577911376953, 2.066577911376953, 2.066577911376953, 8.05160140991211, 2.066577911376953, 8.3500337600708, 4.070887088775635, 4.299493312835693, 6.964208602905273, 8.77637004852295, 13.929498672485352, 5.86659049987793, 6.122725963592529, 6.78724479675293, 10.121845245361328, 4.741456985473633, 111.91879272460938, 13.690210342407227, 38.60496520996094, 14.112979888916016, 8.281102180480957, 83.1390151977539, 15.446277618408203, 14.205228805541992, 8.658162117004395, 76.9600601196289, 1821.3455810546875, 3209.36865234375, 42.485801696777344, 53.76664733886719, 320.5987548828125, 62.41716766357422, 418.7623291015625, 323.4977111816406, 826.1654663085938, 315.17547607421875, 73.89734649658203, 220.93666076660156, 202.5591583251953, 742.0325317382812, 1092.3843994140625, 415.4355163574219, 141.1452178955078, 210.2220001220703, 13.15536117553711, 19.707500457763672, 4.005030632019043, 2.707862377166748, 2.708308696746826, 2.7087478637695312, 16.13019561767578, 2.7465240955352783, 8.349839210510254, 2.0632686614990234, 2.0632688999176025, 2.0632688999176025, 2.0632688999176025, 2.0632688999176025, 2.0632708072662354, 2.063412666320801, 2.0633676052093506, 2.063387632369995, 2.0633630752563477, 2.0633838176727295, 2.063384532928467, 2.063385009765625, 2.0633885860443115, 2.0634074211120605, 2.063403606414795, 2.0635886192321777, 2.06368088722229, 2.06371808052063, 2.063774585723877, 2.063565492630005, 24.436134338378906, 26.174205780029297, 79.75303649902344, 25.05196762084961, 2.8152575492858887, 8.78730583190918, 3.416527271270752, 6.319602966308594, 40.33219528198242, 7.277735710144043, 7.705173492431641, 9.262946128845215, 5.837400436401367, 3.645425796508789, 5.259302139282227, 3.634740114212036, 11.493258476257324, 110.80926513671875, 5.95020866394043, 6.134675025939941, 4.10853385925293, 86.93038177490234, 105.01798248291016, 71.68832397460938, 41.66197967529297, 181.07815551757812, 48.906429290771484, 742.0325317382812, 48.484012603759766, 30.240779876708984, 48.38634490966797, 410.2186584472656, 40.30580139160156, 25.253145217895508, 1092.3843994140625, 277.8829650878906, 515.41943359375, 249.8988800048828, 477.40118408203125, 275.9976806640625, 87.86210632324219, 75.41571044921875, 258.1858825683594, 418.7623291015625], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5295000076293945, 1.5189000368118286, 1.5151000022888184, 1.5147000551223755, 1.5087000131607056, 1.5023000240325928, 1.485200047492981, 1.4824999570846558, 1.4797999858856201, 1.4704999923706055, 1.468999981880188, 1.444700002670288, 1.4429999589920044, 1.4404000043869019, 1.4392999410629272, 1.4391000270843506, 1.4385000467300415, 1.4377000331878662, 1.4330999851226807, 1.4285999536514282, 1.4283000230789185, 1.4282000064849854, 1.4239000082015991, 1.4176000356674194, 1.4168000221252441, 1.4157999753952026, 1.4147000312805176, 1.4112999439239502, 1.4069000482559204, 1.402400016784668, 1.3911999464035034, 1.389799952507019, 1.3841999769210815, 1.3765000104904175, 1.305299997329712, 1.3634999990463257, 1.2970000505447388, 1.381500005722046, 1.2222000360488892, 1.2443000078201294, 1.1858999729156494, 1.2489999532699585, 1.2066999673843384, 1.3416999578475952, 1.3468999862670898, 1.0176000595092773, 1.1993999481201172, 0.8011000156402588, 1.2043999433517456, 0.7071999907493591, 0.6335999965667725, 0.7232999801635742, 0.6668000221252441, 1.1328999996185303, 1.1791000366210938, 0.3587999939918518, 0.27090001106262207, 0.2605000138282776, 0.7233999967575073, 0.8263999819755554, 0.29019999504089355, 0.11680000275373459, -0.014700000174343586, -0.06430000066757202, 0.17569999396800995, 0.15919999778270721, 0.039500001817941666, 0.4377000033855438, -0.4684000015258789, -0.33820000290870667, 1.5779000520706177, 1.5708999633789062, 1.5694999694824219, 1.5627000331878662, 1.5614999532699585, 1.561400055885315, 1.5592000484466553, 1.558899998664856, 1.5580999851226807, 1.5571000576019287, 1.5562000274658203, 1.5555000305175781, 1.548799991607666, 1.5472999811172485, 1.5464999675750732, 1.5458999872207642, 1.545199990272522, 1.541100025177002, 1.5392999649047852, 1.537500023841858, 1.5361000299453735, 1.5335999727249146, 1.5334999561309814, 1.5327999591827393, 1.5317000150680542, 1.529099941253662, 1.5263999700546265, 1.5262000560760498, 1.5236999988555908, 1.5216000080108643, 1.5153000354766846, 1.5045000314712524, 1.520400047302246, 1.4867000579833984, 1.4838999509811401, 1.5111000537872314, 1.5128999948501587, 1.450700044631958, 1.4401999711990356, 1.469499945640564, 1.454699993133545, 1.4515000581741333, 1.4427000284194946, 1.441499948501587, 1.48580002784729, 1.4844000339508057, 1.4972000122070312, 1.3255000114440918, 1.457900047302246, 1.364799976348877, 1.0888999700546265, 1.2128000259399414, 0.760200023651123, 0.2678000032901764, 0.2508000135421753, 1.1569000482559204, 0.6013000011444092, 0.10679999738931656, 0.3476000130176544, 0.21140000224113464, 0.24560000002384186, 0.6545000076293945, 0.2199999988079071, 0.037700001150369644, 0.24079999327659607, -0.13019999861717224, -0.38350000977516174, 0.27149999141693115, -0.4120999872684479, 1.7102999687194824, 1.7093000411987305, 1.7089999914169312, 1.6999000310897827, 1.6957000494003296, 1.6864999532699585, 1.6848000288009644, 1.6845999956130981, 1.6833000183105469, 1.680299997329712, 1.6787999868392944, 1.6775000095367432, 1.676300048828125, 1.6759999990463257, 1.6756000518798828, 1.6710000038146973, 1.6684999465942383, 1.6674000024795532, 1.6628999710083008, 1.6619999408721924, 1.6591999530792236, 1.6588000059127808, 1.6552000045776367, 1.6531000137329102, 1.652400016784668, 1.6516000032424927, 1.6490999460220337, 1.6490000486373901, 1.6477999687194824, 1.6467000246047974, 1.6375000476837158, 1.6353000402450562, 1.6017999649047852, 1.618399977684021, 1.62090003490448, 1.6339000463485718, 1.5371999740600586, 1.4275000095367432, 1.595900058746338, 1.5231000185012817, 1.51419997215271, 1.2582000494003296, 1.3568999767303467, 1.5326000452041626, 1.55840003490448, 1.5586999654769897, 1.2448999881744385, 1.3944000005722046, 1.396299958229065, 1.4726999998092651, 1.4242000579833984, 1.4474999904632568, 1.1165000200271606, 1.2175999879837036, 0.8712000250816345, 1.1469999551773071, 0.920199990272522, 1.3279999494552612, 1.1009999513626099, 1.1771999597549438, 0.8586999773979187, 1.0788999795913696, 1.3594000339508057, 0.8217999935150146, 0.334199994802475, 0.19740000367164612, -0.09489999711513519, -0.06289999932050705, 0.15440000593662262, -0.125, 0.3849000036716461, 0.5097000002861023, 0.6313999891281128, 0.4878000020980835, -0.09480000287294388, 0.0934000015258789, -0.4255000054836273, 0.14959999918937683, 1.8811999559402466, 1.8801000118255615, 1.878100037574768, 1.8747999668121338, 1.8681999444961548, 1.8653000593185425, 1.860700011253357, 1.8603999614715576, 1.8544000387191772, 1.8478000164031982, 1.8478000164031982, 1.8463000059127808, 1.8463000059127808, 1.842900037765503, 1.8427000045776367, 1.8365999460220337, 1.8355000019073486, 1.8329999446868896, 1.832900047302246, 1.829800009727478, 1.8250999450683594, 1.8233000040054321, 1.819200038909912, 1.8187999725341797, 1.8187999725341797, 1.8142999410629272, 1.8092000484466553, 1.804900050163269, 1.7994999885559082, 1.7985999584197998, 1.778499960899353, 1.792199969291687, 1.6689000129699707, 1.6872999668121338, 1.719499945640564, 1.6857999563217163, 1.756600022315979, 1.6992000341415405, 1.722100019454956, 1.475600004196167, 1.6654000282287598, 1.3934999704360962, 1.6243000030517578, 1.7446999549865723, 1.460800051689148, 1.5226000547409058, 1.6193000078201294, 1.5787999629974365, 1.2892999649047852, 1.6081000566482544, 1.3787000179290771, 0.9248999953269958, 1.4240000247955322, 1.3875000476837158, 0.8050000071525574, 0.6740000247955322, 0.7541999816894531, 1.4184999465942383, 0.7462999820709229, 1.1759999990463257, 0.03840000182390213, 1.2503999471664429, 0.8942999839782715, 0.38339999318122864, -0.12970000505447388, 0.09260000288486481, 0.47839999198913574, 0.3425000011920929, -0.47850000858306885, -0.1768999993801117, 0.4343999922275543, 0.14900000393390656, 0.14890000224113464, -0.885699987411499, 2.556299924850464, 2.5394999980926514, 2.5387001037597656, 2.518399953842163, 2.511899948120117, 2.509999990463257, 2.506700038909912, 2.5032999515533447, 2.500999927520752, 2.4976000785827637, 2.4935998916625977, 2.4774999618530273, 2.474100112915039, 2.4739999771118164, 2.4737000465393066, 2.473099946975708, 2.4644999504089355, 2.46370005607605, 2.4626998901367188, 2.460700035095215, 2.4495999813079834, 2.44350004196167, 2.4410998821258545, 2.440999984741211, 2.4409000873565674, 2.4409000873565674, 2.4409000873565674, 2.440700054168701, 2.439300060272217, 2.4391000270843506, 2.4375, 2.4386000633239746, 2.428299903869629, 2.4375998973846436, 2.373800039291382, 2.3687000274658203, 2.32669997215271, 2.3661000728607178, 2.3215999603271484, 2.2737998962402344, 2.1979000568389893, 2.2455999851226807, 2.264400005340576, 2.3749001026153564, 1.9636000394821167, 1.9908000230789185, 2.007200002670288, 2.125699996948242, 2.1287999153137207, 1.973099946975708, 1.947100043296814, 2.1600000858306885, 1.75, 2.276900053024292, 1.7245999574661255, 1.8348000049591064, 1.7319999933242798, 1.6466000080108643, 1.6419999599456787, 1.4061000347137451, 1.257099986076355, 1.5029000043869019, 0.5056999921798706, 1.7177000045776367, 0.8668000102043152, 1.075600028038025, 0.9660000205039978, 0.6029999852180481, 0.5077999830245972, 0.08980000019073486, -0.29679998755455017, -1.083799958229065, -0.7062000036239624, -0.15790000557899475, -0.9266999959945679, -0.5199999809265137, -0.5601999759674072, 0.3190999925136566, -1.0813000202178955, -1.2235000133514404, 3.177999973297119, 3.1779000759124756, 3.177799940109253, 3.062000036239624, 3.061800003051758, 3.0590999126434326, 3.0002999305725098, 3.0, 2.9997000694274902, 2.999300003051758, 2.999300003051758, 2.9992001056671143, 2.995300054550171, 2.9948999881744385, 2.994800090789795, 2.9732000827789307, 2.89490008354187, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.8884999752044678, 2.85479998588562, 2.6768999099731445, 2.7332000732421875, 2.7448999881744385, 2.7990000247955322, 2.6033999919891357, 2.708400011062622, 2.7827000617980957, 2.6094000339508057, 2.663800001144409, 1.9815000295639038, 2.614000082015991, 2.6821000576019287, 2.5290000438690186, 1.6664999723434448, 1.7367000579833984, 1.7081999778747559, 2.0055999755859375, 0.6948000192642212, 0.8302000164985657, -0.17970000207424164, 2.1784000396728516, -0.4122999906539917, 0.9290000200271606, 2.006500005722046, 1.6994999647140503, 2.0850000381469727, -0.09520000219345093, -0.05180000141263008, 1.4423999786376953, -0.541700005531311, -1.0670000314712524, -0.24310000240802765, 1.1608999967575073, -1.1700999736785889, 0.429500013589859, 0.07320000231266022, -0.642799973487854, -0.9883000254631042, -1.5571999549865723, 0.48399999737739563, 0.45190000534057617, -0.878000020980835, -0.8140000104904175, -1.017300009727478, -0.5831000208854675, 0.13650000095367432, 0.6484000086784363, -0.026900000870227814, -1.576200008392334, -1.5540000200271606, 3.1939001083374023, 3.10479998588562, 3.1047000885009766, 3.104599952697754, 3.104300022125244, 3.1036999225616455, 3.094399929046631, 3.0843000411987305, 3.077899932861328, 3.0648999214172363, 3.0464000701904297, 3.0085999965667725, 2.992000102996826, 2.992000102996826, 2.992000102996826, 2.992000102996826, 2.992000102996826, 2.992000102996826, 2.992000102996826, 2.9918999671936035, 2.9918999671936035, 2.9918999671936035, 2.9918999671936035, 2.9918999671936035, 2.99180006980896, 2.99180006980896, 2.9916999340057373, 2.9916999340057373, 2.9916999340057373, 2.9916000366210938, 2.8882999420166016, 2.8320999145507812, 2.8089001178741455, 2.5462000370025635, 2.830699920654297, 2.8896000385284424, 2.7848000526428223, 2.7018001079559326, 2.8134000301361084, 2.8008999824523926, 2.8789000511169434, 2.7955000400543213, 2.6998000144958496, 2.918800115585327, 2.610100030899048, 2.6256000995635986, 2.8617000579833984, 2.845099925994873, 2.734299898147583, 2.6895999908447266, 1.7376999855041504, 2.3856000900268555, 2.3469998836517334, 2.0729000568389893, 1.7860000133514404, 2.212899923324585, 2.366300106048584, 0.15109999477863312, 1.802899956703186, 1.0317000150680542, 2.555999994277954, 1.1577999591827393, 0.7445999979972839, 2.0201001167297363, 0.23649999499320984, 0.20170000195503235, 1.135599970817566, -0.6651999950408936, -1.3799999952316284, -0.384799987077713, -1.0540000200271606, -0.991599977016449, -1.5683000087738037, -0.31209999322891235, -0.5356000065803528, -0.1891999989748001, 0.0658000037074089, -1.8459999561309814, -1.3100999593734741, 0.13840000331401825, -0.9828000068664551, 0.4830000102519989, 0.03550000116229057, -1.7273000478744507, -0.31150001287460327, -1.4608999490737915, -1.8753999471664429, -1.8639999628067017, 3.2643001079559326, 3.235599994659424, 3.207200050354004, 3.2070999145507812, 3.2070999145507812, 3.206899881362915, 3.1768999099731445, 3.1719000339508057, 3.1647000312805176, 3.1584999561309814, 3.121999979019165, 3.095900058746338, 3.095900058746338, 3.0957999229431152, 3.0957999229431152, 3.0957999229431152, 3.0957999229431152, 3.0957999229431152, 3.0957999229431152, 3.0957999229431152, 3.0957000255584717, 3.095599889755249, 3.0954999923706055, 3.095400094985962, 3.0952999591827393, 3.0952999591827393, 3.0952999591827393, 3.0952999591827393, 3.0952999591827393, 3.0952999591827393, 3.0947999954223633, 3.090100049972534, 3.081899881362915, 3.079699993133545, 3.0409998893737793, 3.007999897003174, 2.9588000774383545, 3.0541999340057373, 3.0480000972747803, 2.956199884414673, 3.0731000900268555, 2.878999948501587, 2.8875999450683594, 2.9235000610351562, 2.795599937438965, 2.800299882888794, 2.9967000484466553, 2.8104000091552734, 2.788599967956543, 2.749500036239624, 2.650099992752075, 2.8248000144958496, 2.7186999320983887, 2.7172999382019043, 2.90339994430542, 2.1096999645233154, 2.31030011177063, 2.472100019454956, 2.5713000297546387, 2.2207000255584717, 1.044600009918213, 1.031999945640564, 0.4075999855995178, 0.9210000038146973, 1.7861000299453735, 1.5256999731063843, 0.7961000204086304, 0.1500999927520752, -0.4442000091075897, -1.3414000272750854, -1.805899977684021, -1.4952000379562378, -2.5488998889923096, -1.9114999771118164, 3.4453999996185303, 3.407599925994873, 3.3317999839782715, 3.331399917602539, 3.3313000202178955, 3.3310000896453857, 3.3287999629974365, 3.3280999660491943, 3.3150999546051025, 3.3141000270843506, 3.312000036239624, 3.303100109100342, 3.2797999382019043, 3.2427000999450684, 3.2177999019622803, 3.217400074005127, 3.217400074005127, 3.217400074005127, 3.2172999382019043, 3.2172999382019043, 3.2172999382019043, 3.2172999382019043, 3.2172000408172607, 3.2172000408172607, 3.2172000408172607, 3.2172000408172607, 3.2172000408172607, 3.2172000408172607, 3.217099905014038, 3.217099905014038, 3.217099905014038, 3.198699951171875, 3.1837000846862793, 3.1635000705718994, 3.1552999019622803, 3.133699893951416, 2.97160005569458, 2.7348999977111816, 2.8431999683380127, 3.1217000484466553, 2.9275999069213867, 3.108799934387207, 2.8406999111175537, 2.923799991607666, 2.99399995803833, 2.9472999572753906, 2.6084001064300537, 2.6789000034332275, 2.7953999042510986, 2.183000087738037, 2.4209001064300537, 2.0546998977661133, 2.60479998588562, 2.1993000507354736, 2.5804998874664307, 0.6212999820709229, 1.360700011253357, 2.505500078201294, 1.8768999576568604, 2.1110999584198, 0.051899999380111694, 1.8101999759674072, -0.83160001039505, 1.3669999837875366, 2.0185999870300293, 0.10729999840259552, 1.901900053024292, 1.5540000200271606, 0.006399999838322401, 0.33500000834465027, 0.08619999885559082, -1.2753000259399414, 0.38749998807907104, -0.7283999919891357, -1.0669000148773193, 0.753600001335144, 0.5134999752044678, -2.7990000247955322, 3.5201001167297363, 3.51990008354187, 3.5178000926971436, 3.4546000957489014, 3.453700065612793, 3.452699899673462, 3.4507999420166016, 3.4423999786376953, 3.4358999729156494, 3.435499906539917, 3.4300999641418457, 3.338099956512451, 3.338099956512451, 3.338099956512451, 3.338099956512451, 3.338099956512451, 3.338099956512451, 3.3376998901367188, 3.3375000953674316, 3.3375000953674316, 3.3375000953674316, 3.3375000953674316, 3.3375000953674316, 3.3375000953674316, 3.3375000953674316, 3.3375000953674316, 3.3375000953674316, 3.337399959564209, 3.337399959564209, 3.337399959564209, 3.1847000122070312, 3.228600025177002, 3.2249999046325684, 2.8822999000549316, 3.1210999488830566, 2.7795000076293945, 3.165600061416626, 3.160399913787842, 2.8791000843048096, 2.8798999786376953, 3.1015000343322754, 3.0383999347686768, 1.8839000463485718, 2.0903000831604004, 2.99399995803833, 2.852299928665161, 2.9809000492095947, 2.6656999588012695, 2.7237000465393066, 2.2967000007629395, 1.1663000583648682, 1.611799955368042, 0.9323999881744385, 1.8858000040054321, 0.9617000222206116, 1.0576000213623047, 0.47450000047683716, -0.16940000653266907, 0.5873000025749207, 1.6154999732971191, 1.2264000177383423, 0.9277999997138977, -0.11680000275373459, 0.1770000010728836, 0.243599995970726, -1.1333999633789062, 1.1311999559402466, 0.5411999821662903, -1.257699966430664, -0.8912000060081482, -2.275700092315674, -2.297600030899048, 1.373900055885315, -1.455399990081787, 0.23080000281333923, -1.978700041770935, -1.8702000379562378, 0.02160000056028366, -1.413599967956543, 3.70740008354187, 3.65120005607605, 3.621500015258789, 3.621500015258789, 3.621500015258789, 3.578700065612793, 3.578700065612793, 3.5557000637054443, 3.511399984359741, 3.5113000869750977, 3.5113000869750977, 3.5111000537872314, 3.5106000900268555, 3.5099000930786133, 3.509500026702881, 3.509200096130371, 3.507200002670288, 3.506999969482422, 3.506200075149536, 3.505500078201294, 3.5027999877929688, 3.47760009765625, 3.4704999923706055, 3.4590001106262207, 3.418299913406372, 3.391900062561035, 3.391900062561035, 3.391900062561035, 3.391900062561035, 3.391900062561035, 3.391900062561035, 3.371500015258789, 3.391900062561035, 3.3473000526428223, 3.3405001163482666, 3.3132998943328857, 3.208899974822998, 3.1501998901367188, 3.025899887084961, 3.2249999046325684, 3.190700054168701, 3.0782999992370605, 2.8622000217437744, 3.2337000370025635, 1.4948999881744385, 2.6033999919891357, 1.9736000299453735, 2.536799907684326, 2.838599920272827, 1.3651000261306763, 2.441800117492676, 2.4674999713897705, 2.81030011177063, 1.208899974822998, -1.1505999565124512, -1.628600001335144, 1.625599980354309, 1.4431999921798706, 0.04769999906420708, 1.3234000205993652, -0.2476000040769577, -0.060499999672174454, -0.8521000146865845, -0.04639999940991402, 1.1406999826431274, 0.15780000388622284, 0.2134999930858612, -0.9293000102043152, -1.2901999950408936, -0.5322999954223633, 0.4569999873638153, 0.07159999758005142, 3.6050000190734863, 3.5813000202178955, 3.5713000297546387, 3.530400037765503, 3.5292999744415283, 3.5185000896453857, 3.5081000328063965, 3.469599962234497, 3.4507999420166016, 3.4103000164031982, 3.4103000164031982, 3.4103000164031982, 3.4103000164031982, 3.4103000164031982, 3.4103000164031982, 3.409899950027466, 3.4096999168395996, 3.4096999168395996, 3.4096999168395996, 3.4096999168395996, 3.4096999168395996, 3.409600019454956, 3.409600019454956, 3.409600019454956, 3.409600019454956, 3.40939998626709, 3.4093000888824463, 3.4091999530792236, 3.40910005569458, 3.4089999198913574, 3.3359999656677246, 3.2962000370025635, 3.164900064468384, 3.058300018310547, 3.361299991607666, 3.130000114440918, 3.296799898147583, 3.1277999877929688, 2.6194000244140625, 3.0789999961853027, 3.0488998889923096, 2.92930006980896, 3.06469988822937, 3.2202000617980957, 3.091200113296509, 3.212599992752075, 2.761899948120117, 1.8557000160217285, 2.9948999881744385, 2.949700117111206, 3.1129000186920166, 1.7558000087738037, 1.6205999851226807, 1.645400047302246, 1.8319000005722046, 0.9782000184059143, 1.6995999813079834, -0.029600000008940697, 1.6700999736785889, 1.9594999551773071, 1.6476000547409058, 0.14069999754428864, 1.6995999813079834, 2.014699935913086, -0.7569000124931335, 0.19750000536441803, -0.41040000319480896, 0.1467999964952469, -0.4530999958515167, 0.003700000001117587, 0.9578999876976013, 1.0782999992370605, -0.11150000244379044, -0.5889999866485596], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.950399875640869, -6.758200168609619, -6.65339994430542, -7.4766998291015625, -6.975599765777588, -7.829599857330322, -8.072099685668945, -7.0671000480651855, -8.076899528503418, -6.553999900817871, -7.689599990844727, -8.305999755859375, -8.201299667358398, -8.663900375366211, -8.66510009765625, -8.665300369262695, -6.512899875640869, -7.828400135040283, -4.874499797821045, -6.851200103759766, -5.175899982452393, -7.30079984664917, -7.722599983215332, -8.844499588012695, -8.845499992370605, -8.847200393676758, -7.884500026702881, -8.852399826049805, -8.857999801635742, -8.708800315856934, -4.2967000007629395, -5.668799877166748, -5.416800022125244, -6.19789981842041, -4.459199905395508, -6.376200199127197, -4.748799800872803, -7.212100028991699, -3.7144999504089355, -4.160399913787842, -3.4138998985290527, -4.646500110626221, -4.642899990081787, -6.6072001457214355, -6.842100143432617, -3.6273999214172363, -5.51200008392334, -3.0332999229431152, -5.813300132751465, -3.1517999172210693, -3.1386001110076904, -3.8340001106262207, -3.844099998474121, -5.769599914550781, -6.025100231170654, -4.207399845123291, -4.154600143432617, -4.148399829864502, -5.192800045013428, -5.552700042724609, -4.9039998054504395, -4.853000164031982, -4.742199897766113, -4.917500019073486, -5.144899845123291, -5.244100093841553, -5.283999919891357, -5.465799808502197, -5.385200023651123, -5.4095001220703125, -6.08489990234375, -5.55109977722168, -6.813600063323975, -4.815999984741211, -5.336299896240234, -6.994200229644775, -6.997900009155273, -6.211999893188477, -6.968699932098389, -6.534900188446045, -6.662399768829346, -4.671500205993652, -7.5858001708984375, -7.481100082397461, -7.298900127410889, -7.075699806213379, -6.012800216674805, -7.712399959564209, -6.500899791717529, -5.476799964904785, -7.852399826049805, -7.121200084686279, -4.980000019073486, -7.031700134277344, -7.93179988861084, -7.453199863433838, -7.938899993896484, -8.01830005645752, -4.937600135803223, -7.463699817657471, -4.290299892425537, -4.71560001373291, -6.986999988555908, -4.625699996948242, -4.678800106048584, -6.152699947357178, -6.264999866485596, -4.141499996185303, -3.9398999214172363, -4.936800003051758, -4.564700126647949, -4.59630012512207, -4.611499786376953, -4.8246002197265625, -6.137199878692627, -6.1305999755859375, -6.303299903869629, -4.633800029754639, -6.026400089263916, -5.618299961090088, -4.721199989318848, -5.212299823760986, -4.563199996948242, -3.5044000148773193, -3.5836000442504883, -5.464900016784668, -4.470099925994873, -3.75219988822937, -4.379899978637695, -4.214099884033203, -4.311800003051758, -4.951900005340576, -4.6331000328063965, -4.6072998046875, -4.727700233459473, -4.730000019073486, -4.792399883270264, -4.922599792480469, -4.922999858856201, -6.774899959564209, -7.12529993057251, -7.1255998611450195, -7.370299816131592, -7.486700057983398, -7.622700214385986, -7.559000015258789, -7.6940999031066895, -5.07919979095459, -7.773399829864502, -7.08459997177124, -7.7769999504089355, -7.450200080871582, -7.859000205993652, -6.914999961853027, -7.574100017547607, -4.607500076293945, -7.129899978637695, -7.872799873352051, -8.057999610900879, -5.822400093078613, -7.966000080108643, -7.148399829864502, -8.174099922180176, -8.17490005493164, -7.660699844360352, -6.059800148010254, -8.178600311279297, -8.07229995727539, -5.145899772644043, -5.407100200653076, -6.62939977645874, -4.451900005340576, -5.493299961090088, -6.740200042724609, -7.248899936676025, -4.939599990844727, -4.033899784088135, -6.683300018310547, -5.999100208282471, -5.993299961090088, -3.710200071334839, -4.609099864959717, -6.259799957275391, -6.493500232696533, -6.64300012588501, -4.677800178527832, -5.596199989318848, -5.62529993057251, -6.108799934387207, -5.913099765777588, -6.1269001960754395, -4.645299911499023, -5.149899959564209, -3.856300115585327, -4.980899810791016, -4.151199817657471, -5.739299774169922, -5.0493998527526855, -5.298099994659424, -4.357399940490723, -5.186200141906738, -5.896599769592285, -4.82289981842041, -4.223100185394287, -4.228099822998047, -3.8671000003814697, -3.9219000339508057, -4.254499912261963, -3.959399938583374, -4.585000038146973, -4.8109002113342285, -4.974999904632568, -4.915599822998047, -4.661099910736084, -4.759699821472168, -4.936399936676025, -5.04449987411499, -7.148799896240234, -7.509300231933594, -7.511899948120117, -6.543399810791016, -7.678100109100342, -7.768400192260742, -7.401100158691406, -7.775100231170654, -6.510200023651123, -7.989799976348877, -7.9899001121521, -7.991499900817871, -6.8196001052856445, -7.995299816131592, -7.995200157165527, -7.893799781799316, -7.901000022888184, -8.125300407409668, -8.12559986114502, -8.128999710083008, -7.069399833679199, -8.020899772644043, -8.274900436401367, -8.275500297546387, -8.275199890136719, -8.281100273132324, -7.064899921417236, -7.414100170135498, -6.748600006103516, -8.453399658203125, -4.603700160980225, -6.75629997253418, -3.7764999866485596, -4.263899803161621, -5.537099838256836, -5.21120023727417, -6.600100040435791, -5.512800216674805, -6.460700035095215, -3.5288000106811523, -5.874199867248535, -3.5232999324798584, -5.933300018310547, -7.064700126647949, -4.523900032043457, -5.125800132751465, -5.950900077819824, -6.00540018081665, -4.402200222015381, -6.351399898529053, -5.369900226593018, -3.641400098800659, -5.7347002029418945, -5.625199794769287, -3.6038999557495117, -3.836899995803833, -4.098899841308594, -6.005799770355225, -4.782800197601318, -5.622399806976318, -3.733799934387207, -5.783599853515625, -5.2555999755859375, -4.586400032043457, -3.9886999130249023, -4.332900047302246, -4.924900054931641, -4.8516998291015625, -4.313000202178955, -4.821899890899658, -5.210299968719482, -5.066999912261963, -5.1717000007629395, -5.6132001876831055, -6.906899929046631, -6.922900199890137, -6.4781999588012695, -7.389900207519531, -6.639800071716309, -7.5177001953125, -7.521299839019775, -7.523799896240234, -5.851900100708008, -7.529300212860107, -7.66949987411499, -5.827499866485596, -7.845200061798096, -7.845300197601318, -7.845699787139893, -5.827400207519531, -7.560100078582764, -7.857399940490723, -7.85860013961792, -7.565100193023682, -7.2733001708984375, -7.381400108337402, -8.06350040435791, -8.063599586486816, -8.063599586486816, -8.063599586486816, -8.063799858093262, -8.063899993896484, -8.065099716186523, -8.065299987792969, -7.584700107574463, -7.7204999923706055, -7.297699928283691, -7.87939977645874, -5.701099872589111, -6.218500137329102, -5.69920015335083, -7.10699987411499, -6.6793999671936035, -6.212900161743164, -5.673099994659424, -6.115099906921387, -6.590400218963623, -7.31879997253418, -5.264500141143799, -5.412600040435791, -5.5584001541137695, -6.125699996948242, -6.156400203704834, -5.779600143432617, -5.718800067901611, -6.452499866485596, -5.494999885559082, -6.926000118255615, -5.530200004577637, -5.969600200653076, -5.749899864196777, -5.759200096130371, -5.789700031280518, -5.392300128936768, -5.300000190734863, -5.652599811553955, -4.710400104522705, -6.019800186157227, -5.16510009765625, -5.411099910736084, -5.339600086212158, -5.088500022888184, -5.395699977874756, -5.313499927520752, -5.213600158691406, -4.942800045013428, -5.131700038909912, -5.478499889373779, -5.335599899291992, -5.524400234222412, -5.53000020980835, -5.665599822998047, -5.647600173950195, -5.734399795532227, -6.788400173187256, -6.788400173187256, -6.78849983215332, -7.588200092315674, -7.588500022888184, -7.591100215911865, -7.868599891662598, -7.868800163269043, -7.869200229644775, -7.869500160217285, -7.8694000244140625, -7.037600040435791, -7.873899936676025, -7.874300003051758, -7.8730998039245605, -7.892499923706055, -7.591100215911865, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -8.26039981842041, -6.788400173187256, -6.788300037384033, -7.526700019836426, -7.588200092315674, -7.86899995803833, -7.079100131988525, -7.594200134277344, -7.869200229644775, -7.363999843597412, -7.620299816131592, -6.020400047302246, -7.588099956512451, -7.757599830627441, -7.434999942779541, -6.034599781036377, -6.241399765014648, -6.252799987792969, -6.725599765777588, -5.208700180053711, -5.570199966430664, -4.605199813842773, -7.117199897766113, -4.821199893951416, -6.073299884796143, -7.000500202178955, -6.756199836730957, -7.093699932098389, -5.418700218200684, -5.455100059509277, -6.600599765777588, -5.107999801635742, -4.839300155639648, -5.459099769592285, -6.462500095367432, -5.029099941253662, -6.04580020904541, -5.958600044250488, -5.612599849700928, -5.499199867248535, -5.39169979095459, -6.249899864196777, -6.238500118255615, -5.7947001457214355, -5.818399906158447, -5.8703999519348145, -6.028500080108643, -6.230999946594238, -6.349899768829346, -6.332499980926514, -6.133600234985352, -6.198999881744385, -6.252799987792969, -7.770599842071533, -7.770599842071533, -7.770699977874756, -7.771100044250488, -7.771599769592285, -7.779200077056885, -7.788099765777588, -7.792600154876709, -7.803100109100342, -7.277400016784668, -7.274400234222412, -8.162699699401855, -8.162699699401855, -8.162699699401855, -8.162699699401855, -8.162699699401855, -8.162699699401855, -8.162699699401855, -8.162799835205078, -8.162799835205078, -8.162799835205078, -8.162799835205078, -8.162799835205078, -8.162799835205078, -8.1628999710083, -8.1628999710083, -8.1628999710083, -8.163000106811523, -8.163000106811523, -6.612199783325195, -6.96589994430542, -7.273499965667725, -6.310100078582764, -7.4928998947143555, -7.770599842071533, -7.395699977874756, -7.112599849700928, -7.526100158691406, -7.4903998374938965, -7.775700092315674, -7.499000072479248, -7.230199813842773, -7.926499843597412, -6.972099781036377, -7.019800186157227, -7.801000118255615, -7.7718000411987305, -7.5081000328063965, -7.491000175476074, -5.892399787902832, -6.992300033569336, -7.010499954223633, -6.632199764251709, -6.335700035095215, -6.891499996185303, -7.0904998779296875, -5.172299861907959, -6.657199859619141, -6.069300174713135, -7.331299781799316, -6.27869987487793, -5.977200031280518, -6.941199779510498, -5.613100051879883, -5.714399814605713, -6.418300151824951, -5.601900100708008, -5.238999843597412, -5.7881999015808105, -5.479599952697754, -5.636600017547607, -5.402699947357178, -6.0, -5.940299987792969, -6.092700004577637, -6.2399001121521, -5.618199825286865, -5.821000099182129, -6.418700218200684, -6.1768999099731445, -6.5192999839782715, -6.499499797821045, -6.293600082397461, -6.461400032043457, -6.430699825286865, -6.432799816131592, -6.463799953460693, -7.3831000328063965, -5.792300224304199, -7.659900188446045, -7.659999847412109, -7.659999847412109, -7.660200119018555, -7.686399936676025, -7.458000183105469, -7.695099830627441, -7.161799907684326, -6.293399810791016, -8.05150032043457, -8.05150032043457, -8.05150032043457, -8.051600456237793, -8.051600456237793, -8.051600456237793, -8.0516996383667, -8.051600456237793, -8.0516996383667, -8.0516996383667, -8.051799774169922, -8.051899909973145, -8.052000045776367, -8.052000045776367, -8.052000045776367, -8.052000045776367, -8.05210018157959, -8.05210018157959, -8.05210018157959, -6.223299980163574, -6.988399982452393, -6.486499786376953, -6.993000030517578, -6.609799861907959, -6.233799934387207, -5.811299800872803, -7.415599822998047, -7.417500019073486, -6.386300086975098, -7.774099826812744, -5.8018999099731445, -6.3471999168396, -6.768400192260742, -5.832099914550781, -5.873300075531006, -7.417500019073486, -6.294099807739258, -6.490300178527832, -6.347899913787842, -6.030799865722656, -6.735300064086914, -6.625999927520752, -6.860000133514404, -7.171800136566162, -5.9745001792907715, -6.415299892425537, -6.664000034332275, -6.800600051879883, -6.479499816894531, -5.490300178527832, -5.8541998863220215, -5.904799938201904, -6.294099807739258, -6.569799900054932, -6.500199794769287, -6.304900169372559, -6.1554999351501465, -6.293799877166748, -6.311200141906738, -6.316800117492676, -6.4319000244140625, -6.407899856567383, -6.477700233459473, -6.893199920654297, -7.077199935913086, -7.554699897766113, -7.554999828338623, -7.555099964141846, -7.5553998947143555, -7.557499885559082, -7.557799816131592, -7.568600177764893, -7.568900108337402, -7.571599960327148, -7.193600177764893, -7.055799961090088, -7.626699924468994, -7.946700096130371, -7.9471001625061035, -7.9471001625061035, -7.947199821472168, -7.947199821472168, -7.947199821472168, -7.9471001625061035, -7.9471001625061035, -7.947199821472168, -7.947199821472168, -7.947199821472168, -7.947199821472168, -7.947199821472168, -7.947199821472168, -7.947299957275391, -7.947400093078613, -7.947400093078613, -6.381800174713135, -6.274499893188477, -7.274499893188477, -7.295499801635742, -7.154600143432617, -6.603899955749512, -5.945899963378906, -6.412799835205078, -7.5553998947143555, -6.8831000328063965, -7.555200099945068, -6.617199897766113, -7.0553998947143555, -7.334799766540527, -7.274099826812744, -6.452899932861328, -6.866399765014648, -7.070400238037109, -6.302999973297119, -6.6178998947143555, -6.194799900054932, -6.882699966430664, -6.557499885559082, -6.915599822998047, -5.2947998046875, -5.952400207519531, -6.905399799346924, -6.4253997802734375, -6.614500045776367, -5.268700122833252, -6.552499771118164, -5.2571001052856445, -6.537600040435791, -6.798399925231934, -6.198299884796143, -6.771599769592285, -6.679299831390381, -6.306099891662598, -6.398900032043457, -6.448699951171875, -6.245100021362305, -6.520500183105469, -6.416200160980225, -6.3902997970581055, -6.645999908447266, -6.654099941253662, -6.6579999923706055, -7.181000232696533, -7.18149995803833, -7.1828999519348145, -7.461900234222412, -7.462699890136719, -7.463600158691406, -7.465000152587891, -7.473400115966797, -6.931099891662598, -7.246799945831299, -7.485599994659424, -7.852799892425537, -7.852799892425537, -7.852799892425537, -7.852799892425537, -7.852799892425537, -7.852799892425537, -7.8531999588012695, -7.853300094604492, -7.853300094604492, -7.853300094604492, -7.853300094604492, -7.853400230407715, -7.853300094604492, -7.853400230407715, -7.853400230407715, -7.853400230407715, -7.853400230407715, -7.853400230407715, -7.853400230407715, -7.185200214385986, -7.461599826812744, -7.4629998207092285, -6.384099960327148, -7.198500156402588, -6.56790018081665, -7.4608001708984375, -7.46999979019165, -7.006400108337402, -7.179999828338623, -7.517000198364258, -7.463699817657471, -6.056399822235107, -6.452099800109863, -7.471799850463867, -7.319399833679199, -7.468900203704834, -7.180699825286865, -7.243199825286865, -6.843200206756592, -5.903600215911865, -6.337600231170654, -5.971399784088135, -6.637499809265137, -6.040599822998047, -6.157400131225586, -5.831099987030029, -5.492800235748291, -5.947700023651123, -6.611999988555908, -6.419600009918213, -6.2972002029418945, -5.966400146484375, -6.135499954223633, -6.1682000160217285, -5.6442999839782715, -6.531799793243408, -6.559800148010254, -6.174499988555908, -6.29449987411499, -6.110099792480469, -6.156599998474121, -6.832600116729736, -6.42519998550415, -6.677199840545654, -6.404200077056885, -6.436500072479248, -6.668799877166748, -6.6296000480651855, -6.244699954986572, -6.7444000244140625, -6.923600196838379, -6.923600196838379, -6.923699855804443, -7.142499923706055, -7.142499923706055, -6.460999965667725, -7.423399925231934, -6.7453999519348145, -7.423600196838379, -7.423699855804443, -7.423999786376953, -7.424799919128418, -7.425099849700928, -7.425099849700928, -7.426599979400635, -7.4268999099731445, -7.4274001121521, -7.428400039672852, -7.430099964141846, -6.463500022888184, -7.224100112915039, -6.923399925231934, -6.481299877166748, -7.815000057220459, -7.815000057220459, -7.815000057220459, -7.815000057220459, -7.815000057220459, -7.815000057220459, -6.475500106811523, -7.815000057220459, -6.4633002281188965, -7.188499927520752, -7.161099910736084, -6.783199787139893, -6.610499858856201, -6.2729997634887695, -6.938499927520752, -6.930200099945068, -6.939499855041504, -6.755899906158447, -7.1427998542785645, -5.720200061798096, -6.712699890136719, -6.3059000968933105, -6.749000072479248, -6.980199813842773, -6.147200107574463, -6.753600120544434, -6.811800003051758, -6.964000225067139, -6.3805999755859375, -5.576099872589111, -5.487599849700928, -6.558000087738037, -6.505000114440918, -6.1149001121521, -6.475599765777588, -6.143099784851074, -6.214099884033203, -6.06820011138916, -6.226099967956543, -6.489500045776367, -6.377200126647949, -6.408299922943115, -6.252799987792969, -6.226900100708008, -6.435800075531006, -6.526000022888184, -6.5131001472473145, -5.750999927520752, -5.37060022354126, -6.973999977111816, -7.406300067901611, -7.407199859619141, -7.417900085449219, -5.644100189208984, -7.452899932861328, -6.359799861907959, -7.798299789428711, -7.798299789428711, -7.798299789428711, -7.798299789428711, -7.798299789428711, -7.798299789428711, -7.798600196838379, -7.798799991607666, -7.798799991607666, -7.798799991607666, -7.798799991607666, -7.798799991607666, -7.798900127410889, -7.798900127410889, -7.798900127410889, -7.798900127410889, -7.798999786376953, -7.798999786376953, -7.799200057983398, -7.799200057983398, -7.7993998527526855, -5.4008002281188965, -5.371799945831299, -4.388999938964844, -5.653500080108643, -7.536499977111816, -6.629499912261963, -7.407400131225586, -6.961299896240234, -5.616300106048584, -6.86899995803833, -6.8420000076293945, -6.777500152587891, -7.103799819946289, -7.4191999435424805, -7.181600093841553, -7.429699897766113, -6.7291998863220215, -5.3694000244140625, -7.1545000076293945, -7.1691999435424805, -7.406899929046631, -5.711900234222412, -5.658100128173828, -6.015100002288818, -6.371300220489502, -5.75570011138916, -6.343299865722656, -5.353099822998047, -6.381499767303467, -6.5640997886657715, -6.406000137329102, -5.7754998207092285, -6.536799907684326, -6.689199924468994, -5.693600177764893, -6.1082000732421875, -6.098299980163574, -6.264999866485596, -6.217599868774414, -6.308800220489502, -6.499199867248535, -6.531499862670898, -6.490699768066406, -6.484600067138672]}, \"token.table\": {\"Topic\": [6, 9, 3, 1, 1, 4, 5, 7, 8, 12, 5, 6, 11, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 6, 8, 9, 11, 12, 1, 2, 4, 6, 7, 8, 9, 10, 12, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 4, 2, 6, 5, 3, 8, 9, 10, 11, 12, 1, 2, 3, 4, 7, 10, 12, 7, 10, 12, 1, 2, 3, 4, 5, 6, 7, 9, 11, 4, 2, 5, 11, 3, 4, 5, 6, 8, 9, 3, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 7, 10, 1, 2, 3, 4, 6, 7, 8, 9, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 1, 12, 12, 1, 2, 3, 4, 5, 6, 9, 10, 4, 5, 6, 1, 2, 12, 9, 4, 5, 3, 4, 5, 3, 4, 5, 11, 1, 6, 9, 11, 3, 5, 5, 1, 3, 4, 5, 6, 7, 11, 7, 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 8, 12, 12, 1, 2, 3, 4, 6, 7, 10, 11, 12, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 7, 3, 6, 12, 1, 5, 7, 8, 9, 12, 2, 5, 6, 8, 12, 7, 6, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 5, 2, 8, 9, 12, 1, 10, 2, 1, 2, 5, 6, 7, 11, 8, 5, 1, 2, 3, 4, 5, 6, 7, 9, 10, 3, 10, 1, 4, 2, 5, 6, 7, 9, 9, 11, 2, 1, 2, 3, 4, 5, 7, 9, 5, 6, 8, 9, 5, 5, 7, 8, 9, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 2, 3, 4, 8, 9, 12, 7, 10, 1, 1, 12, 2, 3, 4, 5, 6, 3, 7, 12, 1, 11, 6, 11, 12, 1, 2, 3, 4, 5, 6, 11, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 9, 3, 1, 2, 3, 4, 5, 6, 8, 7, 1, 2, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 3, 3, 4, 6, 12, 5, 6, 7, 9, 12, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 12, 1, 3, 4, 5, 6, 10, 12, 8, 1, 7, 10, 12, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 10, 11, 1, 2, 4, 5, 6, 9, 11, 12, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 2, 9, 1, 2, 3, 4, 5, 6, 7, 10, 12, 3, 4, 5, 6, 6, 11, 6, 2, 4, 5, 7, 8, 9, 8, 9, 12, 1, 4, 10, 2, 5, 6, 8, 9, 12, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 3, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 12, 10, 3, 6, 1, 2, 3, 4, 5, 6, 11, 3, 4, 5, 9, 9, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 7, 11, 5, 2, 3, 5, 6, 7, 8, 10, 11, 12, 1, 2, 6, 10, 6, 7, 11, 1, 2, 3, 4, 5, 6, 9, 10, 11, 4, 5, 6, 7, 8, 9, 10, 5, 9, 1, 2, 3, 4, 9, 11, 4, 5, 6, 4, 5, 7, 9, 11, 3, 4, 5, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 2, 8, 9, 11, 12, 7, 3, 6, 10, 1, 2, 3, 4, 5, 6, 7, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 5, 11, 8, 9, 12, 11, 5, 7, 3, 4, 5, 6, 12, 1, 8, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 7, 10, 11, 1, 5, 6, 10, 2, 5, 6, 10, 11, 2, 3, 6, 8, 9, 10, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 7, 11, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 1, 3, 4, 9, 11, 12, 1, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 7, 12, 7, 8, 9, 4, 1, 3, 4, 5, 6, 7, 8, 9, 12, 10, 5, 7, 10, 8, 11, 4, 4, 2, 3, 5, 1, 4, 6, 7, 12, 1, 2, 3, 5, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 2, 3, 8, 12, 1, 7, 6, 1, 6, 7, 8, 9, 10, 7, 2, 11, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 9, 7, 1, 12, 11, 5, 7, 9, 11, 10, 12, 11, 8, 9, 11, 11, 6, 4, 1, 11, 2, 3, 7, 8, 9, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 11, 1, 6, 6, 7, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 8, 10, 10, 10, 3, 4, 5, 8, 2, 6, 2, 4, 5, 8, 9, 11, 9, 11, 1, 2, 3, 4, 5, 6, 8, 11, 6, 10, 12, 8, 9, 12, 4, 8, 1, 2, 3, 4, 5, 7, 9, 11, 12, 6, 7, 6, 7, 9, 11, 11, 11, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 6, 8, 1, 3, 5, 8, 9, 6, 7, 9, 11, 12, 10, 2, 11, 5, 1, 2, 3, 4, 5, 6, 7, 9, 12, 5, 8, 10, 10, 7, 8, 9, 12, 3, 6, 7, 11, 12, 4, 10, 11, 1, 4, 5, 7, 12, 1, 7, 8, 1, 2, 3, 5, 9, 5, 12, 2, 5, 6, 7, 9, 11, 4, 10, 5, 4, 1, 11, 12, 1, 2, 3, 4, 7, 12, 1, 4, 6, 7, 8, 1, 2, 4, 6, 7, 10, 11, 1, 9, 12, 11, 12, 8, 12, 9, 2, 10, 9, 2, 5, 7, 8, 9, 10, 12, 1, 3, 4, 5, 6, 3, 5, 6, 7, 6, 1, 2, 8, 12, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 5, 8, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 5, 4, 5, 5, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 1, 2, 3, 4, 5, 7, 8, 3, 4, 5, 4, 5, 5, 8, 8, 9, 11, 9, 2, 3, 4, 5, 6, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 10, 6, 5, 10, 1, 2, 4, 5, 7, 9, 12, 1, 2, 3, 5, 6, 7, 8, 9, 11, 7, 8, 9, 12, 2, 3, 5, 6, 6, 1, 2, 3, 4, 5, 8, 9, 11, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 3, 2, 3, 6, 12, 9, 11, 1, 3, 6, 7, 9, 10, 11, 8, 9, 7, 8, 11, 4, 1, 2, 3, 4, 7, 1, 2, 3, 6, 1, 2, 4, 5, 6, 7, 9, 11, 12, 3, 12, 1, 2, 3, 4, 6, 7, 7, 1, 1, 2, 1, 2, 6, 7, 8, 11, 12, 10, 6, 7, 1, 1, 2, 3, 4, 5, 7, 8, 9, 12, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 9, 8, 9, 7, 4, 7, 10, 5, 1, 2, 6, 7, 9, 10, 11, 1, 2, 11, 3, 5, 10, 11, 12, 10, 2, 5, 6, 7, 8, 9, 12, 1, 2, 3, 4, 5, 6, 7, 8, 3, 9, 1, 2, 5, 7, 8, 11, 10, 1, 2, 3, 5, 10, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 1, 12, 1, 2, 3, 5, 1, 2, 4, 7, 8, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 11, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 10, 2, 1, 2, 3, 4, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 8, 9, 12, 2, 6, 8, 11, 5, 6, 7, 6, 12, 3, 5, 7, 8, 3, 4, 5, 7, 2, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 6, 10, 3, 5, 7, 12, 1, 2, 3, 8, 1, 2, 4, 5, 9, 10, 12, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 1, 3, 4, 7, 8, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 10, 1, 5, 6, 7, 8, 5, 1, 2, 3, 4, 5, 7, 10, 11, 7, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 3, 8, 9, 12, 2, 3, 6, 1, 7, 10, 12, 6, 2, 3, 6, 7, 8, 9, 4, 1, 3, 4, 5, 6, 10, 2, 1, 2, 11, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 6, 7, 1, 7, 9, 10, 2, 6, 3, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 10, 4, 2, 5, 7, 8, 9, 12, 1, 2, 3, 4, 6, 7, 4, 10, 1, 4, 10, 1, 2, 3, 4, 1, 2, 4, 6, 10, 2, 5, 7, 9, 10, 11, 12, 6, 9, 11, 5, 7, 2, 3, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 10, 3, 3, 10, 11, 12, 7, 1, 2, 4, 5, 7, 8, 11, 9, 1, 2, 5, 7, 8, 9, 11, 12, 8, 9, 12, 1, 2, 3, 4, 6, 7, 3, 1, 2, 3, 6, 7, 9, 8, 8, 1, 3, 4, 5, 7, 8, 9, 11, 12, 1, 2, 3, 4, 5, 6, 7, 9, 12, 8, 6, 1, 2, 4, 5, 6, 7, 8, 9, 12, 7, 1, 2, 3, 4, 5, 6, 7, 10, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 5, 11, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 1, 5, 6, 9, 11, 5, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 3, 6, 1, 2, 4, 5, 6, 9, 11, 6, 8, 10, 1, 2, 4, 6, 7, 8, 10, 12, 3, 1, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 1, 8, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 2, 11, 1, 10, 7, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 2, 9, 5, 9, 2, 3, 12, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1, 2, 3, 4, 8, 10, 11, 1, 8, 1, 4, 7, 8, 9, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 4, 5, 8, 9, 10, 12, 4, 1, 2, 3, 5, 7, 5, 8, 9, 11, 3, 2, 4, 6, 4, 9, 8, 1, 2, 3, 11, 4, 1, 2, 3, 4, 5, 6, 8, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 3, 7, 11, 2, 3, 4, 5, 6, 8, 9, 7, 10, 11, 2, 3, 11, 2, 6, 11, 5, 8, 2, 7, 9, 12, 5, 3, 4, 1, 2, 3, 4, 5, 6, 8, 1, 3, 4, 12, 3, 10, 2, 7, 8, 9, 11, 12, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 6, 7, 12, 5, 6, 10, 4, 5, 1, 2, 3, 4, 5, 6, 7, 6, 3, 9, 2, 10, 12, 1, 2, 3, 4, 6, 7, 2, 1, 2, 3, 4, 7, 9, 6, 7, 11, 2, 5, 1, 2, 3, 4, 5, 6, 7, 9, 11, 8, 8, 9, 2, 3, 6, 2, 7, 8, 9, 11, 10, 1, 2, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 7, 8, 9, 10, 9, 6, 3, 4, 5, 8, 1, 3, 4, 5, 6, 9, 10, 11, 12, 12, 7, 1, 4, 1, 2, 3, 4, 5, 7, 8, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 4, 5, 6, 8, 9, 10, 3, 4, 5, 6, 3, 5, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 7, 1, 3, 1, 2, 4, 7, 12, 1, 2, 3, 4, 5, 6, 7, 8, 6, 2, 3, 5, 10, 1, 7, 10, 1, 2, 3, 4, 5, 8, 9, 10, 12, 6, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 1, 2, 3, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 11, 7, 2, 3, 5, 8, 2, 11, 1, 2, 3, 4, 5, 6, 9, 10, 12, 1, 2, 3, 4, 5, 6, 10, 9, 9, 9, 9, 1, 2, 3, 4, 5, 6, 9, 10, 9, 1, 2, 5, 7, 8, 11, 1, 2, 3, 4, 6, 7, 11, 12, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 2, 11, 2, 2, 6, 11, 1, 2, 3, 4, 7, 8, 10, 12, 1, 4, 5, 7, 11, 8, 6, 7, 9, 12, 9, 1, 2, 1, 2, 3, 6, 7, 10, 11, 1, 2, 3, 4, 5, 6, 10, 10, 4, 7, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 2, 4, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 2, 6, 7, 8, 9, 11, 12, 8, 1, 3, 4, 5, 6, 7, 8, 9, 11, 6, 12, 1, 2, 4, 5, 6, 7, 9, 10, 11, 1, 2, 9, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 11, 7, 11, 12, 6, 3, 3, 7, 11, 12, 1, 2, 3, 4, 8, 11, 11, 6, 12, 7, 6, 8, 7, 9, 10, 8, 2, 1, 2, 3, 4, 6, 7, 8, 12, 7, 4, 5, 7, 11, 5, 7, 1, 2, 4, 6, 7, 8, 9, 12, 10, 5, 1, 2, 3, 4, 5, 7, 8, 9, 10, 6, 7, 5, 7, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 1, 4, 6, 9, 11, 12, 12, 2, 7, 8, 11, 1, 2, 3, 4, 5, 6, 7, 9, 11, 12, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 7, 12, 6, 1, 1, 2, 4, 5, 6, 7, 8, 1, 4, 7, 8, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 1, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 4, 5, 7, 8, 10, 12, 3, 8, 4, 7, 8, 9, 12, 8, 9, 12, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 4, 5, 9, 4, 5, 4, 5, 6, 7, 9, 4, 5, 7, 8, 6, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 3, 6, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 2, 3, 6, 8, 9, 11, 4, 9, 6, 7, 10, 3, 5, 9, 8, 9, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 8, 9, 11, 12, 2, 3, 6, 7, 8, 9, 12, 3, 5, 2, 3, 5, 10, 6], \"Freq\": [0.690178394317627, 0.4637833833694458, 0.9585070610046387, 0.9295775890350342, 0.10152459144592285, 0.10152459144592285, 0.10152459144592285, 0.5076229572296143, 0.10152459144592285, 0.10152459144592285, 0.19588367640972137, 0.5876510143280029, 0.19588367640972137, 0.17772585153579712, 0.6467246413230896, 0.034557804465293884, 0.02468414604663849, 0.014810487627983093, 0.034557804465293884, 0.009873658418655396, 0.004936829209327698, 0.02468414604663849, 0.01974731683731079, 0.07515916228294373, 0.45095497369766235, 0.3006366491317749, 0.07515916228294373, 0.07515916228294373, 0.2658137083053589, 0.20447209477424622, 0.061341628432273865, 0.16357767581939697, 0.04089441895484924, 0.061341628432273865, 0.04089441895484924, 0.061341628432273865, 0.12268325686454773, 0.7331127524375916, 0.033431850373744965, 0.08357962965965271, 0.014327936805784702, 0.078803651034832, 0.007163968402892351, 0.007163968402892351, 0.009551957249641418, 0.004775978624820709, 0.016715925186872482, 0.011939946562051773, 0.8615782260894775, 0.9434486627578735, 0.0325327143073082, 0.7191625237464905, 0.08416775614023209, 0.08416775614023209, 0.4208388030529022, 0.08416775614023209, 0.08416775614023209, 0.08416775614023209, 0.5586390495300293, 0.16759172081947327, 0.018621301278471947, 0.05586390569806099, 0.018621301278471947, 0.11172781139612198, 0.03724260255694389, 0.20950645208358765, 0.6285193562507629, 0.20950645208358765, 0.12030961364507675, 0.07403668016195297, 0.2498738020658493, 0.19434629380702972, 0.2545011043548584, 0.037018340080976486, 0.037018340080976486, 0.009254585020244122, 0.018509170040488243, 0.9540997743606567, 0.22788465023040771, 0.11394232511520386, 0.45576930046081543, 0.0260019488632679, 0.7735579609870911, 0.1690126657485962, 0.006500487215816975, 0.01300097443163395, 0.006500487215816975, 0.954605221748352, 0.9811763763427734, 0.3207196593284607, 0.2879931628704071, 0.01309059839695692, 0.10472478717565536, 0.11127008497714996, 0.02618119679391384, 0.00654529919847846, 0.02618119679391384, 0.01309059839695692, 0.05890769511461258, 0.02618119679391384, 0.00654529919847846, 0.3879140019416809, 0.3879140019416809, 0.1293046772480011, 0.6466989517211914, 0.11149982362985611, 0.022299963980913162, 0.055749911814928055, 0.022299963980913162, 0.11149982362985611, 0.011149981990456581, 0.011149981990456581, 0.011149981990456581, 0.32455557584762573, 0.23182541131973267, 0.19318784773349762, 0.030910054221749306, 0.05409259721636772, 0.015455027110874653, 0.04636508226394653, 0.007727513555437326, 0.007727513555437326, 0.07727513462305069, 0.007727513555437326, 0.8618015050888062, 0.07181679457426071, 0.48463404178619385, 0.049439992755651474, 0.024719996377825737, 0.024719996377825737, 0.7663199305534363, 0.03707999736070633, 0.06179999187588692, 0.024719996377825737, 0.012359998188912868, 0.914952278137207, 0.03812301158905029, 0.03812301158905029, 0.3260156512260437, 0.16300782561302185, 0.48902344703674316, 0.46375396847724915, 0.9103776216506958, 0.04791460931301117, 0.07054727524518967, 0.7995357513427734, 0.09406302869319916, 0.040206100791692734, 0.18092745542526245, 0.7438128590583801, 0.020103050395846367, 0.940712571144104, 0.24151374399662018, 0.24151374399662018, 0.36227062344551086, 0.9187682867050171, 0.04375087097287178, 0.8931213617324829, 0.12887127697467804, 0.14498019218444824, 0.12887127697467804, 0.45104947686195374, 0.08054455369710922, 0.03221781924366951, 0.016108909621834755, 0.6926319599151611, 0.0886746346950531, 0.31036123633384705, 0.0886746346950531, 0.04433731734752655, 0.0886746346950531, 0.13301195204257965, 0.04433731734752655, 0.22168660163879395, 0.04433731734752655, 0.2748107612133026, 0.1374053806066513, 0.4122161269187927, 0.4846673607826233, 0.6572434306144714, 0.11187122017145157, 0.027967805042862892, 0.08390341699123383, 0.013983902521431446, 0.013983902521431446, 0.06991951167583466, 0.013983902521431446, 0.013983902521431446, 0.40446898341178894, 0.1877891719341278, 0.05055862292647362, 0.06500394642353058, 0.0938945859670639, 0.05778128281235695, 0.028890641406178474, 0.021667981520295143, 0.05778128281235695, 0.007222660351544619, 0.021667981520295143, 0.9537142515182495, 0.03179047629237175, 0.42281410098075867, 0.5637521147727966, 0.48464053869247437, 0.058695416897535324, 0.2347816675901413, 0.058695416897535324, 0.4695633351802826, 0.058695416897535324, 0.11739083379507065, 0.10636183619499207, 0.10636183619499207, 0.10636183619499207, 0.5318091511726379, 0.10636183619499207, 0.45926111936569214, 0.6903886198997498, 0.12339068949222565, 0.3916313350200653, 0.32904183864593506, 0.10908452421426773, 0.01967098005115986, 0.014306167140603065, 0.0035765417851507664, 0.0035765417851507664, 0.0035765417851507664, 0.0017882708925753832, 0.9300364255905151, 0.17732295393943787, 0.531968891620636, 0.2364306002855301, 0.05910765007138252, 0.2718771994113922, 0.5437543988227844, 0.9749130606651306, 0.8153132796287537, 0.04529518261551857, 0.06039357930421829, 0.015098394826054573, 0.015098394826054573, 0.04529518261551857, 0.6889052987098694, 0.7967550754547119, 0.1415882259607315, 0.21690110862255096, 0.5512903332710266, 0.015062577091157436, 0.02711263857781887, 0.021087607368826866, 0.015062577091157436, 0.0030125153716653585, 0.009037545882165432, 0.8951079249382019, 0.47614994645118713, 0.9233490228652954, 0.060218412429094315, 0.17340314388275146, 0.2601047158241272, 0.08670157194137573, 0.08670157194137573, 0.34680628776550293, 0.4637441635131836, 0.4838917553424835, 0.9786843061447144, 0.008906870149075985, 0.1336030513048172, 0.02672061137855053, 0.7838045954704285, 0.02672061137855053, 0.008906870149075985, 0.7023301720619202, 0.8776702284812927, 0.10970877856016159, 0.37866491079330444, 0.567997395992279, 0.8484830260276794, 0.9244018793106079, 0.08419664204120636, 0.16839328408241272, 0.6735731363296509, 0.08419664204120636, 0.364483505487442, 0.14910688996315002, 0.10492707043886185, 0.07179220765829086, 0.09388211369514465, 0.06074725091457367, 0.027612386271357536, 0.011044954881072044, 0.03865734115242958, 0.011044954881072044, 0.011044954881072044, 0.05522477254271507, 0.4846396744251251, 0.30084386467933655, 0.11439651250839233, 0.1592702865600586, 0.3627822995185852, 0.02464897185564041, 0.021488847211003304, 0.005688224453479052, 0.004424174316227436, 0.0006320249522104859, 0.003792149480432272, 0.0006320249522104859, 0.0006320249522104859, 0.18769536912441254, 0.18769536912441254, 0.5630860924720764, 0.40962687134742737, 0.13454897701740265, 0.1142171323299408, 0.28225386142730713, 0.021527836099267006, 0.01375389564782381, 0.008969931863248348, 0.004783963784575462, 0.007773940917104483, 0.0011959909461438656, 0.0005979954730719328, 0.040466297417879105, 0.16186518967151642, 0.16186518967151642, 0.32373037934303284, 0.20233149826526642, 0.040466297417879105, 0.20889714360237122, 0.6266914010047913, 0.8088370561599731, 0.23952557146549225, 0.7185767292976379, 0.08540641516447067, 0.8156312704086304, 0.042703207582235336, 0.055514171719551086, 0.004270320758223534, 0.28592225909233093, 0.4765370786190033, 0.19061483442783356, 0.9640393853187561, 0.4838917553424835, 0.07601463794708252, 0.07601463794708252, 0.7601463794708252, 0.0038715109694749117, 0.9717492461204529, 0.0038715109694749117, 0.0038715109694749117, 0.007743021938949823, 0.007743021938949823, 0.0038715109694749117, 0.4761517345905304, 0.45663759112358093, 0.079130619764328, 0.2589729428291321, 0.36687833070755005, 0.10790538787841797, 0.06474323570728302, 0.07193692773580551, 0.014387384988367558, 0.007193692494183779, 0.021581077948212624, 0.10311800241470337, 0.012889750301837921, 0.7604952454566956, 0.025779500603675842, 0.07733850181102753, 0.012889750301837921, 0.9741998314857483, 0.08675359934568405, 0.8591405153274536, 0.03638054430484772, 0.005597006529569626, 0.002798503264784813, 0.005597006529569626, 0.002798503264784813, 0.4592617154121399, 0.015576871111989021, 0.9657660126686096, 0.22606660425662994, 0.13187217712402344, 0.13187217712402344, 0.018838882446289062, 0.2072277069091797, 0.037677764892578125, 0.11303330212831497, 0.037677764892578125, 0.056516651064157486, 0.018838882446289062, 0.9709469676017761, 0.9742326736450195, 0.8616395592689514, 0.06627997010946274, 0.4846678674221039, 0.08783289045095444, 0.08783289045095444, 0.6148302555084229, 0.08783289045095444, 0.08783289045095444, 0.45592406392097473, 0.7024735808372498, 0.0410536490380764, 0.022807583212852478, 0.11859943717718124, 0.002280758460983634, 0.009123033843934536, 0.04333440959453583, 0.0205268245190382, 0.002280758460983634, 0.0205268245190382, 0.009123033843934536, 0.009123033843934536, 0.5397850871086121, 0.4318280518054962, 0.17248541116714478, 0.36413586139678955, 0.15332037210464478, 0.038330093026161194, 0.21081550419330597, 0.019165046513080597, 0.038330093026161194, 0.45591089129447937, 0.17184558510780334, 0.17184558510780334, 0.3436911702156067, 0.17184558510780334, 0.7233518362045288, 0.3439899981021881, 0.19009973108768463, 0.0724189430475235, 0.08147131651639938, 0.054314207285642624, 0.031683288514614105, 0.03620947152376175, 0.08599749952554703, 0.027157103642821312, 0.04073565825819969, 0.027157103642821312, 0.009052367880940437, 0.8769433498382568, 0.037316739559173584, 0.037316739559173584, 0.018658369779586792, 0.018658369779586792, 0.5156338810920715, 0.02062535472214222, 0.02062535472214222, 0.16500283777713776, 0.08250141888856888, 0.04125070944428444, 0.02062535472214222, 0.12375213205814362, 0.12400192767381668, 0.47534072399139404, 0.02066698856651783, 0.06200096383690834, 0.08266795426607132, 0.02066698856651783, 0.04133397713303566, 0.02066698856651783, 0.02066698856651783, 0.103334940969944, 0.22428175806999207, 0.6728453040122986, 0.042630936950445175, 0.04719853773713112, 0.06851401180028915, 0.7643118500709534, 0.042630936950445175, 0.021315468475222588, 0.0060901339165866375, 0.0060901339165866375, 0.0015225334791466594, 0.20391066372394562, 0.7264317274093628, 0.050977665930986404, 0.012744416482746601, 0.21215717494487762, 0.6364715099334717, 0.45663750171661377, 0.017217567190527916, 0.2582635283470154, 0.6542676091194153, 0.017217567190527916, 0.017217567190527916, 0.03443513438105583, 0.18060904741287231, 0.5418271422386169, 0.18060904741287231, 0.2800428569316864, 0.2800428569316864, 0.4200643002986908, 0.0773986354470253, 0.1547972708940506, 0.03869931772351265, 0.5417904257774353, 0.1547972708940506, 0.03869931772351265, 0.20245586335659027, 0.8098234534263611, 0.21831926703453064, 0.4352909028530121, 0.1118549332022667, 0.06333953887224197, 0.030995946377515793, 0.033691246062517166, 0.03908184543251991, 0.009433548897504807, 0.009433548897504807, 0.0202147476375103, 0.00808589905500412, 0.0202147476375103, 0.27923932671546936, 0.13961966335773468, 0.41885900497436523, 0.4559112787246704, 0.455258846282959, 0.17072206735610962, 0.18210352957248688, 0.04552588239312172, 0.034144412726163864, 0.01138147059828043, 0.034144412726163864, 0.01138147059828043, 0.05690735578536987, 0.47615259885787964, 0.15016743540763855, 0.7508371472358704, 0.04756876081228256, 0.1284356564283371, 0.5137426257133484, 0.18551816046237946, 0.07611002027988434, 0.02378438040614128, 0.02378438040614128, 0.921969473361969, 0.8331475257873535, 0.890010416507721, 0.4637833833694458, 0.7050855755805969, 0.32952186465263367, 0.14122365415096283, 0.09414909780025482, 0.14122365415096283, 0.04707454890012741, 0.07061182707548141, 0.023537274450063705, 0.023537274450063705, 0.023537274450063705, 0.11768637597560883, 0.07763058692216873, 0.1164458766579628, 0.4657835066318512, 0.06900496780872345, 0.2113277018070221, 0.017251241952180862, 0.008625620976090431, 0.004312810488045216, 0.004312810488045216, 0.008625620976090431, 0.017251241952180862, 0.6934294104576111, 0.8277891874313354, 0.7190923094749451, 0.3398591876029968, 0.09268887341022491, 0.061792582273483276, 0.21627403795719147, 0.09268887341022491, 0.12358516454696655, 0.030896291136741638, 0.030896291136741638, 0.030896291136741638, 0.03137553855776787, 0.9255783557891846, 0.015687769278883934, 0.47618892788887024, 0.5555641651153564, 0.2777820825576782, 0.7363381385803223, 0.1704287976026535, 0.14486448466777802, 0.05112864077091217, 0.2982504069805145, 0.19599312543869019, 0.06817151606082916, 0.042607199400663376, 0.025564320385456085, 0.008521439507603645, 0.1956750601530075, 0.7174752354621887, 0.06733684241771698, 0.13467368483543396, 0.5386947393417358, 0.20201052725315094, 0.06733684241771698, 0.1930903047323227, 0.5792708992958069, 0.009313655085861683, 0.1303911656141281, 0.04656827449798584, 0.8009743690490723, 0.13644996285438538, 0.6822497844696045, 0.13815844058990479, 0.6907921433448792, 0.09210561960935593, 0.07039661705493927, 0.35198307037353516, 0.14079323410987854, 0.14079323410987854, 0.2815864682197571, 0.8545687198638916, 0.0776880607008934, 0.025896022096276283, 0.453689843416214, 0.12373359501361847, 0.09623724222183228, 0.06874088197946548, 0.027496354654431343, 0.027496354654431343, 0.013748177327215672, 0.013748177327215672, 0.08248906582593918, 0.027496354654431343, 0.06874088197946548, 0.07037687301635742, 0.49263811111450195, 0.2815074920654297, 0.07037687301635742, 0.07037687301635742, 0.4592616558074951, 0.22695426642894745, 0.22695426642894745, 0.4539085328578949, 0.029454246163368225, 0.1693619191646576, 0.7069019079208374, 0.02209068462252617, 0.029454246163368225, 0.02209068462252617, 0.007363561540842056, 0.007363561540842056, 0.007363561540842056, 0.018275152891874313, 0.02088589034974575, 0.21930183470249176, 0.6213552355766296, 0.09920797497034073, 0.010442945174872875, 0.007832208648324013, 0.002610736293718219, 0.7982988357543945, 0.8931055068969727, 0.2433958351612091, 0.2433958351612091, 0.4867916703224182, 0.7367855906486511, 0.2682167589664459, 0.5364335179328918, 0.14048373699188232, 0.16858048737049103, 0.6743219494819641, 0.7059106230735779, 0.23530353605747223, 0.9413288235664368, 0.4559420645236969, 0.025596972554922104, 0.12798486649990082, 0.7423121929168701, 0.038395460695028305, 0.012798486277461052, 0.025596972554922104, 0.025596972554922104, 0.1397942304611206, 0.1397942304611206, 0.02795884758234024, 0.08387654274702072, 0.1397942304611206, 0.02795884758234024, 0.11183539032936096, 0.1957119256258011, 0.08387654274702072, 0.02795884758234024, 0.02795884758234024, 0.2507741451263428, 0.012538707815110683, 0.025077415630221367, 0.025077415630221367, 0.025077415630221367, 0.10030966252088547, 0.025077415630221367, 0.012538707815110683, 0.012538707815110683, 0.5140870213508606, 0.6097274422645569, 0.2032424807548523, 0.2032424807548523, 0.2779942750930786, 0.1389971375465393, 0.06949856877326965, 0.4169914126396179, 0.14312027394771576, 0.14312027394771576, 0.3578006625175476, 0.14312027394771576, 0.14312027394771576, 0.06189311668276787, 0.8252415657043457, 0.041262075304985046, 0.020631037652492523, 0.041262075304985046, 0.020631037652492523, 0.7135446071624756, 0.046541277319192886, 0.046541277319192886, 0.6795026063919067, 0.046541277319192886, 0.09308255463838577, 0.02792476676404476, 0.018616510555148125, 0.009308255277574062, 0.009308255277574062, 0.009308255277574062, 0.4592474400997162, 0.7365454435348511, 0.9477279186248779, 0.4592374265193939, 0.207331120967865, 0.11057659983634949, 0.5148723125457764, 0.03109966777265072, 0.08638796955347061, 0.017277592793107033, 0.006911037489771843, 0.0034555187448859215, 0.013822074979543686, 0.013822074979543686, 0.0281077828258276, 0.8994490504264832, 0.0281077828258276, 0.0281077828258276, 0.0281077828258276, 0.48454904556274414, 0.956200122833252, 0.025843247771263123, 0.7131189107894897, 0.11625944077968597, 0.08147314935922623, 0.014646858908236027, 0.02563200332224369, 0.004577143583446741, 0.017393143847584724, 0.006408000830560923, 0.002746286103501916, 0.0009154286817647517, 0.006408000830560923, 0.010069715790450573, 0.6946844458580017, 0.4846446216106415, 0.141758993268013, 0.141758993268013, 0.567035973072052, 0.8329070806503296, 0.03945454955101013, 0.07890909910202026, 0.2367272973060608, 0.03945454955101013, 0.07890909910202026, 0.03945454955101013, 0.2761818468570709, 0.1183636486530304, 0.07890909910202026, 0.476188987493515, 0.2482534497976303, 0.2482534497976303, 0.37238016724586487, 0.4559299051761627, 0.748958945274353, 0.8617535829544067, 0.9540120959281921, 0.0227296631783247, 0.9432809948921204, 0.02841207943856716, 0.3193362057209015, 0.039917025715112686, 0.039917025715112686, 0.07983405143022537, 0.43908727169036865, 0.26454344391822815, 0.23147551715373993, 0.09920378774404526, 0.13227172195911407, 0.03306793048977852, 0.06613586097955704, 0.03306793048977852, 0.1653396487236023, 0.11214863508939743, 0.16021233797073364, 0.2723609507083893, 0.16021233797073364, 0.11214863508939743, 0.03204246610403061, 0.016021233052015305, 0.03204246610403061, 0.08010616898536682, 0.016021233052015305, 0.08067105710506439, 0.08067105710506439, 0.726039469242096, 0.08067105710506439, 0.9162876009941101, 0.033936578780412674, 0.45663750171661377, 0.9291278719902039, 0.1182619258761406, 0.5913096070289612, 0.1182619258761406, 0.1182619258761406, 0.1182619258761406, 0.4592651426792145, 0.960506796836853, 0.8598649501800537, 0.15229761600494385, 0.33273717761039734, 0.1804395616054535, 0.3029398024082184, 0.00993245281279087, 0.0165540874004364, 0.0016554088797420263, 0.0016554088797420263, 0.0016554088797420263, 0.3546121418476105, 0.24715392291545868, 0.1611873358488083, 0.0429832898080349, 0.02149164490401745, 0.010745822452008724, 0.010745822452008724, 0.0429832898080349, 0.053729113191366196, 0.010745822452008724, 0.02149164490401745, 0.7024434804916382, 0.4592532217502594, 0.27512282133102417, 0.5502456426620483, 0.4838917553424835, 0.173381045460701, 0.5201431512832642, 0.173381045460701, 0.173381045460701, 0.476188987493515, 0.7281931638717651, 0.7370364665985107, 0.6124799251556396, 0.10207998007535934, 0.2041599601507187, 0.7489603757858276, 0.45663759112358093, 0.9543784260749817, 0.9502159953117371, 0.4838917553424835, 0.07723195105791092, 0.07723195105791092, 0.07723195105791092, 0.386159747838974, 0.23169584572315216, 0.07723195105791092, 0.07723195105791092, 0.20718666911125183, 0.28813058137893677, 0.41808637976646423, 0.059408366680145264, 0.0133668826892972, 0.004455627407878637, 0.003713022917509079, 0.005198231898248196, 0.0007426045485772192, 0.30392682552337646, 0.6078536510467529, 0.20003001391887665, 0.6000900268554688, 0.3305504322052002, 0.09916513413190842, 0.13222017884254456, 0.06611008942127228, 0.03305504471063614, 0.06611008942127228, 0.03305504471063614, 0.03305504471063614, 0.1652752161026001, 0.03305504471063614, 0.6753315329551697, 0.005594579502940178, 0.07552681863307953, 0.8699570894241333, 0.002797289751470089, 0.04475663602352142, 0.002797289751470089, 0.007687117904424667, 0.25111252069473267, 0.6790287494659424, 0.025623725727200508, 0.03074847161769867, 0.002562372712418437, 0.002562372712418437, 0.4761603772640228, 0.723691463470459, 0.47618886828422546, 0.1902831643819809, 0.24102532863616943, 0.532792866230011, 0.012685543857514858, 0.9300387501716614, 0.034445881843566895, 0.38745421171188354, 0.05535060167312622, 0.11070120334625244, 0.05535060167312622, 0.2767530083656311, 0.11070120334625244, 0.18709279596805573, 0.7483711838722229, 0.08599141240119934, 0.2589191794395447, 0.6161142587661743, 0.005669763311743736, 0.02456897497177124, 0.003779842285439372, 0.001889921142719686, 0.001889921142719686, 0.8319656252861023, 0.47615718841552734, 0.4845981299877167, 0.2811586856842041, 0.5623173713684082, 0.749057948589325, 0.2190161645412445, 0.6570484638214111, 0.08902796357870102, 0.05341677740216255, 0.28488948941230774, 0.07122237235307693, 0.28488948941230774, 0.03561118617653847, 0.1068335548043251, 0.017805593088269234, 0.05341677740216255, 0.08322953432798386, 0.832295298576355, 0.531459629535675, 0.17715319991111755, 0.17715319991111755, 0.17715319991111755, 0.4838917553424835, 0.4838917553424835, 0.13190904259681702, 0.08345265686511993, 0.12114095687866211, 0.5796818733215332, 0.05384042486548424, 0.015254787169396877, 0.005384042393416166, 0.000897340418305248, 0.006281382869929075, 0.001794680836610496, 0.050699248909950256, 0.020279699936509132, 0.21800677478313446, 0.6590902209281921, 0.040559399873018265, 0.015209775418043137, 0.0503767728805542, 0.1007535457611084, 0.2015070915222168, 0.6045212745666504, 0.0251883864402771, 0.4559355676174164, 0.02552386373281479, 0.8933352828025818, 0.02552386373281479, 0.05104772746562958, 0.46373021602630615, 0.2276010513305664, 0.1138005256652832, 0.1138005256652832, 0.1138005256652832, 0.4552021026611328, 0.4761565625667572, 0.9444577097892761, 0.4838917553424835, 0.8923149704933167, 0.15911804139614105, 0.15911804139614105, 0.14585819840431213, 0.14585819840431213, 0.1988975554704666, 0.026519672945141792, 0.0662991851568222, 0.026519672945141792, 0.0662991851568222, 0.8519040942192078, 0.4559149444103241, 0.4761580526828766, 0.47615233063697815, 0.09514982998371124, 0.19029965996742249, 0.6660488247871399, 0.48464080691337585, 0.4531836211681366, 0.06474051624536514, 0.12948103249073029, 0.25896206498146057, 0.12948103249073029, 0.19924533367156982, 0.5977360010147095, 0.19924533367156982, 0.27273496985435486, 0.19835270941257477, 0.17355862259864807, 0.04958817735314369, 0.29752904176712036, 0.8933039307594299, 0.0812094509601593, 0.04060472548007965, 0.05640347674489021, 0.05640347674489021, 0.886340320110321, 0.008057639002799988, 0.700486421585083, 0.20296840369701385, 0.7611315250396729, 0.07179009169340134, 0.07179009169340134, 0.07179009169340134, 0.2153702825307846, 0.07179009169340134, 0.4307405650615692, 0.9047201871871948, 0.4761890470981598, 0.7192111015319824, 0.9310864210128784, 0.1582377851009369, 0.1582377851009369, 0.47471335530281067, 0.5954477787017822, 0.049620646983385086, 0.09924129396677017, 0.07443097233772278, 0.024810323491692543, 0.12405162304639816, 0.15538857877254486, 0.07769428938627243, 0.15538857877254486, 0.38847142457962036, 0.07769428938627243, 0.09879621863365173, 0.09879621863365173, 0.09879621863365173, 0.09879621863365173, 0.19759243726730347, 0.09879621863365173, 0.39518487453460693, 0.34261825680732727, 0.17130912840366364, 0.5139274001121521, 0.7357586026191711, 0.48464062809944153, 0.6889363527297974, 0.4846678078174591, 0.46376487612724304, 0.2686375677585602, 0.5372751355171204, 0.46378499269485474, 0.07683142274618149, 0.07683142274618149, 0.038415711373090744, 0.4994042217731476, 0.19207854568958282, 0.038415711373090744, 0.07683142274618149, 0.009207142516970634, 0.11048571020364761, 0.43273571133613586, 0.4143214225769043, 0.01841428503394127, 0.8387253284454346, 0.11981789767742157, 0.023963579908013344, 0.023963579908013344, 0.6894654035568237, 0.16806133091449738, 0.16806133091449738, 0.16806133091449738, 0.5041840076446533, 0.8615345358848572, 0.2726946771144867, 0.13877730071544647, 0.20411601662635803, 0.3218337297439575, 0.028619442135095596, 0.02483951672911644, 0.003779926337301731, 0.0016199684469029307, 0.0005399895017035306, 0.002699947450309992, 0.0005399895017035306, 0.7703743577003479, 0.11005347967147827, 0.21072760224342346, 0.21072760224342346, 0.5268189907073975, 0.06366883218288422, 0.08913636207580566, 0.14398950338363647, 0.6298316717147827, 0.043098900467157364, 0.016651848331093788, 0.00587712274864316, 0.0009795204969123006, 0.00293856137432158, 0.001959040993824601, 0.0009795204969123006, 0.9307464361190796, 0.10629932582378387, 0.850394606590271, 0.8927294015884399, 0.367657870054245, 0.23789627850055695, 0.37847134470939636, 0.01081346720457077, 0.12660366296768188, 0.09890911728143692, 0.28881460428237915, 0.2611200511455536, 0.11077820509672165, 0.0870400220155716, 0.003956364467740059, 0.003956364467740059, 0.003956364467740059, 0.015825457870960236, 0.8386232256889343, 0.0885869562625885, 0.029528986662626266, 0.005905797239392996, 0.005905797239392996, 0.023623188957571983, 0.005905797239392996, 0.05575309321284294, 0.02787654660642147, 0.8920494914054871, 0.06196954473853111, 0.867573618888855, 0.794887900352478, 0.686283528804779, 0.7665351629257202, 0.05475251376628876, 0.16425754129886627, 0.4637850821018219, 0.0038847709074616432, 0.04661725088953972, 0.850764811038971, 0.08158019185066223, 0.01165431272238493, 0.21142907440662384, 0.7752399444580078, 0.03923153504729271, 0.03923153504729271, 0.21297119557857513, 0.571659505367279, 0.112090103328228, 0.011209010146558285, 0.005604505073279142, 0.005604505073279142, 0.005890242755413055, 0.01178048551082611, 0.20026825368404388, 0.4653291702270508, 0.2945121228694916, 0.005890242755413055, 0.005890242755413055, 0.005890242755413055, 0.45663750171661377, 0.8504631519317627, 0.12149474024772644, 0.15859314799308777, 0.277538001537323, 0.15859314799308777, 0.07929657399654388, 0.277538001537323, 0.03964828699827194, 0.07929657399654388, 0.009357491508126259, 0.8951999545097351, 0.015595818869769573, 0.021834146231412888, 0.009357491508126259, 0.012476654723286629, 0.003119163680821657, 0.009357491508126259, 0.021834146231412888, 0.09484552592039108, 0.474227637052536, 0.28453657031059265, 0.09484552592039108, 0.04685449227690697, 0.9078058004379272, 0.023427246138453484, 0.011713623069226742, 0.6900784373283386, 0.003979997243732214, 0.8835594058036804, 0.10745992511510849, 0.003979997243732214, 0.1265663504600525, 0.253132700920105, 0.37969905138015747, 0.1265663504600525, 0.2859216034412384, 0.0714804008603096, 0.16083090007305145, 0.13402575254440308, 0.0357402004301548, 0.026805149391293526, 0.08041545003652573, 0.0178701002150774, 0.0714804008603096, 0.09828554838895798, 0.0178701002150774, 0.9459171891212463, 0.9694634079933167, 0.006506465841084719, 0.019519397988915443, 0.48464569449424744, 0.21090564131736755, 0.6327168941497803, 0.1748955398797989, 0.26234331727027893, 0.08744776993989944, 0.08744776993989944, 0.3497910797595978, 0.08744776993989944, 0.08744776993989944, 0.6580365896224976, 0.28201568126678467, 0.15655720233917236, 0.6262288093566895, 0.15655720233917236, 0.932676374912262, 0.6965088248252869, 0.12418374419212341, 0.010798586532473564, 0.15657950937747955, 0.010798586532473564, 0.01259085163474083, 0.9569047093391418, 0.01259085163474083, 0.01259085163474083, 0.27898547053337097, 0.11159418523311615, 0.15344199538230896, 0.13949273526668549, 0.08369563519954681, 0.06974636763334274, 0.013949273154139519, 0.04184781759977341, 0.11159418523311615, 0.27431637048721313, 0.5486327409744263, 0.003303630044683814, 0.9151055216789246, 0.06607260555028915, 0.003303630044683814, 0.009910889901220798, 0.003303630044683814, 0.45926156640052795, 0.9406027793884277, 0.9032394886016846, 0.06947995722293854, 0.12044332921504974, 0.7935090065002441, 0.007084901910275221, 0.007084901910275221, 0.021254705265164375, 0.03542450815439224, 0.007084901910275221, 0.8589909076690674, 0.2000780552625656, 0.8003122210502625, 0.9646861553192139, 0.19107016921043396, 0.031845029443502426, 0.06369005888700485, 0.06369005888700485, 0.15922513604164124, 0.06369005888700485, 0.1273801177740097, 0.2229151874780655, 0.06369005888700485, 0.8475558161735535, 0.06780446320772171, 0.06780446320772171, 0.23655551671981812, 0.2005990743637085, 0.2573724091053009, 0.2110075205564499, 0.04163376986980438, 0.019870663061738014, 0.007569776847958565, 0.007569776847958565, 0.007569776847958565, 0.005677332635968924, 0.002838666317984462, 0.0018924442119896412, 0.4637832045555115, 0.7975541353225708, 0.1993885338306427, 0.459237664937973, 0.1936781406402588, 0.5810344219207764, 0.1936781406402588, 0.7967429757118225, 0.013436412438750267, 0.9002396464347839, 0.013436412438750267, 0.013436412438750267, 0.013436412438750267, 0.026872824877500534, 0.013436412438750267, 0.6574040651321411, 0.07304489612579346, 0.29217958450317383, 0.1536768227815628, 0.1536768227815628, 0.4610304832458496, 0.1536768227815628, 0.1536768227815628, 0.7233397960662842, 0.18347179889678955, 0.03669435903429985, 0.0733887180685997, 0.0733887180685997, 0.5137210488319397, 0.11008308082818985, 0.03669435903429985, 0.07609771937131882, 0.8578288555145264, 0.020753923803567886, 0.003458987222984433, 0.017294935882091522, 0.006917974445968866, 0.006917974445968866, 0.006917974445968866, 0.919292688369751, 0.035357411950826645, 0.6137633919715881, 0.0371977798640728, 0.1115933433175087, 0.09299445152282715, 0.0185988899320364, 0.09299445152282715, 0.8756041526794434, 0.0239393413066864, 0.1316663771867752, 0.7899982929229736, 0.0359090119600296, 0.0119696706533432, 0.39243629574775696, 0.09472599625587463, 0.027064571157097816, 0.1217905730009079, 0.18945199251174927, 0.027064571157097816, 0.013532285578548908, 0.05412914231419563, 0.06766142696142197, 0.027064571157097816, 0.38205552101135254, 0.5730832815170288, 0.03183240443468094, 0.12732961773872375, 0.8117262721061707, 0.01591620221734047, 0.8002957105636597, 0.11166916787624359, 0.037223055958747864, 0.018611527979373932, 0.037223055958747864, 0.0473562628030777, 0.8997690081596375, 0.0473562628030777, 0.04178186133503914, 0.3405221700668335, 0.5348078012466431, 0.03969276696443558, 0.02298002317547798, 0.0020890929736196995, 0.0020890929736196995, 0.010445465333759785, 0.004178185947239399, 0.7041317820549011, 0.1686982363462448, 0.02200411818921566, 0.04400823637843132, 0.007334705907851458, 0.007334705907851458, 0.02200411818921566, 0.02200411818921566, 0.5812408924102783, 0.2112981528043747, 0.057440273463726044, 0.12035105377435684, 0.0027352510951459408, 0.00820575375109911, 0.012308630160987377, 0.004102876875549555, 0.0020514384377747774, 0.9326851963996887, 0.006652774754911661, 0.961326003074646, 0.026611099019646645, 0.0033263873774558306, 0.31071510910987854, 0.2996181547641754, 0.37729692459106445, 0.04020427539944649, 0.3618384897708893, 0.06030641496181488, 0.10051068663597107, 0.04020427539944649, 0.06030641496181488, 0.06030641496181488, 0.14071495831012726, 0.06030641496181488, 0.04020427539944649, 0.020102137699723244, 0.020102137699723244, 0.694534182548523, 0.23151139914989471, 0.7384682297706604, 0.8179072141647339, 0.07216828316450119, 0.012028046883642673, 0.08419632911682129, 0.22466889023780823, 0.44933778047561646, 0.22466889023780823, 0.45663759112358093, 0.48463526368141174, 0.8527120351791382, 0.19429636001586914, 0.5828890800476074, 0.19429636001586914, 0.1807081401348114, 0.14456650614738464, 0.6144076585769653, 0.03614162653684616, 0.19209282100200653, 0.7683712840080261, 0.33613595366477966, 0.2280922532081604, 0.08003237098455429, 0.13605503737926483, 0.09203723073005676, 0.024009712040424347, 0.0080032367259264, 0.0160064734518528, 0.012004856020212173, 0.028011329472064972, 0.012004856020212173, 0.024009712040424347, 0.8810408115386963, 0.07773889601230621, 0.025912964716553688, 0.08545573800802231, 0.769101619720459, 0.08545573800802231, 0.4846678078174591, 0.8779956102371216, 0.063060462474823, 0.048508044332265854, 0.004850804805755615, 0.08349741250276566, 0.04174870625138283, 0.2504922151565552, 0.2504922151565552, 0.2504922151565552, 0.08349741250276566, 0.04174870625138283, 0.3763551115989685, 0.1478537917137146, 0.10753003507852554, 0.05376501753926277, 0.0806475281715393, 0.12097128480672836, 0.04032376408576965, 0.04032376408576965, 0.026882508769631386, 0.7489569187164307, 0.45926180481910706, 0.06317415833473206, 0.2861417531967163, 0.39762556552886963, 0.22296760976314545, 0.018580634146928787, 0.0037161267828196287, 0.0037161267828196287, 0.0018580633914098144, 0.0018580633914098144, 0.9177977442741394, 0.4610387086868286, 0.05122652277350426, 0.10245304554700851, 0.2561326324939728, 0.05122652277350426, 0.05122652277350426, 0.6903547644615173, 0.3249601721763611, 0.1420196294784546, 0.19016188383102417, 0.08424893766641617, 0.12035562098026276, 0.07462048530578613, 0.02888534963130951, 0.002407112391665578, 0.009628449566662312, 0.009628449566662312, 0.01203556265681982, 0.43646761775016785, 0.17458704113960266, 0.16367535293102264, 0.125484436750412, 0.010911690071225166, 0.016367536038160324, 0.0709259882569313, 0.005455845035612583, 0.2283734679222107, 0.2283734679222107, 0.07612448930740356, 0.3806224465370178, 0.15224897861480713, 0.7967908978462219, 0.6536784768104553, 0.013073569163680077, 0.20917710661888123, 0.052294276654720306, 0.032683923840522766, 0.01961035467684269, 0.006536784581840038, 0.013073569163680077, 0.689583420753479, 0.8396645188331604, 0.272868812084198, 0.2079000473022461, 0.09095627069473267, 0.11694377660751343, 0.0649687647819519, 0.07796251773834229, 0.02598750591278076, 0.03898125886917114, 0.01299375295639038, 0.01299375295639038, 0.07796251773834229, 0.02598750591278076, 0.4559171795845032, 0.6901587247848511, 0.19703266024589539, 0.2534480094909668, 0.1919805407524109, 0.30565324425697327, 0.029470697045326233, 0.013472318649291992, 0.003368079662322998, 0.0025260597467422485, 0.001684039831161499, 0.0008420199155807495, 0.07318605482578278, 0.6586744785308838, 0.14637210965156555, 0.07318605482578278, 0.8930575251579285, 0.07997529953718185, 0.013329217210412025, 0.061995528638362885, 0.12399105727672577, 0.061995528638362885, 0.7439463138580322, 0.45663756132125854, 0.9769738912582397, 0.00814144965261221, 0.00814144965261221, 0.6740837693214417, 0.4559139609336853, 0.7024179697036743, 0.8613336086273193, 0.022028207778930664, 0.23129618167877197, 0.5947616100311279, 0.13216924667358398, 0.011014103889465332, 0.4761819541454315, 0.957985520362854, 0.03646883741021156, 0.9481897354125977, 0.7365357875823975, 0.9525316953659058, 0.05677388980984688, 0.6853419542312622, 0.21087445318698883, 0.012165834195911884, 0.004055277910083532, 0.008110555820167065, 0.008110555820167065, 0.008110555820167065, 0.004429931752383709, 0.9435754418373108, 0.026579588651657104, 0.017719727009534836, 0.004429931752383709, 0.004429931752383709, 0.2699187397956848, 0.5398374795913696, 0.1349593698978424, 0.1349593698978424, 0.9380443692207336, 0.04078453779220581, 0.8751261830329895, 0.0629267618060112, 0.1510242223739624, 0.7299504280090332, 0.0377560555934906, 0.012585352174937725, 0.06470321118831635, 0.26497504115104675, 0.526868999004364, 0.11400089412927628, 0.0184866301715374, 0.0030811051838099957, 0.0030811051838099957, 0.0030811051838099957, 0.9437887668609619, 0.2830733060836792, 0.16984398663043976, 0.11322932690382004, 0.05661466345191002, 0.3396879732608795, 0.05661466345191002, 0.037026241421699524, 0.8674718737602234, 0.07228932529687881, 0.014105234295129776, 0.007052617147564888, 0.001763154286891222, 0.8842957615852356, 0.47615498304367065, 0.9420815706253052, 0.9552919864654541, 0.4761570394039154, 0.07288961112499237, 0.04859307035803795, 0.8017857074737549, 0.07288961112499237, 0.05597025528550148, 0.02798512764275074, 0.8395538330078125, 0.02798512764275074, 0.05597025528550148, 0.1375601440668106, 0.0687800720334053, 0.1375601440668106, 0.4814605116844177, 0.0687800720334053, 0.0687800720334053, 0.0687800720334053, 0.12419889867305756, 0.12419889867305756, 0.6209944486618042, 0.719173789024353, 0.694666862487793, 0.030138002708554268, 0.9041401147842407, 0.052741505205631256, 0.007534500677138567, 0.10893701761960983, 0.12830360233783722, 0.412750244140625, 0.1670367568731308, 0.11983072012662888, 0.029049871489405632, 0.00847287941724062, 0.001210411312058568, 0.006052056327462196, 0.006052056327462196, 0.009683290496468544, 0.001210411312058568, 0.8750367164611816, 0.9477564096450806, 0.12978293001651764, 0.12978293001651764, 0.12978293001651764, 0.3893488049507141, 0.6912322640419006, 0.40338778495788574, 0.062059659510850906, 0.15514914691448212, 0.062059659510850906, 0.21720880270004272, 0.062059659510850906, 0.031029829755425453, 0.4637396037578583, 0.8405143022537231, 0.007641038857400417, 0.03820519521832466, 0.022923117503523827, 0.015282077714800835, 0.03056415542960167, 0.022923117503523827, 0.015282077714800835, 0.6103003621101379, 0.271244615316391, 0.06781115382909775, 0.04135778918862343, 0.8585307002067566, 0.07273266464471817, 0.021391959860920906, 0.002852261532098055, 0.0014261307660490274, 0.9429954886436462, 0.03364017978310585, 0.9335150122642517, 0.004205022472888231, 0.004205022472888231, 0.02102511376142502, 0.6999775171279907, 0.45591074228286743, 0.6889142990112305, 0.3710152506828308, 0.07950326800346375, 0.05300217866897583, 0.10600435733795166, 0.05300217866897583, 0.026501089334487915, 0.1855076253414154, 0.05300217866897583, 0.05300217866897583, 0.2709979712963104, 0.08622662723064423, 0.18785086274147034, 0.3510655462741852, 0.049272358417510986, 0.024636179208755493, 0.024636179208755493, 0.0030795224010944366, 0.4845927059650421, 0.4559103846549988, 0.45663759112358093, 0.4141244888305664, 0.046013832092285156, 0.2185657024383545, 0.09202766418457031, 0.023006916046142578, 0.06902074813842773, 0.011503458023071289, 0.011503458023071289, 0.12653803825378418, 0.45923328399658203, 0.06816466152667999, 0.012623085640370846, 0.09846006333827972, 0.777582049369812, 0.01767231896519661, 0.022721553221344948, 0.002524617128074169, 0.002524617128074169, 0.5697164535522461, 0.28485822677612305, 0.04176761582493782, 0.1871808022260666, 0.7301598191261292, 0.0015469486825168133, 0.032485924661159515, 0.0030938973650336266, 0.0015469486825168133, 0.0015469486825168133, 0.14716872572898865, 0.7358436584472656, 0.10399507731199265, 0.0656810998916626, 0.4159803092479706, 0.17241288721561432, 0.17241288721561432, 0.041050687432289124, 0.002736712573096156, 0.008210137486457825, 0.008210137486457825, 0.008210137486457825, 0.002736712573096156, 0.8510759472846985, 0.07092299312353134, 0.03546149656176567, 0.03546149656176567, 0.5797943472862244, 0.8920799493789673, 0.8439728617668152, 0.04462385177612305, 0.01940167509019375, 0.009700837545096874, 0.0058205025270581245, 0.0252221766859293, 0.011641005054116249, 0.01358117163181305, 0.001940167392604053, 0.007760669570416212, 0.01358117163181305, 0.9245501756668091, 0.04202500730752945, 0.17596563696861267, 0.05027589574456215, 0.4273451268672943, 0.025137947872281075, 0.07541384547948837, 0.2011035829782486, 0.025137947872281075, 0.239144429564476, 0.239144429564476, 0.478288859128952, 0.24496537446975708, 0.1837240308523178, 0.06124134361743927, 0.06124134361743927, 0.06124134361743927, 0.06124134361743927, 0.24496537446975708, 0.06124134361743927, 0.9090718626976013, 0.9639609456062317, 0.7372311949729919, 0.48457103967666626, 0.33481454849243164, 0.25509679317474365, 0.07971774786710739, 0.07174596935510635, 0.00797177478671074, 0.023915324360132217, 0.09566129744052887, 0.06377419829368591, 0.00797177478671074, 0.039858873933553696, 0.01594354957342148, 0.9504281282424927, 0.02318117395043373, 0.2252187430858612, 0.08445702493190765, 0.0563046857714653, 0.1689140498638153, 0.08445702493190765, 0.0563046857714653, 0.0563046857714653, 0.1689140498638153, 0.08445702493190765, 0.02815234288573265, 0.2806430757045746, 0.2664332985877991, 0.20367345213890076, 0.20248930156230927, 0.015393923036754131, 0.009473183192312717, 0.013025627471506596, 0.0011841478990390897, 0.003552443813532591, 0.0023682957980781794, 0.31308144330978394, 0.13674820959568024, 0.09356456995010376, 0.050380922853946686, 0.19072777032852173, 0.03598637133836746, 0.03598637133836746, 0.03598637133836746, 0.028789097443223, 0.03598637133836746, 0.0143945487216115, 0.025190461426973343, 0.23258554935455322, 0.6977566480636597, 0.9127432703971863, 0.723809540271759, 0.6946805119514465, 0.4846678078174591, 0.3959544003009796, 0.26568368077278137, 0.15912453830242157, 0.14969705045223236, 0.007427716162055731, 0.012855662032961845, 0.005427946336567402, 0.0017140882555395365, 0.0005713627906516194, 0.0011427255813032389, 0.8396750092506409, 0.9746313095092773, 0.7004151344299316, 0.2271874099969864, 0.6815622448921204, 0.3802785873413086, 0.1901392936706543, 0.3802785873413086, 0.9574534893035889, 0.13477499783039093, 0.23585623502731323, 0.13477499783039093, 0.03369374945759773, 0.06738749891519547, 0.03369374945759773, 0.1010812446475029, 0.2021624892950058, 0.03369374945759773, 0.2459222376346588, 0.22133000195026398, 0.09836889058351517, 0.27051445841789246, 0.024592222645878792, 0.1229611188173294, 0.024592222645878792, 0.5490706562995911, 0.36604711413383484, 0.47518834471702576, 0.03959902748465538, 0.03959902748465538, 0.11879708617925644, 0.03959902748465538, 0.03959902748465538, 0.15839610993862152, 0.46819937229156494, 0.26115795969963074, 0.15444499254226685, 0.08907949179410934, 0.00699258828535676, 0.007904664613306522, 0.00699258828535676, 0.0006080511375330389, 0.00030402556876651943, 0.0024322045501321554, 0.0006080511375330389, 0.0009120767354033887, 0.29831117391586304, 0.10653969645500183, 0.1917714625597, 0.021307939663529396, 0.25569528341293335, 0.021307939663529396, 0.04261587932705879, 0.04261587932705879, 0.9432362914085388, 0.013994467444717884, 0.9236348271369934, 0.04198340326547623, 0.013994467444717884, 0.013994467444717884, 0.14359132945537567, 0.14359132945537567, 0.14359132945537567, 0.5743653178215027, 0.9512439966201782, 0.028205296024680138, 0.9307747483253479, 0.028205296024680138, 0.9194484949111938, 0.4637884795665741, 0.4559100866317749, 0.05048487335443497, 0.19184252619743347, 0.7269821763038635, 0.020193949341773987, 0.83335942029953, 0.05339399725198746, 0.898798942565918, 0.01779799908399582, 0.00296633318066597, 0.00296633318066597, 0.00593266636133194, 0.00296633318066597, 0.01483166590332985, 0.39040932059288025, 0.18092139065265656, 0.03808871656656265, 0.10474396497011185, 0.009522179141640663, 0.0761774331331253, 0.03808871656656265, 0.019044358283281326, 0.019044358283281326, 0.019044358283281326, 0.10474396497011185, 0.4061032235622406, 0.21658839285373688, 0.02707354910671711, 0.018049031496047974, 0.03609806299209595, 0.06317161023616791, 0.02707354910671711, 0.06317161023616791, 0.009024515748023987, 0.1353677362203598, 0.9330952167510986, 0.24564670026302338, 0.7369400858879089, 0.025848697870969772, 0.051697395741939545, 0.6979148387908936, 0.20678958296775818, 0.012924348935484886, 0.40217098593711853, 0.6032564640045166, 0.5615729093551636, 0.2807864546775818, 0.7372013330459595, 0.7771021127700806, 0.05180680751800537, 0.1554204225540161, 0.19228936731815338, 0.5768680572509766, 0.19228936731815338, 0.9206629991531372, 0.05415664613246918, 0.9663750529289246, 0.02147500030696392, 0.4637870490550995, 0.4846678078174591, 0.8879443407058716, 0.922669529914856, 0.8896237015724182, 0.1351184844970703, 0.11822867393493652, 0.08444905281066895, 0.5995882749557495, 0.04222452640533447, 0.008444905281066895, 0.008444905281066895, 0.044006966054439545, 0.08801393210887909, 0.8361323475837708, 0.7383485436439514, 0.2708064317703247, 0.5416128635406494, 0.0846250131726265, 0.04231250658631325, 0.5923750996589661, 0.169250026345253, 0.04231250658631325, 0.04231250658631325, 0.17845533788204193, 0.7066830992698669, 0.06424392014741898, 0.021414639428257942, 0.014276426285505295, 0.007138213142752647, 0.014276426285505295, 0.3449452817440033, 0.05913347750902176, 0.15768927335739136, 0.08870021253824234, 0.08870021253824234, 0.02956673875451088, 0.00985557958483696, 0.03942231833934784, 0.10841137170791626, 0.03942231833934784, 0.00985557958483696, 0.02956673875451088, 0.680531919002533, 0.02651423029601574, 0.02651423029601574, 0.06186653673648834, 0.044190384447574615, 0.0707046166062355, 0.008838077075779438, 0.017676154151558876, 0.017676154151558876, 0.03535230830311775, 0.008838077075779438, 0.45590871572494507, 0.7023909687995911, 0.6882297992706299, 0.17842994630336761, 0.09738484025001526, 0.011764612048864365, 0.009150253608822823, 0.0026143582072108984, 0.005228716414421797, 0.0006535895518027246, 0.0026143582072108984, 0.001960768597200513, 0.0026143582072108984, 0.6057921051979065, 0.2019307166337967, 0.2019307166337967, 0.7191746830940247, 0.28798654675483704, 0.5759730935096741, 0.8993419408798218, 0.7981509566307068, 0.1226857528090477, 0.1889360547065735, 0.6085213422775269, 0.05643544718623161, 0.009814860299229622, 0.009814860299229622, 0.0024537150748074055, 0.6901760101318359, 0.8752155900001526, 0.7019729614257812, 0.23060902953147888, 0.46121805906295776, 0.23060902953147888, 0.0021825283765792847, 0.9253920912742615, 0.06111079826951027, 0.0021825283765792847, 0.004365056753158569, 0.0021825283765792847, 0.96196049451828, 0.008342224173247814, 0.8675913214683533, 0.10566817224025726, 0.00278074131347239, 0.01112296525388956, 0.8121719360351562, 0.1633259505033493, 0.1633259505033493, 0.4899778366088867, 0.9559754133224487, 0.7191627621650696, 0.10101678222417831, 0.058926455676555634, 0.2525419592857361, 0.15994323790073395, 0.3283045291900635, 0.04209032654762268, 0.016836130991578102, 0.016836130991578102, 0.033672261983156204, 0.455914705991745, 0.6916235685348511, 0.2305411845445633, 0.9430103302001953, 0.04386094585061073, 0.0073101576417684555, 0.25222790241241455, 0.3363038897514343, 0.16815194487571716, 0.16815194487571716, 0.08407597243785858, 0.47617045044898987, 0.21671462059020996, 0.5056674480438232, 0.024079402908682823, 0.048158805817365646, 0.048158805817365646, 0.024079402908682823, 0.024079402908682823, 0.09631761163473129, 0.2875992953777313, 0.17698419094085693, 0.17698419094085693, 0.04424604773521423, 0.19910721480846405, 0.04424604773521423, 0.022123023867607117, 0.022123023867607117, 0.6905633211135864, 0.45663750171661377, 0.11219713091850281, 0.3646406829357147, 0.5048871040344238, 0.45591023564338684, 0.48634666204452515, 0.11830053478479385, 0.07886702567338943, 0.20373980700969696, 0.00657225213944912, 0.03943351283669472, 0.02628900855779648, 0.01971675641834736, 0.01971675641834736, 0.7104145884513855, 0.4592639207839966, 0.9023883938789368, 0.8669110536575317, 0.2701105773448944, 0.18650493025779724, 0.19293613731861115, 0.16721132397651672, 0.05144963786005974, 0.019293613731861115, 0.08360566198825836, 0.019293613731861115, 0.4339149296283722, 0.1584520787000656, 0.07556945085525513, 0.19014249742031097, 0.007313172798603773, 0.0024377242662012577, 0.04144131392240524, 0.007313172798603773, 0.0487544871866703, 0.0024377242662012577, 0.007313172798603773, 0.02437724359333515, 0.21448993682861328, 0.10724496841430664, 0.16086745262145996, 0.2681124210357666, 0.10724496841430664, 0.16086745262145996, 0.4761548638343811, 0.04314623773097992, 0.39910268783569336, 0.5285413861274719, 0.02157311886548996, 0.10655198246240616, 0.7458638548851013, 0.8151565790176392, 0.6900413632392883, 0.4130469560623169, 0.11956622451543808, 0.07971081137657166, 0.19565381109714508, 0.03623218834400177, 0.010869656689465046, 0.014492874965071678, 0.04710184410214424, 0.0253625325858593, 0.028985749930143356, 0.007246437482535839, 0.021739313378930092, 0.4592615067958832, 0.86304771900177, 0.061646267771720886, 0.08184600621461868, 0.04092300310730934, 0.16369201242923737, 0.04092300310730934, 0.6138450503349304, 0.14977777004241943, 0.37077853083610535, 0.4399067461490631, 0.013616161420941353, 0.014663558453321457, 0.009426573291420937, 0.002094794064760208, 0.001047397032380104, 0.839647114276886, 0.9422209858894348, 0.9130337238311768, 0.04347779601812363, 0.7237598896026611, 0.5275070667266846, 0.07535815238952637, 0.37679076194763184, 0.02789190597832203, 0.00929730199277401, 0.10227032750844955, 0.3718920946121216, 0.4090813100337982, 0.0464865118265152, 0.00929730199277401, 0.00929730199277401, 0.01859460398554802, 0.45663750171661377, 0.7294092774391174, 0.12424807250499725, 0.08624278008937836, 0.02046438865363598, 0.001461742096580565, 0.00292348419316113, 0.019002646207809448, 0.0043852259404957294, 0.00584696838632226, 0.00584696838632226, 0.8044979572296143, 0.07098511606454849, 0.07098511606454849, 0.02366170473396778, 0.02366170473396778, 0.4262520670890808, 0.22621271014213562, 0.164518341422081, 0.12650462985038757, 0.02461543306708336, 0.011528747156262398, 0.008412869647145271, 0.0024927021004259586, 0.001557938870973885, 0.0024927021004259586, 0.0043622287921607494, 0.0012463510502129793, 0.18719731271266937, 0.16816028952598572, 0.37756744027137756, 0.14912328124046326, 0.0666295513510704, 0.025382686406373978, 0.02220984920859337, 0.4592616558074951, 0.04890919849276543, 0.9292747974395752, 0.013974056579172611, 0.003493514144793153, 0.3409135043621063, 0.5113703012466431, 0.08477950841188431, 0.015414455905556679, 0.6628215909004211, 0.023121682927012444, 0.14643733203411102, 0.03853613883256912, 0.007707227952778339, 0.007707227952778339, 0.007707227952778339, 0.08805183321237564, 0.11102187633514404, 0.5933927893638611, 0.05359676852822304, 0.09953685849905014, 0.04211174696683884, 0.007656681351363659, 0.46373724937438965, 0.7024023532867432, 0.4637413024902344, 0.4637460708618164, 0.06822416931390762, 0.08528020977973938, 0.5671133995056152, 0.09380823373794556, 0.10660026222467422, 0.059696149080991745, 0.008528021164238453, 0.008528021164238453, 0.46374252438545227, 0.8318808078765869, 0.012798166833817959, 0.051192667335271835, 0.012798166833817959, 0.0383944995701313, 0.0383944995701313, 0.8798555135726929, 0.06851333379745483, 0.032453685998916626, 0.003605965059250593, 0.003605965059250593, 0.003605965059250593, 0.003605965059250593, 0.003605965059250593, 0.2894008457660675, 0.6029184460639954, 0.06358049064874649, 0.0043848613277077675, 0.0043848613277077675, 0.013154583983123302, 0.0021924306638538837, 0.0021924306638538837, 0.006577291991561651, 0.0043848613277077675, 0.0043848613277077675, 0.5774897933006287, 0.3464938700199127, 0.9768326878547668, 0.13091079890727997, 0.13091079890727997, 0.654554009437561, 0.336037814617157, 0.19202159345149994, 0.048005398362874985, 0.07200810313224792, 0.024002699181437492, 0.09601079672574997, 0.048005398362874985, 0.14401620626449585, 0.9431800842285156, 0.21111494302749634, 0.7811253070831299, 0.45924922823905945, 0.8931065201759338, 0.455920934677124, 0.12022054940462112, 0.4808821976184845, 0.12022054940462112, 0.24044109880924225, 0.463784784078598, 0.037699926644563675, 0.9424981474876404, 0.02162298746407032, 0.8703252673149109, 0.06757183372974396, 0.018920114263892174, 0.01081149373203516, 0.00540574686601758, 0.00270287343300879, 0.0074550979770720005, 0.059640783816576004, 0.20874273777008057, 0.4994915723800659, 0.17146725952625275, 0.037275489419698715, 0.0074550979770720005, 0.47618886828422546, 0.9522919058799744, 0.0297591220587492, 0.28861692547798157, 0.5772338509559631, 0.011667703278362751, 0.011667703278362751, 0.32669568061828613, 0.07000622153282166, 0.40836960077285767, 0.08167392015457153, 0.03500311076641083, 0.011667703278362751, 0.023335406556725502, 0.023335406556725502, 0.06344898045063019, 0.17448468506336212, 0.3225322961807251, 0.17448468506336212, 0.13747277855873108, 0.05816156417131424, 0.0052874148823320866, 0.026437073945999146, 0.026437073945999146, 0.0052874148823320866, 0.0052874148823320866, 0.29467037320137024, 0.14733518660068512, 0.44200557470321655, 0.4334692358970642, 0.2599562704563141, 0.24429625272750854, 0.03883684054017067, 0.004384804517030716, 0.007516807876527309, 0.005011205095797777, 0.0006264006369747221, 0.0025056025478988886, 0.0006264006369747221, 0.0025056025478988886, 0.0006264006369747221, 0.9310261011123657, 0.8319405317306519, 0.03869742900133133, 0.42567169666290283, 0.42567169666290283, 0.07739485800266266, 0.48456230759620667, 0.45591697096824646, 0.045199211686849594, 0.045199211686849594, 0.27119526267051697, 0.40679287910461426, 0.045199211686849594, 0.030132807791233063, 0.07533201575279236, 0.060265615582466125, 0.015066403895616531, 0.5645521283149719, 0.28227606415748596, 0.2952435314655304, 0.0922636017203331, 0.1660744845867157, 0.0738108828663826, 0.1291690468788147, 0.0369054414331913, 0.01845272071659565, 0.1476217657327652, 0.01845272071659565, 0.34803012013435364, 0.08700753003358841, 0.08700753003358841, 0.34803012013435364, 0.27562040090560913, 0.2509133815765381, 0.21302931010723114, 0.15812484920024872, 0.035687901079654694, 0.031295545399188995, 0.011529937386512756, 0.00109808926936239, 0.011529937386512756, 0.0032942676916718483, 0.007137580309063196, 0.000549044634681195, 0.8613399863243103, 0.08399185538291931, 0.7661075592041016, 0.10180830955505371, 0.040723323822021484, 0.0025452077388763428, 0.0025452077388763428, 0.0025452077388763428, 0.28439149260520935, 0.1761990785598755, 0.43895208835601807, 0.003091211896389723, 0.052550602704286575, 0.015456059947609901, 0.003091211896389723, 0.02163848467171192, 0.6945827603340149, 0.737111508846283, 0.7385900020599365, 0.45663750171661377, 0.909818172454834, 0.4959973096847534, 0.14171351492404938, 0.28342702984809875, 0.07085675746202469, 0.011695897206664085, 0.8771922588348389, 0.10526307672262192, 0.011695897206664085, 0.6839563250541687, 0.7364723682403564, 0.7371783256530762, 0.2926948666572571, 0.5853897333145142, 0.694683313369751, 0.8318895101547241, 0.8296141624450684, 0.56022709608078, 0.28011354804039, 0.7232003808021545, 0.45591697096824646, 0.9312837719917297, 0.0813913345336914, 0.0406956672668457, 0.1627826690673828, 0.1627826690673828, 0.2848696708679199, 0.0813913345336914, 0.0406956672668457, 0.0406956672668457, 0.4592617154121399, 0.05329551175236702, 0.7461372017860413, 0.10659102350473404, 0.05329551175236702, 0.7190902829170227, 0.45923706889152527, 0.05910848453640938, 0.2364339381456375, 0.05910848453640938, 0.05910848453640938, 0.2955424189567566, 0.11821696907281876, 0.05910848453640938, 0.11821696907281876, 0.8753998875617981, 0.8910809755325317, 0.02715487964451313, 0.009051626548171043, 0.07241301238536835, 0.30775532126426697, 0.5159427523612976, 0.02715487964451313, 0.018103253096342087, 0.009051626548171043, 0.018103253096342087, 0.27852770686149597, 0.5570554137229919, 0.23951998353004456, 0.11975999176502228, 0.598800003528595, 0.24995364248752594, 0.17738644778728485, 0.29161256551742554, 0.16663575172424316, 0.061816491186618805, 0.0067191836424171925, 0.008063020184636116, 0.004031510092318058, 0.02822057157754898, 0.004031510092318058, 0.0013438367750495672, 0.7371276617050171, 0.1606074422597885, 0.321214884519577, 0.08030372112989426, 0.321214884519577, 0.08030372112989426, 0.08030372112989426, 0.4846361577510834, 0.17336304485797882, 0.5200891494750977, 0.17336304485797882, 0.17336304485797882, 0.04947224631905556, 0.04947224631905556, 0.29683345556259155, 0.12368061393499374, 0.12368061393499374, 0.04947224631905556, 0.04947224631905556, 0.12368061393499374, 0.04947224631905556, 0.07420836389064789, 0.056431978940963745, 0.03762131929397583, 0.018810659646987915, 0.7148050665855408, 0.07524263858795166, 0.07524263858795166, 0.018810659646987915, 0.7686665058135986, 0.05549938604235649, 0.07769913971424103, 0.07492417097091675, 0.005549938417971134, 0.011099876835942268, 0.005549938417971134, 0.45663759112358093, 0.9639211297035217, 0.06366166472434998, 0.19098499417304993, 0.19098499417304993, 0.06366166472434998, 0.3183083236217499, 0.12732332944869995, 0.06366166472434998, 0.18445152044296265, 0.18445152044296265, 0.5533545613288879, 0.688966691493988, 0.48027414083480835, 0.019365891814231873, 0.23626388609409332, 0.05422449856996536, 0.1278148889541626, 0.02711224928498268, 0.007746357005089521, 0.011619535274803638, 0.007746357005089521, 0.007746357005089521, 0.019365891814231873, 0.09812630712985992, 0.2747536599636078, 0.23550313711166382, 0.07850104570388794, 0.2747536599636078, 0.019625261425971985, 0.019625261425971985, 0.09487250447273254, 0.00729788513854146, 0.20434078574180603, 0.5765329003334045, 0.09487250447273254, 0.01459577027708292, 0.3228391110897064, 0.046119872480630875, 0.046119872480630875, 0.4150788486003876, 0.046119872480630875, 0.046119872480630875, 0.046119872480630875, 0.9064139127731323, 0.45591098070144653, 0.0932275652885437, 0.0932275652885437, 0.5593653917312622, 0.0932275652885437, 0.0932275652885437, 0.2395578771829605, 0.479115754365921, 0.11977893859148026, 0.015296002849936485, 0.07648001611232758, 0.13766402006149292, 0.10707201808691025, 0.520064115524292, 0.045888010412454605, 0.03059200569987297, 0.015296002849936485, 0.03059200569987297, 0.03059200569987297, 0.8810346126556396, 0.03388594463467598, 0.06777188926935196, 0.9031354784965515, 0.7192177176475525, 0.05290959030389786, 0.8465534448623657, 0.02645479515194893, 0.02645479515194893, 0.02645479515194893, 0.19120587408542633, 0.7010881900787354, 0.03186764568090439, 0.03186764568090439, 0.45663759112358093, 0.9359336495399475, 0.062395576387643814, 0.24669495224952698, 0.08028534054756165, 0.28464803099632263, 0.23209761083126068, 0.07882560789585114, 0.03503360226750374, 0.02335573546588421, 0.001459733466617763, 0.004379200283437967, 0.01021813414990902, 0.001459733466617763, 0.4239383637905121, 0.5087260007858276, 0.7750294804573059, 0.039798811078071594, 0.08797632157802582, 0.00628402316942811, 0.046082835644483566, 0.01256804633885622, 0.00628402316942811, 0.00837869755923748, 0.00209467438980937, 0.00209467438980937, 0.014662720263004303, 0.9416354298591614, 0.18371149897575378, 0.09185574948787689, 0.18371149897575378, 0.36742299795150757, 0.18371149897575378, 0.8920313715934753, 0.09389803558588028, 0.15716339647769928, 0.6286535859107971, 0.15716339647769928, 0.36474141478538513, 0.5992180109024048, 0.02605295740067959, 0.6242007613182068, 0.3121003806591034, 0.9146175980567932, 0.08022961020469666, 0.052576493471860886, 0.013630942441523075, 0.25509336590766907, 0.5218703746795654, 0.13241487741470337, 0.011683665215969086, 0.0019472775747999549, 0.0019472775747999549, 0.0038945551495999098, 0.0038945551495999098, 0.07263672351837158, 0.014527345076203346, 0.29054689407348633, 0.13074611127376556, 0.20338283479213715, 0.20338283479213715, 0.014527345076203346, 0.029054690152406693, 0.04358203709125519, 0.014527345076203346, 0.014527345076203346, 0.5999343395233154, 0.2999671697616577, 0.07499179244041443, 0.07499179244041443, 0.058560773730278015, 0.907692015171051, 0.014640193432569504, 0.45926398038864136, 0.6226476430892944, 0.1556619107723236, 0.4846399128437042, 0.921480119228363, 0.06998583674430847, 0.2581601142883301, 0.12908005714416504, 0.12908005714416504, 0.3872401714324951, 0.6879168748855591], \"Term\": [\"-9.2\", \"3.1.15\", \"6.x\", \"@risk\", \"December\", \"December\", \"December\", \"December\", \"December\", \"December\", \"July\", \"July\", \"July\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a.\", \"a.\", \"a.\", \"a.\", \"a.\", \"academic\", \"academic\", \"academic\", \"academic\", \"academic\", \"academic\", \"academic\", \"academic\", \"academic\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"actionscript\", \"adaboost\", \"adaboost\", \"adjustedr\", \"adp\", \"adp\", \"adp\", \"adp\", \"adp\", \"adp\", \"advanced\", \"advanced\", \"advanced\", \"advanced\", \"advanced\", \"advanced\", \"advanced\", \"advertising\", \"advertising\", \"advertising\", \"agile\", \"agile\", \"agile\", \"agile\", \"agile\", \"agile\", \"agile\", \"agile\", \"agile\", \"agile(scrum\", \"aic\", \"aic\", \"aic\", \"ajax\", \"ajax\", \"ajax\", \"ajax\", \"ajax\", \"ajax\", \"ambari\", \"ampl\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analyst\", \"analyst\", \"analyst\", \"analytical\", \"analytical\", \"analytical\", \"analytical\", \"analytical\", \"analytical\", \"analytical\", \"analytical\", \"analytical\", \"analytics\", \"analytics\", \"analytics\", \"analytics\", \"analytics\", \"analytics\", \"analytics\", \"analytics\", \"analytics\", \"analytics\", \"analytics\", \"andexcel\", \"andexcel\", \"andreal\", \"android\", \"android\", \"android\", \"android\", \"android\", \"android\", \"android\", \"android\", \"android_studio\", \"android_studio\", \"android_studio\", \"andspss\", \"andspss\", \"andspss\", \"andunix\", \"angular_js\", \"angular_js\", \"angularjs\", \"angularjs\", \"angularjs\", \"ant\", \"ant\", \"ant\", \"ant\", \"anylogic\", \"ap\", \"ap\", \"ap\", \"apache_kafka\", \"apache_kafka\", \"applets\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"appliedmachine\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"april\", \"arabic\", \"arabic\", \"arabic\", \"arc\", \"arcgis\", \"arcgis\", \"arcgis\", \"arcgis\", \"arcgis\", \"arcgis\", \"arcgis\", \"arcgis\", \"arcgis\", \"areasof\", \"areasof\", \"areasof\", \"areasof\", \"areasof\", \"areasof\", \"areasof\", \"areasof\", \"areasof\", \"areasof\", \"areasof\", \"arena\", \"arena\", \"arm\", \"arm\", \"atlassiancloud\", \"ats\", \"ats\", \"ats\", \"ats\", \"ats\", \"ats\", \"aug2016\", \"aug2016\", \"aug2016\", \"aug2016\", \"aug2016\", \"automatic\", \"autoregression\", \"aws\", \"aws\", \"aws\", \"aws\", \"aws\", \"aws\", \"aws\", \"aws\", \"aws\", \"aws\", \"awt\", \"b.\", \"b.\", \"b.\", \"b.\", \"b2c\", \"b2c\", \"bagging\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"basesas9.2\", \"be\", \"bigdata\", \"bigdata\", \"bigdata\", \"bigdata\", \"bigdata\", \"bigdata\", \"bigdata\", \"bigdata\", \"bigdata\", \"bigdata_tools\", \"bigdataskill\", \"bloomberg\", \"bloomberg\", \"bo\", \"bo\", \"bo\", \"bo\", \"bo\", \"bo6\", \"boarding\", \"boosting\", \"bootstrap\", \"bootstrap\", \"bootstrap\", \"bootstrap\", \"bootstrap\", \"bootstrap\", \"bottom\", \"bpmn\", \"bpmn\", \"brassring\", \"brassring\", \"brd\", \"build_tools\", \"bullhorn\", \"bullhorn\", \"bullhorn\", \"bullhorn\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"businesslaw\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c#.\", \"c#.\", \"c#.\", \"c++\", \"c++\", \"c++\", \"c++\", \"c++\", \"c++\", \"c++\", \"c++\", \"c++\", \"c++\", \"c++\", \"c.\", \"c.\", \"c.\", \"c.\", \"c.\", \"c.\", \"campaign\", \"campaign\", \"candc++\", \"cantonese\", \"cantonese\", \"cassandra\", \"cassandra\", \"cassandra\", \"cassandra\", \"cassandra\", \"certificate\", \"certificate\", \"certificate\", \"cfa\", \"cfra\", \"chinese\", \"chinese\", \"chinese\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"clinical_and\", \"clintrial4.0\", \"cloud\", \"cloud\", \"cloud\", \"cloud\", \"cloud\", \"cloud\", \"cloud\", \"cloud\", \"cloud\", \"cloudera\", \"cloudera\", \"cloudera\", \"cloudera\", \"cloudera\", \"cloudera\", \"cloudera_cdh\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"cm_synergy\", \"cnn\", \"cnn\", \"co\", \"co\", \"co\", \"co\", \"co\", \"co\", \"co\", \"co\", \"co\", \"co\", \"cognos7.0/6.0\", \"cognosbi_10\", \"coldfusion\", \"coldfusion\", \"columbia\", \"community\", \"community\", \"community\", \"community\", \"community\", \"competencies\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computerskills\", \"computerskills\", \"confluence\", \"confluence\", \"confluence\", \"confluence\", \"confluence\", \"confluence\", \"confluence\", \"connectivity\", \"consumer\", \"consumer\", \"consumer\", \"consumer\", \"copy\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"cplex\", \"cplex\", \"cplex\", \"cplex\", \"cplex\", \"crm\", \"crm\", \"crm\", \"crm\", \"crm\", \"crm\", \"crm\", \"crm\", \"cross\", \"cross\", \"cross\", \"cross\", \"cross\", \"cross\", \"cross\", \"cross\", \"cross\", \"cross\", \"csh\", \"csh\", \"css\", \"css\", \"css\", \"css\", \"css\", \"css\", \"css\", \"css\", \"css\", \"css3\", \"css3\", \"css3\", \"css3\", \"ctms\", \"ctms\", \"cucumber_api\", \"cvs\", \"cvs\", \"cvs\", \"cvs\", \"cvs\", \"cvs\", \"cyber\", \"cyber\", \"cyber\", \"cybersecurity\", \"cybersecurity\", \"cybersecurity\", \"d.\", \"d.\", \"d.\", \"d.\", \"d.\", \"d.\", \"d.c.\", \"d.c.\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data_cleaning\", \"data_cleaning\", \"data_cleaning\", \"data_engineer\", \"dataanalysis\", \"dataanalysis\", \"dataanalysis\", \"dataanalysis\", \"dataanalysis\", \"dataanalysis\", \"dataanalysis\", \"dataanalysis\", \"dataanalysis\", \"databaseadmin\", \"databaseand\", \"databaseand\", \"databases\", \"databases\", \"databases\", \"databases\", \"databases\", \"databases\", \"databases\", \"databasessql\", \"databasetools\", \"dataflux\", \"dataprofiling\", \"dataquality\", \"datascientist\", \"datascientist\", \"datascientist\", \"datascientist\", \"datascientist\", \"datascientist\", \"datascientist\", \"datascientist\", \"datascientist\", \"datascientist\", \"db2\", \"db2\", \"db2\", \"db2\", \"db2\", \"db2\", \"db2\", \"db2\", \"db2\", \"db2\", \"db2\", \"dde\", \"ddl\", \"debugging\", \"dec\", \"dec\", \"dec\", \"dec\", \"dec\", \"dec\", \"dec\", \"dec\", \"dec\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"decisionspace\", \"dell\", \"dell\", \"depression\", \"development\", \"development\", \"development\", \"development\", \"development\", \"development\", \"development\", \"development\", \"development\", \"dhcp\", \"dhcp\", \"dice\", \"dice\", \"dice\", \"dice\", \"dice\", \"diversity\", \"diversity\", \"django\", \"django\", \"django\", \"django\", \"dml\", \"dml\", \"dns\", \"dns\", \"dns\", \"documentum\", \"documentum\", \"documentum\", \"documentum\", \"documentum\", \"dynamodb\", \"dynamodb\", \"dynamodb\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e\", \"e.\", \"e.\", \"e.\", \"e.\", \"e.\", \"e.g.\", \"ebay\", \"ebay\", \"ebay\", \"ec2\", \"ec2\", \"ec2\", \"ec2\", \"ec2\", \"ec2\", \"ec2\", \"ec2\", \"ec2\", \"eclipse\", \"eclipse\", \"eclipse\", \"eclipse\", \"eclipse\", \"eclipse\", \"eclipse\", \"eclipse\", \"eclipse3.x\", \"edain\", \"educational\", \"educational\", \"educational\", \"eeo\", \"eit\", \"eit\", \"ejb\", \"ejb\", \"ejb\", \"electronic\", \"electronic\", \"emblem\", \"emf\", \"emr\", \"emr\", \"emr\", \"emr\", \"emr\", \"emr\", \"emr\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"english\", \"english\", \"english\", \"english\", \"english\", \"english\", \"english\", \"english\", \"english\", \"english\", \"ensembles\", \"ensembles\", \"ensembles\", \"envi\", \"envi\", \"envi\", \"envi\", \"epic\", \"epic\", \"epic\", \"epic\", \"epic\", \"er\", \"er\", \"er\", \"er\", \"er\", \"er\", \"erecruit\", \"erwin\", \"erwin\", \"erwin\", \"erwin\", \"erwin\", \"erwin\", \"erwin\", \"erwin\", \"erwin\", \"erwin\", \"erwin9.x\", \"erwindata\", \"erwinr9.6\", \"esr\", \"etl\", \"etl\", \"etl\", \"etl\", \"etl\", \"etl\", \"etl\", \"etl\", \"etl\", \"etl\", \"etl_tools\", \"etl_tools\", \"etl_tools\", \"etl_tools\", \"etl_tools\", \"etltool\", \"eviews\", \"eviews\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excel\", \"excelandword\", \"exceldata\", \"executive\", \"executive\", \"executive\", \"express.js\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"factor_models\", \"fast\", \"fast\", \"fast\", \"filehandling\", \"filter_methods\", \"firebase\", \"flex\", \"flume\", \"flume\", \"flume\", \"french\", \"french\", \"french\", \"french\", \"french\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g.\", \"g.\", \"g.\", \"g.\", \"gams\", \"gams\", \"gatling_tool\", \"gauss\", \"gc\", \"gc\", \"gc\", \"gc\", \"gc\", \"geocoding\", \"ggplot\", \"ggplot2and\", \"git\", \"git\", \"git\", \"git\", \"git\", \"git\", \"git\", \"git\", \"git\", \"google\", \"google\", \"google\", \"google\", \"google\", \"google\", \"google\", \"google\", \"google\", \"google\", \"google\", \"google_earth\", \"googleanalytic\", \"googledocs\", \"googledocs\", \"googlesuite\", \"graphic\", \"graphic\", \"graphic\", \"graphic\", \"greeks\", \"green\", \"greenbeltsix\", \"greenhouse\", \"greenhouse\", \"greenhouse\", \"gridsearchand\", \"grt\", \"gulp\", \"gurobi\", \"h&r\", \"h.\", \"h.\", \"h.\", \"h.\", \"h.\", \"h.\", \"h.\", \"hadoop\", \"hadoop\", \"hadoop\", \"hadoop\", \"hadoop\", \"hadoop\", \"hadoop\", \"hadoop\", \"hadoop\", \"hadoop2\", \"hadoop2\", \"hadoopmap\", \"hadoopmap\", \"hands\", \"hands\", \"hands\", \"hands\", \"hands\", \"hands\", \"hands\", \"hands\", \"hands\", \"hands\", \"hardworking\", \"hbase\", \"hbase\", \"hbase\", \"hbase\", \"hbase\", \"hbase\", \"hdfs\", \"hdfs\", \"hdfs\", \"hdfs\", \"hdfs\", \"hdfs\", \"hdfs\", \"healthcare_it\", \"hebrew\", \"hfds\", \"hibernate\", \"hibernate\", \"hibernate\", \"hibernate\", \"hierarchical\", \"hierarchical\", \"highlightsof\", \"highlightsof\", \"highlightsof\", \"highlightsof\", \"highlightsof\", \"highlightsof\", \"hiv\", \"hiv\", \"hive\", \"hive\", \"hive\", \"hive\", \"hive\", \"hive\", \"hive\", \"hive\", \"hive2.8\", \"hl7message\", \"hodes_iq\", \"honorsand\", \"honorsand\", \"hootsuite\", \"hospitality\", \"hospitality\", \"hp\", \"hp\", \"hp\", \"hp\", \"hp\", \"hp\", \"hp\", \"hp\", \"hp\", \"hplc\", \"hplc\", \"hpquality\", \"hpquality\", \"hpquality\", \"hpquality\", \"hr_operations\", \"hrtools\", \"html\", \"html\", \"html\", \"html\", \"html\", \"html\", \"html\", \"html\", \"html\", \"html\", \"html5\", \"html5\", \"html5\", \"html5\", \"html5\", \"html5\", \"http\", \"http\", \"http\", \"http\", \"http\", \"hu\", \"hue\", \"hue\", \"hue\", \"hue\", \"huecloudera\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human_services\", \"hypothesis\", \"i-9_compliance\", \"ibatis\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"ibm_mq\", \"ibmutilities\", \"icd10\", \"icd9toicd10\", \"icims\", \"icims\", \"icims\", \"icpc\", \"idf\", \"idf\", \"idf\", \"idf\", \"idf\", \"idrisi\", \"idrisi\", \"idrisi\", \"illustrator\", \"illustrator\", \"illustrator\", \"illustrator\", \"illustrator\", \"iml\", \"iml\", \"iml\", \"impala\", \"impala\", \"impala\", \"impala\", \"inclusion\", \"indesign\", \"indesign\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"infragistics\", \"initiates\", \"initiative\", \"intellijidea\", \"interests\", \"interests\", \"interests\", \"intermediate\", \"intermediate\", \"intermediate\", \"intermediate\", \"intermediate\", \"intermediate\", \"international\", \"international\", \"international\", \"international\", \"international\", \"interpersonal\", \"interpersonal\", \"interpersonal\", \"interpersonal\", \"interpersonal\", \"interpersonal\", \"interpersonal\", \"interviewing\", \"interviewing\", \"interviewing\", \"inv\", \"irdb(in\", \"istqb\", \"istrategy\", \"isup\", \"ithaca\", \"ithaca\", \"itrecruitment\", \"j.\", \"j.\", \"j.\", \"j.\", \"j.\", \"j.\", \"j.\", \"j2ee\", \"j2ee\", \"j2ee\", \"j2ee\", \"j2ee\", \"jad\", \"jad\", \"jad\", \"jad\", \"jama\", \"japanese\", \"japanese\", \"japanese\", \"japanese\", \"jaspersoft\", \"java\", \"java\", \"java\", \"java\", \"java\", \"java\", \"java\", \"java\", \"java\", \"java\", \"java\", \"java_beans\", \"java_beans\", \"javaand\", \"javaand\", \"javaand\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"javascript\", \"jaxb\", \"jboss\", \"jboss\", \"jbuilder\", \"jdbc\", \"jdbc\", \"jdbc\", \"jdbc\", \"jira\", \"jira\", \"jira\", \"jira\", \"jira\", \"jira\", \"jira\", \"jira\", \"jira\", \"jira\", \"jmp\", \"jmp\", \"jmp\", \"jmp\", \"jmp\", \"jmp\", \"jmp\", \"jms\", \"jms\", \"jms\", \"jndi\", \"jndi\", \"jni\", \"jobdiva\", \"jobvite\", \"jobvite\", \"jobvite\", \"jobviteand\", \"jquery\", \"jquery\", \"jquery\", \"jquery\", \"jquery\", \"jsf\", \"jsf\", \"json\", \"json\", \"json\", \"json\", \"json\", \"json\", \"json\", \"json\", \"jsp\", \"jsp\", \"jsp\", \"jsp\", \"jsp\", \"jsp\", \"jsp\", \"jsp\", \"jsp2.0\", \"jstl\", \"jstl\", \"june\", \"june\", \"june\", \"june\", \"june\", \"june\", \"june\", \"k\", \"k\", \"k\", \"k\", \"k\", \"k\", \"k\", \"k\", \"k\", \"k.\", \"k.\", \"k.\", \"k.\", \"kafka\", \"kafka\", \"kafka\", \"kafka\", \"keel\", \"keras\", \"keras\", \"keras\", \"keras\", \"kerberos\", \"kerberos\", \"kerberos\", \"kerberos\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"kinesis\", \"knn\", \"knn\", \"knn\", \"knowledgeloinc\", \"korn\", \"korn\", \"kpi\", \"kpi\", \"kpi\", \"kpi\", \"kpi\", \"kpi\", \"kpi\", \"l.\", \"l.\", \"la\", \"la\", \"la\", \"lamp\", \"latex\", \"latex\", \"latex\", \"latex\", \"latex\", \"lda\", \"lda\", \"lda\", \"lda\", \"leadership\", \"leadership\", \"leadership\", \"leadership\", \"leadership\", \"leadership\", \"leadership\", \"leadership\", \"leadership\", \"leansixsigma\", \"leansixsigma\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learnetc\", \"lessthan1year\", \"lindo\", \"lindo\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linearalgebra\", \"linearandnon\", \"linearandnon\", \"lingo\", \"linkedin\", \"linkedin\", \"linkedin\", \"linkedin\", \"linkedin\", \"linkedin\", \"linkedin\", \"linkedin\", \"linkedin\", \"linq\", \"linq\", \"linq\", \"linux\", \"linux\", \"linux\", \"linux\", \"linux\", \"linux\", \"linux\", \"linux\", \"linux\", \"linux\", \"linux\", \"linux\", \"linuxserver\", \"liu\", \"liu\", \"liwc\", \"lm\", \"lm\", \"lm\", \"log4j\", \"logistic\", \"logistic\", \"logistic\", \"logistic\", \"logistic\", \"logistic\", \"logistic\", \"logit\", \"logit\", \"logit\", \"loinc\", \"loinc\", \"loinc\", \"loinc\", \"loinc\", \"lucid\", \"m.\", \"m.\", \"m.\", \"m.\", \"m.\", \"m.\", \"m.\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"macintosh_hd\", \"macintosh_hd\", \"macros\", \"macros\", \"macros\", \"macros\", \"macros\", \"macros\", \"magento\", \"mahout\", \"mahout\", \"mahout\", \"mahout\", \"mahout\", \"management\", \"management\", \"management\", \"management\", \"management\", \"management\", \"management\", \"management\", \"management\", \"management\", \"mandarin\", \"mandarin\", \"map_reduce\", \"map_reduce\", \"map_reduce\", \"map_reduce\", \"maple\", \"maple\", \"maple\", \"maple\", \"maple\", \"mapr\", \"mapr\", \"mapr\", \"mapreduce\", \"mapreduce\", \"mapreduce\", \"mapreduce\", \"mapreduce\", \"mapreduce\", \"mapreduce\", \"mapreduce\", \"mapreduce\", \"mathematica\", \"mathematica\", \"mathematica\", \"mathematica\", \"mathematica\", \"mathematica\", \"mathematica\", \"mathematica\", \"matlab\", \"matlab\", \"matlab\", \"matlab\", \"matlab\", \"matlab\", \"matlab\", \"matlab\", \"matlab\", \"matplotib\", \"matplotlib\", \"matplotlib\", \"matplotlib\", \"matplotlib\", \"maven\", \"maven\", \"maven\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may2017\", \"may2017\", \"mcsa\", \"means\", \"means\", \"means\", \"means\", \"meditech\", \"meditech\", \"meditech\", \"medra\", \"memory.net\", \"mesos\", \"message\", \"message\", \"message\", \"methodologies\", \"methodologies\", \"methodologies\", \"methodologies\", \"mexico\", \"mexico\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft\", \"microsoft_word\", \"microsoft_word\", \"microsoft_word\", \"middleware\", \"middleware\", \"middleware\", \"migrations\", \"minitab\", \"minitab\", \"minitab\", \"minitab\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"mobile\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeltuning/\", \"modflow\", \"mongodb\", \"mongodb\", \"mongodb\", \"mongodb\", \"mongodb\", \"mongodb\", \"mongodb\", \"mongodb\", \"mongodb\", \"mongodb3.x\", \"montecarlo\", \"montecarlo\", \"montecarlo\", \"montecarlo\", \"montecarlo\", \"montecarlo\", \"movingaverages\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms\", \"ms_excel\", \"ms_excel\", \"ms_excel\", \"ms_excel\", \"ms_excel\", \"ms_excel\", \"ms_excel\", \"ms_excel\", \"ms_outlook\", \"ms_outlook\", \"ms_outlook\", \"ms_outlook\", \"ms_outlook\", \"msmq\", \"msoffice\", \"msoffice\", \"msoffice\", \"msoffice\", \"msoffice\", \"msoffice\", \"msoffice\", \"msoffice\", \"msoffice2013\", \"mssuite2012\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multimedia\", \"my\", \"mysql\", \"mysql\", \"mysql\", \"mysql\", \"mysql\", \"mysql\", \"mysql\", \"mysql\", \"mysql\", \"mysql\", \"n.\", \"n.\", \"n.\", \"n.\", \"naive_bayes\", \"naive_bayes\", \"naive_bayes\", \"native\", \"native\", \"native\", \"native\", \"nativemandarin\", \"na\\u00efve_bayes\", \"na\\u00efve_bayes\", \"na\\u00efve_bayes\", \"ncss\", \"ndm\", \"negotiation\", \"net_2015\", \"netbeans\", \"netbeans\", \"netbeans\", \"netbeans\", \"netbeans\", \"netezzaand\", \"networkx\", \"neural_network\", \"neural_network\", \"neurology\", \"nifi\", \"nlp\", \"nlp\", \"nlp\", \"nlp\", \"nlp\", \"nlp\", \"nlp\", \"nlp\", \"nltk\", \"nltk\", \"nltk\", \"nltk\", \"nltk\", \"nltk\", \"nmr\", \"nmr\", \"nmr\", \"nmr\", \"nn\", \"nn\", \"no_sql\", \"node.js\", \"node.js\", \"node.js\", \"node.js\", \"node.js\", \"nosql\", \"nosql\", \"nosql\", \"nosql\", \"nosql\", \"nosql\", \"nosql\", \"nosql\", \"notepad++\", \"november\", \"november\", \"november\", \"november\", \"november\", \"november\", \"numpy\", \"numpy\", \"numpy\", \"numpy\", \"numpy\", \"numpy\", \"nunit\", \"nurses\", \"nvivo\", \"oauth\", \"obe\", \"obiee\", \"obiee\", \"obiee\", \"obiee\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"october\", \"october\", \"october\", \"october\", \"october\", \"october\", \"october\", \"oncology\", \"oncology\", \"oncology\", \"onlinecourses\", \"ontology\", \"oozie\", \"oozie\", \"oozie\", \"oozie\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle_rdbms\", \"orazuredata\", \"organizational\", \"organizational\", \"organizational\", \"organizational\", \"organizations\", \"other\", \"other\", \"other\", \"other\", \"other\", \"other\", \"other\", \"otherused\", \"outlook\", \"outlook\", \"outlook\", \"outlook\", \"outlook\", \"outlook\", \"outlook\", \"outlook\", \"p.\", \"p.\", \"p.\", \"pandas\", \"pandas\", \"pandas\", \"pandas\", \"pandas\", \"pandas\", \"parquet\", \"pca\", \"pca\", \"pca\", \"pca\", \"pca\", \"pdw\", \"pega_csa\", \"pentaho_kettle\", \"peoplesoft\", \"peoplesoft\", \"peoplesoft\", \"peoplesoft\", \"peoplesoft\", \"peoplesoft\", \"peoplesoft\", \"peoplesoft\", \"peoplesoft\", \"perl\", \"perl\", \"perl\", \"perl\", \"perl\", \"perl\", \"perl\", \"perl\", \"persuasive\", \"pgadminiii\", \"phosco\", \"photoshop\", \"photoshop\", \"photoshop\", \"photoshop\", \"photoshop\", \"photoshop\", \"photoshop\", \"photoshop\", \"photoshop\", \"photovoltaics\", \"php\", \"php\", \"php\", \"php\", \"php\", \"php\", \"php\", \"php\", \"pic\", \"pic\", \"pig\", \"pig\", \"pig\", \"pig\", \"pig\", \"pig\", \"pig\", \"pig\", \"pigand\", \"pigand\", \"pl\", \"pl\", \"pl\", \"pl\", \"pl\", \"pl\", \"pl\", \"pl\", \"pl\", \"pl\", \"pl\", \"plus\", \"plus\", \"plus\", \"plus\", \"po\", \"portal\", \"powerpoint\", \"powerpoint\", \"powerpoint\", \"powerpoint\", \"powerpoint\", \"powerpoint\", \"powerpoint\", \"powerpoint\", \"powerpoint\", \"powerpoint\", \"powerpoint\", \"powerpoint/\", \"powerpoint/\", \"powershell\", \"powershell\", \"powershell\", \"powershell\", \"powershell\", \"powershell\", \"powershell\", \"ppc\", \"ppc\", \"ppc\", \"president\", \"president\", \"president\", \"president\", \"president\", \"president\", \"president\", \"president\", \"presto\", \"probit\", \"proc_print\", \"processdesign\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"proficientin_r\", \"proficientin_r\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"programming\", \"programming\", \"programming\", \"programming\", \"programming\", \"programming\", \"programming\", \"programming\", \"programming\", \"programming\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"project\", \"prototyping\", \"prototyping\", \"pspice\", \"public_health\", \"pune\", \"pyramid\", \"python\", \"python\", \"python\", \"python\", \"python\", \"python\", \"python\", \"python\", \"python\", \"python\", \"python2.7/3.3\", \"python2.x/3.x\", \"python_2\", \"python_3\", \"python_3\", \"pythonandr\", \"pythonandr\", \"pythonandr\", \"pytorch\", \"qa\", \"qa\", \"qa\", \"qa\", \"qa\", \"qa\", \"qa\", \"qa\", \"qa\", \"qgis\", \"qgis\", \"qgis\", \"qgis\", \"qgis\", \"qgis\", \"qgis\", \"qualifications\", \"qualifications\", \"quickbooks\", \"quickbooks\", \"quickbooks\", \"quickbooks\", \"quickbooks\", \"quickbooks\", \"quickbooks\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r\", \"r.\", \"r.\", \"r.\", \"r.\", \"r.\", \"r.\", \"r.\", \"r.\", \"rails\", \"random_forest\", \"random_forest\", \"random_forest\", \"random_forest\", \"random_forest\", \"rave\", \"rave\", \"rave\", \"rave\", \"rcurl\", \"react\", \"react\", \"react\", \"react.js\", \"recruit\", \"redmatch\", \"redshift\", \"redshift\", \"redshift\", \"redshift\", \"redux\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"reshape2\", \"respiratory\", \"respiratory\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"resumix\", \"resumix\", \"retention\", \"retention\", \"rheumatology\", \"ridge\", \"ridge\", \"ridge\", \"riskmanagement\", \"riskmanagement\", \"riskmanagement\", \"rmi\", \"rmi\", \"rnn\", \"rnn\", \"rollout\", \"rollout/\", \"rootcause\", \"rpy2\", \"rspec\", \"ruby\", \"ruby\", \"ruby\", \"ruby\", \"ruby\", \"ruby\", \"ruby\", \"rubyon_rails\", \"rubyon_rails\", \"rubyon_rails\", \"russian\", \"rxnorm\", \"rxnorm\", \"s.\", \"s.\", \"s.\", \"s.\", \"s.\", \"s.\", \"s3\", \"s3\", \"s3\", \"s3\", \"s3\", \"s3\", \"s3\", \"salesforce\", \"salesforce\", \"salesforce\", \"salesforce\", \"salesforce\", \"salesforce\", \"salesforce\", \"salesforce\", \"salesforce\", \"salesforce\", \"salesforce\", \"salesforce\", \"sap\", \"sap\", \"sap\", \"sap\", \"sap\", \"sap\", \"sap\", \"sap\", \"sap\", \"sap\", \"sap\", \"sapfico\", \"sarkar\", \"sas\", \"sas\", \"sas\", \"sas\", \"sas\", \"sas\", \"sas\", \"sas\", \"sas\", \"sas\", \"sas\", \"sas9\", \"sas9\", \"sas9\", \"sas_bi\", \"sas_enterprise\", \"sas_enterprise\", \"sass\", \"sax\", \"scala\", \"scala\", \"scala\", \"scala\", \"scala\", \"scala\", \"scala\", \"scala2.10\", \"scala_nlp\", \"sccp\", \"scholes\", \"scholes\", \"scholes\", \"scikit\", \"scikit\", \"scikit\", \"scikit\", \"scikit\", \"scikit\", \"scikit-\", \"scipy\", \"scipy\", \"scipy\", \"scipy\", \"scipy\", \"scorecards\", \"scraping\", \"scraping\", \"scraping\", \"scrapy\", \"scripting_r\", \"scrum\", \"scrum\", \"scrum\", \"scrum\", \"scrum\", \"scrum\", \"scrum\", \"scrum\", \"scrum\", \"scrum_masters\", \"sdet\", \"sdet\", \"seaborn\", \"seaborn\", \"seaborn\", \"seattle\", \"seattle\", \"seattle\", \"seattle\", \"seattle\", \"seg\", \"selected\", \"selected\", \"selected\", \"selected\", \"selected\", \"selected\", \"selected\", \"selected\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"september2015\", \"servlet2.0\", \"servlets\", \"servlets\", \"servlets\", \"sfdcadmin\", \"sharepoint\", \"sharepoint\", \"sharepoint\", \"sharepoint\", \"sharepoint\", \"sharepoint\", \"sharepoint\", \"sharepoint\", \"sharepoint\", \"side\", \"sigmastat\", \"simio\", \"singleton\", \"skill\", \"skill\", \"skill\", \"skill\", \"skill\", \"skill\", \"skill\", \"skill\", \"skills\", \"skills\", \"skills\", \"skills\", \"skills\", \"skills\", \"skills\", \"skills\", \"skills\", \"skills\", \"skills\", \"skills\", \"slack\", \"slack\", \"slack\", \"slack\", \"slack\", \"slack\", \"snome\", \"soap\", \"soap\", \"soap\", \"soap\", \"soap_ui\", \"soap_ui\", \"social_media\", \"softmax\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"softwarer\", \"solver\", \"solver\", \"spanish\", \"spanish\", \"spanish\", \"spanish\", \"spanish\", \"spark\", \"spark\", \"spark\", \"spark\", \"spark\", \"spark\", \"spark\", \"spark\", \"spark2.0\", \"spark2.x\", \"spark_sql\", \"spark_sql\", \"spatialdata\", \"spoken\", \"spoken\", \"spoken\", \"spring\", \"spring\", \"spring\", \"spring\", \"spring\", \"spring\", \"spring\", \"spring\", \"spring\", \"spring4.0\", \"spss\", \"spss\", \"spss\", \"spss\", \"spss\", \"spss\", \"spss\", \"spss\", \"spss\", \"spss\", \"spss_modeler\", \"spss_modeler\", \"spss_modeler\", \"spss_modeler\", \"spss_modeler\", \"sql\", \"sql\", \"sql\", \"sql\", \"sql\", \"sql\", \"sql\", \"sql\", \"sql\", \"sql\", \"sql\", \"sql\", \"sql_server\", \"sql_server\", \"sql_server\", \"sql_server\", \"sql_server\", \"sql_server\", \"sql_server\", \"sqlandexcel\", \"sqoop\", \"sqoop\", \"sqoop\", \"sqoop\", \"square_tests\", \"square_tests\", \"ssas\", \"ssas\", \"ssas\", \"ssas\", \"ssas\", \"ssas\", \"ssas\", \"ssas\", \"ssas\", \"ssis\", \"ssis\", \"ssis\", \"ssis\", \"ssis\", \"ssis\", \"ssis\", \"ssis_2005\", \"ssis_2008\", \"ssis_2012\", \"ssmsexport\", \"ssrs\", \"ssrs\", \"ssrs\", \"ssrs\", \"ssrs\", \"ssrs\", \"ssrs\", \"ssrs\", \"ssrs_2008\", \"stat\", \"stat\", \"stat\", \"stat\", \"stat\", \"stat\", \"stata\", \"stata\", \"stata\", \"stata\", \"stata\", \"stata\", \"stata\", \"stata\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistics/\", \"statistics/\", \"statsmodels\", \"stepwise\", \"stepwise\", \"stepwise\", \"strategic\", \"strategic\", \"strategic\", \"strategic\", \"strategic\", \"strategic\", \"strategic\", \"strategic\", \"structured\", \"struts\", \"struts\", \"stylus\", \"subqueries\", \"superputty\", \"survey\", \"survey\", \"survey\", \"survey\", \"sustainingedge\", \"svd\", \"svd\", \"svm\", \"svm\", \"svm\", \"svm\", \"svm\", \"svm\", \"svm\", \"svn\", \"svn\", \"svn\", \"svn\", \"svn\", \"svn\", \"svn\", \"swahili\", \"swift\", \"swift\", \"swot_analysis\", \"swot_analysis\", \"sybase\", \"sybase\", \"sybase\", \"sybase\", \"sybase\", \"sybase\", \"sybase\", \"sybase\", \"sybase\", \"sybase\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t_test\", \"t_test\", \"t_test\", \"tableau\", \"tableau\", \"tableau\", \"tableau\", \"tableau\", \"tableau\", \"tableau\", \"tableau\", \"tableau\", \"tableau\", \"tableau\", \"tableau\", \"tableau8.0\", \"tableau_8\", \"taleo\", \"taleo\", \"taleo\", \"taleo\", \"taq\", \"taubetapi\", \"tcp\", \"tcp\", \"tcp\", \"tcp\", \"tcp\", \"tcp\", \"tcp\", \"tcp\", \"tcp\", \"tealeaf\", \"tealeaf\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"teambuilding\", \"teambuilding\", \"teambuilding\", \"teambuilding\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"teleriktoolkit\", \"tensorflow\", \"tensorflow\", \"tensorflow\", \"tensorflow\", \"tensorflow\", \"tensorflow\", \"tensorflow\", \"teradata\", \"teradata\", \"teradata\", \"teradata\", \"teradata\", \"teradata\", \"teradata\", \"teradata\", \"teradata_12\", \"teradataand\", \"testing/\", \"testingtool\", \"tez\", \"tf\", \"tf\", \"tf\", \"tf\", \"theano\", \"theano\", \"theano\", \"theano\", \"theoretical\", \"therapeutic\", \"thingworx\", \"tibcospotfire\", \"tibcospotfire\", \"tika\", \"tmux\", \"toolkit\", \"top1\", \"top1\", \"transaction\", \"transfer\", \"tree\", \"trello\", \"trello\", \"trello\", \"trello\", \"trello\", \"trello\", \"trello\", \"trello\", \"trimble\", \"tso\", \"tso\", \"tso\", \"tso\", \"ttest\", \"tumblr\", \"tx\", \"tx\", \"tx\", \"tx\", \"tx\", \"tx\", \"tx\", \"tx\", \"ubuntuand\", \"udb\", \"uml\", \"uml\", \"uml\", \"uml\", \"uml\", \"uml\", \"uml\", \"uml\", \"uml\", \"undergraduate\", \"undergraduate\", \"univariate\", \"univariate\", \"univariate\", \"unix\", \"unix\", \"unix\", \"unix\", \"unix\", \"unix\", \"unix\", \"unix\", \"unix\", \"unix\", \"unix\", \"unix_script\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"useraccess\", \"userexperience\", \"userexperience\", \"userexperience\", \"userexperience\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux\", \"vb.net\", \"vb.net\", \"vb.net\", \"vb.net\", \"vb.net\", \"vb.net\", \"vb.net\", \"vba\", \"vba\", \"vba\", \"vba\", \"vba\", \"vba\", \"vba\", \"vbasic\", \"vensim\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vice\", \"vice\", \"vice\", \"virtual_edge\", \"visio\", \"visio\", \"visio\", \"visio\", \"visio\", \"visio\", \"visio\", \"visio\", \"visio\", \"visio\", \"visio\", \"vista\", \"vista\", \"vista\", \"vista\", \"vista\", \"vista\", \"vista\", \"visual_studio\", \"visual_studio\", \"visual_studio\", \"visual_studio\", \"visual_studio\", \"visual_studio\", \"volunteer\", \"volunteer\", \"volunteer\", \"volunteer\", \"volunteer\", \"volunteer\", \"volunteer\", \"vpc\", \"vsamand\", \"w.\", \"w.\", \"w.\", \"w.\", \"w.\", \"washington\", \"washington\", \"washington\", \"waterfall\", \"waterfall\", \"waterfall\", \"waterfall\", \"waterfall\", \"waterfall\", \"waterfall\", \"waterfall\", \"waterfall\", \"waterfall\", \"wcf\", \"wcf\", \"wcf\", \"web_api\", \"web_servers\", \"weblogic\", \"weblogic\", \"weblogic\", \"weblogic\", \"weblogic\", \"websphere\", \"websphere\", \"websphere\", \"websphere\", \"whodra\", \"winbugs\", \"winbugs\", \"windows\", \"windows\", \"windows\", \"windows\", \"windows\", \"windows\", \"windows\", \"windows\", \"windows\", \"windows\", \"windows\", \"windows7/8/10\", \"windows7/8/10\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word2vec\", \"workday\", \"workday\", \"workday\", \"workday\", \"workday\", \"wpf\", \"wpf\", \"writing\", \"writing\", \"writing\", \"wsdl\", \"wsdl\", \"wsdl\", \"x.\", \"x.\", \"xgboost\", \"xgboost\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xml\", \"xp\", \"xp\", \"xp\", \"xp\", \"xp\", \"xp\", \"xp\", \"xp\", \"xp\", \"xp\", \"xp\", \"y.\", \"y.\", \"y.\", \"y.\", \"yarn\", \"yarn\", \"yarn\", \"yii2\", \"z.\", \"z.\", \"zohooffice\", \"zookeeper\", \"zookeeper\", \"\\u25c6\", \"\\u25c6\", \"\\u25c6\", \"\\u25c6\", \"\\u2663\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [12, 7, 9, 10, 1, 2, 5, 8, 4, 3, 6, 11]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el16481399931787258561910670915\", ldavis_el16481399931787258561910670915_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el16481399931787258561910670915\", ldavis_el16481399931787258561910670915_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el16481399931787258561910670915\", ldavis_el16481399931787258561910670915_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "11     21.018930        1       1  0.178386 -0.099050\n",
       "6      20.327831        1       2  0.204531 -0.141215\n",
       "8      17.509239        1       3  0.230711  0.043406\n",
       "9      14.393434        1       4  0.171886  0.107890\n",
       "0       7.235928        1       5  0.028248  0.179300\n",
       "1       3.748013        1       6 -0.012753  0.027564\n",
       "4       3.368896        1       7 -0.074784 -0.057546\n",
       "7       3.048049        1       8 -0.158089 -0.021893\n",
       "3       2.673363        1       9 -0.151100  0.037611\n",
       "2       2.334901        1      10 -0.122807 -0.011622\n",
       "5       2.191694        1      11 -0.132711 -0.022145\n",
       "10      2.149720        1      12 -0.161517 -0.042300, topic_info=     Category         Freq          Term        Total  loglift  logprob\n",
       "term                                                                   \n",
       "81    Default  1530.000000           sas  1530.000000  30.0000  30.0000\n",
       "99    Default   701.000000        pandas   701.000000  29.0000  29.0000\n",
       "21    Default  1020.000000    javascript  1020.000000  28.0000  28.0000\n",
       "75    Default  1058.000000          hive  1058.000000  27.0000  27.0000\n",
       "2     Default  1114.000000          html  1114.000000  26.0000  26.0000\n",
       "0     Default   656.000000           css   656.000000  25.0000  25.0000\n",
       "150   Default   567.000000         numpy   567.000000  24.0000  24.0000\n",
       "100   Default   458.000000        scikit   458.000000  23.0000  23.0000\n",
       "204   Default   646.000000           pig   646.000000  22.0000  22.0000\n",
       "7     Default  3289.000000             r  3289.000000  21.0000  21.0000\n",
       "6     Default  3500.000000        python  3500.000000  20.0000  20.0000\n",
       "27    Default  1092.000000         excel  1092.000000  19.0000  19.0000\n",
       "31    Default  1462.000000        matlab  1462.000000  18.0000  18.0000\n",
       "20    Default  1851.000000          java  1851.000000  17.0000  17.0000\n",
       "139   Default   396.000000           php   396.000000  16.0000  16.0000\n",
       "39    Default   357.000000         hbase   357.000000  15.0000  15.0000\n",
       "252   Default   300.000000    matplotlib   300.000000  14.0000  14.0000\n",
       "82    Default   954.000000         spark   954.000000  13.0000  13.0000\n",
       "47    Default   515.000000    powerpoint   515.000000  12.0000  12.0000\n",
       "898   Default   286.000000         sqoop   286.000000  11.0000  11.0000\n",
       "13    Default  1582.000000             c  1582.000000  10.0000  10.0000\n",
       "259   Default   359.000000         scipy   359.000000   9.0000   9.0000\n",
       "195   Default   684.000000          spss   684.000000   8.0000   8.0000\n",
       "253   Default   302.000000         learn   302.000000   7.0000   7.0000\n",
       "216   Default   513.000000           xml   513.000000   6.0000   6.0000\n",
       "78    Default   337.000000    regression   337.000000   5.0000   5.0000\n",
       "269   Default   257.000000        jquery   257.000000   4.0000   4.0000\n",
       "38    Default  1346.000000        hadoop  1346.000000   3.0000   3.0000\n",
       "93    Default   369.000000           svm   369.000000   2.0000   2.0000\n",
       "107   Default   357.000000    clustering   357.000000   1.0000   1.0000\n",
       "...       ...          ...           ...          ...      ...      ...\n",
       "1761  Topic12     2.487796    pythonandr     5.259302   3.0912  -7.1816\n",
       "8791  Topic12     1.941203    googledocs     3.634740   3.2126  -7.4297\n",
       "4203  Topic12     3.911214  teambuilding    11.493258   2.7619  -6.7292\n",
       "363   Topic12    15.235598      research   110.809265   1.8557  -5.3694\n",
       "6281  Topic12     2.556130      japanese     5.950209   2.9949  -7.1545\n",
       "9906  Topic12     2.518835       andspss     6.134675   2.9497  -7.1692\n",
       "9839  Topic12     1.986018   educational     4.108534   3.1129  -7.4069\n",
       "911   Topic12    10.816319     photoshop    86.930382   1.7558  -5.7119\n",
       "49    Topic12    11.414258      relevant   105.017982   1.6206  -5.6581\n",
       "690   Topic12     7.987966    leadership    71.688324   1.6454  -6.0151\n",
       "2370  Topic12     5.593969     strategic    41.661980   1.8319  -6.3713\n",
       "714   Topic12    10.353340      business   181.078156   0.9782  -5.7557\n",
       "390   Topic12     5.752875      academic    48.906429   1.6996  -6.3433\n",
       "176   Topic12    15.485639          data   742.032532  -0.0296  -5.3531\n",
       "1449  Topic12     5.537334           crm    48.484013   1.6701  -6.3815\n",
       "1287  Topic12     4.612993    functional    30.240780   1.9595  -6.5641\n",
       "371   Topic12     5.403158         cross    48.386345   1.6476  -6.4060\n",
       "184   Topic12    10.150373        skills   410.218658   0.1407  -5.7755\n",
       "571   Topic12     4.740997  intermediate    40.305801   1.6996  -6.5368\n",
       "4189  Topic12     4.070770    quickbooks    25.253145   2.0147  -6.6892\n",
       "27    Topic12    11.016294         excel  1092.384399  -0.7569  -5.6936\n",
       "637   Topic12     7.277906       project   277.882965   0.1975  -6.1082\n",
       "47    Topic12     7.350163    powerpoint   515.419434  -0.4104  -6.0983\n",
       "42    Topic12     6.221272     microsoft   249.898880   0.1468  -6.2650\n",
       "54    Topic12     6.523345          word   477.401184  -0.4531  -6.2176\n",
       "26    Topic12     5.955003      software   275.997681   0.0037  -6.3088\n",
       "552   Topic12     4.922417  dataanalysis    87.862106   0.9579  -6.4992\n",
       "456   Topic12     4.765885           ibm    75.415710   1.0783  -6.5315\n",
       "1224  Topic12     4.964687         visio   258.185883  -0.1115  -6.4907\n",
       "106   Topic12     4.994925        access   418.762329  -0.5890  -6.4846\n",
       "\n",
       "[947 rows x 6 columns], token_table=       Topic      Freq        Term\n",
       "term                              \n",
       "6006       6  0.690178        -9.2\n",
       "7600       9  0.463783      3.1.15\n",
       "8822       3  0.958507         6.x\n",
       "541        1  0.929578       @risk\n",
       "480        1  0.101525    December\n",
       "480        4  0.101525    December\n",
       "480        5  0.101525    December\n",
       "480        7  0.507623    December\n",
       "480        8  0.101525    December\n",
       "480       12  0.101525    December\n",
       "128        5  0.195884        July\n",
       "128        6  0.587651        July\n",
       "128       11  0.195884        July\n",
       "208        1  0.177726           a\n",
       "208        2  0.646725           a\n",
       "208        3  0.034558           a\n",
       "208        4  0.024684           a\n",
       "208        5  0.014810           a\n",
       "208        6  0.034558           a\n",
       "208        8  0.009874           a\n",
       "208        9  0.004937           a\n",
       "208       11  0.024684           a\n",
       "208       12  0.019747           a\n",
       "8034       6  0.075159          a.\n",
       "8034       8  0.450955          a.\n",
       "8034       9  0.300637          a.\n",
       "8034      11  0.075159          a.\n",
       "8034      12  0.075159          a.\n",
       "390        1  0.265814    academic\n",
       "390        2  0.204472    academic\n",
       "...      ...       ...         ...\n",
       "216       11  0.003895         xml\n",
       "301        1  0.072637          xp\n",
       "301        2  0.014527          xp\n",
       "301        3  0.290547          xp\n",
       "301        4  0.130746          xp\n",
       "301        5  0.203383          xp\n",
       "301        6  0.203383          xp\n",
       "301        7  0.014527          xp\n",
       "301        8  0.029055          xp\n",
       "301        9  0.043582          xp\n",
       "301       11  0.014527          xp\n",
       "301       12  0.014527          xp\n",
       "8045       8  0.599934          y.\n",
       "8045       9  0.299967          y.\n",
       "8045      11  0.074992          y.\n",
       "8045      12  0.074992          y.\n",
       "1106       2  0.058561        yarn\n",
       "1106       3  0.907692        yarn\n",
       "1106       6  0.014640        yarn\n",
       "14167      7  0.459264        yii2\n",
       "4025       8  0.622648          z.\n",
       "4025       9  0.155662          z.\n",
       "9780      12  0.484640  zohooffice\n",
       "1897       3  0.921480   zookeeper\n",
       "1897       5  0.069986   zookeeper\n",
       "2828       2  0.258160           ◆\n",
       "2828       3  0.129080           ◆\n",
       "2828       5  0.129080           ◆\n",
       "2828      10  0.387240           ◆\n",
       "1332       6  0.687917           ♣\n",
       "\n",
       "[2782 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[12, 7, 9, 10, 1, 2, 5, 8, 4, 3, 6, 11])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis = pyLDAvis.gensim.prepare(lda_final, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2topic =lda_final.get_document_topics(doc_term_matrix,minimum_probability=0)\n",
    "doc2topic = pd.DataFrame(list(doc2topic))\n",
    "for i in doc2topic.columns:\n",
    "    doc2topic.iloc[:,i]=doc2topic.iloc[:,i].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.736292</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.199605</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.956348</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.942707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.200868</td>\n",
       "      <td>0.245110</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.491081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.412771</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.205120</td>\n",
       "      <td>0.337991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.006410  0.006410  0.006410  0.006410  0.006410  0.006410  0.736292   \n",
       "1  0.003968  0.003968  0.003968  0.003968  0.003968  0.003968  0.003968   \n",
       "2  0.005208  0.005208  0.005208  0.005208  0.005208  0.005208  0.005209   \n",
       "3  0.002604  0.042107  0.002604  0.002604  0.002604  0.002604  0.002604   \n",
       "4  0.004902  0.412771  0.004902  0.004902  0.004902  0.004902  0.004902   \n",
       "\n",
       "         7         8         9         10        11  \n",
       "0  0.006410  0.006410  0.199605  0.006410  0.006411  \n",
       "1  0.003968  0.003968  0.956348  0.003968  0.003968  \n",
       "2  0.005208  0.005208  0.005209  0.005208  0.942707  \n",
       "3  0.002604  0.200868  0.245110  0.002604  0.491081  \n",
       "4  0.004902  0.004902  0.004902  0.205120  0.337991  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_info</th>\n",
       "      <th>rb</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>summary_title</th>\n",
       "      <th>location</th>\n",
       "      <th>current_job_company</th>\n",
       "      <th>current_job_title</th>\n",
       "      <th>current_job_desc</th>\n",
       "      <th>current_job_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['TECHNICAL SKILLS\\xa0', &lt;br/&gt;, '\\xa0', &lt;br/&gt;,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tracy-Ruan</td>\n",
       "      <td>c47f7ac095973653?sp=0</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>['• Prepared customer behavior datasets for cl...</td>\n",
       "      <td>August 2017 to November 2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.736292</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.199605</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.006411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['TECHNICAL SKILLS:\\xa0', &lt;br/&gt;, 'Languages   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sai-Nadimpalli</td>\n",
       "      <td>19e0d35744cc56a6?sp=0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>['Sprint Corporation']</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>['• Developed a Hybrid Recommendation System f...</td>\n",
       "      <td>May 2017 to August 2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.956348</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['TECHNICAL SKILLS\\xa0', &lt;br/&gt;, '•   Proficien...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nick-Shi</td>\n",
       "      <td>accfd33784428f69?sp=0</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Malibu, CA</td>\n",
       "      <td>['MarketPsych Data']</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>['•   Manipulated and interpreted insights fro...</td>\n",
       "      <td>February 2018 to Present</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.942707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['TECHNICAL SKILLS\\xa0', &lt;br/&gt;, 'Relevant Cour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harsh-Mehta</td>\n",
       "      <td>2a4af24d87cca9cd?sp=0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bloomington, IN</td>\n",
       "      <td>['Indiana University']</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>['• Implemented probabilistic character recogn...</td>\n",
       "      <td>November 2017 to November 2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.200868</td>\n",
       "      <td>0.245110</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.491081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['SKILLS\\xa0', &lt;br/&gt;, '\\xa0', &lt;br/&gt;, 'SOFTWARE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Daniel-Wu</td>\n",
       "      <td>246fa163d0b35d5b?sp=0</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>['MAPSCorps']</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>['Acted as a Chinese translator when collectin...</td>\n",
       "      <td>July 2016 to August 2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.205120</td>\n",
       "      <td>0.337991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     additional_info  rb            name  \\\n",
       "0  ['TECHNICAL SKILLS\\xa0', <br/>, '\\xa0', <br/>,... NaN      Tracy-Ruan   \n",
       "1  ['TECHNICAL SKILLS:\\xa0', <br/>, 'Languages   ... NaN  Sai-Nadimpalli   \n",
       "2  ['TECHNICAL SKILLS\\xa0', <br/>, '•   Proficien... NaN        Nick-Shi   \n",
       "3  ['TECHNICAL SKILLS\\xa0', <br/>, 'Relevant Cour... NaN     Harsh-Mehta   \n",
       "4  ['SKILLS\\xa0', <br/>, '\\xa0', <br/>, 'SOFTWARE... NaN       Daniel-Wu   \n",
       "\n",
       "                      id          summary_title           location  \\\n",
       "0  c47f7ac095973653?sp=0  Data Scientist Intern  San Francisco, CA   \n",
       "1  19e0d35744cc56a6?sp=0  Junior Data Scientist    Kansas City, MO   \n",
       "2  accfd33784428f69?sp=0  Data Scientist Intern         Malibu, CA   \n",
       "3  2a4af24d87cca9cd?sp=0         Data Scientist    Bloomington, IN   \n",
       "4  246fa163d0b35d5b?sp=0         DATA SCIENTIST       Brooklyn, NY   \n",
       "\n",
       "      current_job_company      current_job_title  \\\n",
       "0                     NaN  Data Scientist Intern   \n",
       "1  ['Sprint Corporation']  Junior Data Scientist   \n",
       "2    ['MarketPsych Data']  Data Scientist Intern   \n",
       "3  ['Indiana University']         Data Scientist   \n",
       "4           ['MAPSCorps']         DATA SCIENTIST   \n",
       "\n",
       "                                    current_job_desc  \\\n",
       "0  ['• Prepared customer behavior datasets for cl...   \n",
       "1  ['• Developed a Hybrid Recommendation System f...   \n",
       "2  ['•   Manipulated and interpreted insights fro...   \n",
       "3  ['• Implemented probabilistic character recogn...   \n",
       "4  ['Acted as a Chinese translator when collectin...   \n",
       "\n",
       "             current_job_duration    ...            2         3         4  \\\n",
       "0    August 2017 to November 2017    ...     0.006410  0.006410  0.006410   \n",
       "1         May 2017 to August 2017    ...     0.003968  0.003968  0.003968   \n",
       "2        February 2018 to Present    ...     0.005208  0.005208  0.005208   \n",
       "3  November 2017 to November 2017    ...     0.002604  0.002604  0.002604   \n",
       "4        July 2016 to August 2016    ...     0.004902  0.004902  0.004902   \n",
       "\n",
       "          5         6         7         8         9        10        11  \n",
       "0  0.006410  0.736292  0.006410  0.006410  0.199605  0.006410  0.006411  \n",
       "1  0.003968  0.003968  0.003968  0.003968  0.956348  0.003968  0.003968  \n",
       "2  0.005208  0.005209  0.005208  0.005208  0.005209  0.005208  0.942707  \n",
       "3  0.002604  0.002604  0.002604  0.200868  0.245110  0.002604  0.491081  \n",
       "4  0.004902  0.004902  0.004902  0.004902  0.004902  0.205120  0.337991  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data_clean_1.csv')\n",
    "data_final =pd.concat([data,doc2topic],axis=1)\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_job_duration_months</th>\n",
       "      <th>total_exp_durations_months</th>\n",
       "      <th>work_authp</th>\n",
       "      <th>prev_job_desc_clean</th>\n",
       "      <th>prev_job_title_cats</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['performed', 'analysis', 'supermarket', 'data...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.200868</td>\n",
       "      <td>0.245110</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.491081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.483999</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.349333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['wrote', 'sql', 'query', 'get', 'age', 'inves...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['wrote', 'sql', 'query', 'get', 'age', 'inves...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.960144</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['bring', 'stream', 'social', 'medium', 'data'...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.066436</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.893881</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['may', '2018xa0', 'br', 'performed', 'data', ...</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.134579</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.501491</td>\n",
       "      <td>0.324456</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.785260</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.162656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['built', 'simple', 'classifier', 'classified'...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.916665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['built', 'cleaned', 'managed', 'database', 'c...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.154745</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.270563</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.533025</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013890</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.847220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['troubleshooting', 'complex', 'matlab', 'code...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.270531</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.683172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.614561</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.292845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['identified', 'group', '63000', 'customer', '...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.541888</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.388664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.968390</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['provided', 'solution', 'research', 'method',...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['studied', 'applied', 'adaptive', 'model', 'n...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['prepared', 'data', 'senior', 'data', 'scient...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.794972</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.165345</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['managed', 'setup', 'teardown', 'networking',...</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.638871</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.330265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['performed', 'meta', 'analysis', 'large', 'sc...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.270813</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.610138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.590856</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.372912</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['ulsan', 'koreaxa0', 'br', 'international', '...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['researched', 'compiled', 'report', 'metastat...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.726912</td>\n",
       "      <td>0.154039</td>\n",
       "      <td>0.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>82</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.154797</td>\n",
       "      <td>0.268572</td>\n",
       "      <td>0.351795</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.210946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>62</td>\n",
       "      <td>291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['key', 'responsibility', 'includedxa0', 'br',...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.097513</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.434617</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.442869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10098</th>\n",
       "      <td>9</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['project', 'work', 'big', 'data', 'apache', '...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.898145</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10099</th>\n",
       "      <td>28</td>\n",
       "      <td>142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.356916</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.605204</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10100</th>\n",
       "      <td>66</td>\n",
       "      <td>172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1', 'led', 'cost', 'improvement', 'initiave'...</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.748176</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.215591</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.003623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['neural', 'networksxa0', 'br', 'xa0', 'br', '...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.541666</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>7</td>\n",
       "      <td>191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['executed', 'development', 'support', 'global...</td>\n",
       "      <td>Software Engg</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10103</th>\n",
       "      <td>63</td>\n",
       "      <td>165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['rice', 'university', 'houston', 'txxa0', 'br...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>13</td>\n",
       "      <td>135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['responsible', 'leveraging', 'analytics', 'de...</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.077794</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.385111</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.487094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>36</td>\n",
       "      <td>152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['simulated', 'team', 'moving', 'environment',...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.027779</td>\n",
       "      <td>0.694437</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027779</td>\n",
       "      <td>0.027780</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10106</th>\n",
       "      <td>12</td>\n",
       "      <td>204</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['edited', 'marketing', 'publicity', 'film', '...</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>9</td>\n",
       "      <td>161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['led', 'development', 'new', 'webbased', 'con...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.672133</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.235272</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.009260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10108</th>\n",
       "      <td>11</td>\n",
       "      <td>146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['rulebased', 'modeling', 'biological', 'pathw...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10110</th>\n",
       "      <td>49</td>\n",
       "      <td>265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['supported', 'new', 'product', 'development',...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10111</th>\n",
       "      <td>64</td>\n",
       "      <td>169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['formulation', 'stochastic', 'process', 'diff...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.462064</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.500056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10112</th>\n",
       "      <td>63</td>\n",
       "      <td>252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['provided', 'advanced', 'business', 'intellig...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10113</th>\n",
       "      <td>105</td>\n",
       "      <td>313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['duty', 'developing', 'software', 'optimizati...</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10114</th>\n",
       "      <td>4</td>\n",
       "      <td>143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['work', 'hire', 'agreement', 'untangling', 'd...</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.708482</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.260653</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10115</th>\n",
       "      <td>232</td>\n",
       "      <td>414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['support', 'sony', 'gsirt', 'security', 'oper...</td>\n",
       "      <td>Software Engg</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.075157</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.869287</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10116</th>\n",
       "      <td>10</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['worked', 'zonar', 'gtr', 'project', 'duty', ...</td>\n",
       "      <td>Software Engg</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10117</th>\n",
       "      <td>276</td>\n",
       "      <td>332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['key', 'member', 'technical', 'staff', 'devel...</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.971353</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.002604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>6</td>\n",
       "      <td>245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['worked', 'scientific', 'application', 'stand...</td>\n",
       "      <td>Software Engg</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>26</td>\n",
       "      <td>468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['httpswwwlinkedincominbillmeadexa0', 'br', 'w...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.516022</td>\n",
       "      <td>0.428421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10413</th>\n",
       "      <td>12</td>\n",
       "      <td>183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['insight', 'consulting', 'senior', 'analyst',...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.506774</td>\n",
       "      <td>0.423780</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.006945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10414</th>\n",
       "      <td>11</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['analysis', 'ecommerce', 'web', 'site', 'metr...</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.327506</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.589159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10415</th>\n",
       "      <td>16</td>\n",
       "      <td>275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['developed', 'consistent', 'vocabulary', 'cur...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10416</th>\n",
       "      <td>42</td>\n",
       "      <td>218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['responsibilitiesxa0', 'br', 'provided', 'sta...</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.770829</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020835</td>\n",
       "      <td>0.020834</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020834</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020834</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10418</th>\n",
       "      <td>14</td>\n",
       "      <td>242</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['algorithm', 'design', 'software', 'architect...</td>\n",
       "      <td>Software Engg</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10451</th>\n",
       "      <td>127</td>\n",
       "      <td>144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['battle', 'tested', 'countless', 'public', 'h...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10453</th>\n",
       "      <td>16</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['responsible', 'working', 'inhouse', 'externa...</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.942707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1966 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prev_job_duration_months  total_exp_durations_months  work_authp  \\\n",
       "3                             0                           1         1.0   \n",
       "5                             0                           2         1.0   \n",
       "6                             1                           8         1.0   \n",
       "7                             1                           8         1.0   \n",
       "8                             0                           8         1.0   \n",
       "9                             2                           7         0.0   \n",
       "11                            0                          -6         NaN   \n",
       "12                            0                           7         NaN   \n",
       "19                           -4                           6         NaN   \n",
       "35                            3                          10         1.0   \n",
       "37                            0                           1         1.0   \n",
       "42                            3                           6         1.0   \n",
       "44                            0                           3         NaN   \n",
       "50                            0                          27         1.0   \n",
       "56                            9                          18         1.0   \n",
       "60                            0                          10         NaN   \n",
       "128                           2                           5         0.0   \n",
       "131                           0                          22         0.0   \n",
       "133                           0                          13         NaN   \n",
       "134                           0                          20         1.0   \n",
       "142                           2                          10         0.0   \n",
       "150                           0                          14         1.0   \n",
       "151                           4                          37         1.0   \n",
       "152                           2                           6         1.0   \n",
       "153                           1                           5         1.0   \n",
       "155                           0                          18         NaN   \n",
       "156                          13                          24         NaN   \n",
       "157                           0                          21         1.0   \n",
       "158                           1                          13         0.0   \n",
       "159                           0                           5         1.0   \n",
       "...                         ...                         ...         ...   \n",
       "10096                        82                         241         NaN   \n",
       "10097                        62                         291         NaN   \n",
       "10098                         9                         138         NaN   \n",
       "10099                        28                         142         1.0   \n",
       "10100                        66                         172         1.0   \n",
       "10101                         5                         193         1.0   \n",
       "10102                         7                         191         NaN   \n",
       "10103                        63                         165         1.0   \n",
       "10104                        13                         135         1.0   \n",
       "10105                        36                         152         1.0   \n",
       "10106                        12                         204         1.0   \n",
       "10107                         9                         161         1.0   \n",
       "10108                        11                         146         1.0   \n",
       "10110                        49                         265         1.0   \n",
       "10111                        64                         169         1.0   \n",
       "10112                        63                         252         NaN   \n",
       "10113                       105                         313         NaN   \n",
       "10114                         4                         143         NaN   \n",
       "10115                       232                         414         NaN   \n",
       "10116                        10                         149         NaN   \n",
       "10117                       276                         332         NaN   \n",
       "10120                         6                         245         1.0   \n",
       "10405                        26                         468         1.0   \n",
       "10413                        12                         183         1.0   \n",
       "10414                        11                         132         NaN   \n",
       "10415                        16                         275         NaN   \n",
       "10416                        42                         218         1.0   \n",
       "10418                        14                         242         1.0   \n",
       "10451                       127                         144         1.0   \n",
       "10453                        16                         241         NaN   \n",
       "\n",
       "                                     prev_job_desc_clean prev_job_title_cats  \\\n",
       "3      ['performed', 'analysis', 'supermarket', 'data...        Data Analyst   \n",
       "5                                                ['nan']              Others   \n",
       "6      ['wrote', 'sql', 'query', 'get', 'age', 'inves...        Data Analyst   \n",
       "7      ['wrote', 'sql', 'query', 'get', 'age', 'inves...        Data Analyst   \n",
       "8                                                ['nan']              Others   \n",
       "9      ['bring', 'stream', 'social', 'medium', 'data'...             Student   \n",
       "11     ['may', '2018xa0', 'br', 'performed', 'data', ...              Others   \n",
       "12                                               ['nan']              Others   \n",
       "19     ['built', 'simple', 'classifier', 'classified'...     Project Manager   \n",
       "35     ['built', 'cleaned', 'managed', 'database', 'c...             Student   \n",
       "37                                               ['nan']              Others   \n",
       "42                                               ['nan']             Student   \n",
       "44                                               ['nan']              Others   \n",
       "50                                               ['nan']              Others   \n",
       "56     ['troubleshooting', 'complex', 'matlab', 'code...             Student   \n",
       "60                                               ['nan']              Others   \n",
       "128    ['identified', 'group', '63000', 'customer', '...             Student   \n",
       "131                                              ['nan']              Others   \n",
       "133                                              ['nan']              Others   \n",
       "134                                              ['nan']              Others   \n",
       "142    ['provided', 'solution', 'research', 'method',...             Student   \n",
       "150                                              ['nan']              Others   \n",
       "151    ['studied', 'applied', 'adaptive', 'model', 'n...             Student   \n",
       "152    ['prepared', 'data', 'senior', 'data', 'scient...             Student   \n",
       "153    ['managed', 'setup', 'teardown', 'networking',...              Others   \n",
       "155                                              ['nan']              Others   \n",
       "156    ['performed', 'meta', 'analysis', 'large', 'sc...      Data Scientist   \n",
       "157                                              ['nan']              Others   \n",
       "158    ['ulsan', 'koreaxa0', 'br', 'international', '...             Student   \n",
       "159    ['researched', 'compiled', 'report', 'metastat...     Project Manager   \n",
       "...                                                  ...                 ...   \n",
       "10096                                            ['nan']              Others   \n",
       "10097  ['key', 'responsibility', 'includedxa0', 'br',...      Data Scientist   \n",
       "10098  ['project', 'work', 'big', 'data', 'apache', '...     Project Manager   \n",
       "10099                                            ['nan']              Others   \n",
       "10100  ['1', 'led', 'cost', 'improvement', 'initiave'...              Others   \n",
       "10101  ['neural', 'networksxa0', 'br', 'xa0', 'br', '...      Data Scientist   \n",
       "10102  ['executed', 'development', 'support', 'global...       Software Engg   \n",
       "10103  ['rice', 'university', 'houston', 'txxa0', 'br...             Student   \n",
       "10104  ['responsible', 'leveraging', 'analytics', 'de...    Business Analyst   \n",
       "10105  ['simulated', 'team', 'moving', 'environment',...             Student   \n",
       "10106  ['edited', 'marketing', 'publicity', 'film', '...              Others   \n",
       "10107  ['led', 'development', 'new', 'webbased', 'con...     Project Manager   \n",
       "10108  ['rulebased', 'modeling', 'biological', 'pathw...      Data Scientist   \n",
       "10110  ['supported', 'new', 'product', 'development',...     Project Manager   \n",
       "10111  ['formulation', 'stochastic', 'process', 'diff...      Data Scientist   \n",
       "10112  ['provided', 'advanced', 'business', 'intellig...        Data Analyst   \n",
       "10113  ['duty', 'developing', 'software', 'optimizati...    Business Analyst   \n",
       "10114  ['work', 'hire', 'agreement', 'untangling', 'd...              Others   \n",
       "10115  ['support', 'sony', 'gsirt', 'security', 'oper...       Software Engg   \n",
       "10116  ['worked', 'zonar', 'gtr', 'project', 'duty', ...       Software Engg   \n",
       "10117  ['key', 'member', 'technical', 'staff', 'devel...              Others   \n",
       "10120  ['worked', 'scientific', 'application', 'stand...       Software Engg   \n",
       "10405  ['httpswwwlinkedincominbillmeadexa0', 'br', 'w...     Project Manager   \n",
       "10413  ['insight', 'consulting', 'senior', 'analyst',...     Project Manager   \n",
       "10414  ['analysis', 'ecommerce', 'web', 'site', 'metr...              Others   \n",
       "10415  ['developed', 'consistent', 'vocabulary', 'cur...     Project Manager   \n",
       "10416  ['responsibilitiesxa0', 'br', 'provided', 'sta...             Student   \n",
       "10418  ['algorithm', 'design', 'software', 'architect...       Software Engg   \n",
       "10451  ['battle', 'tested', 'countless', 'public', 'h...     Project Manager   \n",
       "10453  ['responsible', 'working', 'inhouse', 'externa...    Business Analyst   \n",
       "\n",
       "              0         1         2         3         4         5         6  \\\n",
       "3      0.002604  0.042107  0.002604  0.002604  0.002604  0.002604  0.002604   \n",
       "5      0.016667  0.483999  0.016667  0.349333  0.016667  0.016667  0.016667   \n",
       "6      0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "7      0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "8      0.003623  0.003623  0.003623  0.003623  0.003623  0.003623  0.960144   \n",
       "9      0.003968  0.003968  0.003968  0.003968  0.066436  0.003968  0.893881   \n",
       "11     0.004386  0.134579  0.004386  0.004386  0.004386  0.004386  0.004386   \n",
       "12     0.005208  0.005208  0.005208  0.005208  0.005208  0.005208  0.785260   \n",
       "19     0.007576  0.007576  0.007576  0.007576  0.007576  0.007576  0.007576   \n",
       "35     0.041667  0.541667  0.041667  0.041667  0.041667  0.041667  0.041667   \n",
       "37     0.154745  0.004630  0.004630  0.004630  0.004630  0.004630  0.270563   \n",
       "42     0.013889  0.013889  0.013889  0.013889  0.013889  0.013889  0.013889   \n",
       "44     0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "50     0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "56     0.004630  0.270531  0.004630  0.004630  0.004630  0.004630  0.004630   \n",
       "60     0.009259  0.009259  0.009259  0.009259  0.009259  0.009259  0.009260   \n",
       "128    0.006945  0.006945  0.006944  0.006945  0.006945  0.006945  0.006945   \n",
       "131    0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "133    0.002874  0.002874  0.002874  0.002874  0.002874  0.002874  0.968390   \n",
       "134    0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "142    0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "150    0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "151    0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "152    0.003968  0.003968  0.003968  0.003968  0.003968  0.003968  0.794972   \n",
       "153    0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "155    0.003087  0.003086  0.003087  0.003086  0.003086  0.003086  0.638871   \n",
       "156    0.011905  0.011905  0.011905  0.011905  0.011905  0.011905  0.011905   \n",
       "157    0.003623  0.003623  0.003623  0.590856  0.003623  0.003623  0.372912   \n",
       "158    0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "159    0.011905  0.011905  0.011905  0.011905  0.011905  0.011905  0.011905   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10096  0.001736  0.001736  0.001736  0.001736  0.001736  0.001736  0.154797   \n",
       "10097  0.002778  0.002778  0.002778  0.002778  0.002778  0.002778  0.097513   \n",
       "10098  0.898145  0.009260  0.009259  0.009260  0.009259  0.009259  0.009260   \n",
       "10099  0.003788  0.003788  0.003788  0.003788  0.003788  0.003788  0.356916   \n",
       "10100  0.003623  0.003623  0.748176  0.003623  0.003623  0.003623  0.215591   \n",
       "10101  0.041667  0.041667  0.041667  0.041667  0.541666  0.041667  0.041667   \n",
       "10102  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10103  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10104  0.005556  0.005556  0.005556  0.005556  0.005556  0.005556  0.005556   \n",
       "10105  0.027779  0.694437  0.027778  0.027778  0.027778  0.027778  0.027778   \n",
       "10106  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10107  0.009259  0.009259  0.009259  0.672133  0.009259  0.009259  0.009260   \n",
       "10108  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10110  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10111  0.003788  0.003788  0.003788  0.003788  0.003788  0.003788  0.003788   \n",
       "10112  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10113  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10114  0.708482  0.003086  0.003086  0.003086  0.003086  0.003086  0.260653   \n",
       "10115  0.005556  0.005556  0.075157  0.005556  0.005556  0.005556  0.005556   \n",
       "10116  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10117  0.002604  0.002604  0.002604  0.002604  0.002604  0.002604  0.002604   \n",
       "10120  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10405  0.005556  0.005556  0.005556  0.005556  0.005556  0.005556  0.005556   \n",
       "10413  0.006945  0.006945  0.006945  0.006945  0.006945  0.006944  0.006945   \n",
       "10414  0.008334  0.008333  0.008334  0.008333  0.008333  0.008333  0.008334   \n",
       "10415  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10416  0.770829  0.020833  0.020833  0.020835  0.020834  0.020833  0.020834   \n",
       "10418  0.003333  0.003333  0.003333  0.003333  0.003333  0.003333  0.003334   \n",
       "10451  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "10453  0.005208  0.005208  0.005208  0.005208  0.005208  0.005208  0.005208   \n",
       "\n",
       "              7         8         9        10        11  \n",
       "3      0.002604  0.200868  0.245110  0.002604  0.491081  \n",
       "5      0.016667  0.016667  0.016667  0.016667  0.016667  \n",
       "6      0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "7      0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "8      0.003623  0.003623  0.003623  0.003623  0.003623  \n",
       "9      0.003968  0.003968  0.003968  0.003968  0.003968  \n",
       "11     0.004386  0.501491  0.324456  0.004386  0.004386  \n",
       "12     0.005208  0.005208  0.005208  0.005208  0.162656  \n",
       "19     0.007576  0.007576  0.007576  0.007576  0.916665  \n",
       "35     0.041667  0.041667  0.041667  0.041667  0.041667  \n",
       "37     0.004630  0.533025  0.004630  0.004630  0.004630  \n",
       "42     0.013889  0.013890  0.013889  0.013889  0.847220  \n",
       "44     0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "50     0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "56     0.004630  0.004630  0.004630  0.004630  0.683172  \n",
       "60     0.009259  0.009260  0.614561  0.009259  0.292845  \n",
       "128    0.006945  0.541888  0.006945  0.006945  0.388664  \n",
       "131    0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "133    0.002874  0.002874  0.002874  0.002874  0.002874  \n",
       "134    0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "142    0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "150    0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "151    0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "152    0.003968  0.165345  0.003968  0.003968  0.003968  \n",
       "153    0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "155    0.003086  0.003086  0.003086  0.003086  0.330265  \n",
       "156    0.011905  0.270813  0.011905  0.011905  0.610138  \n",
       "157    0.003623  0.003623  0.003623  0.003623  0.003623  \n",
       "158    0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "159    0.011905  0.011905  0.726912  0.154039  0.011905  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "10096  0.268572  0.351795  0.001736  0.001736  0.210946  \n",
       "10097  0.002778  0.434617  0.002778  0.002778  0.442869  \n",
       "10098  0.009259  0.009260  0.009259  0.009259  0.009260  \n",
       "10099  0.003788  0.003788  0.605204  0.003788  0.003788  \n",
       "10100  0.003623  0.003623  0.003623  0.003624  0.003623  \n",
       "10101  0.041667  0.041667  0.041667  0.041667  0.041667  \n",
       "10102  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10103  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10104  0.077794  0.005556  0.385111  0.005556  0.487094  \n",
       "10105  0.027778  0.027779  0.027780  0.027778  0.027779  \n",
       "10106  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10107  0.009259  0.009260  0.235272  0.009260  0.009260  \n",
       "10108  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10110  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10111  0.003788  0.003788  0.462064  0.003788  0.500056  \n",
       "10112  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10113  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10114  0.003086  0.003087  0.003087  0.003086  0.003087  \n",
       "10115  0.005556  0.005556  0.869287  0.005556  0.005556  \n",
       "10116  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10117  0.002604  0.002604  0.971353  0.002604  0.002604  \n",
       "10120  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10405  0.005556  0.005556  0.005556  0.516022  0.428421  \n",
       "10413  0.506774  0.423780  0.006944  0.006944  0.006945  \n",
       "10414  0.008333  0.327506  0.008334  0.008333  0.589159  \n",
       "10415  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10416  0.020833  0.020833  0.020834  0.020833  0.020835  \n",
       "10418  0.003333  0.003333  0.963333  0.003333  0.003333  \n",
       "10451  0.083333  0.083333  0.083333  0.083333  0.083333  \n",
       "10453  0.005208  0.005208  0.005209  0.005208  0.942707  \n",
       "\n",
       "[1966 rows x 17 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final[data_final['current_job_title']=='Data Scientist'].iloc[:,30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.topic_info.to_csv('12topic_wordDist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv('data_post_LDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis,f'pyLDAvis_{num_topics}.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
